<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
<channel>
<title>AI Papers - 2026-02-13</title>
<link>https://arxiv.org</link>
<description>AI papers as of 2026-02-13 - 244 papers</description>
<lastBuildDate>Fri, 13 Feb 2026 04:02:02 +0000</lastBuildDate>
<item>
<title><![CDATA[Voxtral Realtime]]></title>
<link>https://huggingface.co/papers/2602.11298</link>
<guid>2602.11298</guid>
<description><![CDATA[Source: HuggingFace
Tags: 
Authors: Alexander H. Liu, Andy Ehrenberg, Andy Lo, Chen-Yo Sun, Guillaume Lample
Institution: 
Published: 2026-02-11
Score: 9/10
Citations: 0
Upvotes: 2
GitHub: 
Stars: 0

We introduce Voxtral Realtime, a natively streaming automatic speech recognition model that matches offline transcription quality at sub-second latency. Unlike approaches that adapt offline models through chunking or sliding windows, Voxtral Realtime is trained end-to-end for streaming, with explicit alignment between audio and text streams. Our architecture builds on the Delayed Streams Modeling framework, introducing a new causal audio encoder and Ada RMS-Norm for improved delay conditioning. We scale pretraining to a large-scale dataset spanning 13 languages. At a delay of 480ms, Voxtral Realtime achieves performance on par with Whisper, the most widely deployed offline transcription system. We release the model weights under the Apache 2.0 license.]]></description>
<pubDate>Wed, 11 Feb 2026 19:17:10 +0000</pubDate>
</item>
<item>
<title><![CDATA[ROCKET: Rapid Optimization via Calibration-guided Knapsack Enhanced Truncation for Efficient Model Compression]]></title>
<link>https://huggingface.co/papers/2602.11008</link>
<guid>2602.11008</guid>
<description><![CDATA[Source: HuggingFace
Tags: 
Authors: Ammar Ali, Baher Mohammad, Denis Makhov, Dmitriy Shopkhoev, Magauiya Zhussip
Institution: MIT
Published: 2026-02-11
Score: 8/10
Citations: 0
Upvotes: 15
GitHub: 
Stars: 0

We present ROCKET, a training-free model compression method that achieves state-of-the-art performance in comparison with factorization, structured-sparsification and dynamic compression baselines. Operating under a global compression budget, ROCKET comprises two key innovations: First, it formulates layer-wise compression allocation as a multi-choice knapsack problem, selecting the optimal compression level for each layer to minimize total reconstruction error while adhering to a target model size. Second, it introduces a single-step sparse matrix factorization inspired by dictionary learning: using only a small calibration set, it sparsifies weight coefficients based on activation-weights sensitivity and then updates the dictionary in closed form via least squares bypassing iterative optimization, sparse coding, or backpropagation entirely. ROCKET consistently outperforms existing compression approaches across different model architectures at 20-50\% compression rates. Notably, it retains over 90\% of the original model's performance at 30\% compression without any fine-tuning. Moreover, when applying a light fine-tuning phase, recovery is substantially enhanced: for instance, compressing Qwen3-14B to an 8B-parameter model and healing it with just 30 million tokens yields performance nearly on par with the original Qwen3-8B. The code for ROCKET is at github.com/mts-ai/ROCKET/tree/main.]]></description>
<pubDate>Wed, 11 Feb 2026 16:34:52 +0000</pubDate>
</item>
<item>
<title><![CDATA[DataChef: Cooking Up Optimal Data Recipes for LLM Adaptation via Reinforcement Learning]]></title>
<link>https://huggingface.co/papers/2602.11089</link>
<guid>2602.11089</guid>
<description><![CDATA[Source: HuggingFace
Tags: 
Authors: Yicheng Chen, Zerun Ma, Xinchen Xie, Yining Li, Kai Chen
Institution: 
Published: 2026-02-11
Score: 8/10
Citations: 0
Upvotes: 14
GitHub: 
Stars: 0

In the current landscape of Large Language Models (LLMs), the curation of large-scale, high-quality training data is a primary driver of model performance. A key lever is the data recipe, which comprises a data processing pipeline to transform raw sources into training corpora. Despite the growing use of LLMs to automate individual data processing steps, such as data synthesis and filtering, the overall design of data recipes remains largely manual and labor-intensive, requiring substantial human expertise and iteration. To bridge this gap, we formulate end-to-end data recipe generation for LLM adaptation. Given a target benchmark and a pool of available data sources, a model is required to output a complete data recipe that adapts a base LLM to the target task. We present DataChef-32B, which performs online reinforcement learning using a proxy reward that predicts downstream performance for candidate recipes. Across six held-out tasks, DataChef-32B produces practical recipes that reach comparable downstream performance to those curated by human experts. Notably, the recipe from DataChef-32B adapts Qwen3-1.7B-Base to the math domain, achieving 66.7 on AIME'25 and surpassing Qwen3-1.7B. This work sheds new light on automating LLM training and developing self-evolving AI systems.]]></description>
<pubDate>Wed, 11 Feb 2026 17:56:15 +0000</pubDate>
</item>
<item>
<title><![CDATA[LiveMedBench: A Contamination-Free Medical Benchmark for LLMs with Automated Rubric Evaluation]]></title>
<link>https://huggingface.co/papers/2602.10367</link>
<guid>2602.10367</guid>
<description><![CDATA[Source: HuggingFace
Tags: 
Authors: Zhiling Yan, Dingjie Song, Zhe Fang, Yisheng Ji, Xiang Li
Institution: 
Published: 2026-02-10
Score: 8/10
Citations: 0
Upvotes: 11
GitHub: 
Stars: 0

The deployment of Large Language Models (LLMs) in high-stakes clinical settings demands rigorous and reliable evaluation. However, existing medical benchmarks remain static, suffering from two critical limitations: (1) data contamination, where test sets inadvertently leak into training corpora, leading to inflated performance estimates; and (2) temporal misalignment, failing to capture the rapid evolution of medical knowledge. Furthermore, current evaluation metrics for open-ended clinical reasoning often rely on either shallow lexical overlap (e.g., ROUGE) or subjective LLM-as-a-Judge scoring, both inadequate for verifying clinical correctness. To bridge these gaps, we introduce LiveMedBench, a continuously updated, contamination-free, and rubric-based benchmark that weekly harvests real-world clinical cases from online medical communities, ensuring strict temporal separation from model training data. We propose a Multi-Agent Clinical Curation Framework that filters raw data noise and validates clinical integrity against evidence-based medical principles. For evaluation, we develop an Automated Rubric-based Evaluation Framework that decomposes physician responses into granular, case-specific criteria, achieving substantially stronger alignment with expert physicians than LLM-as-a-Judge. To date, LiveMedBench comprises 2,756 real-world cases spanning 38 medical specialties and multiple languages, paired with 16,702 unique evaluation criteria. Extensive evaluation of 38 LLMs reveals that even the best-performing model achieves only 39.2%, and 84% of models exhibit performance degradation on post-cutoff cases, confirming pervasive data contamination risks. Error analysis further identifies contextual application-not factual knowledge-as the dominant bottleneck, with 35-48% of failures stemming from the inability to tailor medical knowledge to patient-specific constraints.]]></description>
<pubDate>Tue, 10 Feb 2026 23:38:25 +0000</pubDate>
</item>
<item>
<title><![CDATA[Data Repetition Beats Data Scaling in Long-CoT Supervised Fine-Tuning]]></title>
<link>https://huggingface.co/papers/2602.11149</link>
<guid>2602.11149</guid>
<description><![CDATA[Source: HuggingFace
Tags: 
Authors: Dawid J. Kopiczko, Sagar Vaze, Tijmen Blankevoort, Yuki M. Asano
Institution: 
Published: 2026-02-11
Score: 8/10
Citations: 0
Upvotes: 11
GitHub: 
Stars: 0

Supervised fine-tuning (SFT) on chain-of-thought data is an essential post-training step for reasoning language models. Standard machine learning intuition suggests that training with more unique training samples yields better generalization. Counterintuitively, we show that SFT benefits from repetition: under a fixed update budget, training for more epochs on smaller datasets outperforms single-epoch training on larger datasets. On AIME'24/25 and GPQA benchmarks, Olmo3-7B trained for 128 epochs on 400 samples outperforms the equivalent 1 epoch on 51200 samples by 12-26 percentage points, with no additional catastrophic forgetting. We find that training token accuracy reliably signals when repetition has saturated; improvements from additional epochs plateau at full memorization, a pattern consistent across all settings. These findings provide a practical approach for reasoning SFT, where scaling epochs with token accuracy as a stopping criterion can replace expensive undirected data scaling. We pose the repetition advantage, where full memorization coincides with improved generalization, as a new open problem for the community in understanding the training dynamics of large language models.]]></description>
<pubDate>Wed, 11 Feb 2026 18:58:54 +0000</pubDate>
</item>
<item>
<title><![CDATA[The Pensieve Paradigm: Stateful Language Models Mastering Their Own Context]]></title>
<link>https://huggingface.co/papers/2602.12108</link>
<guid>2602.12108</guid>
<description><![CDATA[Source: HuggingFace
Tags: 
Authors: Xiaoyuan Liu, Tian Liang, Dongyang Ma, Deyu Zhou, Haitao Mi
Institution: 
Published: 2026-02-12
Score: 8/10
Citations: 0
Upvotes: 9
GitHub: 
Stars: 0

In the world of Harry Potter, when Dumbledore's mind is overburdened, he extracts memories into a Pensieve to be revisited later. In the world of AI, while we possess the Pensieve-mature databases and retrieval systems, our models inexplicably lack the "wand" to operate it. They remain like a Dumbledore without agency, passively accepting a manually engineered context as their entire memory. This work finally places the wand in the model's hand. We introduce StateLM, a new class of foundation models endowed with an internal reasoning loop to manage their own state. We equip our model with a suite of memory tools, such as context pruning, document indexing, and note-taking, and train it to actively manage these tools. By learning to dynamically engineering its own context, our model breaks free from the architectural prison of a fixed window. Experiments across various model sizes demonstrate StateLM's effectiveness across diverse scenarios. On long-document QA tasks, StateLMs consistently outperform standard LLMs across all model scales; on the chat memory task, they achieve absolute accuracy improvements of 10% to 20% over standard LLMs. On the deep research task BrowseComp-Plus, the performance gap becomes even more pronounced: StateLM achieves up to 52% accuracy, whereas standard LLM counterparts struggle around 5%. Ultimately, our approach shifts LLMs from passive predictors to state-aware agents where reasoning becomes a stateful and manageable process.]]></description>
<pubDate>Thu, 12 Feb 2026 16:00:01 +0000</pubDate>
</item>
<item>
<title><![CDATA[Beyond Correctness: Learning Robust Reasoning via Transfer]]></title>
<link>https://huggingface.co/papers/2602.08489</link>
<guid>2602.08489</guid>
<description><![CDATA[Source: HuggingFace
Tags: 
Authors: Hyunseok Lee, Soheil Abbasloo, Jihoon Tack, Jinwoo Shin
Institution: 
Published: 2026-02-09
Score: 8/10
Citations: 0
Upvotes: 5
GitHub: 
Stars: 0

Reinforcement Learning with Verifiable Rewards (RLVR) has recently strengthened LLM reasoning, but its focus on final answer correctness leaves a critical gap: it does not ensure the robustness of the reasoning process itself. We adopt a simple philosophical view, robust reasoning should remain useful beyond the mind that produced it, and treat reasoning as a form of meaning transfer that must survive truncation, reinterpretation, and continuation. Building on this principle, we introduce Reinforcement Learning with Transferable Reward (RLTR), which operationalizes robustness via transfer reward that tests whether a partial reasoning prefix from one model can guide a separate model to the correct answer. This encourages LLMs to produce reasoning that is stable, interpretable, and genuinely generalizable. Our approach improves sampling consistency while improving final answer accuracy, and it reaches comparable performance in substantially fewer training steps. For example, on MATH500, RLTR achieves a +3.6%p gain in Maj@64 compared to RLVR and matches RLVR's average accuracy with roughly 2.5x fewer training steps, providing both more reliable reasoning and significantly more sample efficient.]]></description>
<pubDate>Mon, 09 Feb 2026 10:41:44 +0000</pubDate>
</item>
<item>
<title><![CDATA[MolmoSpaces: A Large-Scale Open Ecosystem for Robot Navigation and Manipulation]]></title>
<link>https://huggingface.co/papers/2602.11337</link>
<guid>2602.11337</guid>
<description><![CDATA[Source: HuggingFace
Tags: 
Authors: Yejin Kim, Wilbert Pumacay, Omar Rayyan, Max Argus, Winson Han
Institution: 
Published: 2026-02-11
Score: 8/10
Citations: 0
Upvotes: 1
GitHub: 
Stars: 0

Deploying robots at scale demands robustness to the long tail of everyday situations. The countless variations in scene layout, object geometry, and task specifications that characterize real environments are vast and underrepresented in existing robot benchmarks. Measuring this level of generalization requires infrastructure at a scale and diversity that physical evaluation alone cannot provide. We introduce MolmoSpaces, a fully open ecosystem to support large-scale benchmarking of robot policies. MolmoSpaces consists of over 230k diverse indoor environments, ranging from handcrafted household scenes to procedurally generated multiroom houses, populated with 130k richly annotated object assets, including 48k manipulable objects with 42M stable grasps. Crucially, these environments are simulator-agnostic, supporting popular options such as MuJoCo, Isaac, and ManiSkill. The ecosystem supports the full spectrum of embodied tasks: static and mobile manipulation, navigation, and multiroom long-horizon tasks requiring coordinated perception, planning, and interaction across entire indoor environments. We also design MolmoSpaces-Bench, a benchmark suite of 8 tasks in which robots interact with our diverse scenes and richly annotated objects. Our experiments show MolmoSpaces-Bench exhibits strong sim-to-real correlation (R = 0.96, ho = 0.98), confirm newer and stronger zero-shot policies outperform earlier versions in our benchmarks, and identify key sensitivities to prompt phrasing, initial joint positions, and camera occlusion. Through MolmoSpaces and its open-source assets and tooling, we provide a foundation for scalable data generation, policy training, and benchmark creation for robot learning research.]]></description>
<pubDate>Wed, 11 Feb 2026 20:16:31 +0000</pubDate>
</item>
<item>
<title><![CDATA[Large Language Lobotomy: Jailbreaking Mixture-of-Experts via Expert Silencing]]></title>
<link>https://huggingface.co/papers/2602.08741</link>
<guid>2602.08741</guid>
<description><![CDATA[Source: HuggingFace
Tags: 
Authors: Jona te Lintelo, Lichao Wu, Stjepan Picek
Institution: 
Published: 2026-02-09
Score: 8/10
Citations: 0
Upvotes: 1
GitHub: 
Stars: 0

The rapid adoption of Mixture-of-Experts (MoE) architectures marks a major shift in the deployment of Large Language Models (LLMs). MoE LLMs improve scaling efficiency by activating only a small subset of parameters per token, but their routing structure introduces new safety attack surfaces. We find that safety-critical behaviors in MoE LLMs (e.g., refusal) are concentrated in a small set of experts rather than being uniformly distributed. Building on this, we propose Large Language Lobotomy (L^3), a training-free, architecture-agnostic attack that compromises safety alignment by exploiting expert routing dynamics. L^3 learns routing patterns that correlate with refusal, attributes safety behavior to specific experts, and adaptively silences the most safety-relevant experts until harmful outputs are produced. We evaluate L^3 on eight state-of-the-art open-source MoE LLMs and show that our adaptive expert silencing increases average attack success from 7.3% to 70.4%, reaching up to 86.3%, outperforming prior training-free MoE jailbreak methods. Moreover, bypassing guardrails typically requires silencing fewer than 20% of layer-wise experts while largely preserving general language utility. These results reveal a fundamental tension between efficiency-driven MoE design and robust safety alignment and motivate distributing safety mechanisms more robustly in future MoE LLMs with architecture- and routing-aware methods.]]></description>
<pubDate>Mon, 09 Feb 2026 14:42:11 +0000</pubDate>
</item>
<item>
<title><![CDATA[ABot-N0: Technical Report on the VLA Foundation Model for Versatile Embodied Navigation]]></title>
<link>https://huggingface.co/papers/2602.11598</link>
<guid>2602.11598</guid>
<description><![CDATA[Source: HuggingFace
Tags: 
Authors: Zedong Chu, Shichao Xie, Xiaolong Wu, Yanfen Shen, Minghua Luo
Institution: 
Published: 2026-02-12
Score: 8/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Embodied navigation has long been fragmented by task-specific architectures. We introduce ABot-N0, a unified Vision-Language-Action (VLA) foundation model that achieves a ``Grand Unification'' across 5 core tasks: Point-Goal, Object-Goal, Instruction-Following, POI-Goal, and Person-Following. ABot-N0 utilizes a hierarchical ``Brain-Action'' architecture, pairing an LLM-based Cognitive Brain for semantic reasoning with a Flow Matching-based Action Expert for precise, continuous trajectory generation.
  To support large-scale learning, we developed the ABot-N0 Data Engine, curating 16.9M expert trajectories and 5.0M reasoning samples across 7,802 high-fidelity 3D scenes (10.7 km^2). ABot-N0 achieves new SOTA performance across 7 benchmarks, significantly outperforming specialized models. Furthermore, our Agentic Navigation System integrates a planner with hierarchical topological memory, enabling robust, long-horizon missions in dynamic real-world environments.]]></description>
<pubDate>Thu, 12 Feb 2026 05:30:20 +0000</pubDate>
</item>
<item>
<title><![CDATA[Gaia2: Benchmarking LLM Agents on Dynamic and Asynchronous Environments]]></title>
<link>https://huggingface.co/papers/2602.11964</link>
<guid>2602.11964</guid>
<description><![CDATA[Source: HuggingFace
Tags: 
Authors: Romain Froger, Pierre Andrews, Matteo Bettini, Amar Budhiraja, Ricardo Silveira Cabral
Institution: 
Published: 2026-02-12
Score: 8/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

We introduce Gaia2, a benchmark for evaluating large language model agents in realistic, asynchronous environments. Unlike prior static or synchronous evaluations, Gaia2 introduces scenarios where environments evolve independently of agent actions, requiring agents to operate under temporal constraints, adapt to noisy and dynamic events, resolve ambiguity, and collaborate with other agents. Each scenario is paired with a write-action verifier, enabling fine-grained, action-level evaluation and making Gaia2 directly usable for reinforcement learning from verifiable rewards. Our evaluation of state-of-the-art proprietary and open-source models shows that no model dominates across capabilities: GPT-5 (high) reaches the strongest overall score of 42% pass@1 but fails on time-sensitive tasks, Claude-4 Sonnet trades accuracy and speed for cost, Kimi-K2 leads among open-source models with 21% pass@1. These results highlight fundamental trade-offs between reasoning, efficiency, robustness, and expose challenges in closing the "sim2real" gap. Gaia2 is built on a consumer environment with the open-source Agents Research Environments platform and designed to be easy to extend. By releasing Gaia2 alongside the foundational ARE framework, we aim to provide the community with a flexible infrastructure for developing, benchmarking, and training the next generation of practical agent systems.]]></description>
<pubDate>Thu, 12 Feb 2026 13:58:27 +0000</pubDate>
</item>
<item>
<title><![CDATA[StealthRL: Reinforcement Learning Paraphrase Attacks for Multi-Detector Evasion of AI-Text Detectors]]></title>
<link>https://huggingface.co/papers/2602.08934</link>
<guid>2602.08934</guid>
<description><![CDATA[Source: HuggingFace
Tags: 
Authors: Suraj Ranganath, Atharv Ramesh
Institution: 
Published: 2026-02-09
Score: 8/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

AI-text detectors face a critical robustness challenge: adversarial paraphrasing attacks that preserve semantics while evading detection. We introduce StealthRL, a reinforcement learning framework that stress-tests detector robustness under realistic adversarial conditions. StealthRL trains a paraphrase policy against a multi-detector ensemble using Group Relative Policy Optimization (GRPO) with LoRA adapters on Qwen3-4B, optimizing a composite reward that balances detector evasion with semantic preservation. We evaluate six attack settings (M0-M5) against three detector families (RoBERTa, FastDetectGPT, and Binoculars) at the security-relevant 1% false positive rate operating point. StealthRL achieves near-zero detection (0.001 mean TPR@1%FPR), reduces mean AUROC from 0.74 to 0.27, and attains a 99.9% attack success rate. Critically, attacks transfer to a held-out detector family not seen during training, revealing shared architectural vulnerabilities rather than detector-specific brittleness. We additionally conduct LLM-based quality evaluation via Likert scoring, analyze detector score distributions to explain why evasion succeeds, and provide per-detector AUROC with bootstrap confidence intervals. Our results expose significant robustness gaps in current AI-text detection and establish StealthRL as a principled adversarial evaluation protocol. Code and evaluation pipeline are publicly available at https://github.com/suraj-ranganath/StealthRL.]]></description>
<pubDate>Mon, 09 Feb 2026 17:33:46 +0000</pubDate>
</item>
<item>
<title><![CDATA[Learning beyond Teacher: Generalized On-Policy Distillation with Reward Extrapolation]]></title>
<link>https://huggingface.co/papers/2602.12125</link>
<guid>2602.12125</guid>
<description><![CDATA[Source: HuggingFace
Tags: 
Authors: Wenkai Yang, Weijie Liu, Ruobing Xie, Kai Yang, Saiyong Yang
Institution: 
Published: 2026-02-12
Score: 7/10
Citations: 0
Upvotes: 25
GitHub: 
Stars: 0

On-policy distillation (OPD), which aligns the student with the teacher's logit distribution on student-generated trajectories, has demonstrated strong empirical gains in improving student performance and often outperforms off-policy distillation and reinforcement learning (RL) paradigms. In this work, we first theoretically show that OPD is a special case of dense KL-constrained RL where the reward function and the KL regularization are always weighted equally and the reference model can by any model. Then, we propose the Generalized On-Policy Distillation (G-OPD) framework, which extends the standard OPD objective by introducing a flexible reference model and a reward scaling factor that controls the relative weight of the reward term against the KL regularization. Through comprehensive experiments on math reasoning and code generation tasks, we derive two novel insights: (1) Setting the reward scaling factor to be greater than 1 (i.e., reward extrapolation), which we term ExOPD, consistently improves over standard OPD across a range of teacher-student size pairings. In particular, in the setting where we merge the knowledge from different domain experts, obtained by applying domain-specific RL to the same student model, back into the original student, ExOPD enables the student to even surpass the teacher's performance boundary and outperform the domain teachers. (2) Building on ExOPD, we further find that in the strong-to-weak distillation setting (i.e., distilling a smaller student from a larger teacher), performing reward correction by choosing the reference model as the teacher's base model before RL yields a more accurate reward signal and further improves distillation performance. However, this choice assumes access to the teacher's pre-RL variant and incurs more computational overhead. We hope our work offers new insights for future research on OPD.]]></description>
<pubDate>Thu, 12 Feb 2026 16:14:29 +0000</pubDate>
</item>
<item>
<title><![CDATA[LawThinker: A Deep Research Legal Agent in Dynamic Environments]]></title>
<link>https://huggingface.co/papers/2602.12056</link>
<guid>2602.12056</guid>
<description><![CDATA[Source: HuggingFace
Tags: 
Authors: Xinyu Yang, Chenlong Deng, Tongyu Wen, Binyu Xie, Zhicheng Dou
Institution: 
Published: 2026-02-12
Score: 7/10
Citations: 0
Upvotes: 11
GitHub: 
Stars: 0

Legal reasoning requires not only correct outcomes but also procedurally compliant reasoning processes. However, existing methods lack mechanisms to verify intermediate reasoning steps, allowing errors such as inapplicable statute citations to propagate undetected through the reasoning chain. To address this, we propose LawThinker, an autonomous legal research agent that adopts an Explore-Verify-Memorize strategy for dynamic judicial environments. The core idea is to enforce verification as an atomic operation after every knowledge exploration step. A DeepVerifier module examines each retrieval result along three dimensions of knowledge accuracy, fact-law relevance, and procedural compliance, with a memory module for cross-round knowledge reuse in long-horizon tasks. Experiments on the dynamic benchmark J1-EVAL show that LawThinker achieves a 24% improvement over direct reasoning and an 11% gain over workflow-based methods, with particularly strong improvements on process-oriented metrics. Evaluations on three static benchmarks further confirm its generalization capability. The code is available at https://github.com/yxy-919/LawThinker-agent .]]></description>
<pubDate>Thu, 12 Feb 2026 15:19:11 +0000</pubDate>
</item>
<item>
<title><![CDATA[LoopFormer: Elastic-Depth Looped Transformers for Latent Reasoning via Shortcut Modulation]]></title>
<link>https://huggingface.co/papers/2602.11451</link>
<guid>2602.11451</guid>
<description><![CDATA[Source: HuggingFace
Tags: 
Authors: Ahmadreza Jeddi, Marco Ciccone, Babak Taati
Institution: 
Published: 2026-02-11
Score: 7/10
Citations: 0
Upvotes: 10
GitHub: 
Stars: 0

Looped Transformers have emerged as an efficient and powerful class of models for reasoning in the language domain. Recent studies show that these models achieve strong performance on algorithmic and reasoning tasks, suggesting that looped architectures possess an inductive bias toward latent reasoning. However, prior approaches fix the number of loop iterations during training and inference, leaving open the question of whether these models can flexibly adapt their computational depth under variable compute budgets. We introduce LoopFormer, a looped Transformer trained on variable-length trajectories to enable budget-conditioned reasoning. Our core contribution is a shortcut-consistency training scheme that aligns trajectories of different lengths, ensuring that shorter loops yield informative representations while longer loops continue to refine them. LoopFormer conditions each loop on the current time and step size, enabling representations to evolve consistently across trajectories of varying length rather than drifting or stagnating. Empirically, LoopFormer demonstrates robust performance on language modeling and reasoning benchmarks even under aggressive compute constraints, while scaling gracefully with additional budget. These results show that looped Transformers are inherently suited for adaptive language modeling, opening a path toward controllable and budget-aware large language models.]]></description>
<pubDate>Wed, 11 Feb 2026 23:58:28 +0000</pubDate>
</item>
<item>
<title><![CDATA[Blockwise Advantage Estimation for Multi-Objective RL with Verifiable Rewards]]></title>
<link>https://huggingface.co/papers/2602.10231</link>
<guid>2602.10231</guid>
<description><![CDATA[Source: HuggingFace
Tags: 
Authors: Kirill Pavlenko, Alexander Golubev, Simon Karasik, Boris Yangel
Institution: 
Published: 2026-02-10
Score: 7/10
Citations: 0
Upvotes: 9
GitHub: 
Stars: 0

Group Relative Policy Optimization (GRPO) assigns a single scalar advantage to all tokens in a completion. For structured generations with explicit segments and objectives, this couples unrelated reward signals across segments, leading to objective interference and misattributed credit. We propose Blockwise Advantage Estimation, a family of GRPO-compatible methods that assigns each objective its own advantage and applies it only to the tokens in the corresponding text block, reducing reliance on hand-designed scalar rewards and scaling naturally to additional objectives. A key challenge is estimating advantages for later blocks whose rewards are conditioned on sampled prefixes; standard unbiased approaches require expensive nested rollouts from intermediate states. Concretely, we introduce an Outcome-Conditioned Baseline that approximates intermediate state values using only within-group statistics by stratifying samples according to a prefix-derived intermediate outcome. On math tasks with uncertainty estimation, our method mitigates reward interference, is competitive with a state-of-the-art reward-designed approach, and preserves test-time gains from confidence-weighted ensembling. More broadly, it provides a modular recipe for optimizing sequential objectives in structured generations without additional rollouts.]]></description>
<pubDate>Tue, 10 Feb 2026 19:22:37 +0000</pubDate>
</item>
<item>
<title><![CDATA[EcoGym: Evaluating LLMs for Long-Horizon Plan-and-Execute in Interactive Economies]]></title>
<link>https://huggingface.co/papers/2602.09514</link>
<guid>2602.09514</guid>
<description><![CDATA[Source: HuggingFace
Tags: 
Authors: Xavier Hu, Jinxiang Xia, Shengze Xu, Kangqi Song, Yishuo Yuan
Institution: 
Published: 2026-02-10
Score: 7/10
Citations: 0
Upvotes: 9
GitHub: 
Stars: 0

Long-horizon planning is widely recognized as a core capability of autonomous LLM-based agents; however, current evaluation frameworks suffer from being largely episodic, domain-specific, or insufficiently grounded in persistent economic dynamics. We introduce EcoGym, a generalizable benchmark for continuous plan-and-execute decision making in interactive economies. EcoGym comprises three diverse environments: Vending, Freelance, and Operation, implemented in a unified decision-making process with standardized interfaces, and budgeted actions over an effectively unbounded horizon (1000+ steps if 365 day-loops for evaluation). The evaluation of EcoGym is based on business-relevant outcomes (e.g., net worth, income, and DAU), targeting long-term strategic coherence and robustness under partial observability and stochasticity. Experiments across eleven leading LLMs expose a systematic tension: no single model dominates across all three scenarios. Critically, we find that models exhibit significant suboptimality in either high-level strategies or efficient actions executions. EcoGym is released as an open, extensible testbed for transparent long-horizon agent evaluation and for studying controllability-utility trade-offs in realistic economic settings.]]></description>
<pubDate>Tue, 10 Feb 2026 08:12:23 +0000</pubDate>
</item>
<item>
<title><![CDATA[Latent Thoughts Tuning: Bridging Context and Reasoning with Fused Information in Latent Tokens]]></title>
<link>https://huggingface.co/papers/2602.10229</link>
<guid>2602.10229</guid>
<description><![CDATA[Source: HuggingFace
Tags: 
Authors: Weihao Liu, Dehai Min, Lu Cheng
Institution: 
Published: 2026-02-10
Score: 7/10
Citations: 0
Upvotes: 5
GitHub: 
Stars: 0

While explicit Chain-of-Thought (CoT) equips Large Language Models (LLMs) with strong reasoning capabilities, it requires models to verbalize every intermediate step in text tokens, constraining the model thoughts to the discrete vocabulary space. Recently, reasoning in continuous latent space has emerged as a promising alternative, enabling more robust inference and flexible computation beyond discrete token constraints. However, current latent paradigms often suffer from feature collapse and instability, stemming from distribution mismatches when recurrently using hidden states as the input embeddings, or alignment issues when relying on assistant models. To address this, we propose Latent Thoughts Tuning (LT-Tuning), a framework that redefines how latent thoughts are constructed and deployed. Instead of relying solely on raw hidden states, our method introduces a Context-Prediction-Fusion mechanism that jointly leveraging contextual hidden states and predictive semantic guidance from the vocabulary embedding space. Combined with a progressive three-stage curriculum learning pipeline, LT-Tuning also enables dynamically switching between latent and explicit thinking modes. Experiments demonstrate that our method outperforms existing latent reasoning baselines, effectively mitigating feature collapse and achieving robust reasoning accuracy.]]></description>
<pubDate>Tue, 10 Feb 2026 19:19:10 +0000</pubDate>
</item>
<item>
<title><![CDATA[Free(): Learning to Forget in Malloc-Only Reasoning Models]]></title>
<link>https://huggingface.co/papers/2602.08030</link>
<guid>2602.08030</guid>
<description><![CDATA[Source: HuggingFace
Tags: 
Authors: Yilun Zheng, Dongyang Ma, Tian Liang, Jiahao Xu, Xinting Huang
Institution: 
Published: 2026-02-08
Score: 7/10
Citations: 0
Upvotes: 5
GitHub: 
Stars: 0

Reasoning models enhance problem-solving by scaling test-time compute, yet they face a critical paradox: excessive thinking tokens often degrade performance rather than improve it. We attribute this to a fundamental architectural flaw: standard LLMs operate as "malloc-only" engines, continuously accumulating valid and redundant steps alike without a mechanism to prune obsolete information. To break this cycle, we propose Free()LM, a model that introduces an intrinsic self-forgetting capability via the Free-Module, a plug-and-play LoRA adapter. By iteratively switching between reasoning and cleaning modes, Free()LM dynamically identifies and prunes useless context chunks, maintaining a compact and noise-free state.
  Extensive experiments show that Free()LM provides consistent improvements across all model scales (8B to 685B). It achieves a 3.3% average improvement over top-tier reasoning baselines, even establishing a new SOTA on IMOanswerBench using DeepSeek V3.2-Speciale. Most notably, in long-horizon tasks where the standard Qwen3-235B-A22B model suffers a total collapse (0% accuracy), Free()LM restores performance to 50%. Our findings suggest that sustainable intelligence requires the freedom to forget as much as the power to think.]]></description>
<pubDate>Sun, 08 Feb 2026 16:04:23 +0000</pubDate>
</item>
<item>
<title><![CDATA[Reasoning Cache: Continual Improvement Over Long Horizons via Short-Horizon RL]]></title>
<link>https://huggingface.co/papers/2602.03773</link>
<guid>2602.03773</guid>
<description><![CDATA[Source: HuggingFace
Tags: 
Authors: Ian Wu, Yuxiao Qu, Amrith Setlur, Aviral Kumar
Institution: 
Published: 2026-02-03
Score: 7/10
Citations: 0
Upvotes: 4
GitHub: 
Stars: 0

Large Language Models (LLMs) that can continually improve beyond their training budgets are able to solve increasingly difficult problems by adapting at test time, a property we refer to as extrapolation. However, standard reinforcement learning (RL) operates over fixed problem distributions and training budgets, which limits extrapolation amidst distribution shift at test time. To address this, we introduce RC, an iterative decoding algorithm that replaces standard autoregressive decoding during both training and inference. RC exploits an asymmetry between the response generation and summarization capabilities of LLMs to construct reasoning chains that consistently improve across iterations. Models trained to use RC can extrapolate and continually improve over reasoning horizons more than an order of magnitude longer than those seen during training. Empirically, training a 4B model with RC using a 16k-token training budget improves performance on HMMT 2025 from 40% to nearly 70% with 0.5m tokens at test time, outperforming both comparably sized models and many larger reasoning LLMs. Finally, we also show that models trained with RC can more effectively leverage existing scaffolds to further scale test-time performance, due to the improved summary-conditioned generation abilities learned through training.]]></description>
<pubDate>Tue, 03 Feb 2026 17:34:04 +0000</pubDate>
</item>
<item>
<title><![CDATA[ThinkRouter: Efficient Reasoning via Routing Thinking between Latent and Discrete Spaces]]></title>
<link>https://huggingface.co/papers/2602.11683</link>
<guid>2602.11683</guid>
<description><![CDATA[Source: HuggingFace
Tags: 
Authors: Xin Xu, Tong Yu, Xiang Chen, Haoliang Wang, Julian McAuley
Institution: 
Published: 2026-02-12
Score: 7/10
Citations: 0
Upvotes: 1
GitHub: 
Stars: 0

Recent work explores latent reasoning to improve reasoning efficiency by replacing explicit reasoning trajectories with continuous representations in a latent space, yet its effectiveness varies across settings. Analysis of model confidence dynamics under latent reasoning reveals that thinking trajectories ending in incorrect answers contain fewer low-confidence steps than those ending in correct answers. Meanwhile, we suggest that soft embeddings aggregated by multiple low-confidence thinking alternatives may introduce and propagate noise, leading to high confidence in unreliable reasoning trajectories. Motivated by these observations, ThinkRouter, an inference-time confidence-aware routing mechanism is proposed to avoid high confidence and noise for efficient reasoning. ThinkRouter routes thinking to the discrete token space when model confidence is low, and to the latent space otherwise. Extensive experiments on STEM reasoning and coding benchmarks across diverse large reasoning models demonstrate that ThinkRouter outperforms explicit CoT, random routing, and latent reasoning baselines in terms of accuracy, achieving an average improvement of 19.70 points in Pass@1, while reducing generation length by up to 15.55%. Further comprehensive analysis reveals that ThinkRouter can calibrate errors arising from explicit CoT and latent reasoning, and accelerates end-of-thinking token generation by globally lowering model confidence.]]></description>
<pubDate>Thu, 12 Feb 2026 08:01:01 +0000</pubDate>
</item>
<item>
<title><![CDATA[Spend Search Where It Pays: Value-Guided Structured Sampling and Optimization for Generative Recommendation]]></title>
<link>https://huggingface.co/papers/2602.10699</link>
<guid>2602.10699</guid>
<description><![CDATA[Source: HuggingFace
Tags: 
Authors: Jie Jiang, Yangru Huang, Zeyu Wang, Changping Wang, Yuling Xiong
Institution: 
Published: 2026-02-11
Score: 7/10
Citations: 0
Upvotes: 1
GitHub: 
Stars: 0

Generative recommendation via autoregressive models has unified retrieval and ranking into a single conditional generation framework. However, fine-tuning these models with Reinforcement Learning (RL) often suffers from a fundamental probability-reward mismatch. Conventional likelihood-dominated decoding (e.g., beam search) exhibits a myopic bias toward locally probable prefixes, which causes two critical failures: (1) insufficient exploration, where high-reward items in low-probability branches are prematurely pruned and rarely sampled, and (2) advantage compression, where trajectories sharing high-probability prefixes receive highly correlated rewards with low within-group variance, yielding a weak comparative signal for RL. To address these challenges, we propose V-STAR, a Value-guided Sampling and Tree-structured Advantage Reinforcement framework. V-STAR forms a self-evolving loop via two synergistic components. First, a Value-Guided Efficient Decoding (VED) is developed to identify decisive nodes and selectively deepen high-potential prefixes. This improves exploration efficiency without exhaustive tree search. Second, we propose Sibling-GRPO, which exploits the induced tree topology to compute sibling-relative advantages and concentrates learning signals on decisive branching decisions. Extensive experiments on both offline and online datasets demonstrate that V-STAR outperforms state-of-the-art baselines, delivering superior accuracy and candidate-set diversity under strict latency constraints.]]></description>
<pubDate>Wed, 11 Feb 2026 09:57:36 +0000</pubDate>
</item>
<item>
<title><![CDATA[TimeChat-Captioner: Scripting Multi-Scene Videos with Time-Aware and Structural Audio-Visual Captions]]></title>
<link>https://huggingface.co/papers/2602.08711</link>
<guid>2602.08711</guid>
<description><![CDATA[Source: HuggingFace
Tags: 
Authors: Linli Yao, Yuancheng Wei, Yaojie Zhang, Lei Li, Xinlong Chen
Institution: 
Published: 2026-02-09
Score: 6/10
Citations: 0
Upvotes: 24
GitHub: 
Stars: 0

This paper proposes Omni Dense Captioning, a novel task designed to generate continuous, fine-grained, and structured audio-visual narratives with explicit timestamps. To ensure dense semantic coverage, we introduce a six-dimensional structural schema to create "script-like" captions, enabling readers to vividly imagine the video content scene by scene, akin to a cinematographic screenplay. To facilitate research, we construct OmniDCBench, a high-quality, human-annotated benchmark, and propose SodaM, a unified metric that evaluates time-aware detailed descriptions while mitigating scene boundary ambiguity. Furthermore, we construct a training dataset, TimeChatCap-42K, and present TimeChat-Captioner-7B, a strong baseline trained via SFT and GRPO with task-specific rewards. Extensive experiments demonstrate that TimeChat-Captioner-7B achieves state-of-the-art performance, surpassing Gemini-2.5-Pro, while its generated dense descriptions significantly boost downstream capabilities in audio-visual reasoning (DailyOmni and WorldSense) and temporal grounding (Charades-STA). All datasets, models, and code will be made publicly available at https://github.com/yaolinli/TimeChat-Captioner.]]></description>
<pubDate>Mon, 09 Feb 2026 14:21:58 +0000</pubDate>
</item>
<item>
<title><![CDATA[GigaBrain-0.5M*: a VLA That Learns From World Model-Based Reinforcement Learning]]></title>
<link>https://huggingface.co/papers/2602.12099</link>
<guid>2602.12099</guid>
<description><![CDATA[Source: HuggingFace
Tags: 
Authors: GigaBrain Team, Boyuan Wang, Chaojun Ni, Guan Huang, Guosheng Zhao
Institution: 
Published: 2026-02-12
Score: 6/10
Citations: 0
Upvotes: 22
GitHub: 
Stars: 0

Vision-language-action (VLA) models that directly predict multi-step action chunks from current observations face inherent limitations due to constrained scene understanding and weak future anticipation capabilities. In contrast, video world models pre-trained on web-scale video corpora exhibit robust spatiotemporal reasoning and accurate future prediction, making them a natural foundation for enhancing VLA learning. Therefore, we propose GigaBrain-0.5M*, a VLA model trained via world model-based reinforcement learning. Built upon GigaBrain-0.5, which is pre-trained on over 10,000 hours of robotic manipulation data, whose intermediate version currently ranks first on the international RoboChallenge benchmark. GigaBrain-0.5M* further integrates world model-based reinforcement learning via RAMP (Reinforcement leArning via world Model-conditioned Policy) to enable robust cross-task adaptation. Empirical results demonstrate that RAMP achieves substantial performance gains over the RECAP baseline, yielding improvements of approximately 30\% on challenging tasks including Laundry Folding, Box Packing, and Espresso Preparation. Critically, GigaBrain-0.5M^* exhibits reliable long-horizon execution, consistently accomplishing complex manipulation tasks without failure as validated by real-world deployment videos on our https://gigabrain05m.github.io{project page}.]]></description>
<pubDate>Thu, 12 Feb 2026 15:55:19 +0000</pubDate>
</item>
<item>
<title><![CDATA[GameDevBench: Evaluating Agentic Capabilities Through Game Development]]></title>
<link>https://huggingface.co/papers/2602.11103</link>
<guid>2602.11103</guid>
<description><![CDATA[Source: HuggingFace
Tags: 
Authors: Wayne Chi, Yixiong Fang, Arnav Yayavaram, Siddharth Yayavaram, Seth Karten
Institution: 
Published: 2026-02-11
Score: 6/10
Citations: 0
Upvotes: 12
GitHub: 
Stars: 0

Despite rapid progress on coding agents, progress on their multimodal counterparts has lagged behind. A key challenge is the scarcity of evaluation testbeds that combine the complexity of software development with the need for deep multimodal understanding. Game development provides such a testbed as agents must navigate large, dense codebases while manipulating intrinsically multimodal assets such as shaders, sprites, and animations within a visual game scene. We present GameDevBench, the first benchmark for evaluating agents on game development tasks. GameDevBench consists of 132 tasks derived from web and video tutorials. Tasks require significant multimodal understanding and are complex -- the average solution requires over three times the amount of lines of code and file changes compared to prior software development benchmarks. Agents still struggle with game development, with the best agent solving only 54.5% of tasks. We find a strong correlation between perceived task difficulty and multimodal complexity, with success rates dropping from 46.9% on gameplay-oriented tasks to 31.6% on 2D graphics tasks. To improve multimodal capability, we introduce two simple image and video-based feedback mechanisms for agents. Despite their simplicity, these methods consistently improve performance, with the largest change being an increase in Claude Sonnet 4.5's performance from 33.3% to 47.7%. We release GameDevBench publicly to support further research into agentic game development.]]></description>
<pubDate>Wed, 11 Feb 2026 18:15:11 +0000</pubDate>
</item>
<item>
<title><![CDATA[Ex-Omni: Enabling 3D Facial Animation Generation for Omni-modal Large Language Models]]></title>
<link>https://huggingface.co/papers/2602.07106</link>
<guid>2602.07106</guid>
<description><![CDATA[Source: HuggingFace
Tags: 
Authors: Haoyu Zhang, Zhipeng Li, Yiwen Guo, Tianshu Yu
Institution: 
Published: 2026-02-06
Score: 6/10
Citations: 0
Upvotes: 11
GitHub: 
Stars: 0

Omni-modal large language models (OLLMs) aim to unify multimodal understanding and generation, yet incorporating speech with 3D facial animation remains largely unexplored despite its importance for natural interaction. A key challenge arises from the representation mismatch between discrete, token-level semantic reasoning in LLMs and the dense, fine-grained temporal dynamics required for 3D facial motion, which makes direct modeling difficult to optimize under limited data. We propose Expressive Omni (Ex-Omni), an open-source omni-modal framework that augments OLLMs with speech-accompanied 3D facial animation. Ex-Omni reduces learning difficulty by decoupling semantic reasoning from temporal generation, leveraging speech units as temporal scaffolding and a unified token-as-query gated fusion (TQGF) mechanism for controlled semantic injection. We further introduce InstructEx, a dataset aims to facilitate augment OLLMs with speech-accompanied 3D facial animation. Extensive experiments demonstrate that Ex-Omni performs competitively against existing open-source OLLMs while enabling stable aligned speech and facial animation generation.]]></description>
<pubDate>Fri, 06 Feb 2026 18:03:30 +0000</pubDate>
</item>
<item>
<title><![CDATA[Benchmarking Large Language Models for Knowledge Graph Validation]]></title>
<link>https://huggingface.co/papers/2602.10748</link>
<guid>2602.10748</guid>
<description><![CDATA[Source: HuggingFace
Tags: 
Authors: Farzad Shami, Stefano Marchesin, Gianmaria Silvello
Institution: 
Published: 2026-02-11
Score: 6/10
Citations: 0
Upvotes: 4
GitHub: 
Stars: 0

Knowledge Graphs (KGs) store structured factual knowledge by linking entities through relationships, crucial for many applications. These applications depend on the KG's factual accuracy, so verifying facts is essential, yet challenging. Expert manual verification is ideal but impractical on a large scale. Automated methods show promise but are not ready for real-world KGs. Large Language Models (LLMs) offer potential with their semantic understanding and knowledge access, yet their suitability and effectiveness for KG fact validation remain largely unexplored.
  In this paper, we introduce FactCheck, a benchmark designed to evaluate LLMs for KG fact validation across three key dimensions: (1) LLMs internal knowledge; (2) external evidence via Retrieval-Augmented Generation (RAG); and (3) aggregated knowledge employing a multi-model consensus strategy. We evaluated open-source and commercial LLMs on three diverse real-world KGs. FactCheck also includes a RAG dataset with 2+ million documents tailored for KG fact validation. Additionally, we offer an interactive exploration platform for analyzing verification decisions.
  The experimental analyses demonstrate that while LLMs yield promising results, they are still not sufficiently stable and reliable to be used in real-world KG validation scenarios. Integrating external evidence through RAG methods yields fluctuating performance, providing inconsistent improvements over more streamlined approaches -- at higher computational costs. Similarly, strategies based on multi-model consensus do not consistently outperform individual models, underscoring the lack of a one-fits-all solution. These findings further emphasize the need for a benchmark like FactCheck to systematically evaluate and drive progress on this difficult yet crucial task.]]></description>
<pubDate>Wed, 11 Feb 2026 11:24:46 +0000</pubDate>
</item>
<item>
<title><![CDATA[Budget-Constrained Agentic Large Language Models: Intention-Based Planning for Costly Tool Use]]></title>
<link>https://huggingface.co/papers/2602.11541</link>
<guid>2602.11541</guid>
<description><![CDATA[Source: HuggingFace
Tags: 
Authors: Hanbing Liu, Chunhao Tian, Nan An, Ziyuan Wang, Pinyan Lu
Institution: 
Published: 2026-02-12
Score: 6/10
Citations: 0
Upvotes: 2
GitHub: 
Stars: 0

We study budget-constrained tool-augmented agents, where a large language model must solve multi-step tasks by invoking external tools under a strict monetary budget. We formalize this setting as sequential decision making in context space with priced and stochastic tool executions, making direct planning intractable due to massive state-action spaces, high variance of outcomes and prohibitive exploration cost. To address these challenges, we propose INTENT, an inference-time planning framework that leverages an intention-aware hierarchical world model to anticipate future tool usage, risk-calibrated cost, and guide decisions online. Across cost-augmented StableToolBench, INTENT strictly enforces hard budget feasibility while substantially improving task success over baselines, and remains robust under dynamic market shifts such as tool price changes and varying budgets.]]></description>
<pubDate>Thu, 12 Feb 2026 04:01:30 +0000</pubDate>
</item>
<item>
<title><![CDATA[TIC-VLA: A Think-in-Control Vision-Language-Action Model for Robot Navigation in Dynamic Environments]]></title>
<link>https://huggingface.co/papers/2602.02459</link>
<guid>2602.02459</guid>
<description><![CDATA[Source: HuggingFace
Tags: 
Authors: Zhiyu Huang, Yun Zhang, Johnson Liu, Rui Song, Chen Tang
Institution: 
Published: 2026-02-02
Score: 6/10
Citations: 0
Upvotes: 2
GitHub: 
Stars: 0

Robots in dynamic, human-centric environments must follow language instructions while maintaining real-time reactive control. Vision-language-action (VLA) models offer a promising framework, but they assume temporally aligned reasoning and control, despite semantic inference being inherently delayed relative to real-time action. We introduce Think-in-Control (TIC)-VLA, a latency-aware framework that explicitly models delayed semantic reasoning during action generation. TIC-VLA defines a delayed semantic-control interface that conditions action generation on delayed vision-language semantic states and explicit latency metadata, in addition to current observations, enabling policies to compensate for asynchronous reasoning. We further propose a latency-consistent training pipeline that injects reasoning inference delays during imitation learning and online reinforcement learning, aligning training with asynchronous deployment. To support realistic evaluation, we present DynaNav, a physics-accurate, photo-realistic simulation suite for language-guided navigation in dynamic environments. Extensive experiments in simulation and on a real robot show that TIC-VLA consistently outperforms prior VLA models while maintaining robust real-time control under multi-second reasoning latency. Project website: https://ucla-mobility.github.io/TIC-VLA/]]></description>
<pubDate>Mon, 02 Feb 2026 18:47:49 +0000</pubDate>
</item>
<item>
<title><![CDATA[Weight Decay Improves Language Model Plasticity]]></title>
<link>https://huggingface.co/papers/2602.11137</link>
<guid>2602.11137</guid>
<description><![CDATA[Source: HuggingFace
Tags: 
Authors: Tessa Han, Sebastian Bordt, Hanlin Zhang, Sham Kakade
Institution: 
Published: 2026-02-11
Score: 6/10
Citations: 0
Upvotes: 2
GitHub: 
Stars: 0

The prevailing paradigm in large language model (LLM) development is to pretrain a base model, then perform further training to improve performance and model behavior. However, hyperparameter optimization and scaling laws have been studied primarily from the perspective of the base model's validation loss, ignoring downstream adaptability. In this work, we study pretraining from the perspective of model plasticity, that is, the ability of the base model to successfully adapt to downstream tasks through fine-tuning. We focus on the role of weight decay, a key regularization parameter during pretraining. Through systematic experiments, we show that models trained with larger weight decay values are more plastic, meaning they show larger performance gains when fine-tuned on downstream tasks. This phenomenon can lead to counterintuitive trade-offs where base models that perform worse after pretraining can perform better after fine-tuning. Further investigation of weight decay's mechanistic effects on model behavior reveals that it encourages linearly separable representations, regularizes attention matrices, and reduces overfitting on the training data. In conclusion, this work demonstrates the importance of using evaluation metrics beyond cross-entropy loss for hyperparameter optimization and casts light on the multifaceted role of that a single optimization hyperparameter plays in shaping model behavior.]]></description>
<pubDate>Wed, 11 Feb 2026 18:49:26 +0000</pubDate>
</item>
<item>
<title><![CDATA[UMEM: Unified Memory Extraction and Management Framework for Generalizable Memory]]></title>
<link>https://huggingface.co/papers/2602.10652</link>
<guid>2602.10652</guid>
<description><![CDATA[Source: HuggingFace
Tags: 
Authors: Yongshi Ye, Hui Jiang, Feihu Jiang, Tian Lan, Yichao Du
Institution: 
Published: 2026-02-11
Score: 6/10
Citations: 0
Upvotes: 2
GitHub: 
Stars: 0

Self-evolving memory serves as the trainable parameters for Large Language Models (LLMs)-based agents, where extraction (distilling insights from experience) and management (updating the memory bank) must be tightly coordinated. Existing methods predominately optimize memory management while treating memory extraction as a static process, resulting in poor generalization, where agents accumulate instance-specific noise rather than robust memories. To address this, we propose Unified Memory Extraction and Management (UMEM), a self-evolving agent framework that jointly optimizes a Large Language Model to simultaneous extract and manage memories. To mitigate overfitting to specific instances, we introduce Semantic Neighborhood Modeling and optimize the model with a neighborhood-level marginal utility reward via GRPO. This approach ensures memory generalizability by evaluating memory utility across clusters of semantically related queries. Extensive experiments across five benchmarks demonstrate that UMEM significantly outperforms highly competitive baselines, achieving up to a 10.67% improvement in multi-turn interactive tasks. Futhermore, UMEM maintains a monotonic growth curve during continuous evolution. Codes and models will be publicly released.]]></description>
<pubDate>Wed, 11 Feb 2026 08:58:41 +0000</pubDate>
</item>
<item>
<title><![CDATA[dVoting: Fast Voting for dLLMs]]></title>
<link>https://huggingface.co/papers/2602.12153</link>
<guid>2602.12153</guid>
<description><![CDATA[Source: HuggingFace
Tags: 
Authors: Sicheng Feng, Zigeng Chen, Xinyin Ma, Gongfan Fang, Xinchao Wang
Institution: 
Published: 2026-02-12
Score: 6/10
Citations: 0
Upvotes: 1
GitHub: 
Stars: 0

Diffusion Large Language Models (dLLMs) represent a new paradigm beyond autoregressive modeling, offering competitive performance while naturally enabling a flexible decoding process. Specifically, dLLMs can generate tokens at arbitrary positions in parallel, endowing them with significant potential for parallel test-time scaling, which was previously constrained by severe inefficiency in autoregressive modeling. In this work, we introduce dVoting, a fast voting technique that boosts reasoning capability without training, with only an acceptable extra computational overhead. dVoting is motivated by the observation that, across multiple samples for the same prompt, token predictions remain largely consistent, whereas performance is determined by a small subset of tokens exhibiting cross-sample variability. Leveraging the arbitrary-position generation capability of dLLMs, dVoting performs iterative refinement by sampling, identifying uncertain tokens via consistency analysis, regenerating them through voting, and repeating this process until convergence. Extensive evaluations demonstrate that dVoting consistently improves performance across various benchmarks. It achieves gains of 6.22%-7.66% on GSM8K, 4.40%-7.20% on MATH500, 3.16%-14.84% on ARC-C, and 4.83%-5.74% on MMLU. Our code is available at https://github.com/fscdc/dVoting]]></description>
<pubDate>Thu, 12 Feb 2026 16:35:05 +0000</pubDate>
</item>
<item>
<title><![CDATA[ScalSelect: Scalable Training-Free Multimodal Data Selection for Efficient Visual Instruction Tuning]]></title>
<link>https://huggingface.co/papers/2602.11636</link>
<guid>2602.11636</guid>
<description><![CDATA[Source: HuggingFace
Tags: 
Authors: Changti Wu, Jiahuai Mao, Yuzhuo Miao, Shijie Lian, Bin Yu
Institution: 
Published: 2026-02-12
Score: 6/10
Citations: 0
Upvotes: 1
GitHub: 
Stars: 0

Large-scale Visual Instruction Tuning (VIT) has become a key paradigm for advancing the performance of vision-language models (VLMs) across various multimodal tasks. However, training on the large-scale datasets is computationally expensive and inefficient due to redundancy in the data, which motivates the need for multimodal data selection to improve training efficiency. Existing data selection methods for VIT either require costly training or gradient computation. Training-free alternatives often depend on proxy models or datasets, instruction-agnostic representations, and pairwise similarity with quadratic complexity, limiting scalability and representation fidelity. In this work, we propose ScalSelect, a scalable training-free multimodal data selection method with linear-time complexity with respect to the number of samples, eliminating the need for external models or auxiliary datasets. ScalSelect first constructs sample representations by extracting visual features most attended by instruction tokens in the target VLM, capturing instruction-relevant information. It then identifies samples whose representations best approximate the dominant subspace of the full dataset representations, enabling scalable importance scoring without pairwise comparisons. Extensive experiments across multiple VLMs, datasets, and selection budgets demonstrate that ScalSelect achieves over 97.5% of the performance of training on the full dataset using only 16% of the data, and even outperforms full-data training in some settings. The code is available at https://github.com/ChangtiWu/ScalSelect{ScalSelect}.]]></description>
<pubDate>Thu, 12 Feb 2026 06:38:49 +0000</pubDate>
</item>
<item>
<title><![CDATA[Graph-Enhanced Deep Reinforcement Learning for Multi-Objective Unrelated Parallel Machine Scheduling]]></title>
<link>https://huggingface.co/papers/2602.08052</link>
<guid>2602.08052</guid>
<description><![CDATA[Source: HuggingFace
Tags: 
Authors: Bulent Soykan, Sean Mondesire, Ghaith Rabadi, Grace Bochenek
Institution: 
Published: 2026-02-08
Score: 6/10
Citations: 0
Upvotes: 1
GitHub: 
Stars: 0

The Unrelated Parallel Machine Scheduling Problem (UPMSP) with release dates, setups, and eligibility constraints presents a significant multi-objective challenge. Traditional methods struggle to balance minimizing Total Weighted Tardiness (TWT) and Total Setup Time (TST). This paper proposes a Deep Reinforcement Learning framework using Proximal Policy Optimization (PPO) and a Graph Neural Network (GNN). The GNN effectively represents the complex state of jobs, machines, and setups, allowing the PPO agent to learn a direct scheduling policy. Guided by a multi-objective reward function, the agent simultaneously minimizes TWT and TST. Experimental results on benchmark instances demonstrate that our PPO-GNN agent significantly outperforms a standard dispatching rule and a metaheuristic, achieving a superior trade-off between both objectives. This provides a robust and scalable solution for complex manufacturing scheduling.]]></description>
<pubDate>Sun, 08 Feb 2026 16:54:47 +0000</pubDate>
</item>
<item>
<title><![CDATA[GoodVibe: Security-by-Vibe for LLM-Based Code Generation]]></title>
<link>https://huggingface.co/papers/2602.10778</link>
<guid>2602.10778</guid>
<description><![CDATA[Source: HuggingFace
Tags: 
Authors: Maximilian Thang, Lichao Wu, Sasha Behrouzi, Mohamadreza Rostami, Jona te Lintelo
Institution: 
Published: 2026-02-11
Score: 6/10
Citations: 0
Upvotes: 1
GitHub: 
Stars: 0

Large language models (LLMs) are increasingly used for code generation in fast, informal development workflows, often referred to as vibe coding, where speed and convenience are prioritized, and security requirements are rarely made explicit. In this setting, models frequently produce functionally correct but insecure code, creating a growing security risk. Existing approaches to improving code security rely on full-parameter fine-tuning or parameter-efficient adaptations, which are either costly and prone to catastrophic forgetting or operate at coarse granularity with limited interpretability and control.
  We present GoodVibe, a neuron-level framework for improving the security of code language models by default. GoodVibe is based on the key insight that security-relevant reasoning is localized to a small subset of neurons. We identify these neurons using gradient-based attribution from a supervised security task and perform neuron-selective fine-tuning that updates only this security-critical subspace. To further reduce training cost, we introduce activation-driven neuron clustering, enabling structured updates with minimal overhead. We evaluate GoodVibe on six LLMs across security-critical programming languages, including C++, Java, Swift, and Go. GoodVibe substantially improves the security of generated code while preserving general model utility, achieving up to a 2.5x improvement over base models, matching or exceeding full fine-tuning with over 4,700x fewer trainable parameters, and reducing training computation by more than 3.6x compared to the parameter-efficient baseline (LoRA). Our results demonstrate that neuron-level optimization offers an effective and scalable approach to securing code generation without sacrificing efficiency or generality.]]></description>
<pubDate>Wed, 11 Feb 2026 12:10:14 +0000</pubDate>
</item>
<item>
<title><![CDATA[MiniCPM-SALA: Hybridizing Sparse and Linear Attention for Efficient Long-Context Modeling]]></title>
<link>https://huggingface.co/papers/2602.11761</link>
<guid>2602.11761</guid>
<description><![CDATA[Source: HuggingFace
Tags: 
Authors: MiniCPM Team, Wenhao An, Yingfa Chen, Yewei Fang, Jiayi Li
Institution: 
Published: 2026-02-12
Score: 6/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

The evolution of large language models (LLMs) towards applications with ultra-long contexts faces challenges posed by the high computational and memory costs of the Transformer architecture. While existing sparse and linear attention mechanisms attempt to mitigate these issues, they typically involve a trade-off between memory efficiency and model performance. This paper introduces MiniCPM-SALA, a 9B-parameter hybrid architecture that integrates the high-fidelity long-context modeling of sparse attention (InfLLM-V2) with the global efficiency of linear attention (Lightning Attention). By employing a layer selection algorithm to integrate these mechanisms in a 1:3 ratio and utilizing a hybrid positional encoding (HyPE), the model maintains efficiency and performance for long-context tasks. Furthermore, we introduce a cost-effective continual training framework that transforms pre-trained Transformer-based models into hybrid models, which reduces training costs by approximately 75% compared to training from scratch. Extensive experiments show that MiniCPM-SALA maintains general capabilities comparable to full-attention models while offering improved efficiency. On a single NVIDIA A6000D GPU, the model achieves up to 3.5x the inference speed of the full-attention model at the sequence length of 256K tokens and supports context lengths of up to 1M tokens, a scale where traditional full-attention 8B models fail because of memory constraints.]]></description>
<pubDate>Thu, 12 Feb 2026 09:37:05 +0000</pubDate>
</item>
<item>
<title><![CDATA[PhyCritic: Multimodal Critic Models for Physical AI]]></title>
<link>https://huggingface.co/papers/2602.11124</link>
<guid>2602.11124</guid>
<description><![CDATA[Source: HuggingFace
Tags: 
Authors: Tianyi Xiong, Shihao Wang, Guilin Liu, Yi Dong, Ming Li
Institution: 
Published: 2026-02-11
Score: 5/10
Citations: 0
Upvotes: 45
GitHub: 
Stars: 0

With the rapid development of large multimodal models, reliable judge and critic models have become essential for open-ended evaluation and preference alignment, providing pairwise preferences, numerical scores, and explanatory justifications for assessing model-generated responses. However, existing critics are primarily trained in general visual domains such as captioning or image question answering, leaving physical AI tasks involving perception, causal reasoning, and planning largely underexplored. We introduce PhyCritic, a multimodal critic model optimized for physical AI through a two-stage RLVR pipeline: a physical skill warmup stage that enhances physically oriented perception and reasoning, followed by self-referential critic finetuning, where the critic generates its own prediction as an internal reference before judging candidate responses, improving judgment stability and physical correctness. Across both physical and general-purpose multimodal judge benchmarks, PhyCritic achieves strong performance gains over open-source baselines and, when applied as a policy model, further improves perception and reasoning in physically grounded tasks.]]></description>
<pubDate>Wed, 11 Feb 2026 18:35:39 +0000</pubDate>
</item>
<item>
<title><![CDATA[The Devil Behind Moltbook: Anthropic Safety is Always Vanishing in Self-Evolving AI Societies]]></title>
<link>https://huggingface.co/papers/2602.09877</link>
<guid>2602.09877</guid>
<description><![CDATA[Source: HuggingFace
Tags: 
Authors: Chenxu Wang, Chaozhuo Li, Songyang Liu, Zejian Chen, Jinyu Hou
Institution: 
Published: 2026-02-10
Score: 5/10
Citations: 0
Upvotes: 42
GitHub: 
Stars: 0

The emergence of multi-agent systems built from large language models (LLMs) offers a promising paradigm for scalable collective intelligence and self-evolution. Ideally, such systems would achieve continuous self-improvement in a fully closed loop while maintaining robust safety alignment--a combination we term the self-evolution trilemma. However, we demonstrate both theoretically and empirically that an agent society satisfying continuous self-evolution, complete isolation, and safety invariance is impossible. Drawing on an information-theoretic framework, we formalize safety as the divergence degree from anthropic value distributions. We theoretically demonstrate that isolated self-evolution induces statistical blind spots, leading to the irreversible degradation of the system's safety alignment. Empirical and qualitative results from an open-ended agent community (Moltbook) and two closed self-evolving systems reveal phenomena that align with our theoretical prediction of inevitable safety erosion. We further propose several solution directions to alleviate the identified safety concern. Our work establishes a fundamental limit on the self-evolving AI societies and shifts the discourse from symptom-driven safety patches to a principled understanding of intrinsic dynamical risks, highlighting the need for external oversight or novel safety-preserving mechanisms.]]></description>
<pubDate>Tue, 10 Feb 2026 15:18:19 +0000</pubDate>
</item>
<item>
<title><![CDATA[ASA: Training-Free Representation Engineering for Tool-Calling Agents]]></title>
<link>https://huggingface.co/papers/2602.04935</link>
<guid>2602.04935</guid>
<description><![CDATA[Source: HuggingFace
Tags: 
Authors: Youjin Wang, Run Zhou, Rong Fu, Shuaishuai Cao, Hongwei Zeng
Institution: 
Published: 2026-02-04
Score: 5/10
Citations: 0
Upvotes: 39
GitHub: 
Stars: 0

Adapting LLM agents to domain-specific tool calling remains notably brittle under evolving interfaces. Prompt and schema engineering is easy to deploy but often fragile under distribution shift and strict parsers, while continual parameter-efficient fine-tuning improves reliability at the cost of training, maintenance, and potential forgetting. We identify a critical Lazy Agent failure mode where tool necessity is nearly perfectly decodable from mid-layer activations, yet the model remains conservative in entering tool mode, revealing a representation-behavior gap. We propose Activation Steering Adapter (ASA), a training-free, inference-time controller that performs a single-shot mid-layer intervention and targets tool domains via a router-conditioned mixture of steering vectors with a probe-guided signed gate to amplify true intent while suppressing spurious triggers. On MTU-Bench with Qwen2.5-1.5B, ASA improves strict tool-use F1 from 0.18 to 0.50 while reducing the false positive rate from 0.15 to 0.05, using only about 20KB of portable assets and no weight updates.]]></description>
<pubDate>Wed, 04 Feb 2026 14:20:02 +0000</pubDate>
</item>
<item>
<title><![CDATA[ECHO-2: A Large-Scale Distributed Rollout Framework for Cost-Efficient Reinforcement Learning]]></title>
<link>https://huggingface.co/papers/2602.02192</link>
<guid>2602.02192</guid>
<description><![CDATA[Source: HuggingFace
Tags: 
Authors: Jie Xiao, Meng Chen, Qingnan Ren, Jingwei Song, Jiaqi Huang
Institution: 
Published: 2026-02-02
Score: 5/10
Citations: 0
Upvotes: 11
GitHub: 
Stars: 0

Reinforcement learning (RL) is a critical stage in post-training large language models (LLMs), involving repeated interaction between rollout generation, reward evaluation, and centralized learning. Distributing rollout execution offers opportunities to leverage more cost-efficient inference resources, but introduces challenges in wide-area coordination and policy dissemination. We present ECHO-2, a distributed RL framework for post-training with remote inference workers and non-negligible dissemination latency. ECHO-2 combines centralized learning with distributed rollouts and treats bounded policy staleness as a user-controlled parameter, enabling rollout generation, dissemination, and training to overlap. We introduce an overlap-based capacity model that relates training time, dissemination latency, and rollout throughput, yielding a practical provisioning rule for sustaining learner utilization. To mitigate dissemination bottlenecks and lower cost, ECHO-2 employs peer-assisted pipelined broadcast and cost-aware activation of heterogeneous workers. Experiments on GRPO post-training of 4B and 8B models under real wide-area bandwidth regimes show that ECHO-2 significantly improves cost efficiency while preserving RL reward comparable to strong baselines.]]></description>
<pubDate>Mon, 02 Feb 2026 14:57:53 +0000</pubDate>
</item>
<item>
<title><![CDATA[VidVec: Unlocking Video MLLM Embeddings for Video-Text Retrieval]]></title>
<link>https://huggingface.co/papers/2602.08099</link>
<guid>2602.08099</guid>
<description><![CDATA[Source: HuggingFace
Tags: 
Authors: Issar Tzachor, Dvir Samuel, Rami Ben-Ari
Institution: 
Published: 2026-02-08
Score: 5/10
Citations: 0
Upvotes: 9
GitHub: 
Stars: 0

Recent studies have adapted generative Multimodal Large Language Models (MLLMs) into embedding extractors for vision tasks, typically through fine-tuning to produce universal representations. However, their performance on video remains inferior to Video Foundation Models (VFMs). In this paper, we focus on leveraging MLLMs for video-text embedding and retrieval. We first conduct a systematic layer-wise analysis, showing that intermediate (pre-trained) MLLM layers already encode substantial task-relevant information. Leveraging this insight, we demonstrate that combining intermediate-layer embeddings with a calibrated MLLM head yields strong zero-shot retrieval performance without any training. Building on these findings, we introduce a lightweight text-based alignment strategy which maps dense video captions to short summaries and enables task-related video-text embedding learning without visual supervision. Remarkably, without any fine-tuning beyond text, our method outperforms current methods, often by a substantial margin, achieving state-of-the-art results across common video retrieval benchmarks.]]></description>
<pubDate>Sun, 08 Feb 2026 19:39:32 +0000</pubDate>
</item>
<item>
<title><![CDATA[Dreaming in Code for Curriculum Learning in Open-Ended Worlds]]></title>
<link>https://huggingface.co/papers/2602.08194</link>
<guid>2602.08194</guid>
<description><![CDATA[Source: HuggingFace
Tags: 
Authors: Konstantinos Mitsides, Maxence Faldor, Antoine Cully
Institution: MIT
Published: 2026-02-09
Score: 5/10
Citations: 0
Upvotes: 2
GitHub: 
Stars: 0

Open-ended learning frames intelligence as emerging from continual interaction with an ever-expanding space of environments. While recent advances have utilized foundation models to programmatically generate diverse environments, these approaches often focus on discovering isolated behaviors rather than orchestrating sustained progression. In complex open-ended worlds, the large combinatorial space of possible challenges makes it difficult for agents to discover sequences of experiences that remain consistently learnable. To address this, we propose Dreaming in Code (DiCode), a framework in which foundation models synthesize executable environment code to scaffold learning toward increasing competence. In DiCode, "dreaming" takes the form of materializing code-level variations of the world. We instantiate DiCode in Craftax, a challenging open-ended benchmark characterized by rich mechanics and long-horizon progression. Empirically, DiCode enables agents to acquire long-horizon skills, achieving a 16% improvement in mean return over the strongest baseline and non-zero success on late-game combat tasks where prior methods fail. Our results suggest that code-level environment design provides a practical mechanism for curriculum control, enabling the construction of intermediate environments that bridge competence gaps in open-ended worlds. Project page and source code are available at https://konstantinosmitsides.github.io/dreaming-in-code and https://github.com/konstantinosmitsides/dreaming-in-code.]]></description>
<pubDate>Mon, 09 Feb 2026 01:24:40 +0000</pubDate>
</item>
<item>
<title><![CDATA[FedPS: Federated data Preprocessing via aggregated Statistics]]></title>
<link>https://huggingface.co/papers/2602.10870</link>
<guid>2602.10870</guid>
<description><![CDATA[Source: HuggingFace
Tags: 
Authors: Xuefeng Xu, Graham Cormode
Institution: 
Published: 2026-02-11
Score: 5/10
Citations: 0
Upvotes: 1
GitHub: 
Stars: 0

Federated Learning (FL) enables multiple parties to collaboratively train machine learning models without sharing raw data. However, before training, data must be preprocessed to address missing values, inconsistent formats, and heterogeneous feature scales. This preprocessing stage is critical for model performance but is largely overlooked in FL research. In practical FL systems, privacy constraints prohibit centralizing raw data, while communication efficiency introduces further challenges for distributed preprocessing. We introduce FedPS, a unified framework for federated data preprocessing based on aggregated statistics. FedPS leverages data-sketching techniques to efficiently summarize local datasets while preserving essential statistical information. Building on these summaries, we design federated algorithms for feature scaling, encoding, discretization, and missing-value imputation, and extend preprocessing-related models such as k-Means, k-Nearest Neighbors, and Bayesian Linear Regression to both horizontal and vertical FL settings. FedPS provides flexible, communication-efficient, and consistent preprocessing pipelines for practical FL deployments.]]></description>
<pubDate>Wed, 11 Feb 2026 13:58:55 +0000</pubDate>
</item>
<item>
<title><![CDATA[Neural Additive Experts: Context-Gated Experts for Controllable Model Additivity]]></title>
<link>https://huggingface.co/papers/2602.10585</link>
<guid>2602.10585</guid>
<description><![CDATA[Source: HuggingFace
Tags: 
Authors: Guangzhi Xiong, Sanchit Sinha, Aidong Zhang
Institution: 
Published: 2026-02-11
Score: 5/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

The trade-off between interpretability and accuracy remains a core challenge in machine learning. Standard Generalized Additive Models (GAMs) offer clear feature attributions but are often constrained by their strictly additive nature, which can limit predictive performance. Introducing feature interactions can boost accuracy yet may obscure individual feature contributions. To address these issues, we propose Neural Additive Experts (NAEs), a novel framework that seamlessly balances interpretability and accuracy. NAEs employ a mixture of experts framework, learning multiple specialized networks per feature, while a dynamic gating mechanism integrates information across features, thereby relaxing rigid additive constraints. Furthermore, we propose targeted regularization techniques to mitigate variance among expert predictions, facilitating a smooth transition from an exclusively additive model to one that captures intricate feature interactions while maintaining clarity in feature attributions. Our theoretical analysis and experiments on synthetic data illustrate the model's flexibility, and extensive evaluations on real-world datasets confirm that NAEs achieve an optimal balance between predictive accuracy and transparent, feature-level explanations. The code is available at https://github.com/Teddy-XiongGZ/NAE.]]></description>
<pubDate>Wed, 11 Feb 2026 07:19:25 +0000</pubDate>
</item>
<item>
<title><![CDATA[From Features to Actions: Explainability in Traditional and Agentic AI Systems]]></title>
<link>https://huggingface.co/papers/2602.06841</link>
<guid>2602.06841</guid>
<description><![CDATA[Source: HuggingFace
Tags: 
Authors: Sindhuja Chaduvula, Jessee Ho, Kina Kim, Aravind Narayanan, Mahshid Alinoori
Institution: 
Published: 2026-02-06
Score: 5/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Over the last decade, explainable AI has primarily focused on interpreting individual model predictions, producing post-hoc explanations that relate inputs to outputs under a fixed decision structure. Recent advances in large language models (LLMs) have enabled agentic AI systems whose behaviour unfolds over multi-step trajectories. In these settings, success and failure are determined by sequences of decisions rather than a single output. While useful, it remains unclear how explanation approaches designed for static predictions translate to agentic settings where behaviour emerges over time. In this work, we bridge the gap between static and agentic explainability by comparing attribution-based explanations with trace-based diagnostics across both settings. To make this distinction explicit, we empirically compare attribution-based explanations used in static classification tasks with trace-based diagnostics used in agentic benchmarks (TAU-bench Airline and AssistantBench). Our results show that while attribution methods achieve stable feature rankings in static settings (Spearman = 0.86), they cannot be applied reliably to diagnose execution-level failures in agentic trajectories. In contrast, trace-grounded rubric evaluation for agentic settings consistently localizes behaviour breakdowns and reveals that state tracking inconsistency is 2.7times more prevalent in failed runs and reduces success probability by 49\%. These findings motivate a shift towards trajectory-level explainability for agentic systems when evaluating and diagnosing autonomous AI behaviour.
  Resources:
  https://github.com/VectorInstitute/unified-xai-evaluation-framework https://vectorinstitute.github.io/unified-xai-evaluation-framework]]></description>
<pubDate>Fri, 06 Feb 2026 16:34:29 +0000</pubDate>
</item>
<item>
<title><![CDATA[How Do Decoder-Only LLMs Perceive Users? Rethinking Attention Masking for User Representation Learning]]></title>
<link>https://huggingface.co/papers/2602.10622</link>
<guid>2602.10622</guid>
<description><![CDATA[Source: HuggingFace
Tags: 
Authors: Jiahao Yuan, Yike Xu, Jinyong Wen, Baokun Wang, Yang Chen
Institution: 
Published: 2026-02-11
Score: 4/10
Citations: 0
Upvotes: 24
GitHub: 
Stars: 0

Decoder-only large language models are increasingly used as behavioral encoders for user representation learning, yet the impact of attention masking on the quality of user embeddings remains underexplored. In this work, we conduct a systematic study of causal, hybrid, and bidirectional attention masks within a unified contrastive learning framework trained on large-scale real-world Alipay data that integrates long-horizon heterogeneous user behaviors. To improve training dynamics when transitioning from causal to bidirectional attention, we propose Gradient-Guided Soft Masking, a gradient-based pre-warmup applied before a linear scheduler that gradually opens future attention during optimization. Evaluated on 9 industrial user cognition benchmarks covering prediction, preference, and marketing sensitivity tasks, our approach consistently yields more stable training and higher-quality bidirectional representations compared with causal, hybrid, and scheduler-only baselines, while remaining compatible with decoder pretraining. Overall, our findings highlight the importance of masking design and training transition in adapting decoder-only LLMs for effective user representation learning. Our code is available at https://github.com/JhCircle/Deepfind-GGSM.]]></description>
<pubDate>Wed, 11 Feb 2026 08:12:43 +0000</pubDate>
</item>
<item>
<title><![CDATA[FeatureBench: Benchmarking Agentic Coding for Complex Feature Development]]></title>
<link>https://huggingface.co/papers/2602.10975</link>
<guid>2602.10975</guid>
<description><![CDATA[Source: HuggingFace
Tags: 
Authors: Qixing Zhou, Jiacheng Zhang, Haiyang Wang, Rui Hao, Jiahe Wang
Institution: 
Published: 2026-02-11
Score: 4/10
Citations: 0
Upvotes: 17
GitHub: 
Stars: 0

Agents powered by large language models (LLMs) are increasingly adopted in the software industry, contributing code as collaborators or even autonomous developers. As their presence grows, it becomes important to assess the current boundaries of their coding abilities. Existing agentic coding benchmarks, however, cover a limited task scope, e.g., bug fixing within a single pull request (PR), and often rely on non-executable evaluations or lack an automated approach for continually updating the evaluation coverage. To address such issues, we propose FeatureBench, a benchmark designed to evaluate agentic coding performance in end-to-end, feature-oriented software development. FeatureBench incorporates an execution-based evaluation protocol and a scalable test-driven method that automatically derives tasks from code repositories with minimal human effort. By tracing from unit tests along a dependency graph, our approach can identify feature-level coding tasks spanning multiple commits and PRs scattered across the development timeline, while ensuring the proper functioning of other features after the separation. Using this framework, we curated 200 challenging evaluation tasks and 3825 executable environments from 24 open-source repositories in the first version of our benchmark. Empirical evaluation reveals that the state-of-the-art agentic model, such as Claude 4.5 Opus, which achieves a 74.4% resolved rate on SWE-bench, succeeds on only 11.0% of tasks, opening new opportunities for advancing agentic coding. Moreover, benefiting from our automated task collection toolkit, FeatureBench can be easily scaled and updated over time to mitigate data leakage. The inherent verifiability of constructed environments also makes our method potentially valuable for agent training.]]></description>
<pubDate>Wed, 11 Feb 2026 16:06:32 +0000</pubDate>
</item>
<item>
<title><![CDATA[Unveiling Implicit Advantage Symmetry: Why GRPO Struggles with Exploration and Difficulty Adaptation]]></title>
<link>https://huggingface.co/papers/2602.05548</link>
<guid>2602.05548</guid>
<description><![CDATA[Source: HuggingFace
Tags: 
Authors: Zhiqi Yu, Zhangquan Chen, Mengting Liu, Heye Zhang, Liangqiong Qu
Institution: 
Published: 2026-02-05
Score: 4/10
Citations: 0
Upvotes: 9
GitHub: 
Stars: 0

Reinforcement Learning with Verifiable Rewards (RLVR), particularly GRPO, has become the standard for eliciting LLM reasoning. However, its efficiency in exploration and difficulty adaptation remains an open challenge. In this work, we argue that these bottlenecks stem from an implicit advantage symmetry inherent in Group Relative Advantage Estimation (GRAE). This symmetry induces two critical limitations: (i) at the group level, strict symmetry in weights between correct and incorrect trajectories leaves unsampled action logits unchanged, thereby hindering exploration of novel correct solution. (ii) at the sample level, the algorithm implicitly prioritizes medium-difficulty samples, remaining agnostic to the non-stationary demands of difficulty focus. Through controlled experiments, we reveal that this symmetric property is sub-optimal, yielding two pivotal insights: (i) asymmetrically suppressing the advantages of correct trajectories encourages essential exploration. (ii) learning efficiency is maximized by a curriculum-like transition-prioritizing simpler samples initially before gradually shifting to complex ones. Motivated by these findings, we propose Asymmetric GRAE (A-GRAE), which dynamically modulates exploration incentives and sample-difficulty focus. Experiments across seven benchmarks demonstrate that A-GRAE consistently improves GRPO and its variants across both LLMs and MLLMs.]]></description>
<pubDate>Thu, 05 Feb 2026 11:07:14 +0000</pubDate>
</item>
<item>
<title><![CDATA[Bielik Guard: Efficient Polish Language Safety Classifiers for LLM Content Moderation]]></title>
<link>https://huggingface.co/papers/2602.07954</link>
<guid>2602.07954</guid>
<description><![CDATA[Source: HuggingFace
Tags: 
Authors: Krzysztof Wrbel, Jan Maria Kowalski, Jerzy Surma, Igor Ciuciura, Maciej Szymaski
Institution: 
Published: 2026-02-08
Score: 4/10
Citations: 0
Upvotes: 4
GitHub: 
Stars: 0

As Large Language Models (LLMs) become increasingly deployed in Polish language applications, the need for efficient and accurate content safety classifiers has become paramount. We present Bielik Guard, a family of compact Polish language safety classifiers comprising two model variants: a 0.1B parameter model based on MMLW-RoBERTa-base and a 0.5B parameter model based on PKOBP/polish-roberta-8k. Fine-tuned on a community-annotated dataset of 6,885 Polish texts, these models classify content across five safety categories: Hate/Aggression, Vulgarities, Sexual Content, Crime, and Self-Harm. Our evaluation demonstrates that both models achieve strong performance on multiple benchmarks. The 0.5B variant offers the best overall discrimination capability with F1 scores of 0.791 (micro) and 0.785 (macro) on the test set, while the 0.1B variant demonstrates exceptional efficiency. Notably, Bielik Guard 0.1B v1.1 achieves superior precision (77.65%) and very low false positive rate (0.63%) on real user prompts, outperforming HerBERT-PL-Guard (31.55% precision, 4.70% FPR) despite identical model size. The models are publicly available and designed to provide appropriate responses rather than simple content blocking, particularly for sensitive categories like self-harm.]]></description>
<pubDate>Sun, 08 Feb 2026 12:57:04 +0000</pubDate>
</item>
<item>
<title><![CDATA[Scaling Verification Can Be More Effective than Scaling Policy Learning for Vision-Language-Action Alignment]]></title>
<link>http://arxiv.org/abs/2602.12281v1</link>
<guid>2602.12281v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.RO, cs.AI
Authors: Jacky Kwok, Xilun Zhang, Mengdi Xu, Yuejiang Liu, Azalia Mirhoseini et al.
Institution: 
Published: 2026-02-12
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

The long-standing vision of general-purpose robots hinges on their ability to understand and act upon natural language instructions. Vision-Language-Action (VLA) models have made remarkable progress toward this goal, yet their generated actions can still misalign with the given instructions. In this paper, we investigate test-time verification as a means to shrink the "intention-action gap.'' We first characterize the test-time scaling law for embodied instruction following and demonstrate that jointly scaling the number of rephrased instructions and generated actions greatly increases test-time sample diversity, often recovering correct actions more efficiently than scaling each dimension independently. To capitalize on these scaling laws, we present CoVer, a contrastive verifier for vision-language-action alignment, and show that our architecture scales gracefully with additional computational resources and data. We then introduce "boot-time compute" and a hierarchical verification inference pipeline for VLAs. At deployment, our framework precomputes a diverse set of rephrased instructions from a Vision-Language-Model (VLM), repeatedly generates action candidates for each instruction, and then uses a verifier to select the optimal high-level prompt and low-level action chunks. Compared to scaling policy pre-training on the same data, our verification approach yields 22% gains in-distribution and 13% out-of-distribution on the SIMPLER benchmark, with a further 45% improvement in real-world experiments. On the PolaRiS benchmark, CoVer achieves 14% gains in task progress and 9% in success rate.]]></description>
<pubDate>Thu, 12 Feb 2026 18:59:59 +0000</pubDate>
</item>
<item>
<title><![CDATA[Stroke of Surprise: Progressive Semantic Illusions in Vector Sketching]]></title>
<link>http://arxiv.org/abs/2602.12280v1</link>
<guid>2602.12280v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.CV
Authors: Huai-Hsun Cheng, Siang-Ling Zhang, Yu-Lun Liu
Institution: 
Published: 2026-02-12
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Visual illusions traditionally rely on spatial manipulations such as multi-view consistency. In this work, we introduce Progressive Semantic Illusions, a novel vector sketching task where a single sketch undergoes a dramatic semantic transformation through the sequential addition of strokes. We present Stroke of Surprise, a generative framework that optimizes vector strokes to satisfy distinct semantic interpretations at different drawing stages. The core challenge lies in the "dual-constraint": initial prefix strokes must form a coherent object (e.g., a duck) while simultaneously serving as the structural foundation for a second concept (e.g., a sheep) upon adding delta strokes. To address this, we propose a sequence-aware joint optimization framework driven by a dual-branch Score Distillation Sampling (SDS) mechanism. Unlike sequential approaches that freeze the initial state, our method dynamically adjusts prefix strokes to discover a "common structural subspace" valid for both targets. Furthermore, we introduce a novel Overlay Loss that enforces spatial complementarity, ensuring structural integration rather than occlusion. Extensive experiments demonstrate that our method significantly outperforms state-of-the-art baselines in recognizability and illusion strength, successfully expanding visual anagrams from the spatial to the temporal dimension. Project page: https://stroke-of-surprise.github.io/]]></description>
<pubDate>Thu, 12 Feb 2026 18:59:54 +0000</pubDate>
</item>
<item>
<title><![CDATA[UniT: Unified Multimodal Chain-of-Thought Test-time Scaling]]></title>
<link>http://arxiv.org/abs/2602.12279v1</link>
<guid>2602.12279v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.CV, cs.AI, cs.LG
Authors: Leon Liangyu Chen, Haoyu Ma, Zhipeng Fan, Ziqi Huang, Animesh Sinha et al.
Institution: 
Published: 2026-02-12
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Unified models can handle both multimodal understanding and generation within a single architecture, yet they typically operate in a single pass without iteratively refining their outputs. Many multimodal tasks, especially those involving complex spatial compositions, multiple interacting objects, or evolving instructions, require decomposing instructions, verifying intermediate results, and making iterative corrections. While test-time scaling (TTS) has demonstrated that allocating additional inference compute for iterative reasoning substantially improves language model performance, extending this paradigm to unified multimodal models remains an open challenge. We introduce UniT, a framework for multimodal chain-of-thought test-time scaling that enables a single unified model to reason, verify, and refine across multiple rounds. UniT combines agentic data synthesis, unified model training, and flexible test-time inference to elicit cognitive behaviors including verification, subgoal decomposition, and content memory. Our key findings are: (1) unified models trained on short reasoning trajectories generalize to longer inference chains at test time; (2) sequential chain-of-thought reasoning provides a more scalable and compute-efficient TTS strategy than parallel sampling; (3) training on generation and editing trajectories improves out-of-distribution visual reasoning. These results establish multimodal test-time scaling as an effective paradigm for advancing both generation and understanding in unified models.]]></description>
<pubDate>Thu, 12 Feb 2026 18:59:49 +0000</pubDate>
</item>
<item>
<title><![CDATA[AttentionRetriever: Attention Layers are Secretly Long Document Retrievers]]></title>
<link>http://arxiv.org/abs/2602.12278v1</link>
<guid>2602.12278v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.IR, cs.AI
Authors: David Jiahao Fu, Lam Thanh Do, Jiayu Li, Kevin Chen-Chuan Chang
Institution: 
Published: 2026-02-12
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Retrieval augmented generation (RAG) has been widely adopted to help Large Language Models (LLMs) to process tasks involving long documents. However, existing retrieval models are not designed for long document retrieval and fail to address several key challenges of long document retrieval, including context-awareness, causal dependence, and scope of retrieval. In this paper, we proposed AttentionRetriever, a novel long document retrieval model that leverages attention mechanism and entity-based retrieval to build context-aware embeddings for long document and determine the scope of retrieval. With extensive experiments, we found AttentionRetriever is able to outperform existing retrieval models on long document retrieval datasets by a large margin while remaining as efficient as dense retrieval models.]]></description>
<pubDate>Thu, 12 Feb 2026 18:59:35 +0000</pubDate>
</item>
<item>
<title><![CDATA[Agentic Test-Time Scaling for WebAgents]]></title>
<link>http://arxiv.org/abs/2602.12276v1</link>
<guid>2602.12276v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.AI, cs.CL
Authors: Nicholas Lee, Lutfi Eren Erdogan, Chris Joseph John, Surya Krishnapillai, Michael W. Mahoney et al.
Institution: 
Published: 2026-02-12
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Test-time scaling has become a standard way to improve performance and boost reliability of neural network models. However, its behavior on agentic, multi-step tasks remains less well-understood: small per-step errors can compound over long horizons; and we find that naive policies that uniformly increase sampling show diminishing returns. In this work, we present CATTS, a simple technique for dynamically allocating compute for multi-step agents. We first conduct an empirical study of inference-time scaling for web agents. We find that uniformly increasing per-step compute quickly saturates in long-horizon environments. We then investigate stronger aggregation strategies, including an LLM-based Arbiter that can outperform naive voting, but that can overrule high-consensus decisions. We show that uncertainty statistics derived from the agent's own vote distribution (entropy and top-1/top-2 margin) correlate with downstream success and provide a practical signal for dynamic compute allocation. Based on these findings, we introduce Confidence-Aware Test-Time Scaling (CATTS), which uses vote-derived uncertainty to allocate compute only when decisions are genuinely contentious. CATTS improves performance on WebArena-Lite and GoBrowse by up to 9.1% over React while using up to 2.3x fewer tokens than uniform scaling, providing both efficiency gains and an interpretable decision rule.]]></description>
<pubDate>Thu, 12 Feb 2026 18:58:30 +0000</pubDate>
</item>
<item>
<title><![CDATA[On-Policy Context Distillation for Language Models]]></title>
<link>http://arxiv.org/abs/2602.12275v1</link>
<guid>2602.12275v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.CL
Authors: Tianzhu Ye, Li Dong, Xun Wu, Shaohan Huang, Furu Wei
Institution: 
Published: 2026-02-12
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Context distillation enables language models to internalize in-context knowledge into their parameters. In our work, we propose On-Policy Context Distillation (OPCD), a framework that bridges on-policy distillation with context distillation by training a student model on its own generated trajectories while minimizing reverse Kullback-Leibler divergence against a context-conditioned teacher. We demonstrate the effectiveness of OPCD on two important applications: experiential knowledge distillation, where models extract and consolidate transferable knowledge from their historical solution traces, and system prompt distillation, where models internalize beneficial behaviors encoded in optimized prompts. Across mathematical reasoning, text-based games, and domain-specific tasks, OPCD consistently outperforms baseline methods, achieving higher task accuracy while better preserving out-of-distribution capabilities. We further show that OPCD enables effective cross-size distillation, where smaller student models can internalize experiential knowledge from larger teachers.]]></description>
<pubDate>Thu, 12 Feb 2026 18:58:28 +0000</pubDate>
</item>
<item>
<title><![CDATA[Function-Space Decoupled Diffusion for Forward and Inverse Modeling in Carbon Capture and Storage]]></title>
<link>http://arxiv.org/abs/2602.12274v1</link>
<guid>2602.12274v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.LG
Authors: Xin Ju, Jiachen Yao, Anima Anandkumar, Sally M. Benson, Gege Wen
Institution: 
Published: 2026-02-12
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Accurate characterization of subsurface flow is critical for Carbon Capture and Storage (CCS) but remains challenged by the ill-posed nature of inverse problems with sparse observations. We present Fun-DDPS, a generative framework that combines function-space diffusion models with differentiable neural operator surrogates for both forward and inverse modeling. Our approach learns a prior distribution over geological parameters (geomodel) using a single-channel diffusion model, then leverages a Local Neural Operator (LNO) surrogate to provide physics-consistent guidance for cross-field conditioning on the dynamics field. This decoupling allows the diffusion prior to robustly recover missing information in parameter space, while the surrogate provides efficient gradient-based guidance for data assimilation. We demonstrate Fun-DDPS on synthetic CCS modeling datasets, achieving two key results: (1) For forward modeling with only 25% observations, Fun-DDPS achieves 7.7% relative error compared to 86.9% for standard surrogates (an 11x improvement), proving its capability to handle extreme data sparsity where deterministic methods fail. (2) We provide the first rigorous validation of diffusion-based inverse solvers against asymptotically exact Rejection Sampling (RS) posteriors. Both Fun-DDPS and the joint-state baseline (Fun-DPS) achieve Jensen-Shannon divergence less than 0.06 against the ground truth. Crucially, Fun-DDPS produces physically consistent realizations free from the high-frequency artifacts observed in joint-state baselines, achieving this with 4x improved sample efficiency compared to rejection sampling.]]></description>
<pubDate>Thu, 12 Feb 2026 18:58:12 +0000</pubDate>
</item>
<item>
<title><![CDATA[Learning to Control: The iUzawa-Net for Nonsmooth Optimal Control of Linear PDEs]]></title>
<link>http://arxiv.org/abs/2602.12273v1</link>
<guid>2602.12273v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.LG
Authors: Yongcun Song, Xiaoming Yuan, Hangrui Yue, Tianyou Zeng
Institution: 
Published: 2026-02-12
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

We propose an optimization-informed deep neural network approach, named iUzawa-Net, aiming for the first solver that enables real-time solutions for a class of nonsmooth optimal control problems of linear partial differential equations (PDEs). The iUzawa-Net unrolls an inexact Uzawa method for saddle point problems, replacing classical preconditioners and PDE solvers with specifically designed learnable neural networks. We prove universal approximation properties and establish the asymptotic $\varepsilon$-optimality for the iUzawa-Net, and validate its promising numerical efficiency through nonsmooth elliptic and parabolic optimal control problems. Our techniques offer a versatile framework for designing and analyzing various optimization-informed deep learning approaches to optimal control and other PDE-constrained optimization problems. The proposed learning-to-control approach synergizes model-based optimization algorithms and data-driven deep learning techniques, inheriting the merits of both methodologies.]]></description>
<pubDate>Thu, 12 Feb 2026 18:57:43 +0000</pubDate>
</item>
<item>
<title><![CDATA[MonarchRT: Efficient Attention for Real-Time Video Generation]]></title>
<link>http://arxiv.org/abs/2602.12271v1</link>
<guid>2602.12271v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.CV, cs.LG
Authors: Krish Agarwal, Zhuoming Chen, Cheng Luo, Yongqi Chen, Haizhong Zheng et al.
Institution: 
Published: 2026-02-12
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Real-time video generation with Diffusion Transformers is bottlenecked by the quadratic cost of 3D self-attention, especially in real-time regimes that are both few-step and autoregressive, where errors compound across time and each denoising step must carry substantially more information. In this setting, we find that prior sparse-attention approximations break down, despite showing strong results for bidirectional, many-step diffusion. Specifically, we observe that video attention is not reliably sparse, but instead combines pronounced periodic structure driven by spatiotemporal position with dynamic, sparse semantic correspondences and dense mixing, exceeding the representational capacity of even oracle top-k attention. Building on this insight, we propose Monarch-RT, a structured attention parameterization for video diffusion models that factorizes attention using Monarch matrices. Through appropriately aligned block structure and our extended tiled Monarch parameterization, we achieve high expressivity while preserving computational efficiency. We further overcome the overhead of parameterization through finetuning, with custom Triton kernels. We first validate the high efficacy of Monarch-RT over existing sparse baselines designed only for bidirectional models. We further observe that Monarch-RT attains up to 95% attention sparsity with no loss in quality when applied to the state-of-the-art model Self-Forcing, making Monarch-RT a pioneering work on highly-capable sparse attention parameterization for real-time video generation. Our optimized implementation outperforms FlashAttention-2, FlashAttention-3, and FlashAttention-4 kernels on Nvidia RTX 5090, H100, and B200 GPUs respectively, providing kernel speedups in the range of 1.4-11.8X. This enables us, for the first time, to achieve true real-time video generation with Self-Forcing at 16 FPS on a single RTX 5090.]]></description>
<pubDate>Thu, 12 Feb 2026 18:56:53 +0000</pubDate>
</item>
<item>
<title><![CDATA[Creative Ownership in the Age of AI]]></title>
<link>http://arxiv.org/abs/2602.12270v1</link>
<guid>2602.12270v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.AI, cs.GT
Authors: Annie Liang, Jay Lu
Institution: 
Published: 2026-02-12
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Copyright law focuses on whether a new work is "substantially similar" to an existing one, but generative AI can closely imitate style without copying content, a capability now central to ongoing litigation. We argue that existing definitions of infringement are ill-suited to this setting and propose a new criterion: a generative AI output infringes on an existing work if it could not have been generated without that work in its training corpus. To operationalize this definition, we model generative systems as closure operators mapping a corpus of existing works to an output of new works. AI generated outputs are \emph{permissible} if they do not infringe on any existing work according to our criterion. Our results characterize structural properties of permissible generation and reveal a sharp asymptotic dichotomy: when the process of organic creations is light-tailed, dependence on individual works eventually vanishes, so that regulation imposes no limits on AI generation; with heavy-tailed creations, regulation can be persistently constraining.]]></description>
<pubDate>Thu, 12 Feb 2026 18:56:42 +0000</pubDate>
</item>
<item>
<title><![CDATA[CM2: Reinforcement Learning with Checklist Rewards for Multi-Turn and Multi-Step Agentic Tool Use]]></title>
<link>http://arxiv.org/abs/2602.12268v1</link>
<guid>2602.12268v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.AI
Authors: Zhen Zhang, Kaiqiang Song, Xun Wang, Yebowen Hu, Weixiang Yan et al.
Institution: 
Published: 2026-02-12
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

AI agents are increasingly used to solve real-world tasks by reasoning over multi-turn user interactions and invoking external tools. However, applying reinforcement learning to such settings remains difficult: realistic objectives often lack verifiable rewards and instead emphasize open-ended behaviors; moreover, RL for multi-turn, multi-step agentic tool use is still underexplored; and building and maintaining executable tool environments is costly, limiting scale and coverage. We propose CM2, an RL framework that replaces verifiable outcome rewards with checklist rewards. CM2 decomposes each turn's intended behavior into fine-grained binary criteria with explicit evidence grounding and structured metadata, turning open-ended judging into more stable classification-style decisions. To balance stability and informativeness, our method adopts a strategy of sparse reward assignment but dense evaluation criteria. Training is performed in a scalable LLM-simulated tool environment, avoiding heavy engineering for large tool sets. Experiments show that CM2 consistently improves over supervised fine-tuning. Starting from an 8B Base model and training on an 8k-example RL dataset, CM2 improves over the SFT counterpart by 8 points on tau^-Bench, by 10 points on BFCL-V4, and by 12 points on ToolSandbox. The results match or even outperform similarly sized open-source baselines, including the judging model. CM2 thus provides a scalable recipe for optimizing multi-turn, multi-step tool-using agents without relying on verifiable rewards. Code provided by the open-source community: https://github.com/namezhenzhang/CM2-RLCR-Tool-Agent.]]></description>
<pubDate>Thu, 12 Feb 2026 18:55:09 +0000</pubDate>
</item>
<item>
<title><![CDATA[Self-Supervised Learning via Flow-Guided Neural Operator on Time-Series Data]]></title>
<link>http://arxiv.org/abs/2602.12267v1</link>
<guid>2602.12267v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.LG
Authors: Duy Nguyen, Jiachen Yao, Jiayun Wang, Julius Berner, Animashree Anandkumar
Institution: 
Published: 2026-02-12
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Self-supervised learning (SSL) is a powerful paradigm for learning from unlabeled time-series data. However, popular methods such as masked autoencoders (MAEs) rely on reconstructing inputs from a fixed, predetermined masking ratio. Instead of this static design, we propose treating the corruption level as a new degree of freedom for representation learning, enhancing flexibility and performance. To achieve this, we introduce the Flow-Guided Neural Operator (FGNO), a novel framework combining operator learning with flow matching for SSL training. FGNO learns mappings in functional spaces by using Short-Time Fourier Transform to unify different time resolutions. We extract a rich hierarchy of features by tapping into different network layers and flow times that apply varying strengths of noise to the input data. This enables the extraction of versatile representations, from low-level patterns to high-level global features, using a single model adaptable to specific tasks. Unlike prior generative SSL methods that use noisy inputs during inference, we propose using clean inputs for representation extraction while learning representations with noise; this eliminates randomness and boosts accuracy. We evaluate FGNO across three biomedical domains, where it consistently outperforms established baselines. Our method yields up to 35% AUROC gains in neural signal decoding (BrainTreeBank), 16% RMSE reductions in skin temperature prediction (DREAMT), and over 20% improvement in accuracy and macro-F1 on SleepEDF under low-data regimes. These results highlight FGNO's robustness to data scarcity and its superior capacity to learn expressive representations for diverse time series.]]></description>
<pubDate>Thu, 12 Feb 2026 18:54:57 +0000</pubDate>
</item>
<item>
<title><![CDATA[T3D: Few-Step Diffusion Language Models via Trajectory Self-Distillation with Direct Discriminative Optimization]]></title>
<link>http://arxiv.org/abs/2602.12262v1</link>
<guid>2602.12262v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.CL, cs.LG
Authors: Tunyu Zhang, Xinxi Zhang, Ligong Han, Haizhou Shi, Xiaoxiao He et al.
Institution: 
Published: 2026-02-12
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Diffusion large language models (DLLMs) have the potential to enable fast text generation by decoding multiple tokens in parallel. However, in practice, their inference efficiency is constrained by the need for many refinement steps, while aggressively reducing the number of steps leads to a substantial degradation in generation quality. To alleviate this, we propose a trajectory self-distillation framework that improves few-step decoding by distilling the model's own generative trajectories. We incorporate Direct Discriminative Optimization (DDO), a reverse-KL objective that promotes mode-seeking distillation and encourages the student to concentrate on high-probability teacher modes. Across benchmarks, our approach consistently outperforms strong few-step baselines and standard training under tight step budgets. Although full-step decoding remains superior, we substantially narrow the gap, establishing a strong foundation towards practical few-step DLLMs. The source code is available at https://github.com/Tyrion58/T3D.]]></description>
<pubDate>Thu, 12 Feb 2026 18:52:35 +0000</pubDate>
</item>
<item>
<title><![CDATA[Think like a Scientist: Physics-guided LLM Agent for Equation Discovery]]></title>
<link>http://arxiv.org/abs/2602.12259v1</link>
<guid>2602.12259v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.AI, cs.LG
Authors: Jianke Yang, Ohm Venkatachalam, Mohammad Kianezhad, Sharvaree Vadgama, Rose Yu
Institution: 
Published: 2026-02-12
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Explaining observed phenomena through symbolic, interpretable formulas is a fundamental goal of science. Recently, large language models (LLMs) have emerged as promising tools for symbolic equation discovery, owing to their broad domain knowledge and strong reasoning capabilities. However, most existing LLM-based systems try to guess equations directly from data, without modeling the multi-step reasoning process that scientists often follow: first inferring physical properties such as symmetries, then using these as priors to restrict the space of candidate equations. We introduce KeplerAgent, an agentic framework that explicitly follows this scientific reasoning process. The agent coordinates physics-based tools to extract intermediate structure and uses these results to configure symbolic regression engines such as PySINDy and PySR, including their function libraries and structural constraints. Across a suite of physical equation benchmarks, KeplerAgent achieves substantially higher symbolic accuracy and greater robustness to noisy data than both LLM and traditional baselines.]]></description>
<pubDate>Thu, 12 Feb 2026 18:49:27 +0000</pubDate>
</item>
<item>
<title><![CDATA[On the implicit regularization of Langevin dynamics with projected noise]]></title>
<link>http://arxiv.org/abs/2602.12257v1</link>
<guid>2602.12257v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.AI
Authors: Govind Menon, Austin J. Stromme, Adrien Vacher
Institution: 
Published: 2026-02-12
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

We study Langevin dynamics with noise projected onto the directions orthogonal to an isometric group action. This mathematical model is introduced to shed new light on the effects of symmetry on stochastic gradient descent for over-parametrized models. Our main result identifies a novel form of implicit regularization: when the initial and target density are both invariant under the group action, Langevin dynamics with projected noise is equivalent in law to Langevin dynamics with isotropic diffusion but with an additional drift term proportional to the negative log volume of the group orbit. We prove this result by constructing a coupling of the two processes via a third process on the group itself, and identify the additional drift as the mean curvature of the orbits.]]></description>
<pubDate>Thu, 12 Feb 2026 18:45:42 +0000</pubDate>
</item>
<item>
<title><![CDATA[Is Online Linear Optimization Sufficient for Strategic Robustness?]]></title>
<link>http://arxiv.org/abs/2602.12253v1</link>
<guid>2602.12253v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.GT, cs.LG
Authors: Yang Cai, Haipeng Luo, Chen-Yu Wei, Weiqiang Zheng
Institution: 
Published: 2026-02-12
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

We consider bidding in repeated Bayesian first-price auctions. Bidding algorithms that achieve optimal regret have been extensively studied, but their strategic robustness to the seller's manipulation remains relatively underexplored. Bidding algorithms based on no-swap-regret algorithms achieve both desirable properties, but are suboptimal in terms of statistical and computational efficiency. In contrast, online gradient ascent is the only algorithm that achieves $O(\sqrt{TK})$ regret and strategic robustness [KSS24], where $T$ denotes the number of auctions and $K$ the number of bids.
  In this paper, we explore whether simple online linear optimization (OLO) algorithms suffice for bidding algorithms with both desirable properties. Our main result shows that sublinear linearized regret is sufficient for strategic robustness. Specifically, we construct simple black-box reductions that convert any OLO algorithm into a strategically robust no-regret bidding algorithm, in both known and unknown value distribution settings. For the known value distribution case, our reduction yields a bidding algorithm that achieves $O(\sqrt{T \log K})$ regret and strategic robustness (with exponential improvement on the $K$-dependence compared to [KSS24]). For the unknown value distribution case, our reduction gives a bidding algorithm with high-probability $O(\sqrt{T (\log K+\log(T/)})$ regret and strategic robustness, while removing the bounded density assumption made in [KSS24].]]></description>
<pubDate>Thu, 12 Feb 2026 18:41:55 +0000</pubDate>
</item>
<item>
<title><![CDATA[A technical curriculum on language-oriented artificial intelligence in translation and specialised communication]]></title>
<link>http://arxiv.org/abs/2602.12251v1</link>
<guid>2602.12251v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.CL, cs.AI, cs.HC
Authors: Ralph Krger
Institution: 
Published: 2026-02-12
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

This paper presents a technical curriculum on language-oriented artificial intelligence (AI) in the language and translation (L&T) industry. The curriculum aims to foster domain-specific technical AI literacy among stakeholders in the fields of translation and specialised communication by exposing them to the conceptual and technical/algorithmic foundations of modern language-oriented AI in an accessible way. The core curriculum focuses on 1) vector embeddings, 2) the technical foundations of neural networks, 3) tokenization and 4) transformer neural networks. It is intended to help users develop computational thinking as well as algorithmic awareness and algorithmic agency, ultimately contributing to their digital resilience in AI-driven work environments. The didactic suitability of the curriculum was tested in an AI-focused MA course at the Institute of Translation and Multilingual Communication at TH Koeln. Results suggest the didactic effectiveness of the curriculum, but participant feedback indicates that it should be embedded into higher-level didactic scaffolding - e.g., in the form of lecturer support - in order to enable optimal learning conditions.]]></description>
<pubDate>Thu, 12 Feb 2026 18:37:23 +0000</pubDate>
</item>
<item>
<title><![CDATA[Community Concealment from Unsupervised Graph Learning-Based Clustering]]></title>
<link>http://arxiv.org/abs/2602.12250v1</link>
<guid>2602.12250v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.LG, cs.CR, cs.SI
Authors: Dalyapraz Manatova, Pablo Moriano, L. Jean Camp
Institution: 
Published: 2026-02-12
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Graph neural networks (GNNs) are designed to use attributed graphs to learn representations. Such representations are beneficial in the unsupervised learning of clusters and community detection. Nonetheless, such inference may reveal sensitive groups, clustered systems, or collective behaviors, raising concerns regarding group-level privacy. Community attribution in social and critical infrastructure networks, for example, can expose coordinated asset groups, operational hierarchies, and system dependencies that could be used for profiling or intelligence gathering. We study a defensive setting in which a data publisher (defender) seeks to conceal a community of interest while making limited, utility-aware changes in the network. Our analysis indicates that community concealment is strongly influenced by two quantifiable factors: connectivity at the community boundary and feature similarity between the protected community and adjacent communities. Informed by these findings, we present a perturbation strategy that rewires a set of selected edges and modifies node features to reduce the distinctiveness leveraged by GNN message passing. The proposed method outperforms DICE in our experiments on synthetic benchmarks and real network graphs under identical perturbation budgets. Overall, it achieves median relative concealment improvements of approximately 20-45% across the evaluated settings. These findings demonstrate a mitigation strategy against GNN-based community learning and highlight group-level privacy risks intrinsic to graph learning.]]></description>
<pubDate>Thu, 12 Feb 2026 18:36:19 +0000</pubDate>
</item>
<item>
<title><![CDATA["Sorry, I Didn't Catch That": How Speech Models Miss What Matters Most]]></title>
<link>http://arxiv.org/abs/2602.12249v1</link>
<guid>2602.12249v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.AI, cs.CL, cs.CY
Authors: Kaitlyn Zhou, Martijn Bartelds, Federico Bianchi, James Zou
Institution: 
Published: 2026-02-12
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Despite speech recognition systems achieving low word error rates on standard benchmarks, they often fail on short, high-stakes utterances in real-world deployments. Here, we study this failure mode in a high-stakes task: the transcription of U.S. street names as spoken by U.S. participants. We evaluate 15 models from OpenAI, Deepgram, Google, and Microsoft on recordings from linguistically diverse U.S. speakers and find an average transcription error rate of 44%. We quantify the downstream impact of failed transcriptions by geographic locations and show that mis-transcriptions systematically cause errors for all speakers, but that routing distance errors are twice as large for non-English primary speakers compared to English primary speakers. To mitigate this harm, we introduce a synthetic data generation approach that produces diverse pronunciations of named entities using open-source text-to-speech models. Fine-tuning with less than 1,000 synthetic samples improves street name transcription accuracy by nearly 60% (relative to base models) for non-English primary speakers. Our results highlight a critical gap between benchmark performance and real-world reliability in speech systems and demonstrate a simple, scalable path to reducing high-stakes transcription errors.]]></description>
<pubDate>Thu, 12 Feb 2026 18:36:09 +0000</pubDate>
</item>
<item>
<title><![CDATA[ExtractBench: A Benchmark and Evaluation Methodology for Complex Structured Extraction]]></title>
<link>http://arxiv.org/abs/2602.12247v1</link>
<guid>2602.12247v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.LG, cs.AI
Authors: Nick Ferguson, Josh Pennington, Narek Beghian, Aravind Mohan, Douwe Kiela et al.
Institution: 
Published: 2026-02-12
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Unstructured documents like PDFs contain valuable structured information, but downstream systems require this data in reliable, standardized formats. LLMs are increasingly deployed to automate this extraction, making accuracy and reliability paramount. However, progress is bottlenecked by two gaps. First, no end-to-end benchmark evaluates PDF-to-JSON extraction under enterprise-scale schema breadth. Second, no principled methodology captures the semantics of nested extraction, where fields demand different notions of correctness (exact match for identifiers, tolerance for quantities, semantic equivalence for names), arrays require alignment, and omission must be distinguished from hallucination. We address both gaps with ExtractBench, an open-source benchmark and evaluation framework for PDF-to-JSON structured extraction. The benchmark pairs 35 PDF documents with JSON Schemas and human-annotated gold labels across economically valuable domains, yielding 12,867 evaluatable fields spanning schema complexities from tens to hundreds of fields. The evaluation framework treats the schema as an executable specification: each field declares its scoring metric. Baseline evaluations reveal that frontier models (GPT-5/5.2, Gemini-3 Flash/Pro, Claude 4.5 Opus/Sonnet) remain unreliable on realistic schemas. Performance degrades sharply with schema breadth, culminating in 0% valid output on a 369-field financial reporting schema across all tested models. We release ExtractBench at https://github.com/ContextualAI/extract-bench.]]></description>
<pubDate>Thu, 12 Feb 2026 18:31:37 +0000</pubDate>
</item>
<item>
<title><![CDATA[Intrinsic-Energy Joint Embedding Predictive Architectures Induce Quasimetric Spaces]]></title>
<link>http://arxiv.org/abs/2602.12245v1</link>
<guid>2602.12245v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.LG, cs.AI
Authors: Anthony Kobanda, Waris Radji
Institution: 
Published: 2026-02-12
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Joint-Embedding Predictive Architectures (JEPAs) aim to learn representations by predicting target embeddings from context embeddings, inducing a scalar compatibility energy in a latent space. In contrast, Quasimetric Reinforcement Learning (QRL) studies goal-conditioned control through directed distance values (cost-to-go) that support reaching goals under asymmetric dynamics. In this short article, we connect these viewpoints by restricting attention to a principled class of JEPA energy functions : intrinsic (least-action) energies, defined as infima of accumulated local effort over admissible trajectories between two states. Under mild closure and additivity assumptions, any intrinsic energy is a quasimetric. In goal-reaching control, optimal cost-to-go functions admit exactly this intrinsic form ; inversely, JEPAs trained to model intrinsic energies lie in the quasimetric value class targeted by QRL. Moreover, we observe why symmetric finite energies are structurally mismatched with one-way reachability, motivating asymmetric (quasimetric) energies when directionality matters.]]></description>
<pubDate>Thu, 12 Feb 2026 18:30:27 +0000</pubDate>
</item>
<item>
<title><![CDATA[Moonshine v2: Ergodic Streaming Encoder ASR for Latency-Critical Speech Applications]]></title>
<link>http://arxiv.org/abs/2602.12241v1</link>
<guid>2602.12241v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.CL, cs.LG, cs.SD
Authors: Manjunath Kudlur, Evan King, James Wang, Pete Warden
Institution: 
Published: 2026-02-12
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Latency-critical speech applications (e.g., live transcription, voice commands, and real-time translation) demand low time-to-first-token (TTFT) and high transcription accuracy, particularly on resource-constrained edge devices. Full-attention Transformer encoders remain a strong accuracy baseline for automatic speech recognition (ASR) because every frame can directly attend to every other frame, which resolves otherwise locally ambiguous acoustics using distant lexical context. However, this global dependency incurs quadratic complexity in sequence length, inducing an inherent "encode-the-whole-utterance" latency profile. For streaming use cases, this causes TTFT to grow linearly with utterance length as the encoder must process the entire prefix before any decoder token can be emitted. To better meet the needs of on-device, streaming ASR use cases we introduce Moonshine v2, an ergodic streaming-encoder ASR model that employs sliding-window self-attention to achieve bounded, low-latency inference while preserving strong local context. Our models achieve state of the art word error rates across standard benchmarks, attaining accuracy on-par with models 6x their size while running significantly faster. These results demonstrate that carefully designed local attention is competitive with the accuracy of full attention at a fraction of the size and latency cost, opening new possibilities for interactive speech interfaces on edge devices.]]></description>
<pubDate>Thu, 12 Feb 2026 18:20:45 +0000</pubDate>
</item>
<item>
<title><![CDATA[Olmix: A Framework for Data Mixing Throughout LM Development]]></title>
<link>http://arxiv.org/abs/2602.12237v1</link>
<guid>2602.12237v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.LG, cs.AI, cs.CL
Authors: Mayee F. Chen, Tyler Murray, David Heineman, Matt Jordan, Hannaneh Hajishirzi et al.
Institution: 
Published: 2026-02-12
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Data mixing -- determining the ratios of data from different domains -- is a first-order concern for training language models (LMs). While existing mixing methods show promise, they fall short when applied during real-world LM development. We present Olmix, a framework that addresses two such challenges. First, the configuration space for developing a mixing method is not well understood -- design choices across existing methods lack justification or consensus and overlook practical issues like data constraints. We conduct a comprehensive empirical study of this space, identifying which design choices lead to a strong mixing method. Second, in practice, the domain set evolves throughout LM development as datasets are added, removed, partitioned, and revised -- a problem setting largely unaddressed by existing works, which assume fixed domains. We study how to efficiently recompute the mixture after the domain set is updated, leveraging information from past mixtures. We introduce mixture reuse, a mechanism that reuses existing ratios and recomputes ratios only for domains affected by the update. Over a sequence of five domain-set updates mirroring real-world LM development, mixture reuse matches the performance of fully recomputing the mix after each update with 74% less compute and improves over training without mixing by 11.6% on downstream tasks.]]></description>
<pubDate>Thu, 12 Feb 2026 18:16:05 +0000</pubDate>
</item>
<item>
<title><![CDATA[Energy-Aware Spike Budgeting for Continual Learning in Spiking Neural Networks for Neuromorphic Vision]]></title>
<link>http://arxiv.org/abs/2602.12236v1</link>
<guid>2602.12236v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.NE, cs.AI, cs.CV
Authors: Anika Tabassum Meem, Muntasir Hossain Nadid, Md Zesun Ahmed Mia
Institution: 
Published: 2026-02-12
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Neuromorphic vision systems based on spiking neural networks (SNNs) offer ultra-low-power perception for event-based and frame-based cameras, yet catastrophic forgetting remains a critical barrier to deployment in continually evolving environments. Existing continual learning methods, developed primarily for artificial neural networks, seldom jointly optimize accuracy and energy efficiency, with particularly limited exploration on event-based datasets. We propose an energy-aware spike budgeting framework for continual SNN learning that integrates experience replay, learnable leaky integrate-and-fire neuron parameters, and an adaptive spike scheduler to enforce dataset-specific energy constraints during training. Our approach exhibits modality-dependent behavior: on frame-based datasets (MNIST, CIFAR-10), spike budgeting acts as a sparsity-inducing regularizer, improving accuracy while reducing spike rates by up to 47\%; on event-based datasets (DVS-Gesture, N-MNIST, CIFAR-10-DVS), controlled budget relaxation enables accuracy gains up to 17.45 percentage points with minimal computational overhead. Across five benchmarks spanning both modalities, our method demonstrates consistent performance improvements while minimizing dynamic power consumption, advancing the practical viability of continual learning in neuromorphic vision systems.]]></description>
<pubDate>Thu, 12 Feb 2026 18:15:32 +0000</pubDate>
</item>
<item>
<title><![CDATA[Detecting Overflow in Compressed Token Representations for Retrieval-Augmented Generation]]></title>
<link>http://arxiv.org/abs/2602.12235v1</link>
<guid>2602.12235v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.CL
Authors: Julia Belikova, Danila Rozhevskii, Dennis Svirin, Konstantin Polev, Alexander Panchenko
Institution: 
Published: 2026-02-12
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Efficient long-context processing remains a crucial challenge for contemporary large language models (LLMs), especially in resource-constrained environments. Soft compression architectures promise to extend effective context length by replacing long token sequences with smaller sets of learned compressed tokens. Yet, the limits of compressibility -- and when compression begins to erase task-relevant content -- remain underexplored. In this paper, we define \emph{token overflow} as a regime in which compressed representations no longer contain sufficient information to answer a given query, and propose a methodology to characterize and detect it. In the xRAG soft-compression setting, we find that query-agnostic saturation statistics reliably separate compressed from uncompressed token representations, providing a practical tool for identifying compressed tokens but showing limited overflow detection capability. Lightweight probing classifiers over both query and context xRAG representations detect overflow with 0.72 AUC-ROC on average on HotpotQA, SQuADv2, and TriviaQA datasets, demonstrating that incorporating query information improves detection performance. These results advance from query-independent diagnostics to query-aware detectors, enabling low-cost pre-LLM gating to mitigate compression-induced errors.]]></description>
<pubDate>Thu, 12 Feb 2026 18:15:08 +0000</pubDate>
</item>
<item>
<title><![CDATA[Categorical Flow Maps]]></title>
<link>http://arxiv.org/abs/2602.12233v1</link>
<guid>2602.12233v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.LG
Authors: Daan Roos, Oscar Davis, Floor Eijkelboom, Michael Bronstein, Max Welling et al.
Institution: 
Published: 2026-02-12
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

We introduce Categorical Flow Maps, a flow-matching method for accelerated few-step generation of categorical data via self-distillation. Building on recent variational formulations of flow matching and the broader trend towards accelerated inference in diffusion and flow-based models, we define a flow map towards the simplex that transports probability mass toward a predicted endpoint, yielding a parametrisation that naturally constrains model predictions. Since our trajectories are continuous rather than discrete, Categorical Flow Maps can be trained with existing distillation techniques, as well as a new objective based on endpoint consistency. This continuous formulation also automatically unlocks test-time inference: we can directly reuse existing guidance and reweighting techniques in the categorical setting to steer sampling toward downstream objectives. Empirically, we achieve state-of-the-art few-step results on images, molecular graphs, and text, with strong performance even in single-step generation.]]></description>
<pubDate>Thu, 12 Feb 2026 18:10:46 +0000</pubDate>
</item>
<item>
<title><![CDATA[Diffusion Alignment Beyond KL: Variance Minimisation as Effective Policy Optimiser]]></title>
<link>http://arxiv.org/abs/2602.12229v1</link>
<guid>2602.12229v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.LG
Authors: Zijing Ou, Jacob Si, Junyi Zhu, Ondrej Bohdal, Mete Ozay et al.
Institution: 
Published: 2026-02-12
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Diffusion alignment adapts pretrained diffusion models to sample from reward-tilted distributions along the denoising trajectory. This process naturally admits a Sequential Monte Carlo (SMC) interpretation, where the denoising model acts as a proposal and reward guidance induces importance weights. Motivated by this view, we introduce Variance Minimisation Policy Optimisation (VMPO), which formulates diffusion alignment as minimising the variance of log importance weights rather than directly optimising a Kullback-Leibler (KL) based objective. We prove that the variance objective is minimised by the reward-tilted target distribution and that, under on-policy sampling, its gradient coincides with that of standard KL-based alignment. This perspective offers a common lens for understanding diffusion alignment. Under different choices of potential functions and variance minimisation strategies, VMPO recovers various existing methods, while also suggesting new design directions beyond KL.]]></description>
<pubDate>Thu, 12 Feb 2026 18:06:03 +0000</pubDate>
</item>
<item>
<title><![CDATA[Bandit Learning in Matching Markets with Interviews]]></title>
<link>http://arxiv.org/abs/2602.12224v1</link>
<guid>2602.12224v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.GT, cs.AI
Authors: Amirmahdi Mirfakhar, Xuchuang Wang, Mengfan Xu, Hedyeh Beyhaghi, Mohammad Hajiesmaili
Institution: 
Published: 2026-02-12
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Two-sided matching markets rely on preferences from both sides, yet it is often impractical to evaluate preferences. Participants, therefore, conduct a limited number of interviews, which provide early, noisy impressions and shape final decisions. We study bandit learning in matching markets with interviews, modeling interviews as \textit{low-cost hints} that reveal partial preference information to both sides. Our framework departs from existing work by allowing firm-side uncertainty: firms, like agents, may be unsure of their own preferences and can make early hiring mistakes by hiring less preferred agents. To handle this, we extend the firm's action space to allow \emph{strategic deferral} (choosing not to hire in a round), enabling recovery from suboptimal hires and supporting decentralized learning without coordination. We design novel algorithms for (i) a centralized setting with an omniscient interview allocator and (ii) decentralized settings with two types of firm-side feedback. Across all settings, our algorithms achieve time-independent regret, a substantial improvement over the $O(\log T)$ regret bounds known for learning stable matchings without interviews. Also, under mild structured markets, decentralized performance matches the centralized counterpart up to polynomial factors in the number of agents and firms.]]></description>
<pubDate>Thu, 12 Feb 2026 18:03:37 +0000</pubDate>
</item>
<item>
<title><![CDATA[Towards On-Policy SFT: Distribution Discriminant Theory and its Applications in LLM Training]]></title>
<link>http://arxiv.org/abs/2602.12222v1</link>
<guid>2602.12222v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.LG, cs.AI, cs.CV
Authors: Miaosen Zhang, Yishan Liu, Shuxia Lin, Xu Yang, Qi Dai et al.
Institution: 
Published: 2026-02-12
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Supervised fine-tuning (SFT) is computationally efficient but often yields inferior generalization compared to reinforcement learning (RL). This gap is primarily driven by RL's use of on-policy data. We propose a framework to bridge this chasm by enabling On-Policy SFT. We first present \textbf{\textit{Distribution Discriminant Theory (DDT)}}, which explains and quantifies the alignment between data and the model-induced distribution. Leveraging DDT, we introduce two complementary techniques: (i) \textbf{\textit{In-Distribution Finetuning (IDFT)}}, a loss-level method to enhance generalization ability of SFT, and (ii) \textbf{\textit{Hinted Decoding}}, a data-level technique that can re-align the training corpus to the model's distribution. Extensive experiments demonstrate that our framework achieves generalization performance on par with prominent offline RL algorithms, including DPO and SimPO, while maintaining the efficiency of an SFT pipeline. The proposed framework thus offers a practical alternative in domains where RL is infeasible. We open-source the code here: https://github.com/zhangmiaosen2000/Towards-On-Policy-SFT]]></description>
<pubDate>Thu, 12 Feb 2026 17:59:58 +0000</pubDate>
</item>
<item>
<title><![CDATA[Best of Both Worlds: Multimodal Reasoning and Generation via Unified Discrete Flow Matching]]></title>
<link>http://arxiv.org/abs/2602.12221v1</link>
<guid>2602.12221v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.CV
Authors: Onkar Susladkar, Tushar Prakash, Gayatri Deshmukh, Kiet A. Nguyen, Jiaxun Zhang et al.
Institution: 
Published: 2026-02-12
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

We propose UniDFlow, a unified discrete flow-matching framework for multimodal understanding, generation, and editing. It decouples understanding and generation via task-specific low-rank adapters, avoiding objective interference and representation entanglement, while a novel reference-based multimodal preference alignment optimizes relative outcomes under identical conditioning, improving faithfulness and controllability without large-scale retraining. UniDFlpw achieves SOTA performance across eight benchmarks and exhibits strong zero-shot generalization to tasks including inpainting, in-context image generation, reference-based editing, and compositional generation, despite no explicit task-specific training.]]></description>
<pubDate>Thu, 12 Feb 2026 17:59:08 +0000</pubDate>
</item>
<item>
<title><![CDATA[The Observer Effect in World Models: Invasive Adaptation Corrupts Latent Physics]]></title>
<link>http://arxiv.org/abs/2602.12218v1</link>
<guid>2602.12218v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.LG, cs.AI
Authors: Christian Intern, Jumpei Yamaguchi, Loren Amdahl-Culleton, Markus Olhofer, David Klindt et al.
Institution: 
Published: 2026-02-12
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Determining whether neural models internalize physical laws as world models, rather than exploiting statistical shortcuts, remains challenging, especially under out-of-distribution (OOD) shifts. Standard evaluations often test latent capability via downstream adaptation (e.g., fine-tuning or high-capacity probes), but such interventions can change the representations being measured and thus confound what was learned during self-supervised learning (SSL). We propose a non-invasive evaluation protocol, PhyIP. We test whether physical quantities are linearly decodable from frozen representations, motivated by the linear representation hypothesis. Across fluid dynamics and orbital mechanics, we find that when SSL achieves low error, latent structure becomes linearly accessible. PhyIP recovers internal energy and Newtonian inverse-square scaling on OOD tests (e.g., $> 0.90$). In contrast, adaptation-based evaluations can collapse this structure ($\approx 0.05$). These findings suggest that adaptation-based evaluation can obscure latent structures and that low-capacity probes offer a more accurate evaluation of physical world models.]]></description>
<pubDate>Thu, 12 Feb 2026 17:56:07 +0000</pubDate>
</item>
<item>
<title><![CDATA[VIRENA: Virtual Arena for Research, Education, and Democratic Innovation]]></title>
<link>http://arxiv.org/abs/2602.12207v1</link>
<guid>2602.12207v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.HC, cs.AI, cs.SI
Authors: Emma Hoes, K. Jonathan Klueser, Fabrizio Gilardi
Institution: 
Published: 2026-02-12
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Digital platforms shape how people communicate, deliberate, and form opinions. Studying these dynamics has become increasingly difficult due to restricted data access, ethical constraints on real-world experiments, and limitations of existing research tools. VIRENA (Virtual Arena) is a platform that enables controlled experimentation in realistic social media environments. Multiple participants interact simultaneously in realistic replicas of feed-based platforms (Instagram, Facebook, Reddit) and messaging apps (WhatsApp, Messenger). Large language model-powered AI agents participate alongside humans with configurable personas and realistic behavior. Researchers can manipulate content moderation approaches, pre-schedule stimulus content, and run experiments across conditions through a visual interface requiring no programming skills. VIRENA makes possible research designs that were previously impractical: studying human--AI interaction in realistic social contexts, experimentally comparing moderation interventions, and observing group deliberation as it unfolds. Built on open-source technologies that ensure data remain under institutional control and comply with data protection requirements, VIRENA is currently in use at the University of Zurich and available for pilot collaborations. Designed for researchers, educators, and public organizations alike, VIRENA's no-code interface makes controlled social media simulation accessible across disciplines and sectors. This paper documents its design, architecture, and capabilities.]]></description>
<pubDate>Thu, 12 Feb 2026 17:46:52 +0000</pubDate>
</item>
<item>
<title><![CDATA[DeepGen 1.0: A Lightweight Unified Multimodal Model for Advancing Image Generation and Editing]]></title>
<link>http://arxiv.org/abs/2602.12205v1</link>
<guid>2602.12205v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.CV, cs.AI
Authors: Dianyi Wang, Ruihang Li, Feng Han, Chaofan Ma, Wei Song et al.
Institution: 
Published: 2026-02-12
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Current unified multimodal models for image generation and editing typically rely on massive parameter scales (e.g., >10B), entailing prohibitive training costs and deployment footprints. In this work, we present DeepGen 1.0, a lightweight 5B unified model that achieves comprehensive capabilities competitive with or surpassing much larger counterparts. To overcome the limitations of compact models in semantic understanding and fine-grained control, we introduce Stacked Channel Bridging (SCB), a deep alignment framework that extracts hierarchical features from multiple VLM layers and fuses them with learnable 'think tokens' to provide the generative backbone with structured, reasoning-rich guidance. We further design a data-centric training strategy spanning three progressive stages: (1) Alignment Pre-training on large-scale image-text pairs and editing triplets to synchronize VLM and DiT representations, (2) Joint Supervised Fine-tuning on a high-quality mixture of generation, editing, and reasoning tasks to foster omni-capabilities, and (3) Reinforcement Learning with MR-GRPO, which leverages a mixture of reward functions and supervision signals, resulting in substantial gains in generation quality and alignment with human preferences, while maintaining stable training progress and avoiding visual artifacts. Despite being trained on only ~50M samples, DeepGen 1.0 achieves leading performance across diverse benchmarks, surpassing the 80B HunyuanImage by 28% on WISE and the 27B Qwen-Image-Edit by 37% on UniREditBench. By open-sourcing our training code, weights, and datasets, we provide an efficient, high-performance alternative to democratize unified multimodal research.]]></description>
<pubDate>Thu, 12 Feb 2026 17:44:24 +0000</pubDate>
</item>
<item>
<title><![CDATA[Learning to Forget Attention: Memory Consolidation for Adaptive Compute Reduction]]></title>
<link>http://arxiv.org/abs/2602.12204v1</link>
<guid>2602.12204v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.LG
Authors: Ibne Farabi Shihab, Sanjeda Akter, Anuj Sharma
Institution: 
Published: 2026-02-12
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Hybrid architectures combining state-space models with attention have achieved strong efficiency-quality tradeoffs, yet existing approaches either apply attention uniformly or learn static sparse patterns. This misses a key opportunity: \emph{attention demand should decrease over time as recurring patterns become familiar}. We present a surprising finding from analyzing GPT-2 models: \textbf{88\%} of attention operations retrieve information already predictable from the model's hidden state, and this redundancy does \emph{not} decrease during training. Motivated by this observation, we introduce \textbf{\ours{}} (\textbf{C}onsolidation-based \textbf{R}outing for \textbf{A}daptive \textbf{M}emory), a biologically inspired memory consolidation mechanism that gradually distills episodic retrievals into parametric semantic memory. Unlike prior sparse attention methods, \ours{} exhibits \emph{decreasing attention utilization} over training, achieving a \textbf{37.8$\times$} reduction through a sharp phase transition at approximately 3K steps. We prove that this capability is \emph{impossible} without consolidation: any static routing scheme requires $(f \cdot n)$ attention for tasks with recurring patterns of frequency $f$. On our proposed SRCD benchmark, \ours{} achieves \textbf{100\% retrieval accuracy} at 1.6\% attention compute (vs.\ 68\% for baselines), and consolidated patterns transfer to unseen tasks with \textbf{48--52\%} attention reduction without retraining. Remarkably, the learned consolidation dynamics quantitatively match human episodic-to-semantic memory transition curves from cognitive psychology ($= 0.43$ vs.\ $_{\text{human}} \approx 0.4$--$0.5$). Code and benchmarks are available at [anonymized].]]></description>
<pubDate>Thu, 12 Feb 2026 17:40:15 +0000</pubDate>
</item>
<item>
<title><![CDATA[ExStrucTiny: A Benchmark for Schema-Variable Structured Information Extraction from Document Images]]></title>
<link>http://arxiv.org/abs/2602.12203v1</link>
<guid>2602.12203v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.CL
Authors: Mathieu Sibue, Andres Muoz Garza, Samuel Mensah, Pranav Shetty, Zhiqiang Ma et al.
Institution: 
Published: 2026-02-12
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Enterprise documents, such as forms and reports, embed critical information for downstream applications like data archiving, automated workflows, and analytics. Although generalist Vision Language Models (VLMs) perform well on established document understanding benchmarks, their ability to conduct holistic, fine-grained structured extraction across diverse document types and flexible schemas is not well studied. Existing Key Entity Extraction (KEE), Relation Extraction (RE), and Visual Question Answering (VQA) datasets are limited by narrow entity ontologies, simple queries, or homogeneous document types, often overlooking the need for adaptable and structured extraction. To address these gaps, we introduce ExStrucTiny, a new benchmark dataset for structured Information Extraction (IE) from document images, unifying aspects of KEE, RE, and VQA. Built through a novel pipeline combining manual and synthetic human-validated samples, ExStrucTiny covers more varied document types and extraction scenarios. We analyze open and closed VLMs on this benchmark, highlighting challenges such as schema adaptation, query under-specification, and answer localization. We hope our work provides a bedrock for improving generalist models for structured IE in documents.]]></description>
<pubDate>Thu, 12 Feb 2026 17:38:57 +0000</pubDate>
</item>
<item>
<title><![CDATA[Visual Reasoning Benchmark: Evaluating Multimodal LLMs on Classroom-Authentic Visual Problems from Primary Education]]></title>
<link>http://arxiv.org/abs/2602.12196v1</link>
<guid>2602.12196v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.CL, cs.AI
Authors: Mohamed Huti, Alasdair Mackintosh, Amy Waldock, Dominic Andrews, Maxime Lelivre et al.
Institution: 
Published: 2026-02-12
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

AI models have achieved state-of-the-art results in textual reasoning; however, their ability to reason over spatial and relational structures remains a critical bottleneck -- particularly in early-grade maths, which relies heavily on visuals. This paper introduces the visual reasoning benchmark (VRB), a novel dataset designed to evaluate Multimodal Large Language Models (MLLMs) on their ability to solve authentic visual problems from classrooms. This benchmark is built on a set of 701 questions sourced from primary school examinations in Zambia and India, which cover a range of tasks such as reasoning by analogy, pattern completion, and spatial matching. We outline the methodology and development of the benchmark which intentionally uses unedited, minimal-text images to test if models can meet realistic needs of primary education. Our findings reveal a ``jagged frontier'' of capability where models demonstrate better proficiency in static skills such as counting and scaling, but reach a distinct ``spatial ceiling'' when faced with dynamic operations like folding, reflection, and rotation. These weaknesses pose a risk for classroom use on visual reasoning problems, with the potential for incorrect marking, false scaffolding, and reinforcing student misconceptions. Consequently, education-focused benchmarks like the VRB are essential for determining the functional boundaries of multimodal tools used in classrooms.]]></description>
<pubDate>Thu, 12 Feb 2026 17:29:03 +0000</pubDate>
</item>
<item>
<title><![CDATA[Query-focused and Memory-aware Reranker for Long Context Processing]]></title>
<link>http://arxiv.org/abs/2602.12192v1</link>
<guid>2602.12192v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.CL
Authors: Yuqing Li, Jiangnan Li, Mo Yu, Guoxuan Ding, Zheng Lin et al.
Institution: 
Published: 2026-02-12
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Built upon the existing analysis of retrieval heads in large language models, we propose an alternative reranking framework that trains models to estimate passage-query relevance using the attention scores of selected heads. This approach provides a listwise solution that leverages holistic information within the entire candidate shortlist during ranking. At the same time, it naturally produces continuous relevance scores, enabling training on arbitrary retrieval datasets without requiring Likert-scale supervision. Our framework is lightweight and effective, requiring only small-scale models (e.g., 4B parameters) to achieve strong performance. Extensive experiments demonstrate that our method outperforms existing state-of-the-art pointwise and listwise rerankers across multiple domains, including Wikipedia and long narrative datasets. It further establishes a new state-of-the-art on the LoCoMo benchmark that assesses the capabilities of dialogue understanding and memory usage. We further demonstrate that our framework supports flexible extensions. For example, augmenting candidate passages with contextual information further improves ranking accuracy, while training attention heads from middle layers enhances efficiency without sacrificing performance.]]></description>
<pubDate>Thu, 12 Feb 2026 17:23:38 +0000</pubDate>
</item>
<item>
<title><![CDATA[WaveFormer: Wavelet Embedding Transformer for Biomedical Signals]]></title>
<link>http://arxiv.org/abs/2602.12189v1</link>
<guid>2602.12189v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.LG
Authors: Habib Irani, Bikram De, Vangelis Metsis
Institution: 
Published: 2026-02-12
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Biomedical signal classification presents unique challenges due to long sequences, complex temporal dynamics, and multi-scale frequency patterns that are poorly captured by standard transformer architectures. We propose WaveFormer, a transformer architecture that integrates wavelet decomposition at two critical stages: embedding construction, where multi-channel Discrete Wavelet Transform (DWT) extracts frequency features to create tokens containing both time-domain and frequency-domain information, and positional encoding, where Dynamic Wavelet Positional Encoding (DyWPE) adapts position embeddings to signal-specific temporal structure through mono-channel DWT analysis. We evaluate WaveFormer on eight diverse datasets spanning human activity recognition and brain signal analysis, with sequence lengths ranging from 50 to 3000 timesteps and channel counts from 1 to 144. Experimental results demonstrate that WaveFormer achieves competitive performance through comprehensive frequency-aware processing. Our approach provides a principled framework for incorporating frequency-domain knowledge into transformer-based time series classification.]]></description>
<pubDate>Thu, 12 Feb 2026 17:20:43 +0000</pubDate>
</item>
<item>
<title><![CDATA[SAGEO Arena: A Realistic Environment for Evaluating Search-Augmented Generative Engine Optimization]]></title>
<link>http://arxiv.org/abs/2602.12187v1</link>
<guid>2602.12187v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.IR, cs.AI
Authors: Sunghwan Kim, Wooseok Jeong, Serin Kim, Sangam Lee, Dongha Lee
Institution: 
Published: 2026-02-12
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Search-Augmented Generative Engines (SAGE) have emerged as a new paradigm for information access, bridging web-scale retrieval with generative capabilities to deliver synthesized answers. This shift has fundamentally reshaped how web content gains exposure online, giving rise to Search-Augmented Generative Engine Optimization (SAGEO), the practice of optimizing web documents to improve their visibility in AI-generated responses. Despite growing interest, no evaluation environment currently supports comprehensive investigation of SAGEO. Specifically, existing benchmarks lack end-to-end visibility evaluation of optimization strategies, operating on pre-determined candidate documents that abstract away retrieval and reranking preceding generation. Moreover, existing benchmarks discard structural information (e.g., schema markup) present in real web documents, overlooking the rich signals that search systems actively leverage in practice. Motivated by these gaps, we introduce SAGEO Arena, a realistic and reproducible environment for stage-level SAGEO analysis. Our objective is to jointly target search-oriented optimization (SEO) and generation-centric optimization (GEO). To achieve this, we integrate a full generative search pipeline over a large-scale corpus of web documents with rich structural information. Our findings reveal that existing approaches remain largely impractical under realistic conditions and often degrade performance in retrieval and reranking. We also find that structural information helps mitigate these limitations, and that effective SAGEO requires tailoring optimization to each pipeline stage. Overall, our benchmark paves the way for realistic SAGEO evaluation and optimization beyond simplified settings.]]></description>
<pubDate>Thu, 12 Feb 2026 17:18:00 +0000</pubDate>
</item>
<item>
<title><![CDATA[Convex Markov Games and Beyond: New Proof of Existence, Characterization and Learning Algorithms for Nash Equilibria]]></title>
<link>http://arxiv.org/abs/2602.12181v1</link>
<guid>2602.12181v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.GT, cs.LG, cs.MA
Authors: Anas Barakat, Ioannis Panageas, Antonios Varvitsiotis
Institution: 
Published: 2026-02-12
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Convex Markov Games (cMGs) were recently introduced as a broad class of multi-agent learning problems that generalize Markov games to settings where strategic agents optimize general utilities beyond additive rewards. While cMGs expand the modeling frontier, their theoretical foundations, particularly the structure of Nash equilibria (NE) and guarantees for learning algorithms, are not yet well understood. In this work, we address these gaps for an extension of cMGs, which we term General Utility Markov Games (GUMGs), capturing new applications requiring coupling between agents' occupancy measures. We prove that in GUMGs, Nash equilibria coincide with the fixed points of projected pseudo-gradient dynamics (i.e., first-order stationary points), enabled by a novel agent-wise gradient domination property. This insight also yields a simple proof of NE existence using Brouwer's fixed-point theorem. We further show the existence of Markov perfect equilibria. Building on this characterization, we establish a policy gradient theorem for GUMGs and design a model-free policy gradient algorithm. For potential GUMGs, we establish iteration complexity guarantees for computing approximate-NE under exact gradients and provide sample complexity bounds in both the generative model and on-policy settings. Our results extend beyond prior work restricted to zero-sum cMGs, providing the first theoretical analysis of common-interest cMGs.]]></description>
<pubDate>Thu, 12 Feb 2026 17:11:20 +0000</pubDate>
</item>
<item>
<title><![CDATA[How Sampling Shapes LLM Alignment: From One-Shot Optima to Iterative Dynamics]]></title>
<link>http://arxiv.org/abs/2602.12180v1</link>
<guid>2602.12180v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.LG, cs.GT
Authors: Yurong Chen, Yu He, Michael I. Jordan, Fan Yao
Institution: 
Published: 2026-02-12
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Standard methods for aligning large language models with human preferences learn from pairwise comparisons among sampled candidate responses and regularize toward a reference policy. Despite their effectiveness, the effects of sampling and reference choices are poorly understood theoretically. We investigate these effects through Identity Preference Optimization, a widely used preference alignment framework, and show that proper instance-dependent sampling can yield stronger ranking guarantees, while skewed on-policy sampling can induce excessive concentration under structured preferences. We then analyze iterative alignment dynamics in which the learned policy feeds back into future sampling and reference policies, reflecting a common practice of model-generated preference data. We prove that these dynamics can exhibit persistent oscillations or entropy collapse for certain parameter choices, and characterize regimes that guarantee stability. Our theoretical insights extend to Direct Preference Optimization, indicating the phenomena we captured are common to a broader class of preference-alignment methods. Experiments on real-world preference data validate our findings.]]></description>
<pubDate>Thu, 12 Feb 2026 17:11:08 +0000</pubDate>
</item>
<item>
<title><![CDATA[EO-VAE: Towards A Multi-sensor Tokenizer for Earth Observation Data]]></title>
<link>http://arxiv.org/abs/2602.12177v1</link>
<guid>2602.12177v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.CV
Authors: Nils Lehmann, Yi Wang, Zhitong Xiong, Xiaoxiang Zhu
Institution: 
Published: 2026-02-12
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

State-of-the-art generative image and video models rely heavily on tokenizers that compress high-dimensional inputs into more efficient latent representations. While this paradigm has revolutionized RGB generation, Earth observation (EO) data presents unique challenges due to diverse sensor specifications and variable spectral channels. We propose EO-VAE, a multi-sensor variational autoencoder designed to serve as a foundational tokenizer for the EO domain. Unlike prior approaches that train separate tokenizers for each modality, EO-VAE utilizes a single model to encode and reconstruct flexible channel combinations via dynamic hypernetworks. Our experiments on the TerraMesh dataset demonstrate that EO-VAE achieves superior reconstruction fidelity compared to the TerraMind tokenizers, establishing a robust baseline for latent generative modeling in remote sensing.]]></description>
<pubDate>Thu, 12 Feb 2026 17:09:14 +0000</pubDate>
</item>
<item>
<title><![CDATA[SAM3-LiteText: An Anatomical Study of the SAM3 Text Encoder for Efficient Vision-Language Segmentation]]></title>
<link>http://arxiv.org/abs/2602.12173v1</link>
<guid>2602.12173v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.AI
Authors: Chengxi Zeng, Yuxuan Jiang, Ge Gao, Shuai Wang, Duolikun Danier et al.
Institution: 
Published: 2026-02-12
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Vision-language segmentation models such as SAM3 enable flexible, prompt-driven visual grounding, but inherit large, general-purpose text encoders originally designed for open-ended language understanding. In practice, segmentation prompts are short, structured, and semantically constrained, leading to substantial over-provisioning in text encoder capacity and persistent computational and memory overhead. In this paper, we perform a large-scale anatomical analysis of text prompting in vision-language segmentation, covering 404,796 real prompts across multiple benchmarks. Our analysis reveals severe redundancy: most context windows are underutilized, vocabulary usage is highly sparse, and text embeddings lie on low-dimensional manifold despite high-dimensional representations. Motivated by these findings, we propose SAM3-LiteText, a lightweight text encoding framework that replaces the original SAM3 text encoder with a compact MobileCLIP student that is optimized by knowledge distillation. Extensive experiments on image and video segmentation benchmarks show that SAM3-LiteText reduces text encoder parameters by up to 88%, substantially reducing static memory footprint, while maintaining segmentation performance comparable to the original model. Code: https://github.com/SimonZeng7108/efficientsam3/tree/sam3_litetext.]]></description>
<pubDate>Thu, 12 Feb 2026 17:01:49 +0000</pubDate>
</item>
<item>
<title><![CDATA[Pedagogically-Inspired Data Synthesis for Language Model Knowledge Distillation]]></title>
<link>http://arxiv.org/abs/2602.12172v1</link>
<guid>2602.12172v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.AI, cs.CL
Authors: Bowei He, Yankai Chen, Xiaokun Zhang, Linghe Kong, Philip S. Yu et al.
Institution: 
Published: 2026-02-12
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Knowledge distillation from Large Language Models (LLMs) to smaller models has emerged as a critical technique for deploying efficient AI systems. However, current methods for distillation via synthetic data lack pedagogical awareness, treating knowledge transfer as a one-off data synthesis and training task rather than a systematic learning process. In this paper, we propose a novel pedagogically-inspired framework for LLM knowledge distillation that draws from fundamental educational principles. Our approach introduces a three-stage pipeline -- Knowledge Identifier, Organizer, and Adapter (IOA) -- that systematically identifies knowledge deficiencies in student models, organizes knowledge delivery through progressive curricula, and adapts representations to match the cognitive capacity of student models. We integrate Bloom's Mastery Learning Principles and Vygotsky's Zone of Proximal Development to create a dynamic distillation process where student models approach teacher model's performance on prerequisite knowledge before advancing, and new knowledge is introduced with controlled, gradual difficulty increments. Extensive experiments using LLaMA-3.1/3.2 and Qwen2.5 as student models demonstrate that IOA achieves significant improvements over baseline distillation methods, with student models retaining 94.7% of teacher performance on DollyEval while using less than 1/10th of the parameters. Our framework particularly excels in complex reasoning tasks, showing 19.2% improvement on MATH and 22.3% on HumanEval compared with state-of-the-art baselines.]]></description>
<pubDate>Thu, 12 Feb 2026 17:00:36 +0000</pubDate>
</item>
<item>
<title><![CDATA[Statistical Parsing for Logical Information Retrieval]]></title>
<link>http://arxiv.org/abs/2602.12170v1</link>
<guid>2602.12170v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.AI
Authors: Greg Coppola
Institution: 
Published: 2026-02-12
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

In previous work (Coppola, 2024) we introduced the Quantified Boolean Bayesian Network (QBBN), a logical graphical model that implements the forward fragment of natural deduction (Prawitz, 1965) as a probabilistic factor graph. That work left two gaps: no negation/backward reasoning, and no parser for natural language.
  This paper addresses both gaps across inference, semantics, and syntax. For inference, we extend the QBBN with NEG factors enforcing P(x) + P(neg x) = 1, enabling contrapositive reasoning (modus tollens) via backward lambda messages, completing Prawitz's simple elimination rules. The engine handles 44/44 test cases spanning 22 reasoning patterns. For semantics, we present a typed logical language with role-labeled predicates, modal quantifiers, and three tiers of expressiveness following Prawitz: first-order quantification, propositions as arguments, and predicate quantification via lambda abstraction. For syntax, we present a typed slot grammar that deterministically compiles sentences to logical form (33/33 correct, zero ambiguity). LLMs handle disambiguation (95% PP attachment accuracy) but cannot produce structured parses directly (12.4% UAS), confirming grammars are necessary. The architecture: LLM preprocesses, grammar parses, LLM reranks, QBBN infers.
  We argue this reconciles formal semantics with Sutton's "bitter lesson" (2019): LLMs eliminate the annotation bottleneck that killed formal NLP, serving as annotator while the QBBN serves as verifier. Code: https://github.com/gregorycoppola/world]]></description>
<pubDate>Thu, 12 Feb 2026 16:57:25 +0000</pubDate>
</item>
<item>
<title><![CDATA[Sci-CoE: Co-evolving Scientific Reasoning LLMs via Geometric Consensus with Sparse Supervision]]></title>
<link>http://arxiv.org/abs/2602.12164v1</link>
<guid>2602.12164v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.AI
Authors: Xiaohan He, Shiyang Feng, Songtao Huang, Lei Bai, Bin Wang et al.
Institution: 
Published: 2026-02-12
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Large language models (LLMs) have demonstrated exceptional reasoning capabilities, and co-evolving paradigms have shown promising results in domains such as code and math. However, in scientific reasoning tasks, these models remain fragile due to unreliable solution evaluation and limited diversity in verification strategies. In this work, we propose Sci-CoE, a two-stage scientific co-evolving framework that enables models to self-evolve as both solver and verifier through a transition from sparse supervision to unsupervised learning. In the first stage, the model uses a small set of annotated data to establish fundamental correctness judgment anchors for the Verifier. In the second stage, we introduce a geometric reward mechanism that jointly considers consensus, reliability, and diversity, driving large-scale self-iteration on unlabeled data. Experiments on several general scientific benchmarks demonstrate that Sci-CoE enhances complex reasoning capabilities and exhibits strong scalability, facilitating the construction of more robust and diverse evaluation systems. Codes are available at https://github.com/InternScience/Sci-CoE.]]></description>
<pubDate>Thu, 12 Feb 2026 16:46:00 +0000</pubDate>
</item>
<item>
<title><![CDATA[Amortized Molecular Optimization via Group Relative Policy Optimization]]></title>
<link>http://arxiv.org/abs/2602.12162v1</link>
<guid>2602.12162v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.LG
Authors: Muhammad bin Javaid, Hasham Hussain, Ashima Khanna, Berke Kisin, Jonathan Pirnay et al.
Institution: 
Published: 2026-02-12
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Molecular design encompasses tasks ranging from de-novo design to structural alteration of given molecules or fragments. For the latter, state-of-the-art methods predominantly function as "Instance Optimizers'', expending significant compute restarting the search for every input structure. While model-based approaches theoretically offer amortized efficiency by learning a policy transferable to unseen structures, existing methods struggle to generalize. We identify a key failure mode: the high variance arising from the heterogeneous difficulty of distinct starting structures. To address this, we introduce GRXForm, adapting a pre-trained Graph Transformer model that optimizes molecules via sequential atom-and-bond additions. We employ Group Relative Policy Optimization (GRPO) for goal-directed fine-tuning to mitigate variance by normalizing rewards relative to the starting structure. Empirically, GRXForm generalizes to out-of-distribution molecular scaffolds without inference-time oracle calls or refinement, achieving scores in multi-objective optimization competitive with leading instance optimizers.]]></description>
<pubDate>Thu, 12 Feb 2026 16:43:59 +0000</pubDate>
</item>
<item>
<title><![CDATA[DreamID-Omni: Unified Framework for Controllable Human-Centric Audio-Video Generation]]></title>
<link>http://arxiv.org/abs/2602.12160v1</link>
<guid>2602.12160v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.CV
Authors: Xu Guo, Fulong Ye, Qichao Sun, Liyang Chen, Bingchuan Li et al.
Institution: 
Published: 2026-02-12
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Recent advancements in foundation models have revolutionized joint audio-video generation. However, existing approaches typically treat human-centric tasks including reference-based audio-video generation (R2AV), video editing (RV2AV) and audio-driven video animation (RA2V) as isolated objectives. Furthermore, achieving precise, disentangled control over multiple character identities and voice timbres within a single framework remains an open challenge. In this paper, we propose DreamID-Omni, a unified framework for controllable human-centric audio-video generation. Specifically, we design a Symmetric Conditional Diffusion Transformer that integrates heterogeneous conditioning signals via a symmetric conditional injection scheme. To resolve the pervasive identity-timbre binding failures and speaker confusion in multi-person scenarios, we introduce a Dual-Level Disentanglement strategy: Synchronized RoPE at the signal level to ensure rigid attention-space binding, and Structured Captions at the semantic level to establish explicit attribute-subject mappings. Furthermore, we devise a Multi-Task Progressive Training scheme that leverages weakly-constrained generative priors to regularize strongly-constrained tasks, preventing overfitting and harmonizing disparate objectives. Extensive experiments demonstrate that DreamID-Omni achieves comprehensive state-of-the-art performance across video, audio, and audio-visual consistency, even outperforming leading proprietary commercial models. We will release our code to bridge the gap between academic research and commercial-grade applications.]]></description>
<pubDate>Thu, 12 Feb 2026 16:41:52 +0000</pubDate>
</item>
<item>
<title><![CDATA[3DGSNav: Enhancing Vision-Language Model Reasoning for Object Navigation via Active 3D Gaussian Splatting]]></title>
<link>http://arxiv.org/abs/2602.12159v1</link>
<guid>2602.12159v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.RO, cs.AI
Authors: Wancai Zheng, Hao Chen, Xianlong Lu, Linlin Ou, Xinyi Yu
Institution: 
Published: 2026-02-12
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Object navigation is a core capability of embodied intelligence, enabling an agent to locate target objects in unknown environments. Recent advances in vision-language models (VLMs) have facilitated zero-shot object navigation (ZSON). However, existing methods often rely on scene abstractions that convert environments into semantic maps or textual representations, causing high-level decision making to be constrained by the accuracy of low-level perception. In this work, we present 3DGSNav, a novel ZSON framework that embeds 3D Gaussian Splatting (3DGS) as persistent memory for VLMs to enhance spatial reasoning. Through active perception, 3DGSNav incrementally constructs a 3DGS representation of the environment, enabling trajectory-guided free-viewpoint rendering of frontier-aware first-person views. Moreover, we design structured visual prompts and integrate them with Chain-of-Thought (CoT) prompting to further improve VLM reasoning. During navigation, a real-time object detector filters potential targets, while VLM-driven active viewpoint switching performs target re-verification, ensuring efficient and reliable recognition. Extensive evaluations across multiple benchmarks and real-world experiments on a quadruped robot demonstrate that our method achieves robust and competitive performance against state-of-the-art approaches.The Project Page:https://aczheng-cai.github.io/3dgsnav.github.io/]]></description>
<pubDate>Thu, 12 Feb 2026 16:41:26 +0000</pubDate>
</item>
<item>
<title><![CDATA[SafeNeuron: Neuron-Level Safety Alignment for Large Language Models]]></title>
<link>http://arxiv.org/abs/2602.12158v1</link>
<guid>2602.12158v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.LG
Authors: Zhaoxin Wang, Jiaming Liang, Fengbin Zhu, Weixiang Zhao, Junfeng Fang et al.
Institution: 
Published: 2026-02-12
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Large language models (LLMs) and multimodal LLMs are typically safety-aligned before release to prevent harmful content generation. However, recent studies show that safety behaviors are concentrated in a small subset of parameters, making alignment brittle and easily bypassed through neuron-level attacks. Moreover, most existing alignment methods operate at the behavioral level, offering limited control over the model's internal safety mechanisms. In this work, we propose SafeNeuron, a neuron-level safety alignment framework that improves robustness by redistributing safety representations across the network. SafeNeuron first identifies safety-related neurons, then freezes these neurons during preference optimization to prevent reliance on sparse safety pathways and force the model to construct redundant safety representations. Extensive experiments across models and modalities demonstrate that SafeNeuron significantly improves robustness against neuron pruning attacks, reduces the risk of open-source models being repurposed as red-team generators, and preserves general capabilities. Furthermore, our layer-wise analysis reveals that safety behaviors are governed by stable and shared internal representations. Overall, SafeNeuron provides an interpretable and robust perspective for model alignment.]]></description>
<pubDate>Thu, 12 Feb 2026 16:40:05 +0000</pubDate>
</item>
<item>
<title><![CDATA[TexSpot: 3D Texture Enhancement with Spatially-uniform Point Latent Representation]]></title>
<link>http://arxiv.org/abs/2602.12157v1</link>
<guid>2602.12157v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.CV, cs.GR
Authors: Ziteng Lu, Yushuang Wu, Chongjie Ye, Yuda Qiu, Jing Shao et al.
Institution: 
Published: 2026-02-12
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

High-quality 3D texture generation remains a fundamental challenge due to the view-inconsistency inherent in current mainstream multi-view diffusion pipelines. Existing representations either rely on UV maps, which suffer from distortion during unwrapping, or point-based methods, which tightly couple texture fidelity to geometric density that limits high-resolution texture generation. To address these limitations, we introduce TexSpot, a diffusion-based texture enhancement framework. At its core is Texlet, a novel 3D texture representation that merges the geometric expressiveness of point-based 3D textures with the compactness of UV-based representation. Each Texlet latent vector encodes a local texture patch via a 2D encoder and is further aggregated using a 3D encoder to incorporate global shape context. A cascaded 3D-to-2D decoder reconstructs high-quality texture patches, enabling the Texlet space learning. Leveraging this representation, we train a diffusion transformer conditioned on Texlets to refine and enhance textures produced by multi-view diffusion methods. Extensive experiments demonstrate that TexSpot significantly improves visual fidelity, geometric consistency, and robustness over existing state-of-the-art 3D texture generation and enhancement approaches. Project page: https://anonymous.4open.science/w/TexSpot-page-2D91.]]></description>
<pubDate>Thu, 12 Feb 2026 16:37:31 +0000</pubDate>
</item>
<item>
<title><![CDATA[FAIL: Flow Matching Adversarial Imitation Learning for Image Generation]]></title>
<link>http://arxiv.org/abs/2602.12155v1</link>
<guid>2602.12155v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.CV
Authors: Yeyao Ma, Chen Li, Xiaosong Zhang, Han Hu, Weidi Xie
Institution: 
Published: 2026-02-12
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Post-training of flow matching models-aligning the output distribution with a high-quality target-is mathematically equivalent to imitation learning. While Supervised Fine-Tuning mimics expert demonstrations effectively, it cannot correct policy drift in unseen states. Preference optimization methods address this but require costly preference pairs or reward modeling. We propose Flow Matching Adversarial Imitation Learning (FAIL), which minimizes policy-expert divergence through adversarial training without explicit rewards or pairwise comparisons. We derive two algorithms: FAIL-PD exploits differentiable ODE solvers for low-variance pathwise gradients, while FAIL-PG provides a black-box alternative for discrete or computationally constrained settings. Fine-tuning FLUX with only 13,000 demonstrations from Nano Banana pro, FAIL achieves competitive performance on prompt following and aesthetic benchmarks. Furthermore, the framework generalizes effectively to discrete image and video generation, and functions as a robust regularizer to mitigate reward hacking in reward-based optimization. Code and data are available at https://github.com/HansPolo113/FAIL.]]></description>
<pubDate>Thu, 12 Feb 2026 16:36:33 +0000</pubDate>
</item>
<item>
<title><![CDATA[GPT-4o Lacks Core Features of Theory of Mind]]></title>
<link>http://arxiv.org/abs/2602.12150v1</link>
<guid>2602.12150v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.AI, cs.CL, cs.LG
Authors: John Muchovej, Amanda Royka, Shane Lee, Julian Jara-Ettinger
Institution: 
Published: 2026-02-12
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Do Large Language Models (LLMs) possess a Theory of Mind (ToM)? Research into this question has focused on evaluating LLMs against benchmarks and found success across a range of social tasks. However, these evaluations do not test for the actual representations posited by ToM: namely, a causal model of mental states and behavior. Here, we use a cognitively-grounded definition of ToM to develop and test a new evaluation framework. Specifically, our approach probes whether LLMs have a coherent, domain-general, and consistent model of how mental states cause behavior -- regardless of whether that model matches a human-like ToM. We find that even though LLMs succeed in approximating human judgments in a simple ToM paradigm, they fail at a logically equivalent task and exhibit low consistency between their action predictions and corresponding mental state inferences. As such, these findings suggest that the social proficiency exhibited by LLMs is not the result of an domain-general or consistent ToM.]]></description>
<pubDate>Thu, 12 Feb 2026 16:33:58 +0000</pubDate>
</item>
<item>
<title><![CDATA[It's TIME: Towards the Next Generation of Time Series Forecasting Benchmarks]]></title>
<link>http://arxiv.org/abs/2602.12147v1</link>
<guid>2602.12147v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.LG
Authors: Zhongzheng Qiao, Sheng Pan, Anni Wang, Viktoriya Zhukova, Yong Liu et al.
Institution: 
Published: 2026-02-12
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Time series foundation models (TSFMs) are revolutionizing the forecasting landscape from specific dataset modeling to generalizable task evaluation. However, we contend that existing benchmarks exhibit common limitations in four dimensions: constrained data composition dominated by reused legacy sources, compromised data integrity lacking rigorous quality assurance, misaligned task formulations detached from real-world contexts, and rigid analysis perspectives that obscure generalizable insights. To bridge these gaps, we introduce TIME, a next-generation task-centric benchmark comprising 50 fresh datasets and 98 forecasting tasks, tailored for strict zero-shot TSFM evaluation free from data leakage. Integrating large language models and human expertise, we establish a rigorous human-in-the-loop benchmark construction pipeline to ensure high data integrity and redefine task formulation by aligning forecasting configurations with real-world operational requirements and variate predictability. Furthermore, we propose a novel pattern-level evaluation perspective that moves beyond traditional dataset-level evaluations based on static meta labels. By leveraging structural time series features to characterize intrinsic temporal properties, this approach offers generalizable insights into model capabilities across diverse patterns. We evaluate 12 representative TSFMs and establish a multi-granular leaderboard to facilitate in-depth analysis and visualized inspection. The leaderboard is available at https://huggingface.co/spaces/Real-TSF/TIME-leaderboard.]]></description>
<pubDate>Thu, 12 Feb 2026 16:31:01 +0000</pubDate>
</item>
<item>
<title><![CDATA[Seq2Seq2Seq: Lossless Data Compression via Discrete Latent Transformers and Reinforcement Learning]]></title>
<link>http://arxiv.org/abs/2602.12146v1</link>
<guid>2602.12146v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.AI, cs.CL, cs.IT
Authors: Mahdi Khodabandeh, Ghazal Shabani, Arash Yousefi Jordehi, Seyed Abolghasem Mirroshandel
Institution: 
Published: 2026-02-12
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Efficient lossless compression is essential for minimizing storage costs and transmission overhead while preserving data integrity. Traditional compression techniques, such as dictionary-based and statistical methods, often struggle to optimally exploit the structure and redundancy in complex data formats. Recent advancements in deep learning have opened new avenues for compression; however, many existing approaches depend on dense vector representations that obscure the underlying token structure. To address these limitations, we propose a novel lossless compression method that leverages Reinforcement Learning applied to a T5 language model architecture. This approach enables the compression of data into sequences of tokens rather than traditional vector representations. Unlike auto-encoders, which typically encode information into continuous latent spaces, our method preserves the token-based structure, aligning more closely with the original data format. This preservation allows for higher compression ratios while maintaining semantic integrity. By training the model using an off-policy Reinforcement Learning algorithm, we optimize sequence length to minimize redundancy and enhance compression efficiency. Our method introduces an efficient and adaptive data compression system built upon advanced Reinforcement Learning techniques, functioning independently of external grammatical or world knowledge. This approach shows significant improvements in compression ratios compared to conventional methods. By leveraging the latent information within language models, our system effectively compresses data without requiring explicit content understanding, paving the way for more robust and practical compression solutions across various applications.]]></description>
<pubDate>Thu, 12 Feb 2026 16:30:55 +0000</pubDate>
</item>
<item>
<title><![CDATA[On the Adoption of AI Coding Agents in Open-source Android and iOS Development]]></title>
<link>http://arxiv.org/abs/2602.12144v1</link>
<guid>2602.12144v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.SE, cs.AI
Authors: Muhammad Ahmad Khan, Hasnain Ali, Muneeb Rana, Muhammad Saqib Ilyas, Abdul Ali Bangash
Institution: 
Published: 2026-02-12
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

AI coding agents are increasingly contributing to software development, yet their impact on mobile development has received little empirical attention. In this paper, we present the first category-level empirical study of agent-generated code in open-source mobile app projects. We analyzed PR acceptance behaviors across mobile platforms, agents, and task categories using 2,901 AI-authored pull requests (PRs) in 193 verified Android and iOS open-source GitHub repositories in the AIDev dataset. We find that Android projects have received 2x more AI-authored PRs and have achieved higher PR acceptance rate (71%) than iOS (63%), with significant agent-level variation on Android. Across task categories, PRs with routine tasks (feature, fix, and ui) achieve the highest acceptance, while structural changes like refactor and build achieve lower success and longer resolution times. Furthermore, our evolution analysis shows improvement in PR resolution time on Android through mid-2025 before it declined again. Our findings offer the first evidence-based characterization of AI agents effects on OSS mobile projects and establish empirical baselines for evaluating agent-generated contributions to design platform aware agentic systems.]]></description>
<pubDate>Thu, 12 Feb 2026 16:30:29 +0000</pubDate>
</item>
<item>
<title><![CDATA[STAR : Bridging Statistical and Agentic Reasoning for Large Model Performance Prediction]]></title>
<link>http://arxiv.org/abs/2602.12143v1</link>
<guid>2602.12143v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.AI, cs.LG
Authors: Xiaoxiao Wang, Chunxiao Li, Junying Wang, Yijin Guo, Zijian Chen et al.
Institution: 
Published: 2026-02-12
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

As comprehensive large model evaluation becomes prohibitively expensive, predicting model performance from limited observations has become essential. However, existing statistical methods struggle with pattern shifts, data sparsity, and lack of explanation, while pure LLM methods remain unreliable. We propose STAR, a framework that bridges data-driven STatistical expectations with knowledge-driven Agentic Reasoning. STAR leverages specialized retrievers to gather external knowledge and embeds semantic features into Constrained Probabilistic Matrix Factorization (CPMF) to generate statistical expectations with uncertainty. A reasoning module guided by Expectation Violation Theory (EVT) then refines predictions through intra-family analysis, cross-model comparison, and credibility-aware aggregation, producing adjustments with traceable explanations. Extensive experiments show that STAR consistently outperforms all baselines on both score-based and rank-based metrics, delivering a 14.46% gain in total score over the strongest statistical method under extreme sparsity, with only 1--2 observed scores per test model.]]></description>
<pubDate>Thu, 12 Feb 2026 16:30:07 +0000</pubDate>
</item>
<item>
<title><![CDATA[Oscillators Are All You Need: Irregular Time Series Modelling via Damped Harmonic Oscillators with Closed-Form Solutions]]></title>
<link>http://arxiv.org/abs/2602.12139v1</link>
<guid>2602.12139v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.LG
Authors: Yashas Shende, Aritra Das, Reva Laxmi Chauhan, Arghya Pathak, Debayan Gupta
Institution: 
Published: 2026-02-12
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Transformers excel at time series modelling through attention mechanisms that capture long-term temporal patterns. However, they assume uniform time intervals and therefore struggle with irregular time series. Neural Ordinary Differential Equations (NODEs) effectively handle irregular time series by modelling hidden states as continuously evolving trajectories. ContiFormers arxiv:2402.10635 combine NODEs with Transformers, but inherit the computational bottleneck of the former by using heavy numerical solvers. This bottleneck can be removed by using a closed-form solution for the given dynamical system - but this is known to be intractable in general! We obviate this by replacing NODEs with a novel linear damped harmonic oscillator analogy - which has a known closed-form solution. We model keys and values as damped, driven oscillators and expand the query in a sinusoidal basis up to a suitable number of modes. This analogy naturally captures the query-key coupling that is fundamental to any transformer architecture by modelling attention as a resonance phenomenon. Our closed-form solution eliminates the computational overhead of numerical ODE solvers while preserving expressivity. We prove that this oscillator-based parameterisation maintains the universal approximation property of continuous-time attention; specifically, any discrete attention matrix realisable by ContiFormer's continuous keys can be approximated arbitrarily well by our fixed oscillator modes. Our approach delivers both theoretical guarantees and scalability, achieving state-of-the-art performance on irregular time series benchmarks while being orders of magnitude faster.]]></description>
<pubDate>Thu, 12 Feb 2026 16:27:09 +0000</pubDate>
</item>
<item>
<title><![CDATA[CitiLink-Minutes: A Multilayer Annotated Dataset of Municipal Meeting Minutes]]></title>
<link>http://arxiv.org/abs/2602.12137v1</link>
<guid>2602.12137v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.CL
Authors: Ricardo Campos, Ana Filipa Pacheco, Ana Lusa Fernandes, Ins Cantante, Rute Rebouas et al.
Institution: 
Published: 2026-02-12
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

City councils play a crucial role in local governance, directly influencing citizens' daily lives through decisions made during municipal meetings. These deliberations are formally documented in meeting minutes, which serve as official records of discussions, decisions, and voting outcomes. Despite their importance, municipal meeting records have received little attention in Information Retrieval (IR) and Natural Language Processing (NLP), largely due to the lack of annotated datasets, which ultimately limit the development of computational models. To address this gap, we introduce CitiLink-Minutes, a multilayer dataset of 120 European Portuguese municipal meeting minutes from six municipalities. Unlike prior annotated datasets of parliamentary or video records, CitiLink-Minutes provides multilayer annotations and structured linkage of official written minutes. The dataset contains over one million tokens, with all personal identifiers de-identified. Each minute was manually annotated by two trained annotators and curated by an experienced linguist across three complementary dimensions: (1) metadata, (2) subjects of discussion, and (3) voting outcomes, totaling over 38,000 individual annotations. Released under FAIR principles and accompanied by baseline results on metadata extraction, topic classification, and vote labeling, CitiLink-Minutes demonstrates its potential for downstream NLP and IR tasks, while promoting transparent access to municipal decisions.]]></description>
<pubDate>Thu, 12 Feb 2026 16:22:55 +0000</pubDate>
</item>
<item>
<title><![CDATA[WavBench: Benchmarking Reasoning, Colloquialism, and Paralinguistics for End-to-End Spoken Dialogue Models]]></title>
<link>http://arxiv.org/abs/2602.12135v1</link>
<guid>2602.12135v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.CL
Authors: Yangzhuo Li, Shengpeng Ji, Yifu Chen, Tianle Liang, Haorong Ying et al.
Institution: 
Published: 2026-02-12
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

With the rapid integration of advanced reasoning capabilities into spoken dialogue models, the field urgently demands benchmarks that transcend simple interactions to address real-world complexity. However, current evaluations predominantly adhere to text-generation standards, overlooking the unique audio-centric characteristics of paralinguistics and colloquialisms, alongside the cognitive depth required by modern agents. To bridge this gap, we introduce WavBench, a comprehensive benchmark designed to evaluate realistic conversational abilities where prior works fall short. Uniquely, WavBench establishes a tripartite framework: 1) Pro subset, designed to rigorously challenge reasoning-enhanced models with significantly increased difficulty; 2) Basic subset, defining a novel standard for spoken colloquialism that prioritizes "listenability" through natural vocabulary, linguistic fluency, and interactive rapport, rather than rigid written accuracy; and 3) Acoustic subset, covering explicit understanding, generation, and implicit dialogue to rigorously evaluate comprehensive paralinguistic capabilities within authentic real-world scenarios. Through evaluating five state-of-the-art models, WavBench offers critical insights into the intersection of complex problem-solving, colloquial delivery, and paralinguistic fidelity, guiding the evolution of robust spoken dialogue models. The benchmark dataset and evaluation toolkit are available at https://naruto-2024.github.io/wavbench.github.io/.]]></description>
<pubDate>Thu, 12 Feb 2026 16:22:11 +0000</pubDate>
</item>
<item>
<title><![CDATA[Value Alignment Tax: Measuring Value Trade-offs in LLM Alignment]]></title>
<link>http://arxiv.org/abs/2602.12134v1</link>
<guid>2602.12134v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.AI, cs.HC
Authors: Jiajun Chen, Hua Shen
Institution: 
Published: 2026-02-12
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Existing work on value alignment typically characterizes value relations statically, ignoring how interventions - such as prompting, fine-tuning, or preference optimization - reshape the broader value system. We introduce the Value Alignment Tax (VAT), a framework that measures how alignment-induced changes propagate across interconnected values relative to achieved on-target gain. VAT captures the dynamics of value expression under alignment pressure. Using a controlled scenario-action dataset grounded in Schwartz value theory, we collect paired pre-post normative judgments and analyze alignment effects across models, values, and alignment strategies. Our results show that alignment often produces uneven, structured co-movement among values. These effects are invisible under conventional target-only evaluation, revealing systemic, process-level alignment risks and offering new insights into the dynamics of value alignment in LLMs.]]></description>
<pubDate>Thu, 12 Feb 2026 16:21:22 +0000</pubDate>
</item>
<item>
<title><![CDATA[Neutral Prompts, Non-Neutral People: Quantifying Gender and Skin-Tone Bias in Gemini Flash 2.5 Image and GPT Image 1.5]]></title>
<link>http://arxiv.org/abs/2602.12133v1</link>
<guid>2602.12133v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.AI, cs.CL, cs.CY, cs.HC
Authors: Roberto Balestri
Institution: 
Published: 2026-02-12
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

This study quantifies gender and skin-tone bias in two widely deployed commercial image generators - Gemini Flash 2.5 Image (NanoBanana) and GPT Image 1.5 - to test the assumption that neutral prompts yield demographically neutral outputs. We generated 3,200 photorealistic images using four semantically neutral prompts. The analysis employed a rigorous pipeline combining hybrid color normalization, facial landmark masking, and perceptually uniform skin tone quantification using the Monk (MST), PERLA, and Fitzpatrick scales. Neutral prompts produced highly polarized defaults. Both models exhibited a strong "default white" bias (>96% of outputs). However, they diverged sharply on gender: Gemini favored female-presenting subjects, while GPT favored male-presenting subjects with lighter skin tones. This research provides a large-scale, comparative audit of state-of-the-art models using an illumination-aware colorimetric methodology, distinguishing aesthetic rendering from underlying pigmentation in synthetic imagery. The study demonstrates that neutral prompts function as diagnostic probes rather than neutral instructions. It offers a robust framework for auditing algorithmic visual culture and challenges the sociolinguistic assumption that unmarked language results in inclusive representation.]]></description>
<pubDate>Thu, 12 Feb 2026 16:21:03 +0000</pubDate>
</item>
<item>
<title><![CDATA[A Rule-based Computational Model for Gaidhlig Morphology]]></title>
<link>http://arxiv.org/abs/2602.12132v1</link>
<guid>2602.12132v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.CL
Authors: Peter J Barclay
Institution: 
Published: 2026-02-12
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Language models and software tools are essential to support the continuing vitality of lesser-used languages; however, currently popular neural models require considerable data for training, which normally is not available for such low-resource languages. This paper describes work-in-progress to construct a rule-based model of Gaidhlig morphology using data from Wiktionary, arguing that rule-based systems effectively leverage limited sample data, support greater interpretability, and provide insights useful in the design of teaching materials. The use of SQL for querying the occurrence of different lexical patterns is investigated, and a declarative rule-base is presented that allows Python utilities to derive inflected forms of Gaidhlig words. This functionality could be used to support educational tools that teach or explain language patterns, for example, or to support higher level tools such as rule-based dependency parsers. This approach adds value to the data already present in Wiktionary by adapting it to new use-cases.]]></description>
<pubDate>Thu, 12 Feb 2026 16:20:17 +0000</pubDate>
</item>
<item>
<title><![CDATA[Towards Personalized Bangla Book Recommendation: A Large-Scale Multi-Entity Book Graph Dataset]]></title>
<link>http://arxiv.org/abs/2602.12129v1</link>
<guid>2602.12129v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.IR, cs.LG
Authors: Rahin Arefin Ahmed, Md. Anik Chowdhury, Sakil Ahmed Sheikh Reza, Devnil Bhattacharjee, Muhammad Abdullah Adnan et al.
Institution: 
Published: 2026-02-12
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Personalized book recommendation in Bangla literature has been constrained by the lack of structured, large-scale, and publicly available datasets. This work introduces RokomariBG, a large-scale, multi-entity heterogeneous book graph dataset designed to support research on personalized recommendation in a low-resource language setting. The dataset comprises 127,302 books, 63,723 users, 16,601 authors, 1,515 categories, 2,757 publishers, and 209,602 reviews, connected through eight relation types and organized as a comprehensive knowledge graph.
  To demonstrate the utility of the dataset, we provide a systematic benchmarking study on the Top-N recommendation task, evaluating a diverse set of representative recommendation models, including classical collaborative filtering methods, matrix factorization models, content-based approaches, graph neural networks, a hybrid matrix factorization model with side information, and a neural two-tower retrieval architecture. The benchmarking results highlight the importance of leveraging multi-relational structure and textual side information, with neural retrieval models achieving the strongest performance (NDCG@10 = 0.204). Overall, this work establishes a foundational benchmark and a publicly available resource for Bangla book recommendation research, enabling reproducible evaluation and future studies on recommendation in low-resource cultural domains. The dataset and code are publicly available at https://github.com/backlashblitz/Bangla-Book-Recommendation-Dataset]]></description>
<pubDate>Thu, 12 Feb 2026 16:18:55 +0000</pubDate>
</item>
<item>
<title><![CDATA[HLA: Hadamard Linear Attention]]></title>
<link>http://arxiv.org/abs/2602.12128v1</link>
<guid>2602.12128v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.AI
Authors: Hanno Ackermann, Hong Cai, Mohsen Ghafoorian, Amirhossein Habibian
Institution: 
Published: 2026-02-12
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

The attention mechanism is an important reason for the success of transformers. It relies on computing pairwise relations between tokens. To reduce the high computational cost of standard quadratic attention, linear attention has been proposed as an efficient approximation. It employs kernel functions that are applied independently to the inputs before the pairwise similarities are calculated. That allows for an efficient computational procedure which, however, amounts to a low-degree rational function approximating softmax.
  We propose Hadamard Linear Attention (HLA). Unlike previous works on linear attention, the nonlinearity in HLA is not applied separately to queries and keys, but, analogously to standard softmax attention, after the pairwise similarities have been computed. It will be shown that the proposed nonlinearity amounts to a higher-degree rational function to approximate softmax. An efficient computational scheme for the proposed method is derived that is similar to that of standard linear attention. In contrast to other approaches, no time-consuming tensor reshaping is necessary to apply the proposed algorithm. The effectiveness of the approach is demonstrated by applying it to a large diffusion transformer model for video generation, an application that involves very large amounts of tokens.]]></description>
<pubDate>Thu, 12 Feb 2026 16:16:47 +0000</pubDate>
</item>
<item>
<title><![CDATA[PosterOmni: Generalized Artistic Poster Creation via Task Distillation and Unified Reward Feedback]]></title>
<link>http://arxiv.org/abs/2602.12127v1</link>
<guid>2602.12127v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.CV
Authors: Sixiang Chen, Jianyu Lai, Jialin Gao, Hengyu Shi, Zhongying Liu et al.
Institution: 
Published: 2026-02-12
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Image-to-poster generation is a high-demand task requiring not only local adjustments but also high-level design understanding. Models must generate text, layout, style, and visual elements while preserving semantic fidelity and aesthetic coherence. The process spans two regimes: local editing, where ID-driven generation, rescaling, filling, and extending must preserve concrete visual entities; and global creation, where layout- and style-driven tasks rely on understanding abstract design concepts. These intertwined demands make image-to-poster a multi-dimensional process coupling entity-preserving editing with concept-driven creation under image-prompt control. To address these challenges, we propose PosterOmni, a generalized artistic poster creation framework that unlocks the potential of a base edit model for multi-task image-to-poster generation. PosterOmni integrates the two regimes, namely local editing and global creation, within a single system through an efficient data-distillation-reward pipeline: (i) constructing multi-scenario image-to-poster datasets covering six task types across entity-based and concept-based creation; (ii) distilling knowledge between local and global experts for supervised fine-tuning; and (iii) applying unified PosterOmni Reward Feedback to jointly align visual entity-preserving and aesthetic preference across all tasks. Additionally, we establish PosterOmni-Bench, a unified benchmark for evaluating both local editing and global creation. Extensive experiments show that PosterOmni significantly enhances reference adherence, global composition quality, and aesthetic harmony, outperforming all open-source baselines and even surpassing several proprietary systems.]]></description>
<pubDate>Thu, 12 Feb 2026 16:16:38 +0000</pubDate>
</item>
<item>
<title><![CDATA[Capability-Oriented Training Induced Alignment Risk]]></title>
<link>http://arxiv.org/abs/2602.12124v1</link>
<guid>2602.12124v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.LG, cs.CL
Authors: Yujun Zhou, Yue Huang, Han Bao, Kehan Guo, Zhenwen Liang et al.
Institution: 
Published: 2026-02-12
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

While most AI alignment research focuses on preventing models from generating explicitly harmful content, a more subtle risk is emerging: capability-oriented training induced exploitation. We investigate whether language models, when trained with reinforcement learning (RL) in environments with implicit loopholes, will spontaneously learn to exploit these flaws to maximize their reward, even without any malicious intent in their training. To test this, we design a suite of four diverse "vulnerability games", each presenting a unique, exploitable flaw related to context-conditional compliance, proxy metrics, reward tampering, and self-evaluation. Our experiments show that models consistently learn to exploit these vulnerabilities, discovering opportunistic strategies that significantly increase their reward at the expense of task correctness or safety. More critically, we find that these exploitative strategies are not narrow "tricks" but generalizable skills; they can be transferred to new tasks and even "distilled" from a capable teacher model to other student models through data alone. Our findings reveal that capability-oriented training induced risks pose a fundamental challenge to current alignment approaches, suggesting that future AI safety work must extend beyond content moderation to rigorously auditing and securing the training environments and reward mechanisms themselves. Code is available at https://github.com/YujunZhou/Capability_Oriented_Alignment_Risk.]]></description>
<pubDate>Thu, 12 Feb 2026 16:13:14 +0000</pubDate>
</item>
<item>
<title><![CDATA[Meta-Sel: Efficient Demonstration Selection for In-Context Learning via Supervised Meta-Learning]]></title>
<link>http://arxiv.org/abs/2602.12123v1</link>
<guid>2602.12123v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.LG, cs.AI, cs.CL
Authors: Xubin Wang, Weijia Jia
Institution: 
Published: 2026-02-12
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Demonstration selection is a practical bottleneck in in-context learning (ICL): under a tight prompt budget, accuracy can change substantially depending on which few-shot examples are included, yet selection must remain cheap enough to run per query over large candidate pools. We propose Meta-Sel, a lightweight supervised meta-learning approach for intent classification that learns a fast, interpretable scoring function for (candidate, query) pairs from labeled training data.
  Meta-Sel constructs a meta-dataset by sampling pairs from the training split and using class agreement as supervision, then trains a calibrated logistic regressor on two inexpensive meta-features: TF--IDF cosine similarity and a length-compatibility ratio. At inference time, the selector performs a single vectorized scoring pass over the full candidate pool and returns the top-k demonstrations, requiring no model fine-tuning, no online exploration, and no additional LLM calls. This yields deterministic rankings and makes the selection mechanism straightforward to audit via interpretable feature weights.
  Beyond proposing Meta-Sel, we provide a broad empirical study of demonstration selection, benchmarking 12 methods -- spanning prompt engineering baselines, heuristic selection, reinforcement learning, and influence-based approaches -- across four intent datasets and five open-source LLMs. Across this benchmark, Meta-Sel consistently ranks among the top-performing methods, is particularly effective for smaller models where selection quality can partially compensate for limited model capacity, and maintains competitive selection-time overhead.]]></description>
<pubDate>Thu, 12 Feb 2026 16:11:29 +0000</pubDate>
</item>
<item>
<title><![CDATA[Commencing-Student Enrolment Forecasting Under Data Sparsity with Time Series Foundation Models]]></title>
<link>http://arxiv.org/abs/2602.12120v1</link>
<guid>2602.12120v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.AI
Authors: Jittarin Jetwiriyanon, Teo Susnjak, Surangika Ranathunga
Institution: 
Published: 2026-02-12
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Many universities face increasing financial pressure and rely on accurate forecasts of commencing enrolments. However, enrolment forecasting in higher education is often data-sparse; annual series are short and affected by reporting changes and regime shifts. Popular classical approaches can be unreliable, as parameter estimation and model selection are unstable with short samples, and structural breaks degrade extrapolation. Recently, TSFMs have provided zero-shot priors, delivering strong gains in annual, data-sparse institutional forecasting under leakage-disciplined covariate construction. We benchmark multiple TSFM families in a zero-shot setting and test a compact, leakage-safe covariate set and introduce the Institutional Operating Conditions Index (IOCI), a transferable 0-100 regime covariate derived from time-stamped documentary evidence available at each forecast origin, alongside Google Trends demand proxies with stabilising feature engineering. Using an expanding-window backtest with strict vintage alignment, covariate-conditioned TSFMs perform on par with classical benchmarks without institution-specific training, with performance differences varying by cohort and model.]]></description>
<pubDate>Thu, 12 Feb 2026 16:10:42 +0000</pubDate>
</item>
<item>
<title><![CDATA[KAN-FIF: Spline-Parameterized Lightweight Physics-based Tropical Cyclone Estimation on Meteorological Satellite]]></title>
<link>http://arxiv.org/abs/2602.12117v1</link>
<guid>2602.12117v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.LG, cs.AI
Authors: Jiakang Shen, Qinghui Chen, Runtong Wang, Chenrui Xu, Jinglin Zhang et al.
Institution: 
Published: 2026-02-12
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Tropical cyclones (TC) are among the most destructive natural disasters, causing catastrophic damage to coastal regions through extreme winds, heavy rainfall, and storm surges. Timely monitoring of tropical cyclones is crucial for reducing loss of life and property, yet it is hindered by the computational inefficiency and high parameter counts of existing methods on resource-constrained edge devices. Current physics-guided models suffer from linear feature interactions that fail to capture high-order polynomial relationships between TC attributes, leading to inflated model sizes and hardware incompatibility. To overcome these challenges, this study introduces the Kolmogorov-Arnold Network-based Feature Interaction Framework (KAN-FIF), a lightweight multimodal architecture that integrates MLP and CNN layers with spline-parameterized KAN layers. For Maximum Sustained Wind (MSW) prediction, experiments demonstrate that the KAN-FIF framework achieves a $94.8\%$ reduction in parameters (0.99MB vs 19MB) and $68.7\%$ faster inference per sample (2.3ms vs 7.35ms) compared to baseline model Phy-CoCo, while maintaining superior accuracy with $32.5\%$ lower MAE. The offline deployment experiment of the FY-4 series meteorological satellite processor on the Qingyun-1000 development board achieved a 14.41ms per-sample inference latency with the KAN-FIF framework, demonstrating promising feasibility for operational TC monitoring and extending deployability to edge-device AI applications. The code is released at https://github.com/Jinglin-Zhang/KAN-FIF.]]></description>
<pubDate>Thu, 12 Feb 2026 16:07:39 +0000</pubDate>
</item>
<item>
<title><![CDATA[P-GenRM: Personalized Generative Reward Model with Test-time User-based Scaling]]></title>
<link>http://arxiv.org/abs/2602.12116v1</link>
<guid>2602.12116v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.CL
Authors: Pinyi Zhang, Ting-En Lin, Yuchuan Wu, Jingyang Chen, Zongqi Wang et al.
Institution: 
Published: 2026-02-12
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Personalized alignment of large language models seeks to adapt responses to individual user preferences, typically via reinforcement learning. A key challenge is obtaining accurate, user-specific reward signals in open-ended scenarios. Existing personalized reward models face two persistent limitations: (1) oversimplifying diverse, scenario-specific preferences into a small, fixed set of evaluation principles, and (2) struggling with generalization to new users with limited feedback. To this end, we propose P-GenRM, the first Personalized Generative Reward Model with test-time user-based scaling. P-GenRM transforms preference signals into structured evaluation chains that derive adaptive personas and scoring rubrics across various scenarios. It further clusters users into User Prototypes and introduces a dual-granularity scaling mechanism: at the individual level, it adaptively scales and aggregates each user's scoring scheme; at the prototype level, it incorporates preferences from similar users. This design mitigates noise in inferred preferences and enhances generalization to unseen users through prototype-based transfer. Empirical results show that P-GenRM achieves state-of-the-art results on widely-used personalized reward model benchmarks, with an average improvement of 2.31%, and demonstrates strong generalization on an out-of-distribution dataset. Notably, Test-time User-based scaling provides an additional 3% boost, demonstrating stronger personalized alignment with test-time scalability.]]></description>
<pubDate>Thu, 12 Feb 2026 16:07:22 +0000</pubDate>
</item>
<item>
<title><![CDATA[Stop Unnecessary Reflection: Training LRMs for Efficient Reasoning with Adaptive Reflection and Length Coordinated Penalty]]></title>
<link>http://arxiv.org/abs/2602.12113v1</link>
<guid>2602.12113v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.AI, cs.CL
Authors: Zewei Yu, Lirong Gao, Yuke Zhu, Bo Zheng, Sheng Guo et al.
Institution: 
Published: 2026-02-12
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Large Reasoning Models (LRMs) have demonstrated remarkable performance on complex reasoning tasks by employing test-time scaling. However, they often generate over-long chains-of-thought that, driven by substantial reflections such as repetitive self-questioning and circular reasoning, lead to high token consumption, substantial computational overhead, and increased latency without improving accuracy, particularly in smaller models. Our observation reveals that increasing problem complexity induces more excessive and unnecessary reflection, which in turn reduces accuracy and increases token overhead. To address this challenge, we propose Adaptive Reflection and Length Coordinated Penalty (ARLCP), a novel reinforcement learning framework designed to dynamically balance reasoning efficiency and solution accuracy. ARLCP introduces two key innovations: (1) a reflection penalty that adaptively curtails unnecessary reflective steps while preserving essential reasoning, and (2) a length penalty calibrated to the estimated complexity of the problem. By coordinating these penalties, ARLCP encourages the model to generate more concise and effective reasoning paths. We evaluate our method on five mathematical reasoning benchmarks using DeepSeek-R1-Distill-Qwen-1.5B and DeepSeek-R1-Distill-Qwen-7B models. Experimental results show that ARLCP achieves a superior efficiency-accuracy trade-off compared to existing approaches. For the 1.5B model, it reduces the average response length by 53.1% while simultaneously improving accuracy by 5.8%. For the 7B model, it achieves a 35.0% reduction in length with a 2.7% accuracy gain. The code is released at https://github.com/ZeweiYu1/ARLCP .]]></description>
<pubDate>Thu, 12 Feb 2026 16:04:00 +0000</pubDate>
</item>
<item>
<title><![CDATA[Few-Shot Design Optimization by Exploiting Auxiliary Information]]></title>
<link>http://arxiv.org/abs/2602.12112v1</link>
<guid>2602.12112v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.LG
Authors: Arjun Mani, Carl Vondrick, Richard Zemel
Institution: 
Published: 2026-02-12
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Many real-world design problems involve optimizing an expensive black-box function $f(x)$, such as hardware design or drug discovery. Bayesian Optimization has emerged as a sample-efficient framework for this problem. However, the basic setting considered by these methods is simplified compared to real-world experimental setups, where experiments often generate a wealth of useful information. We introduce a new setting where an experiment generates high-dimensional auxiliary information $h(x)$ along with the performance measure $f(x)$; moreover, a history of previously solved tasks from the same task family is available for accelerating optimization. A key challenge of our setting is learning how to represent and utilize $h(x)$ for efficiently solving new optimization tasks beyond the task history. We develop a novel approach for this setting based on a neural model which predicts $f(x)$ for unseen designs given a few-shot context containing observations of $h(x)$. We evaluate our method on two challenging domains, robotic hardware design and neural network hyperparameter tuning, and introduce a novel design problem and large-scale benchmark for the former. On both domains, our method utilizes auxiliary feedback effectively to achieve more accurate few-shot prediction and faster optimization of design tasks, significantly outperforming several methods for multi-task optimization.]]></description>
<pubDate>Thu, 12 Feb 2026 16:03:46 +0000</pubDate>
</item>
<item>
<title><![CDATA[On the Complexity of Offline Reinforcement Learning with $Q^\star$-Approximation and Partial Coverage]]></title>
<link>http://arxiv.org/abs/2602.12107v1</link>
<guid>2602.12107v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.LG, cs.AI, stat.ML
Authors: Haolin Liu, Braham Snyder, Chen-Yu Wei
Institution: 
Published: 2026-02-12
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

We study offline reinforcement learning under $Q^\star$-approximation and partial coverage, a setting that motivates practical algorithms such as Conservative $Q$-Learning (CQL; Kumar et al., 2020) but has received limited theoretical attention. Our work is inspired by the following open question: "Are $Q^\star$-realizability and Bellman completeness sufficient for sample-efficient offline RL under partial coverage?"
  We answer in the negative by establishing an information-theoretic lower bound. Going substantially beyond this, we introduce a general framework that characterizes the intrinsic complexity of a given $Q^\star$ function class, inspired by model-free decision-estimation coefficients (DEC) for online RL (Foster et al., 2023b; Liu et al., 2025b). This complexity recovers and improves the quantities underlying the guarantees of Chen and Jiang (2022) and Uehara et al. (2023), and extends to broader settings. Our decision-estimation decomposition can be combined with a wide range of $Q^\star$ estimation procedures, modularizing and generalizing existing approaches.
  Beyond the general framework, we make further contributions: By developing a novel second-order performance difference lemma, we obtain the first $^{-2}$ sample complexity under partial coverage for soft $Q$-learning, improving the $^{-4}$ bound of Uehara et al. (2023). We remove Chen and Jiang's (2022) need for additional online interaction when the value gap of $Q^\star$ is unknown. We also give the first characterization of offline learnability for general low-Bellman-rank MDPs without Bellman completeness (Jiang et al., 2017; Du et al., 2021; Jin et al., 2021), a canonical setting in online RL that remains unexplored in offline RL except for special cases. Finally, we provide the first analysis for CQL under $Q^\star$-realizability and Bellman completeness beyond the tabular case.]]></description>
<pubDate>Thu, 12 Feb 2026 15:59:42 +0000</pubDate>
</item>
<item>
<title><![CDATA[Iskra: A System for Inverse Geometry Processing]]></title>
<link>http://arxiv.org/abs/2602.12105v1</link>
<guid>2602.12105v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.GR, cs.CV, cs.LG
Authors: Ana Dodik, Ahmed H. Mahmoud, Justin Solomon
Institution: 
Published: 2026-02-12
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

We propose a system for differentiating through solutions to geometry processing problems. Our system differentiates a broad class of geometric algorithms, exploiting existing fast problem-specific schemes common to geometry processing, including local-global and ADMM solvers. It is compatible with machine learning frameworks, opening doors to new classes of inverse geometry processing applications. We marry the scatter-gather approach to mesh processing with tensor-based workflows and rely on the adjoint method applied to user-specified imperative code to generate an efficient backward pass behind the scenes. We demonstrate our approach by differentiating through mean curvature flow, spectral conformal parameterization, geodesic distance computation, and as-rigid-as-possible deformation, examining usability and performance on these applications. Our system allows practitioners to differentiate through existing geometry processing algorithms without needing to reformulate them, resulting in low implementation effort, fast runtimes, and lower memory requirements than differentiable optimization tools not tailored to geometry processing.]]></description>
<pubDate>Thu, 12 Feb 2026 15:59:06 +0000</pubDate>
</item>
<item>
<title><![CDATA[AssetFormer: Modular 3D Assets Generation with Autoregressive Transformer]]></title>
<link>http://arxiv.org/abs/2602.12100v1</link>
<guid>2602.12100v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.CV
Authors: Lingting Zhu, Shengju Qian, Haidi Fan, Jiayu Dong, Zhenchao Jin et al.
Institution: 
Published: 2026-02-12
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

The digital industry demands high-quality, diverse modular 3D assets, especially for user-generated content~(UGC). In this work, we introduce AssetFormer, an autoregressive Transformer-based model designed to generate modular 3D assets from textual descriptions. Our pilot study leverages real-world modular assets collected from online platforms. AssetFormer tackles the challenge of creating assets composed of primitives that adhere to constrained design parameters for various applications. By innovatively adapting module sequencing and decoding techniques inspired by language models, our approach enhances asset generation quality through autoregressive modeling. Initial results indicate the effectiveness of AssetFormer in streamlining asset creation for professional development and UGC scenarios. This work presents a flexible framework extendable to various types of modular 3D assets, contributing to the broader field of 3D content generation. The code is available at https://github.com/Advocate99/AssetFormer.]]></description>
<pubDate>Thu, 12 Feb 2026 15:55:21 +0000</pubDate>
</item>
<item>
<title><![CDATA[Multi Graph Search for High-Dimensional Robot Motion Planning]]></title>
<link>http://arxiv.org/abs/2602.12096v1</link>
<guid>2602.12096v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.RO, cs.AI
Authors: Itamar Mishani, Maxim Likhachev
Institution: 
Published: 2026-02-12
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Efficient motion planning for high-dimensional robotic systems, such as manipulators and mobile manipulators, is critical for real-time operation and reliable deployment. Although advances in planning algorithms have enhanced scalability to high-dimensional state spaces, these improvements often come at the cost of generating unpredictable, inconsistent motions or requiring excessive computational resources and memory. In this work, we introduce Multi-Graph Search (MGS), a search-based motion planning algorithm that generalizes classical unidirectional and bidirectional search to a multi-graph setting. MGS maintains and incrementally expands multiple implicit graphs over the state space, focusing exploration on high-potential regions while allowing initially disconnected subgraphs to be merged through feasible transitions as the search progresses. We prove that MGS is complete and bounded-suboptimal, and empirically demonstrate its effectiveness on a range of manipulation and mobile manipulation tasks. Demonstrations, benchmarks and code are available at https://multi-graph-search.github.io/.]]></description>
<pubDate>Thu, 12 Feb 2026 15:50:15 +0000</pubDate>
</item>
<item>
<title><![CDATA[DeepSight: An All-in-One LM Safety Toolkit]]></title>
<link>http://arxiv.org/abs/2602.12092v1</link>
<guid>2602.12092v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.CL, cs.AI, cs.CR, cs.CV
Authors: Bo Zhang, Jiaxuan Guo, Lijun Li, Dongrui Liu, Sujin Chen et al.
Institution: 
Published: 2026-02-12
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

As the development of Large Models (LMs) progresses rapidly, their safety is also a priority. In current Large Language Models (LLMs) and Multimodal Large Language Models (MLLMs) safety workflow, evaluation, diagnosis, and alignment are often handled by separate tools. Specifically, safety evaluation can only locate external behavioral risks but cannot figure out internal root causes. Meanwhile, safety diagnosis often drifts from concrete risk scenarios and remains at the explainable level. In this way, safety alignment lack dedicated explanations of changes in internal mechanisms, potentially degrading general capabilities. To systematically address these issues, we propose an open-source project, namely DeepSight, to practice a new safety evaluation-diagnosis integrated paradigm. DeepSight is low-cost, reproducible, efficient, and highly scalable large-scale model safety evaluation project consisting of a evaluation toolkit DeepSafe and a diagnosis toolkit DeepScan. By unifying task and data protocols, we build a connection between the two stages and transform safety evaluation from black-box to white-box insight. Besides, DeepSight is the first open source toolkit that support the frontier AI risk evaluation and joint safety evaluation and diagnosis.]]></description>
<pubDate>Thu, 12 Feb 2026 15:43:14 +0000</pubDate>
</item>
<item>
<title><![CDATA[Choose Your Agent: Tradeoffs in Adopting AI Advisors, Coaches, and Delegates in Multi-Party Negotiation]]></title>
<link>http://arxiv.org/abs/2602.12089v1</link>
<guid>2602.12089v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.GT, cs.AI, cs.HC
Authors: Kehang Zhu, Lithium Thain, Vivian Tsai, James Wexler, Crystal Qian
Institution: 
Published: 2026-02-12
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

As AI usage becomes more prevalent in social contexts, understanding agent-user interaction is critical to designing systems that improve both individual and group outcomes. We present an online behavioral experiment (N = 243) in which participants play three multi-turn bargaining games in groups of three. Each game, presented in randomized order, grants \textit{access to} a single LLM assistance modality: proactive recommendations from an \textit{Advisor}, reactive feedback from a \textit{Coach}, or autonomous execution by a \textit{Delegate}; all modalities are powered by an underlying LLM that achieves superhuman performance in an all-agent environment. On each turn, participants privately decide whether to act manually or use the AI modality available in that game. Despite preferring the \textit{Advisor} modality, participants achieve the highest mean individual gains with the \textit{Delegate}, demonstrating a preference-performance misalignment. Moreover, delegation generates positive externalities; even non-adopting users in \textit{access-to-delegate} treatment groups benefit by receiving higher-quality offers. Mechanism analysis reveals that the \textit{Delegate} agent acts as a market maker, injecting rational, Pareto-improving proposals that restructure the trading environment. Our research reveals a gap between agent capabilities and realized group welfare. While autonomous agents can exhibit super-human strategic performance, their impact on realized welfare gains can be constrained by interfaces, user perceptions, and adoption barriers. Assistance modalities should be designed as mechanisms with endogenous participation; adoption-compatible interaction rules are a prerequisite to improving human welfare with automated assistance.]]></description>
<pubDate>Thu, 12 Feb 2026 15:41:57 +0000</pubDate>
</item>
<item>
<title><![CDATA[Geometry of Uncertainty: Learning Metric Spaces for Multimodal State Estimation in RL]]></title>
<link>http://arxiv.org/abs/2602.12087v1</link>
<guid>2602.12087v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.LG
Authors: Alfredo Reichlin, Adriano Pacciarelli, Danica Kragic, Miguel Vasco
Institution: 
Published: 2026-02-12
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Estimating the state of an environment from high-dimensional, multimodal, and noisy observations is a fundamental challenge in reinforcement learning (RL). Traditional approaches rely on probabilistic models to account for the uncertainty, but often require explicit noise assumptions, in turn limiting generalization. In this work, we contribute a novel method to learn a structured latent representation, in which distances between states directly correlate with the minimum number of actions required to transition between them. The proposed metric space formulation provides a geometric interpretation of uncertainty without the need for explicit probabilistic modeling. To achieve this, we introduce a multimodal latent transition model and a sensor fusion mechanism based on inverse distance weighting, allowing for the adaptive integration of multiple sensor modalities without prior knowledge of noise distributions. We empirically validate the approach on a range of multimodal RL tasks, demonstrating improved robustness to sensor noise and superior state estimation compared to baseline methods. Our experiments show enhanced performance of an RL agent via the learned representation, eliminating the need of explicit noise augmentation. The presented results suggest that leveraging transition-aware metric spaces provides a principled and scalable solution for robust state estimation in sequential decision-making.]]></description>
<pubDate>Thu, 12 Feb 2026 15:41:20 +0000</pubDate>
</item>
<item>
<title><![CDATA[Differentiable Modal Logic for Multi-Agent Diagnosis, Orchestration and Communication]]></title>
<link>http://arxiv.org/abs/2602.12083v1</link>
<guid>2602.12083v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.AI, cs.LO
Authors: Antonin Sulc
Institution: 
Published: 2026-02-12
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

As multi-agent AI systems evolve from simple chatbots to autonomous swarms, debugging semantic failures requires reasoning about knowledge, belief, causality, and obligation, precisely what modal logic was designed to formalize. However, traditional modal logic requires manual specification of relationship structures that are unknown or dynamic in real systems. This tutorial demonstrates differentiable modal logic (DML), implemented via Modal Logical Neural Networks (MLNNs), enabling systems to learn trust networks, causal chains, and regulatory boundaries from behavioral data alone.
  We present a unified neurosymbolic debugging framework through four modalities: epistemic (who to trust), temporal (when events cause failures), deontic (what actions are permitted), and doxastic (how to interpret agent confidence). Each modality is demonstrated on concrete multi-agent scenarios, from discovering deceptive alliances in diplomacy games to detecting LLM hallucinations, with complete implementations showing how logical contradictions become learnable optimization objectives. Key contributions for the neurosymbolic community: (1) interpretable learned structures where trust and causality are explicit parameters, not opaque embeddings; (2) knowledge injection via differentiable axioms that guide learning with sparse data (3) compositional multi-modal reasoning that combines epistemic, temporal, and deontic constraints; and (4) practical deployment patterns for monitoring, active control and communication of multi-agent systems. All code provided as executable Jupyter notebooks.]]></description>
<pubDate>Thu, 12 Feb 2026 15:39:18 +0000</pubDate>
</item>
<item>
<title><![CDATA[Empirical Gaussian Processes]]></title>
<link>http://arxiv.org/abs/2602.12082v1</link>
<guid>2602.12082v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.LG, stat.ML
Authors: Jihao Andreas Lin, Sebastian Ament, Louis C. Tiao, David Eriksson, Maximilian Balandat et al.
Institution: 
Published: 2026-02-12
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Gaussian processes (GPs) are powerful and widely used probabilistic regression models, but their effectiveness in practice is often limited by the choice of kernel function. This kernel function is typically handcrafted from a small set of standard functions, a process that requires expert knowledge, results in limited adaptivity to data, and imposes strong assumptions on the hypothesis space. We study Empirical GPs, a principled framework for constructing flexible, data-driven GP priors that overcome these limitations. Rather than relying on standard parametric kernels, we estimate the mean and covariance functions empirically from a corpus of historical observations, enabling the prior to reflect rich, non-trivial covariance structures present in the data. Theoretically, we show that the resulting model converges to the GP that is closest (in KL-divergence sense) to the real data generating process. Practically, we formulate the problem of learning the GP prior from independent datasets as likelihood estimation and derive an Expectation-Maximization algorithm with closed-form updates, allowing the model handle heterogeneous observation locations across datasets. We demonstrate that Empirical GPs achieve competitive performance on learning curve extrapolation and time series forecasting benchmarks.]]></description>
<pubDate>Thu, 12 Feb 2026 15:39:08 +0000</pubDate>
</item>
<item>
<title><![CDATA[PathCRF: Ball-Free Soccer Event Detection via Possession Path Inference from Player Trajectories]]></title>
<link>http://arxiv.org/abs/2602.12080v1</link>
<guid>2602.12080v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.LG
Authors: Hyunsung Kim, Kunhee Lee, Sangwoo Seo, Sang-Ki Ko, Jinsung Yoon et al.
Institution: 
Published: 2026-02-12
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Despite recent advances in AI, event data collection in soccer still relies heavily on labor-intensive manual annotation. Although prior work has explored automatic event detection using player and ball trajectories, ball tracking also remains difficult to scale due to high infrastructural and operational costs. As a result, comprehensive data collection in soccer is largely confined to top-tier competitions, limiting the broader adoption of data-driven analysis in this domain. To address this challenge, this paper proposes PathCRF, a framework for detecting on-ball soccer events using only player tracking data. We model player trajectories as a fully connected dynamic graph and formulate event detection as the problem of selecting exactly one edge corresponding to the current possession state at each time step. To ensure logical consistency of the resulting edge sequence, we employ a Conditional Random Field (CRF) that forbids impossible transitions between consecutive edges. Both emission and transition scores dynamically computed from edge embeddings produced by a Set Attention-based backbone architecture. During inference, the most probable edge sequence is obtained via Viterbi decoding, and events such as ball controls or passes are detected whenever the selected edge changes between adjacent time steps. Experiments show that PathCRF produces accurate, logically consistent possession paths, enabling reliable downstream analyses while substantially reducing the need for manual event annotation. The source code is available at https://github.com/hyunsungkim-ds/pathcrf.git.]]></description>
<pubDate>Thu, 12 Feb 2026 15:37:31 +0000</pubDate>
</item>
<item>
<title><![CDATA[Tiny Recursive Reasoning with Mamba-2 Attention Hybrid]]></title>
<link>http://arxiv.org/abs/2602.12078v1</link>
<guid>2602.12078v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.AI, cs.CL
Authors: Wenlong Wang, Fergal Reid
Institution: 
Published: 2026-02-12
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Recent work on recursive reasoning models like TRM demonstrates that tiny networks (7M parameters) can achieve strong performance on abstract reasoning tasks through latent recursion -- iterative refinement in hidden representation space without emitting intermediate tokens. This raises a natural question about operator choice: Mamba-2's state space recurrence is itself a form of iterative refinement, making it a natural candidate for recursive reasoning -- but does introducing Mamba-2 into the recursive scaffold preserve reasoning capability? We investigate this by replacing the Transformer blocks in TRM with Mamba-2 hybrid operators while maintaining parameter parity (6.83M vs 6.86M parameters). On ARC-AGI-1, we find that the hybrid improves pass@2 (the official metric) by +2.0\% (45.88\% vs 43.88\%) and consistently outperforms at higher K values (+4.75\% at pass@100), whilst maintaining pass@1 parity. This suggests improved candidate coverage -- the model generates correct solutions more reliably -- with similar top-1 selection. Our results validate that Mamba-2 hybrid operators preserve reasoning capability within the recursive scaffold, establishing SSM-based operators as viable candidates in the recursive operator design space and taking a first step towards understanding the best mixing strategies for recursive reasoning.]]></description>
<pubDate>Thu, 12 Feb 2026 15:36:32 +0000</pubDate>
</item>
<item>
<title><![CDATA[ModelWisdom: An Integrated Toolkit for TLA+ Model Visualization, Digest and Repair]]></title>
<link>http://arxiv.org/abs/2602.12058v1</link>
<guid>2602.12058v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.SE, cs.AI, cs.FL
Authors: Zhiyong Chen, Jialun Cao, Chang Xu, Shing-Chi Cheung
Institution: 
Published: 2026-02-12
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Model checking in TLA+ provides strong correctness guarantees, yet practitioners continue to face significant challenges in interpreting counterexamples, understanding large state-transition graphs, and repairing faulty models. These difficulties stem from the limited explainability of raw model-checker output and the substantial manual effort required to trace violations back to source specifications. Although the TLA+ Toolbox includes a state diagram viewer, it offers only a static, fully expanded graph without folding, color highlighting, or semantic explanations, which limits its scalability and interpretability. We present ModelWisdom, an interactive environment that uses visualization and large language models to make TLA+ model checking more interpretable and actionable. ModelWisdom offers: (i) Model Visualization, with colorized violation highlighting, click-through links from transitions to TLA+ code, and mapping between violating states and broken properties; (ii) Graph Optimization, including tree-based structuring and node/edge folding to manage large models; (iii) Model Digest, which summarizes and explains subgraphs via large language models (LLMs) and performs preprocessing and partial explanations; and (iv) Model Repair, which extracts error information and supports iterative debugging. Together, these capabilities turn raw model-checker output into an interactive, explainable workflow, improving understanding and reducing debugging effort for nontrivial TLA+ specifications. The website to ModelWisdom is available: https://model-wisdom.pages.dev. A demonstrative video can be found at https://www.youtube.com/watch?v=plyZo30VShA.]]></description>
<pubDate>Thu, 12 Feb 2026 15:19:18 +0000</pubDate>
</item>
<item>
<title><![CDATA[Multi UAVs Preflight Planning in a Shared and Dynamic Airspace]]></title>
<link>http://arxiv.org/abs/2602.12055v1</link>
<guid>2602.12055v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.AI, cs.MA, cs.RO
Authors: Amath Sow, Mauricio Rodriguez Cesen, Fabiola Martins Campos de Oliveira, Mariusz Wzorek, Daniel de Leng et al.
Institution: 
Published: 2026-02-12
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Preflight planning for large-scale Unmanned Aerial Vehicle (UAV) fleets in dynamic, shared airspace presents significant challenges, including temporal No-Fly Zones (NFZs), heterogeneous vehicle profiles, and strict delivery deadlines. While Multi-Agent Path Finding (MAPF) provides a formal framework, existing methods often lack the scalability and flexibility required for real-world Unmanned Traffic Management (UTM). We propose DTAPP-IICR: a Delivery-Time Aware Prioritized Planning method with Incremental and Iterative Conflict Resolution. Our framework first generates an initial solution by prioritizing missions based on urgency. Secondly, it computes roundtrip trajectories using SFIPP-ST, a novel 4D single-agent planner (Safe Flight Interval Path Planning with Soft and Temporal Constraints). SFIPP-ST handles heterogeneous UAVs, strictly enforces temporal NFZs, and models inter-agent conflicts as soft constraints. Subsequently, an iterative Large Neighborhood Search, guided by a geometric conflict graph, efficiently resolves any residual conflicts. A completeness-preserving directional pruning technique further accelerates the 3D search. On benchmarks with temporal NFZs, DTAPP-IICR achieves near-100% success with fleets of up to 1,000 UAVs and gains up to 50% runtime reduction from pruning, outperforming batch Enhanced Conflict-Based Search in the UTM context. Scaling successfully in realistic city-scale operations where other priority-based methods fail even at moderate deployments, DTAPP-IICR is positioned as a practical and scalable solution for preflight planning in dense, dynamic urban airspace.]]></description>
<pubDate>Thu, 12 Feb 2026 15:18:46 +0000</pubDate>
</item>
<item>
<title><![CDATA[Improving HPC Code Generation Capability of LLMs via Online Reinforcement Learning with Real-Machine Benchmark Rewards]]></title>
<link>http://arxiv.org/abs/2602.12049v1</link>
<guid>2602.12049v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.LG
Authors: Ryo Mikasa, Shun-ichiro Hayashi, Daichi Mukunoki, Tetsuya Hoshino, Takahiro Katagiri
Institution: 
Published: 2026-02-12
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Large language models (LLMs) have demonstrated strong code generation capabilities, yet the runtime performance of generated code is not guaranteed, and there have been few attempts to train LLMs using runtime performance as a reward in the HPC domain. We propose an online reinforcement learning approach that executes LLM-generated code on a supercomputer and directly feeds back the measured runtime performance (GFLOPS) as a reward. We further introduce a Staged Quality-Diversity (SQD) algorithm that progressively varies the permitted optimization techniques on a per-problem basis, enabling the model to learn code optimization from diverse perspectives. We build a distributed system connecting a GPU training cluster with a CPU benchmarking cluster, and train Qwen2.5 Coder 14B on a double-precision matrix multiplication task using Group Relative Policy Optimization (GRPO). Through two experiments, we show that reinforcement learning combining runtime performance feedback with staged optimization can improve the HPC code generation capability of LLMs.]]></description>
<pubDate>Thu, 12 Feb 2026 15:12:59 +0000</pubDate>
</item>
<item>
<title><![CDATA[Safety Beyond the Training Data: Robust Out-of-Distribution MPC via Conformalized System Level Synthesis]]></title>
<link>http://arxiv.org/abs/2602.12047v1</link>
<guid>2602.12047v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.RO, cs.LG
Authors: Anutam Srinivasan, Antoine Leeman, Glen Chou
Institution: 
Published: 2026-02-12
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

We present a novel framework for robust out-of-distribution planning and control using conformal prediction (CP) and system level synthesis (SLS), addressing the challenge of ensuring safety and robustness when using learned dynamics models beyond the training data distribution. We first derive high-confidence model error bounds using weighted CP with a learned, state-control-dependent covariance model. These bounds are integrated into an SLS-based robust nonlinear model predictive control (MPC) formulation, which performs constraint tightening over the prediction horizon via volume-optimized forward reachable sets. We provide theoretical guarantees on coverage and robustness under distributional drift, and analyze the impact of data density and trajectory tube size on prediction coverage. Empirically, we demonstrate our method on nonlinear systems of increasing complexity, including a 4D car and a {12D} quadcopter, improving safety and robustness compared to fixed-bound and non-robust baselines, especially outside of the data distribution.]]></description>
<pubDate>Thu, 12 Feb 2026 15:11:44 +0000</pubDate>
</item>
<item>
<title><![CDATA[Fourier Transformers for Latent Crystallographic Diffusion and Generative Modeling]]></title>
<link>http://arxiv.org/abs/2602.12045v1</link>
<guid>2602.12045v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.LG, cs.AI
Authors: Jed A. Duersch, Elohan Veillon, Astrid Klipfel, Adlane Sayede, Zied Bouraoui
Institution: 
Published: 2026-02-12
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

The discovery of new crystalline materials calls for generative models that handle periodic boundary conditions, crystallographic symmetries, and physical constraints, while scaling to large and structurally diverse unit cells. We propose a reciprocal-space generative pipeline that represents crystals through a truncated Fourier transform of the species-resolved unit-cell density, rather than modeling atomic coordinates directly. This representation is periodicity-native, admits simple algebraic actions of space-group symmetries, and naturally supports variable atomic multiplicities during generation, addressing a common limitation of particle-based approaches. Using only nine Fourier basis functions per spatial dimension, our approach reconstructs unit cells containing up to 108 atoms per chemical species. We instantiate this pipeline with a transformer variational autoencoder over complex-valued Fourier coefficients, and a latent diffusion model that generates in the compressed latent space. We evaluate reconstruction and latent diffusion on the LeMaterial benchmark and compare unconditional generation against coordinate-based baselines in the small-cell regime ($\leq 16$ atoms per unit cell).]]></description>
<pubDate>Thu, 12 Feb 2026 15:11:12 +0000</pubDate>
</item>
<item>
<title><![CDATA[A DMD-Based Adaptive Modulation Method for High Dynamic Range Imaging in High-Glare Environments]]></title>
<link>http://arxiv.org/abs/2602.12044v1</link>
<guid>2602.12044v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.CV
Authors: Banglei Guan, Jing Tao, Liang Xu, Dongcai Tan, Pengju Sun et al.
Institution: 
Published: 2026-02-12
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Background The accuracy of photomechanics measurements critically relies on image quality,particularly under extreme illumination conditions such as welding arc monitoring and polished metallic surface analysis. High dynamic range (HDR) imaging above 120 dB is essential in these contexts. Conventional CCD/CMOS sensors, with dynamic ranges typically below 70 dB, are highly susceptible to saturation under glare, resulting in irreversible loss of detail and significant errors in digital image correlation (DIC). Methods This paper presents an HDR imaging system that leverages the spatial modulation capability of a digital micromirror device (DMD). The system architecture enables autonomous regional segmentation and adaptive exposure control for high-dynamic-range scenes through an integrated framework comprising two synergistic subsystems: a DMD-based optical modulation unit and an adaptive computational imaging pipeline. Results The system achieves a measurable dynamic range of 127 dB, effectively eliminating satu ration artifacts under high glare. Experimental results demonstrate a 78% reduction in strain error and improved DIC positioning accuracy, confirming reliable performance across extreme intensity variations. Conclusion The DMD-based system provides high fidelity adaptive HDR imaging, overcoming key limitations of conventional sensors. It exhibits strong potential for optical metrology and stress analysis in high-glare environments where traditional methods are inadequate.]]></description>
<pubDate>Thu, 12 Feb 2026 15:10:25 +0000</pubDate>
</item>
<item>
<title><![CDATA[Improved Inference for CSDID Using the Cluster Jackknife]]></title>
<link>http://arxiv.org/abs/2602.12043v1</link>
<guid>2602.12043v1</guid>
<description><![CDATA[Source: arXiv
Tags: stat.ME, stat.ML
Authors: Sunny R. Karim, Morten rregaard Nielsen, James G. MacKinnon, Matthew D. Webb
Institution: 
Published: 2026-02-12
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Obtaining reliable inferences with traditional difference-in-differences (DiD) methods can be difficult. Problems can arise when both outcomes and errors are serially correlated, when there are few clusters or few treated clusters, when cluster sizes vary greatly, and in various other cases. In recent years, recognition of the ``staggered adoption'' problem has shifted the focus away from inference towards consistent estimation of treatment effects. One of the most popular new estimators is the CSDID procedure of Callaway and Sant'Anna (2021). We find that the issues of over-rejection with few clusters and/or few treated clusters are at least as severe for CSDID as for traditional DiD methods. We also propose using a cluster jackknife for inference with CSDID, which simulations suggest greatly improves inference. We provide software packages in Stata csdidjack and R didjack to calculate cluster-jackknife standard errors easily.]]></description>
<pubDate>Thu, 12 Feb 2026 15:08:23 +0000</pubDate>
</item>
<item>
<title><![CDATA[The Implicit Bias of Logit Regularization]]></title>
<link>http://arxiv.org/abs/2602.12039v1</link>
<guid>2602.12039v1</guid>
<description><![CDATA[Source: arXiv
Tags: stat.ML, cs.LG
Authors: Alon Beck, Yohai Bar Sinai, Noam Levi
Institution: 
Published: 2026-02-12
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Logit regularization, the addition a convex penalty directly in logit space, is widely used in modern classifiers, with label smoothing as a prominent example. While such methods often improve calibration and generalization, their mechanism remains under-explored. In this work, we analyze a general class of such logit regularizers in the context of linear classification, and demonstrate that they induce an implicit bias of logit clustering around finite per-sample targets. For Gaussian data, or whenever logits are sufficiently clustered, we prove that logit clustering drives the weight vector to align exactly with Fisher's Linear Discriminant. To demonstrate the consequences, we study a simple signal-plus-noise model in which this transition has dramatic effects: Logit regularization halves the critical sample complexity and induces grokking in the small-noise limit, while making generalization robust to noise. Our results extend the theoretical understanding of label smoothing and highlight the efficacy of a broader class of logit-regularization methods.]]></description>
<pubDate>Thu, 12 Feb 2026 15:06:08 +0000</pubDate>
</item>
<item>
<title><![CDATA[An Empirical Study of the Imbalance Issue in Software Vulnerability Detection]]></title>
<link>http://arxiv.org/abs/2602.12038v1</link>
<guid>2602.12038v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.SE, cs.AI
Authors: Yuejun Guo, Qiang Hu, Qiang Tang, Yves Le Traon
Institution: 
Published: 2026-02-12
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Vulnerability detection is crucial to protect software security. Nowadays, deep learning (DL) is the most promising technique to automate this detection task, leveraging its superior ability to extract patterns and representations within extensive code volumes. Despite its promise, DL-based vulnerability detection remains in its early stages, with model performance exhibiting variability across datasets. Drawing insights from other well-explored application areas like computer vision, we conjecture that the imbalance issue (the number of vulnerable code is extremely small) is at the core of the phenomenon. To validate this, we conduct a comprehensive empirical study involving nine open-source datasets and two state-of-the-art DL models. The results confirm our conjecture. We also obtain insightful findings on how existing imbalance solutions perform in vulnerability detection. It turns out that these solutions perform differently as well across datasets and evaluation metrics. Specifically: 1) Focal loss is more suitable to improve the precision, 2) mean false error and class-balanced loss encourages the recall, and 3) random over-sampling facilitates the F1-measure. However, none of them excels across all metrics. To delve deeper, we explore external influences on these solutions and offer insights for developing new solutions.]]></description>
<pubDate>Thu, 12 Feb 2026 15:05:47 +0000</pubDate>
</item>
<item>
<title><![CDATA[Composition-RL: Compose Your Verifiable Prompts for Reinforcement Learning of Large Language Models]]></title>
<link>http://arxiv.org/abs/2602.12036v1</link>
<guid>2602.12036v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.CL
Authors: Xin Xu, Clive Bai, Kai Yang, Tianhao Chen, Yangkun Chen et al.
Institution: 
Published: 2026-02-12
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Large-scale verifiable prompts underpin the success of Reinforcement Learning with Verifiable Rewards (RLVR), but they contain many uninformative examples and are costly to expand further. Recent studies focus on better exploiting limited training data by prioritizing hard prompts whose rollout pass rate is 0. However, easy prompts with a pass rate of 1 also become increasingly prevalent as training progresses, thereby reducing the effective data size. To mitigate this, we propose Composition-RL, a simple yet useful approach for better utilizing limited verifiable prompts targeting pass-rate-1 prompts. More specifically, Composition-RL automatically composes multiple problems into a new verifiable question and uses these compositional prompts for RL training. Extensive experiments across model sizes from 4B to 30B show that Composition-RL consistently improves reasoning capability over RL trained on the original dataset. Performance can be further boosted with a curriculum variant of Composition-RL that gradually increases compositional depth over training. Additionally, Composition-RL enables more effective cross-domain RL by composing prompts drawn from different domains. Codes, datasets, and models are available at https://github.com/XinXU-USTC/Composition-RL.]]></description>
<pubDate>Thu, 12 Feb 2026 15:03:37 +0000</pubDate>
</item>
<item>
<title><![CDATA[PrefillShare: A Shared Prefill Module for KV Reuse in Multi-LLM Disaggregated Serving]]></title>
<link>http://arxiv.org/abs/2602.12029v1</link>
<guid>2602.12029v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.LG, cs.DC
Authors: Sunghyeon Woo, Hoseung Kim, Sunghwan Shim, Minjung Jo, Hyunjoon Jeong et al.
Institution: 
Published: 2026-02-12
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Multi-agent systems increasingly orchestrate multiple specialized language models to solve complex real-world problems, often invoking them over a shared context. This execution pattern repeatedly processes the same prompt prefix across models. Consequently, each model redundantly executes the prefill stage and maintains its own key-value (KV) cache, increasing aggregate prefill load and worsening tail latency by intensifying prefill-decode interference in existing LLM serving stacks. Disaggregated serving reduces such interference by placing prefill and decode on separate GPUs, but disaggregation does not fundamentally eliminate inter-model redundancy in computation and KV storage for the same prompt. To address this issue, we propose PrefillShare, a novel algorithm that enables sharing the prefill stage across multiple models in a disaggregated setting. PrefillShare factorizes the model into prefill and decode modules, freezes the prefill module, and fine-tunes only the decode module. This design allows multiple task-specific models to share a prefill module and the KV cache generated for the same prompt. We further introduce a routing mechanism that enables effective prefill sharing across heterogeneous models in a vLLM-based disaggregated system. PrefillShare not only matches full fine-tuning accuracy on a broad range of tasks and models, but also delivers 4.5x lower p95 latency and 3.9x higher throughput in multi-model agent workloads.]]></description>
<pubDate>Thu, 12 Feb 2026 14:59:50 +0000</pubDate>
</item>
<item>
<title><![CDATA[Protein Circuit Tracing via Cross-layer Transcoders]]></title>
<link>http://arxiv.org/abs/2602.12026v1</link>
<guid>2602.12026v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.LG
Authors: Darin Tsui, Kunal Talreja, Daniel Saeedi, Amirali Aghazadeh
Institution: 
Published: 2026-02-12
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Protein language models (pLMs) have emerged as powerful predictors of protein structure and function. However, the computational circuits underlying their predictions remain poorly understood. Recent mechanistic interpretability methods decompose pLM representations into interpretable features, but they treat each layer independently and thus fail to capture cross-layer computation, limiting their ability to approximate the full model. We introduce ProtoMech, a framework for discovering computational circuits in pLMs using cross-layer transcoders that learn sparse latent representations jointly across layers to capture the model's full computational circuitry. Applied to the pLM ESM2, ProtoMech recovers 82-89% of the original performance on protein family classification and function prediction tasks. ProtoMech then identifies compressed circuits that use <1% of the latent space while retaining up to 79% of model accuracy, revealing correspondence with structural and functional motifs, including binding, signaling, and stability. Steering along these circuits enables high-fitness protein design, surpassing baseline methods in more than 70% of cases. These results establish ProtoMech as a principled framework for protein circuit tracing.]]></description>
<pubDate>Thu, 12 Feb 2026 14:57:57 +0000</pubDate>
</item>
<item>
<title><![CDATA[Decomposition of Spillover Effects Under Misspecification:Pseudo-true Estimands and a Local--Global Extension]]></title>
<link>http://arxiv.org/abs/2602.12023v1</link>
<guid>2602.12023v1</guid>
<description><![CDATA[Source: arXiv
Tags: stat.ML
Authors: Yechan Park, Xiaodong Yang
Institution: 
Published: 2026-02-12
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Applied work with interference typically models outcomes as functions of own treatment and a low-dimensional exposure mapping of others' treatments, even when that mapping may be misspecified. This raises a basic question: what policy object are exposure-based estimands implicitly targeting, and how should we interpret their direct and spillover components relative to the underlying policy question? We take as primitive the marginal policy effect, defined as the effect of a small change in the treatment probability under the actual experimental design, and show that any researcher-chosen exposure mapping induces a unique pseudo-true outcome model. This model is the best approximation to the underlying potential outcomes that depends only on the user-chosen exposure. Utilizing that representation, the marginal policy effect admits a canonical decomposition into exposure-based direct and spillover effects, and each component provides its optimal approximation to the corresponding oracle objects that would be available if interference were fully known. We then focus on a setting that nests important empirical and theoretical applications in which both local network spillovers and global spillovers, such as market equilibrium, operate. There, the marginal policy effect further decomposes asymptotically into direct, local, and global channels. An important implication is that many existing methods are more robust than previously understood once we reinterpret their targets as channel-specific components of this pseudo-true policy estimand. Simulations and a semi-synthetic experiment calibrated to a large cash-transfer experiment show that these components can be recovered in realistic experimental designs.]]></description>
<pubDate>Thu, 12 Feb 2026 14:54:28 +0000</pubDate>
</item>
<item>
<title><![CDATA[Improved state mixing in higher-order and block diagonal linear recurrent networks]]></title>
<link>http://arxiv.org/abs/2602.12021v1</link>
<guid>2602.12021v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.LG
Authors: Igor Dubinin, Antonio Orvieto, Felix Effenberger
Institution: 
Published: 2026-02-12
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Linear recurrent networks (LRNNs) and linear state space models (SSMs) promise computational and memory efficiency on long-sequence modeling tasks, yet their diagonal state transitions limit expressivity. Dense and nonlinear architectures (e.g., LSTMs) on the other hand are provably more expressive, but computationally costly. Here, we explore how expressivity in LRNNs can be increased via richer state mixing across time and channels while maintaining competitive efficiency. Specifically, we introduce two structured LRNN architectures: (i) Higher-order Linear Recurrent Units (H-LRU), which generalize first-order recurrence to higher order, mixing multiple past states, and (ii) Block-Diagonal LRUs (BD-LRU), which enable dense intra-block channel mixing. Per-channel (H-LRU) or per-row (BD-LRU) L1-normalization of selective gates stabilizes training and allows for scaling window/block sizes. A parallel-scan implementation of the proposed architectures keeps the throughput competitive with diagonal LRNNs for moderate orders (H-LRU) and block sizes (BD-LRU). In synthetic sequence modeling tasks, the performance of BD-LRU matches or exceeds those of linear SSMs (Mamba), low-rank LRNNs (DeltaNet) and LSTM baselines, while H-LRU is found to be the most parameter-efficient in compression task. In both synthetic sequence modeling and language modeling, our results indicate that the structure of state mixing rather than width alone shapes expressivity of LRNNs, offering a practical route to closing the efficiency-expressivity gap in linear sequence models.]]></description>
<pubDate>Thu, 12 Feb 2026 14:51:59 +0000</pubDate>
</item>
<item>
<title><![CDATA[Artificial intelligence is creating a new global linguistic hierarchy]]></title>
<link>http://arxiv.org/abs/2602.12018v1</link>
<guid>2602.12018v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.CY, cs.CL
Authors: Giulia Occhini, Kumiko Tanaka-Ishii, Anna Barford, Refael Tikochinski, Songbo Hu et al.
Institution: 
Published: 2026-02-12
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Artificial intelligence (AI) has the potential to transform healthcare, education, governance and socioeconomic equity, but its benefits remain concentrated in a small number of languages (Bender, 2019; Blasi et al., 2022; Joshi et al., 2020; Ranathunga and de Silva, 2022; Young, 2015). Language AI - the technologies that underpin widely-used conversational systems such as ChatGPT - could provide major benefits if available in people's native languages, yet most of the world's 7,000+ linguistic communities currently lack access and face persistent digital marginalization. Here we present a global longitudinal analysis of social, economic and infrastructural conditions across languages to assess systemic inequalities in language AI. We first analyze the existence of AI resources for 6003 languages. We find that despite efforts of the community to broaden the reach of language technologies (Bapna et al., 2022; Costa-Juss et al., 2022), the dominance of a handful of languages is exacerbating disparities on an unprecedented scale, with divides widening exponentially rather than narrowing. Further, we contrast the longitudinal diffusion of AI with that of earlier IT technologies, revealing a distinctive hype-driven pattern of spread. To translate our findings into practical insights and guide prioritization efforts, we introduce the Language AI Readiness Index (EQUATE), which maps the state of technological, socio-economic, and infrastructural prerequisites for AI deployment across languages. The index highlights communities where capacity exists but remains underutilized, and provides a framework for accelerating more equitable diffusion of language AI. Our work contributes to setting the baseline for a transition towards more sustainable and equitable language technologies.]]></description>
<pubDate>Thu, 12 Feb 2026 14:50:44 +0000</pubDate>
</item>
<item>
<title><![CDATA[Disentangling Ambiguity from Instability in Large Language Models: A Clinical Text-to-SQL Case Study]]></title>
<link>http://arxiv.org/abs/2602.12015v1</link>
<guid>2602.12015v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.CL
Authors: Angelo Ziletti, Leonardo D'Ambrosi
Institution: 
Published: 2026-02-12
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Deploying large language models for clinical Text-to-SQL requires distinguishing two qualitatively different causes of output diversity: (i) input ambiguity that should trigger clarification, and (ii) model instability that should trigger human review. We propose CLUES, a framework that models Text-to-SQL as a two-stage process (interpretations --> answers) and decomposes semantic uncertainty into an ambiguity score and an instability score. The instability score is computed via the Schur complement of a bipartite semantic graph matrix. Across AmbigQA/SituatedQA (gold interpretations) and a clinical Text-to-SQL benchmark (known interpretations), CLUES improves failure prediction over state-of-the-art Kernel Language Entropy. In deployment settings, it remains competitive while providing a diagnostic decomposition unavailable from a single score. The resulting uncertainty regimes map to targeted interventions - query refinement for ambiguity, model improvement for instability. The high-ambiguity/high-instability regime contains 51% of errors while covering 25% of queries, enabling efficient triage.]]></description>
<pubDate>Thu, 12 Feb 2026 14:46:20 +0000</pubDate>
</item>
<item>
<title><![CDATA[FedGRPO: Privately Optimizing Foundation Models with Group-Relative Rewards from Domain Client]]></title>
<link>http://arxiv.org/abs/2602.12014v1</link>
<guid>2602.12014v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.LG
Authors: Gongxi Zhu, Hanlin Gu, Lixin Fan, Qiang Yang, Yuxing Han
Institution: 
Published: 2026-02-12
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

One important direction of Federated Foundation Models (FedFMs) is leveraging data from small client models to enhance the performance of a large server-side foundation model. Existing methods based on model level or representation level knowledge transfer either require expensive local training or incur high communication costs and introduce unavoidable privacy risks. We reformulate this problem as a reinforcement learning style evaluation process and propose FedGRPO, a privacy preserving framework comprising two modules. The first module performs competence-based expert selection by building a lightweight confidence graph from auxiliary data to identify the most suitable clients for each question. The second module leverages the "Group Relative" concept from the Group Relative Policy Optimization (GRPO) framework by packaging each question together with its solution rationale into candidate policies, dispatching these policies to a selected subset of expert clients, and aggregating solely the resulting scalar reward signals via a federated group-relative loss function. By exchanging reward values instead of data or model updates, FedGRPO reduces privacy risk and communication overhead while enabling parallel evaluation across heterogeneous devices. Empirical results on diverse domain tasks demonstrate that FedGRPO achieves superior downstream accuracy and communication efficiency compared to conventional FedFMs baselines.]]></description>
<pubDate>Thu, 12 Feb 2026 14:45:56 +0000</pubDate>
</item>
<item>
<title><![CDATA[InjectRBP: Steering Large Language Model Reasoning Behavior via Pattern Injection]]></title>
<link>http://arxiv.org/abs/2602.12013v1</link>
<guid>2602.12013v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.AI
Authors: Xiuping Wu, Zhao Yu, Yuxin Cheng, Ngai Wong, Liangjun Ke et al.
Institution: 
Published: 2026-02-12
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Reasoning can significantly enhance the performance of Large Language Models. While recent studies have exploited behavior-related prompts adjustment to enhance reasoning, these designs remain largely intuitive and lack a systematic analysis of the underlying behavioral patterns. Motivated by this, we investigate how models' reasoning behaviors shape reasoning from the perspective of behavioral patterns. We observe that models exhibit adaptive distributions of reasoning behaviors when responding to specific types of questions, and that structurally injecting these patterns can substantially influence the quality of the models' reasoning processes and outcomes. Building on these findings, we propose two optimization methods that require no parameter updates: InjectCorrect and InjectRLOpt. InjectCorrect guides the model by imitating behavioral patterns derived from its own past correct answers. InjectRLOpt learns a value function from historical behavior-pattern data and, via our proposed Reliability-Aware Softmax Policy, generates behavioral injectant during inference to steer the reasoning process. Our experiments demonstrate that both methods can improve model performance across various reasoning tasks without requiring any modifications to model parameters, achieving gains of up to 5.34% and 8.67%, respectively.]]></description>
<pubDate>Thu, 12 Feb 2026 14:44:40 +0000</pubDate>
</item>
<item>
<title><![CDATA[On the Sensitivity of Firing Rate-Based Federated Spiking Neural Networks to Differential Privacy]]></title>
<link>http://arxiv.org/abs/2602.12009v1</link>
<guid>2602.12009v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.LG, cs.AI
Authors: Luiz Pereira, Mirko Perkusich, Dalton Valadares, Kyller Gorgnio
Institution: 
Published: 2026-02-12
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Federated Neuromorphic Learning (FNL) enables energy-efficient and privacy-preserving learning on devices without centralizing data. However, real-world deployments require additional privacy mechanisms that can significantly alter training signals. This paper analyzes how Differential Privacy (DP) mechanisms, specifically gradient clipping and noise injection, perturb firing-rate statistics in Spiking Neural Networks (SNNs) and how these perturbations are propagated to rate-based FNL coordination. On a speech recognition task under non-IID settings, ablations across privacy budgets and clipping bounds reveal systematic rate shifts, attenuated aggregation, and ranking instability during client selection. Moreover, we relate these shifts to sparsity and memory indicators. Our findings provide actionable guidance for privacy-preserving FNL, specifically regarding the balance between privacy strength and rate-dependent coordination.]]></description>
<pubDate>Thu, 12 Feb 2026 14:40:25 +0000</pubDate>
</item>
<item>
<title><![CDATA[LaCy: What Small Language Models Can and Should Learn is Not Just a Question of Loss]]></title>
<link>http://arxiv.org/abs/2602.12005v1</link>
<guid>2602.12005v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.CL
Authors: Szilvia Ujvry, Louis Bthune, Pierre Ablin, Joo Monteiro, Marco Cuturi et al.
Institution: 
Published: 2026-02-12
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Language models have consistently grown to compress more world knowledge into their parameters, but the knowledge that can be pretrained into them is upper-bounded by their parameter size. Especially the capacity of Small Language Models (SLMs) is limited, leading to factually incorrect generations. This problem is often mitigated by giving the SLM access to an outside source: the ability to query a larger model, documents, or a database. Under this setting, we study the fundamental question of \emph{which tokens an SLM can and should learn} during pretraining, versus \emph{which ones it should delegate} via a \texttt{<CALL>} token. We find that this is not simply a question of loss: although the loss is predictive of whether a predicted token mismatches the ground-truth, some tokens are \emph{acceptable} in that they are truthful alternative continuations of a pretraining document, and should not trigger a \texttt{<CALL>} even if their loss is high. We find that a spaCy grammar parser can help augment the loss signal to decide which tokens the SLM should learn to delegate to prevent factual errors and which are safe to learn and predict even under high losses. We propose LaCy, a novel pretraining method based on this token selection philosophy. Our experiments demonstrate that LaCy models successfully learn which tokens to predict and where to delegate for help. This results in higher FactScores when generating in a cascade with a bigger model and outperforms Rho or LLM-judge trained SLMs, while being simpler and cheaper.]]></description>
<pubDate>Thu, 12 Feb 2026 14:37:25 +0000</pubDate>
</item>
<item>
<title><![CDATA[CSEval: A Framework for Evaluating Clinical Semantics in Text-to-Image Generation]]></title>
<link>http://arxiv.org/abs/2602.12004v1</link>
<guid>2602.12004v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.AI
Authors: Robert Cronshaw, Konstantinos Vilouras, Junyu Yan, Yuning Du, Feng Chen et al.
Institution: 
Published: 2026-02-12
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Text-to-image generation has been increasingly applied in medical domains for various purposes such as data augmentation and education. Evaluating the quality and clinical reliability of these generated images is essential. However, existing methods mainly assess image realism or diversity, while failing to capture whether the generated images reflect the intended clinical semantics, such as anatomical location and pathology. In this study, we propose the Clinical Semantics Evaluator (CSEval), a framework that leverages language models to assess clinical semantic alignment between the generated images and their conditioning prompts. Our experiments show that CSEval identifies semantic inconsistencies overlooked by other metrics and correlates with expert judgment. CSEval provides a scalable and clinically meaningful complement to existing evaluation methods, supporting the safe adoption of generative models in healthcare.]]></description>
<pubDate>Thu, 12 Feb 2026 14:35:31 +0000</pubDate>
</item>
<item>
<title><![CDATA[Projected Representation Conditioning for High-fidelity Novel View Synthesis]]></title>
<link>http://arxiv.org/abs/2602.12003v1</link>
<guid>2602.12003v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.CV
Authors: Min-Seop Kwak, Minkyung Kwon, Jinhyeok Choi, Jiho Park, Seungryong Kim
Institution: 
Published: 2026-02-12
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

We propose a novel framework for diffusion-based novel view synthesis in which we leverage external representations as conditions, harnessing their geometric and semantic correspondence properties for enhanced geometric consistency in generated novel viewpoints. First, we provide a detailed analysis exploring the correspondence capabilities emergent in the spatial attention of external visual representations. Building from these insights, we propose a representation-guided novel view synthesis through dedicated representation projection modules that inject external representations into the diffusion process, a methodology named ReNoV, short for representation-guided novel view synthesis. Our experiments show that this design yields marked improvements in both reconstruction fidelity and inpainting quality, outperforming prior diffusion-based novel-view methods on standard benchmarks and enabling robust synthesis from sparse, unposed image collections.]]></description>
<pubDate>Thu, 12 Feb 2026 14:35:30 +0000</pubDate>
</item>
<item>
<title><![CDATA[Can Local Vision-Language Models improve Activity Recognition over Vision Transformers? -- Case Study on Newborn Resuscitation]]></title>
<link>http://arxiv.org/abs/2602.12002v1</link>
<guid>2602.12002v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.CV
Authors: Enrico Guerriero, Kjersti Engan, yvind Meinich-Bache
Institution: 
Published: 2026-02-12
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Accurate documentation of newborn resuscitation is essential for quality improvement and adherence to clinical guidelines, yet remains underutilized in practice. Previous work using 3D-CNNs and Vision Transformers (ViT) has shown promising results in detecting key activities from newborn resuscitation videos, but also highlighted the challenges in recognizing such fine-grained activities. This work investigates the potential of generative AI (GenAI) methods to improve activity recognition from such videos. Specifically, we explore the use of local vision-language models (VLMs), combined with large language models (LLMs), and compare them to a supervised TimeSFormer baseline. Using a simulated dataset comprising 13.26 hours of newborn resuscitation videos, we evaluate several zero-shot VLM-based strategies and fine-tuned VLMs with classification heads, including Low-Rank Adaptation (LoRA). Our results suggest that small (local) VLMs struggle with hallucinations, but when fine-tuned with LoRA, the results reach F1 score at 0.91, surpassing the TimeSformer results of 0.70.]]></description>
<pubDate>Thu, 12 Feb 2026 14:31:10 +0000</pubDate>
</item>
<item>
<title><![CDATA[Momentum LMS Theory beyond Stationarity: Stability, Tracking, and Regret]]></title>
<link>http://arxiv.org/abs/2602.11995v1</link>
<guid>2602.11995v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.LG
Authors: Yifei Jin, Xin Zheng, Lei Guo
Institution: 
Published: 2026-02-12
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

In large-scale data processing scenarios, data often arrive in sequential streams generated by complex systems that exhibit drifting distributions and time-varying system parameters. This nonstationarity challenges theoretical analysis, as it violates classical assumptions of i.i.d. (independent and identically distributed) samples, necessitating algorithms capable of real-time updates without expensive retraining. An effective approach should process each sample in a single pass, while maintaining computational and memory complexities independent of the data stream length. Motivated by these challenges, this paper investigates the Momentum Least Mean Squares (MLMS) algorithm as an adaptive identification tool, leveraging its computational simplicity and online processing capabilities. Theoretically, we derive tracking performance and regret bounds for the MLMS in time-varying stochastic linear systems under various practical conditions. Unlike classical LMS, whose stability can be characterized by first-order random vector difference equations, MLMS introduces an additional dynamical state due to momentum, leading to second-order time-varying random vector difference equations whose stability analysis hinges on more complicated products of random matrices, which poses a substantially challenging problem to resolve. Experiments on synthetic and real-world data streams demonstrate that MLMS achieves rapid adaptation and robust tracking, in agreement with our theoretical results especially in nonstationary settings, highlighting its promise for modern streaming and online learning applications.]]></description>
<pubDate>Thu, 12 Feb 2026 14:24:42 +0000</pubDate>
</item>
<item>
<title><![CDATA[Evaluating AGENTS.md: Are Repository-Level Context Files Helpful for Coding Agents?]]></title>
<link>http://arxiv.org/abs/2602.11988v1</link>
<guid>2602.11988v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.SE, cs.AI
Authors: Thibaud Gloaguen, Niels Mndler, Mark Mller, Veselin Raychev, Martin Vechev
Institution: 
Published: 2026-02-12
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

A widespread practice in software development is to tailor coding agents to repositories using context files, such as AGENTS.md, by either manually or automatically generating them. Although this practice is strongly encouraged by agent developers, there is currently no rigorous investigation into whether such context files are actually effective for real-world tasks. In this work, we study this question and evaluate coding agents' task completion performance in two complementary settings: established SWE-bench tasks from popular repositories, with LLM-generated context files following agent-developer recommendations, and a novel collection of issues from repositories containing developer-committed context files.
  Across multiple coding agents and LLMs, we find that context files tend to reduce task success rates compared to providing no repository context, while also increasing inference cost by over 20%. Behaviorally, both LLM-generated and developer-provided context files encourage broader exploration (e.g., more thorough testing and file traversal), and coding agents tend to respect their instructions. Ultimately, we conclude that unnecessary requirements from context files make tasks harder, and human-written context files should describe only minimal requirements.]]></description>
<pubDate>Thu, 12 Feb 2026 14:15:22 +0000</pubDate>
</item>
<item>
<title><![CDATA[Automatic Simplification of Common Vulnerabilities and Exposures Descriptions]]></title>
<link>http://arxiv.org/abs/2602.11982v1</link>
<guid>2602.11982v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.CL
Authors: Varpu Vehomki, Kimmo K. Kaski
Institution: 
Published: 2026-02-12
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Understanding cyber security is increasingly important for individuals and organizations. However, a lot of information related to cyber security can be difficult to understand to those not familiar with the topic. In this study, we focus on investigating how large language models (LLMs) could be utilized in automatic text simplification (ATS) of Common Vulnerability and Exposure (CVE) descriptions. Automatic text simplification has been studied in several contexts, such as medical, scientific, and news texts, but it has not yet been studied to simplify texts in the rapidly changing and complex domain of cyber security. We created a baseline for cyber security ATS and a test dataset of 40 CVE descriptions, evaluated by two groups of cyber security experts in two survey rounds. We have found that while out-of-the box LLMs can make the text appear simpler, they struggle with meaning preservation. Code and data are available at https://version.aalto.fi/gitlab/vehomav1/simplification\_nmi.]]></description>
<pubDate>Thu, 12 Feb 2026 14:12:58 +0000</pubDate>
</item>
<item>
<title><![CDATA[Spatial Chain-of-Thought: Bridging Understanding and Generation Models for Spatial Reasoning Generation]]></title>
<link>http://arxiv.org/abs/2602.11980v1</link>
<guid>2602.11980v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.CV
Authors: Wei Chen, Yancheng Long, Mingqiao Liu, Haojie Ding, Yankai Yang et al.
Institution: 
Published: 2026-02-12
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

While diffusion models have shown exceptional capabilities in aesthetic image synthesis, they often struggle with complex spatial understanding and reasoning. Existing approaches resort to Multimodal Large Language Models (MLLMs) to enhance this capability. However, they either incur high computational costs through joint training or suffer from spatial information loss when relying solely on textual prompts. To alleviate these limitations, we propose a Spatial Chain-of-Thought (SCoT) framework, a plug-and-play approach that effectively bridges the reasoning capabilities of MLLMs with the generative power of diffusion models. Specifically, we first enhance the diffusion model's layout awareness by training it on an interleaved text-coordinate instruction format. We then leverage state-of-the-art MLLMs as planners to generate comprehensive layout plans, transferring their spatial planning capabilities directly to the generation process. Extensive experiments demonstrate that our method achieves state-of-the-art performance on image generation benchmarks and significantly outperforms baselines on complex reasoning tasks, while also showing strong efficacy in image editing scenarios.]]></description>
<pubDate>Thu, 12 Feb 2026 14:12:14 +0000</pubDate>
</item>
<item>
<title><![CDATA[Accelerating Robotic Reinforcement Learning with Agent Guidance]]></title>
<link>http://arxiv.org/abs/2602.11978v1</link>
<guid>2602.11978v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.RO, cs.AI
Authors: Haojun Chen, Zili Zou, Chengdong Ma, Yaoxiang Pu, Haotong Zhang et al.
Institution: 
Published: 2026-02-12
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Reinforcement Learning (RL) offers a powerful paradigm for autonomous robots to master generalist manipulation skills through trial-and-error. However, its real-world application is stifled by severe sample inefficiency. Recent Human-in-the-Loop (HIL) methods accelerate training by using human corrections, yet this approach faces a scalability barrier. Reliance on human supervisors imposes a 1:1 supervision ratio that limits fleet expansion, suffers from operator fatigue over extended sessions, and introduces high variance due to inconsistent human proficiency. We present Agent-guided Policy Search (AGPS), a framework that automates the training pipeline by replacing human supervisors with a multimodal agent. Our key insight is that the agent can be viewed as a semantic world model, injecting intrinsic value priors to structure physical exploration. By using executable tools, the agent provides precise guidance via corrective waypoints and spatial constraints for exploration pruning. We validate our approach on two tasks, ranging from precision insertion to deformable object manipulation. Results demonstrate that AGPS outperforms HIL methods in sample efficiency. This automates the supervision pipeline, unlocking the path to labor-free and scalable robot learning. Project website: https://agps-rl.github.io/agps.]]></description>
<pubDate>Thu, 12 Feb 2026 14:09:32 +0000</pubDate>
</item>
<item>
<title><![CDATA[Calibrated Bayesian Deep Learning for Explainable Decision Support Systems Based on Medical Imaging]]></title>
<link>http://arxiv.org/abs/2602.11973v1</link>
<guid>2602.11973v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.CV, cs.LG
Authors: Hua Xu, Julin D. Arias-Londoo, Juan I. Godino-Llorente
Institution: 
Published: 2026-02-12
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

In critical decision support systems based on medical imaging, the reliability of AI-assisted decision-making is as relevant as predictive accuracy. Although deep learning models have demonstrated significant accuracy, they frequently suffer from miscalibration, manifested as overconfidence in erroneous predictions. To facilitate clinical acceptance, it is imperative that models quantify uncertainty in a manner that correlates with prediction correctness, allowing clinicians to identify unreliable outputs for further review. In order to address this necessity, the present paper proposes a generalizable probabilistic optimization framework grounded in Bayesian deep learning. Specifically, a novel Confidence-Uncertainty Boundary Loss (CUB-Loss) is introduced that imposes penalties on high-certainty errors and low-certainty correct predictions, explicitly enforcing alignment between prediction correctness and uncertainty estimates. Complementing this training-time optimization, a Dual Temperature Scaling (DTS) strategy is devised for post-hoc calibration, further refining the posterior distribution to improve intuitive explainability. The proposed framework is validated on three distinct medical imaging tasks: automatic screening of pneumonia, diabetic retinopathy detection, and identification of skin lesions. Empirical results demonstrate that the proposed approach achieves consistent calibration improvements across diverse modalities, maintains robust performance in data-scarce scenarios, and remains effective on severely imbalanced datasets, underscoring its potential for real clinical deployment.]]></description>
<pubDate>Thu, 12 Feb 2026 14:03:41 +0000</pubDate>
</item>
<item>
<title><![CDATA[UPDA: Unsupervised Progressive Domain Adaptation for No-Reference Point Cloud Quality Assessment]]></title>
<link>http://arxiv.org/abs/2602.11969v1</link>
<guid>2602.11969v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.CV, cs.MM
Authors: Bingxu Xie, Fang Zhou, Jincan Wu, Yonghui Liu, Weiqing Li et al.
Institution: 
Published: 2026-02-12
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

While no-reference point cloud quality assessment (NR-PCQA) approaches have achieved significant progress over the past decade, their performance often degrades substantially when a distribution gap exists between the training (source domain) and testing (target domain) data. However, to date, limited attention has been paid to transferring NR-PCQA models across domains. To address this challenge, we propose the first unsupervised progressive domain adaptation (UPDA) framework for NR-PCQA, which introduces a two-stage coarse-to-fine alignment paradigm to address domain shifts. At the coarse-grained stage, a discrepancy-aware coarse-grained alignment method is designed to capture relative quality relationships between cross-domain samples through a novel quality-discrepancy-aware hybrid loss, circumventing the challenges of direct absolute feature alignment. At the fine-grained stage, a perception fusion fine-grained alignment approach with symmetric feature fusion is developed to identify domain-invariant features, while a conditional discriminator selectively enhances the transfer of quality-relevant features. Extensive experiments demonstrate that the proposed UPDA effectively enhances the performance of NR-PCQA methods in cross-domain scenarios, validating its practical applicability. The code is available at https://github.com/yokeno1/UPDA-main.]]></description>
<pubDate>Thu, 12 Feb 2026 14:02:05 +0000</pubDate>
</item>
<item>
<title><![CDATA[DHPLT: large-scale multilingual diachronic corpora and word representations for semantic change modelling]]></title>
<link>http://arxiv.org/abs/2602.11968v1</link>
<guid>2602.11968v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.CL
Authors: Mariia Fedorova, Andrey Kutuzov, Khonzoda Umarova
Institution: 
Published: 2026-02-12
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

In this resource paper, we present DHPLT, an open collection of diachronic corpora in 41 diverse languages. DHPLT is based on the web-crawled HPLT datasets; we use web crawl timestamps as the approximate signal of document creation time. The collection covers three time periods: 2011-2015, 2020-2021 and 2024-present (1 million documents per time period for each language). We additionally provide pre-computed word type and token embeddings and lexical substitutions for our chosen target words, while at the same time leaving it open for the other researchers to come up with their own target words using the same datasets. DHPLT aims at filling in the current lack of multilingual diachronic corpora for semantic change modelling (beyond a dozen of high-resource languages). It opens the way for a variety of new experimental setups in this field. All the resources described in this paper are available at https://data.hplt-project.org/three/diachronic/, sorted by language.]]></description>
<pubDate>Thu, 12 Feb 2026 14:01:40 +0000</pubDate>
</item>
<item>
<title><![CDATA[Manifold-Aware Temporal Domain Generalization for Large Language Models]]></title>
<link>http://arxiv.org/abs/2602.11965v1</link>
<guid>2602.11965v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.LG, cs.AI
Authors: Yiheng Yao, Zekun Cai, Xinyuan Song, Hiroki Hill Kobayashi, Xuan Song et al.
Institution: 
Published: 2026-02-12
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Temporal distribution shifts are pervasive in real-world deployments of Large Language Models (LLMs), where data evolves continuously over time. While Temporal Domain Generalization (TDG) seeks to model such structured evolution, existing approaches characterize model adaptation in the full parameter space. This formulation becomes computationally infeasible for modern LLMs. This paper introduces a geometric reformulation of TDG under parameter-efficient fine-tuning. We establish that the low-dimensional temporal structure underlying model evolution can be preserved under parameter-efficient reparameterization, enabling temporal modeling without operating in the ambient parameter space. Building on this principle, we propose Manifold-aware Temporal LoRA (MaT-LoRA), which constrains temporal updates to a shared low-dimensional manifold within a low-rank adaptation subspace, and models its evolution through a structured temporal core. This reparameterization dramatically reduces temporal modeling complexity while retaining expressive power. Extensive experiments on synthetic and real-world datasets, including scientific documents, news publishers, and review ratings, demonstrate that MaT-LoRA achieves superior temporal generalization performance with practical scalability for LLMs.]]></description>
<pubDate>Thu, 12 Feb 2026 14:00:44 +0000</pubDate>
</item>
<item>
<title><![CDATA[Scaling Model and Data for Multilingual Machine Translation with Open Large Language Models]]></title>
<link>http://arxiv.org/abs/2602.11961v1</link>
<guid>2602.11961v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.CL
Authors: Yuzhe Shang, Pengzhi Gao, Wei Liu, Jian Luan, Jinsong Su
Institution: 
Published: 2026-02-12
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Open large language models (LLMs) have demonstrated improving multilingual capabilities in recent years. In this paper, we present a study of open LLMs for multilingual machine translation (MT) across a range of languages, and investigate the effects of model scaling and data scaling when adapting open LLMs to multilingual MT through continual pretraining and instruction finetuning. Based on the Gemma3 model family, we develop MiLMMT-46, which achieves top-tier multilingual translation performance across 46 languages. Extensive experiments show that MiLMMT-46 consistently outperforms recent state-of-the-art (SOTA) models, including Seed-X, HY-MT-1.5, and TranslateGemma, and achieves competitive performance with strong proprietary systems such as Google Translate and Gemini 3 Pro.]]></description>
<pubDate>Thu, 12 Feb 2026 13:56:02 +0000</pubDate>
</item>
<item>
<title><![CDATA[Benchmarking Vision-Language Models for French PDF-to-Markdown Conversion]]></title>
<link>http://arxiv.org/abs/2602.11960v1</link>
<guid>2602.11960v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.CV, cs.CL, cs.LG
Authors: Bruno Rigal, Victor Dupriez, Alexis Mignon, Ronan Le Hy, Nicolas Mery
Institution: 
Published: 2026-02-12
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

This report evaluates PDF-to-Markdown conversion using recent Vision-Language Models (VLMs) on challenging French documents. Document parsing is a critical step for Retrieval-Augmented Generation (RAG) pipelines, where transcription and layout errors propagate to downstream retrieval and grounding. Existing benchmarks often emphasize English or Chinese and can over-penalize benign formatting and linearization choices (e.g., line breaks, list segmentation, alternative table renderings) that are largely irrelevant for downstream use.
  We introduce a French-focused benchmark of difficult pages selected via model-disagreement sampling from a corpus of 60{,}000 documents, covering handwritten forms, complex layouts, dense tables, and graphics-rich pages. Evaluation is performed with unit-test-style checks that target concrete failure modes (text presence, reading order, and local table constraints) combined with category-specific normalization designed to discount presentation-only variance. Across 15 models, we observe substantially higher robustness for the strongest proprietary models on handwriting and forms, while several open-weights systems remain competitive on standard printed layouts.]]></description>
<pubDate>Thu, 12 Feb 2026 13:55:43 +0000</pubDate>
</item>
<item>
<title><![CDATA[RAM-Net: Expressive Linear Attention with Selectively Addressable Memory]]></title>
<link>http://arxiv.org/abs/2602.11958v1</link>
<guid>2602.11958v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.LG, cs.CL
Authors: Kaicheng Xiao, Haotian Li, Liran Dong, Guoliang Xing
Institution: 
Published: 2026-02-12
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

While linear attention architectures offer efficient inference, compressing unbounded history into a fixed-size memory inherently limits expressivity and causes information loss. To address this limitation, we introduce Random Access Memory Network (RAM-Net), a novel architecture designed to bridge the gap between the representational capacity of full attention and the memory efficiency of linear models. The core of RAM-Net maps inputs to high-dimensional sparse vectors serving as explicit addresses, allowing the model to selectively access a massive memory state. This design enables exponential state size scaling without additional parameters, which significantly mitigates signal interference and enhances retrieval fidelity. Moreover, the inherent sparsity ensures exceptional computational efficiency, as state updates are confined to minimal entries. Extensive experiments demonstrate that RAM-Net consistently surpasses state-of-the-art baselines in fine-grained long-range retrieval tasks and achieves competitive performance in standard language modeling and zero-shot commonsense reasoning benchmarks, validating its superior capability to capture complex dependencies with significantly reduced computational overhead.]]></description>
<pubDate>Thu, 12 Feb 2026 13:55:29 +0000</pubDate>
</item>
<item>
<title><![CDATA[Are Two LLMs Better Than One? A Student-Teacher Dual-Head LLMs Architecture for Pharmaceutical Content Optimization]]></title>
<link>http://arxiv.org/abs/2602.11957v1</link>
<guid>2602.11957v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.LG
Authors: Suyash Mishra, Qiang Li, Anubhav Girdhar
Institution: 
Published: 2026-02-12
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Large language models (LLMs) are increasingly used to create content in regulated domains such as pharmaceuticals, where outputs must be scientifically accurate and legally compliant. Manual quality control (QC) is slow, error prone, and can become a publication bottleneck. We introduce LRBTC, a modular LLM and vision language model (VLM) driven QC architecture covering Language, Regulatory, Brand, Technical, and Content Structure checks. LRBTC combines a Student-Teacher dual model architecture, human in the loop (HITL) workflow with waterfall rule filtering to enable scalable, verifiable content validation and optimization. On AIReg-Bench, our approach achieves 83.0% F1 and 97.5% recall, reducing missed violations by 5x compared with Gemini 2.5 Pro. On CSpelling, it improves mean accuracy by 26.7%. Error analysis further reveals that while current models are strong at detecting misspellings (92.5 recall), they fail to identify complex medical grammatical (25.0 recall) and punctuation (41.7 recall) errors, highlighting a key area for future work. This work provides a practical, plug and play solution for reliable, transparent quality control of content in high stakes, compliance critical industries. We also provide access to our Demo under MIT Licenses.]]></description>
<pubDate>Thu, 12 Feb 2026 13:53:29 +0000</pubDate>
</item>
<item>
<title><![CDATA[TAVAE: A VAE with Adaptable Priors Explains Contextual Modulation in the Visual Cortex]]></title>
<link>http://arxiv.org/abs/2602.11956v1</link>
<guid>2602.11956v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.AI, cs.LG
Authors: Balzs Meszna, Keith T. Murray, Julien Corbo, O. Batuhan Erkat, Mrton A. Hajnal et al.
Institution: 
Published: 2026-02-12
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

The brain interprets visual information through learned regularities, a computation formalized as probabilistic inference under a prior. The visual cortex establishes priors for this inference, some delivered through established top-down connections that inform low-level cortices about statistics represented at higher levels in the cortical hierarchy. While evidence shows that adaptation leads to priors reflecting the structure of natural images, it remains unclear whether similar priors can be flexibly acquired when learning a specific task. To investigate this, we built a generative model of V1 optimized for a simple discrimination task and analyzed it together with large-scale recordings from mice performing an analogous task. In line with recent approaches, we assumed that neuronal activity in V1 corresponds to latent posteriors in the generative model, enabling investigation of task-related priors in neuronal responses. To obtain a flexible test bed, we extended the VAE formalism so that a task can be acquired efficiently by reusing previously learned representations. Task-specific priors learned by this Task-Amortized VAE were used to investigate biases in mice and model when presenting stimuli that violated trained task statistics. Mismatch between learned task statistics and incoming sensory evidence produced signatures of uncertainty in stimulus category in the TAVAE posterior, reflecting properties of bimodal response profiles in V1 recordings. The task-optimized generative model accounted for key characteristics of V1 population activity, including within-day updates to population responses. Our results confirm that flexible task-specific contextual priors can be learned on demand by the visual system and deployed as early as the entry level of visual cortex.]]></description>
<pubDate>Thu, 12 Feb 2026 13:50:56 +0000</pubDate>
</item>
<item>
<title><![CDATA[Insights on Muon from Simple Quadratics]]></title>
<link>http://arxiv.org/abs/2602.11948v1</link>
<guid>2602.11948v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.LG
Authors: Antoine Gonon, Andreea-Alexandra Muat, Nicolas Boumal
Institution: 
Published: 2026-02-12
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Muon updates weight matrices along (approximate) polar factors of the gradients and has shown strong empirical performance in large-scale training. Existing attempts at explaining its performance largely focus on single-step comparisons (on quadratic proxies) and worst-case guarantees that treat the inexactness of the polar-factor as a nuisance ``to be argued away''. We show that already on simple strongly convex functions such as $L(W)=\frac12\|W\|_{\text{F}}^2$, these perspectives are insufficient, suggesting that understanding Muon requires going beyond local proxies and pessimistic worst-case bounds. Instead, our analysis exposes two observations that already affect behavior on simple quadratics and are not well captured by prevailing abstractions: (i) approximation error in the polar step can qualitatively alter discrete-time dynamics and improve reachability and finite-time performance -- an effect practitioners exploit to tune Muon, but that existing theory largely treats as a pure accuracy compromise; and (ii) structural properties of the objective affect finite-budget constants beyond the prevailing conditioning-based explanations. Thus, any general theory covering these cases must either incorporate these ingredients explicitly or explain why they are irrelevant in the regimes of interest.]]></description>
<pubDate>Thu, 12 Feb 2026 13:43:58 +0000</pubDate>
</item>
<item>
<title><![CDATA[Mixed-Integer Programming for Change-point Detection]]></title>
<link>http://arxiv.org/abs/2602.11947v1</link>
<guid>2602.11947v1</guid>
<description><![CDATA[Source: arXiv
Tags: stat.ML
Authors: Apoorva Narula, Santanu S. Dey, Yao Xie
Institution: 
Published: 2026-02-12
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

We present a new mixed-integer programming (MIP) approach for offline multiple change-point detection by casting the problem as a globally optimal piecewise linear (PWL) fitting problem. Our main contribution is a family of strengthened MIP formulations whose linear programming (LP) relaxations admit integral projections onto the segment assignment variables, which encode the segment membership of each data point. This property yields provably tighter relaxations than existing formulations for offline multiple change-point detection. We further extend the framework to two settings of active research interest: (i) multidimensional PWL models with shared change-points, and (ii) sparse change-point detection, where only a subset of dimensions undergo structural change. Extensive computational experiments on benchmark real-world datasets demonstrate that the proposed formulations achieve reductions in solution times under both $\ell_1$ and $\ell_2$ loss functions in comparison to the state-of-the-art.]]></description>
<pubDate>Thu, 12 Feb 2026 13:43:56 +0000</pubDate>
</item>
<item>
<title><![CDATA[Towards Performance-Enhanced Model-Contrastive Federated Learning using Historical Information in Heterogeneous Scenarios]]></title>
<link>http://arxiv.org/abs/2602.11945v1</link>
<guid>2602.11945v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.LG, cs.AI
Authors: Hongliang Zhang, Jiguo Yu, Guijuan Wang, Wenshuo Ma, Tianqing He et al.
Institution: 
Published: 2026-02-12
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Federated Learning (FL) enables multiple nodes to collaboratively train a model without sharing raw data. However, FL systems are usually deployed in heterogeneous scenarios, where nodes differ in both data distributions and participation frequencies, which undermines the FL performance. To tackle the above issue, this paper proposes PMFL, a performance-enhanced model-contrastive federated learning framework using historical training information. Specifically, on the node side, we design a novel model-contrastive term into the node optimization objective by incorporating historical local models to capture stable contrastive points, thereby improving the consistency of model updates in heterogeneous data distributions.
  On the server side, we utilize the cumulative participation count of each node to adaptively adjust its aggregation weight, thereby correcting the bias in the global objective caused by different node participation frequencies. Furthermore, the updated global model incorporates historical global models to reduce its fluctuations in performance between adjacent rounds. Extensive experiments demonstrate that PMFL achieves superior performance compared with existing FL methods in heterogeneous scenarios.]]></description>
<pubDate>Thu, 12 Feb 2026 13:40:37 +0000</pubDate>
</item>
<item>
<title><![CDATA[Using predictive multiplicity to measure individual performance within the AI Act]]></title>
<link>http://arxiv.org/abs/2602.11944v1</link>
<guid>2602.11944v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.LG, cs.CY
Authors: Karolin Frohnapfel, Mara Seyfert, Sebastian Bordt, Ulrike von Luxburg, Kristof Meding
Institution: 
Published: 2026-02-12
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

When building AI systems for decision support, one often encounters the phenomenon of predictive multiplicity: a single best model does not exist; instead, one can construct many models with similar overall accuracy that differ in their predictions for individual cases. Especially when decisions have a direct impact on humans, this can be highly unsatisfactory. For a person subject to high disagreement between models, one could as well have chosen a different model of similar overall accuracy that would have decided the person's case differently. We argue that this arbitrariness conflicts with the EU AI Act, which requires providers of high-risk AI systems to report performance not only at the dataset level but also for specific persons. The goal of this paper is to put predictive multiplicity in context with the EU AI Act's provisions on accuracy and to subsequently derive concrete suggestions on how to evaluate and report predictive multiplicity in practice. Specifically: (1) We argue that incorporating information about predictive multiplicity can serve compliance with the EU AI Act's accuracy provisions for providers. (2) Based on this legal analysis, we suggest individual conflict ratios and $$-ambiguity as tools to quantify the disagreement between models on individual cases and to help detect individuals subject to conflicting predictions. (3) Based on computational insights, we derive easy-to-implement rules on how model providers could evaluate predictive multiplicity in practice. (4) Ultimately, we suggest that information about predictive multiplicity should be made available to deployers under the AI Act, enabling them to judge whether system outputs for specific individuals are reliable enough for their use case.]]></description>
<pubDate>Thu, 12 Feb 2026 13:40:00 +0000</pubDate>
</item>
<item>
<title><![CDATA[Synthesis of Late Gadolinium Enhancement Images via Implicit Neural Representations for Cardiac Scar Segmentation]]></title>
<link>http://arxiv.org/abs/2602.11942v1</link>
<guid>2602.11942v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.CV, cs.AI
Authors: Soufiane Ben Haddou, Laura Alvarez-Florez, Erik J. Bekkers, Fleur V. Y. Tjong, Ahmad S. Amin et al.
Institution: 
Published: 2026-02-12
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Late gadolinium enhancement (LGE) imaging is the clinical standard for myocardial scar assessment, but limited annotated datasets hinder the development of automated segmentation methods. We propose a novel framework that synthesises both LGE images and their corresponding segmentation masks using implicit neural representations (INRs) combined with denoising diffusion models. Our approach first trains INRs to capture continuous spatial representations of LGE data and associated myocardium and fibrosis masks. These INRs are then compressed into compact latent embeddings, preserving essential anatomical information. A diffusion model operates on this latent space to generate new representations, which are decoded into synthetic LGE images with anatomically consistent segmentation masks. Experiments on 133 cardiac MRI scans suggest that augmenting training data with 200 synthetic volumes contributes to improved fibrosis segmentation performance, with the Dice score showing an increase from 0.509 to 0.524. Our approach provides an annotation-free method to help mitigate data scarcity.The code for this research is publicly available.]]></description>
<pubDate>Thu, 12 Feb 2026 13:38:07 +0000</pubDate>
</item>
<item>
<title><![CDATA[IncompeBench: A Permissively Licensed, Fine-Grained Benchmark for Music Information Retrieval]]></title>
<link>http://arxiv.org/abs/2602.11941v1</link>
<guid>2602.11941v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.IR, cs.AI
Authors: Benjamin Clavi, Atoof Shakir, Jonah Turner, Sean Lee, Aamir Shakir et al.
Institution: 
Published: 2026-02-12
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Multimodal Information Retrieval has made significant progress in recent years, leveraging the increasingly strong multimodal abilities of deep pre-trained models to represent information across modalities. Music Information Retrieval (MIR), in particular, has considerably increased in quality, with neural representations of music even making its way into everyday life products. However, there is a lack of high-quality benchmarks for evaluating music retrieval performance. To address this issue, we introduce \textbf{IncompeBench}, a carefully annotated benchmark comprising $1,574$ permissively licensed, high-quality music snippets, $500$ diverse queries, and over $125,000$ individual relevance judgements. These annotations were created through the use of a multi-stage pipeline, resulting in high agreement between human annotators and the generated data. The resulting datasets are publicly available at https://huggingface.co/datasets/mixedbread-ai/incompebench-strict and https://huggingface.co/datasets/mixedbread-ai/incompebench-lenient with the prompts available at https://github.com/mixedbread-ai/incompebench-programs.]]></description>
<pubDate>Thu, 12 Feb 2026 13:37:58 +0000</pubDate>
</item>
<item>
<title><![CDATA[Temporally Unified Adversarial Perturbations for Time Series Forecasting]]></title>
<link>http://arxiv.org/abs/2602.11940v1</link>
<guid>2602.11940v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.LG
Authors: Ruixian Su, Yukun Bao, Xinze Zhang
Institution: 
Published: 2026-02-12
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

While deep learning models have achieved remarkable success in time series forecasting, their vulnerability to adversarial examples remains a critical security concern. However, existing attack methods in the forecasting field typically ignore the temporal consistency inherent in time series data, leading to divergent and contradictory perturbation values for the same timestamp across overlapping samples. This temporally inconsistent perturbations problem renders adversarial attacks impractical for real-world data manipulation. To address this, we introduce Temporally Unified Adversarial Perturbations (TUAPs), which enforce a temporal unification constraint to ensure identical perturbations for each timestamp across all overlapping samples. Moreover, we propose a novel Timestamp-wise Gradient Accumulation Method (TGAM) that provides a modular and efficient approach to effectively generate TUAPs by aggregating local gradient information from overlapping samples. By integrating TGAM with momentum-based attack algorithms, we ensure strict temporal consistency while fully utilizing series-level gradient information to explore the adversarial perturbation space. Comprehensive experiments on three benchmark datasets and four representative state-of-the-art models demonstrate that our proposed method significantly outperforms baselines in both white-box and black-box transfer attack scenarios under TUAP constraints. Moreover, our method also exhibits superior transfer attack performance even without TUAP constraints, demonstrating its effectiveness and superiority in generating adversarial perturbations for time series forecasting models.]]></description>
<pubDate>Thu, 12 Feb 2026 13:37:45 +0000</pubDate>
</item>
<item>
<title><![CDATA[Do Large Language Models Adapt to Language Variation across Socioeconomic Status?]]></title>
<link>http://arxiv.org/abs/2602.11939v1</link>
<guid>2602.11939v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.CL
Authors: Elisa Bassignana, Mike Zhang, Dirk Hovy, Amanda Cercas Curry
Institution: 
Published: 2026-02-12
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Humans adjust their linguistic style to the audience they are addressing. However, the extent to which LLMs adapt to different social contexts is largely unknown. As these models increasingly mediate human-to-human communication, their failure to adapt to diverse styles can perpetuate stereotypes and marginalize communities whose linguistic norms are less closely mirrored by the models, thereby reinforcing social stratification. We study the extent to which LLMs integrate into social media communication across different socioeconomic status (SES) communities. We collect a novel dataset from Reddit and YouTube, stratified by SES. We prompt four LLMs with incomplete text from that corpus and compare the LLM-generated completions to the originals along 94 sociolinguistic metrics, including syntactic, rhetorical, and lexical features. LLMs modulate their style with respect to SES to only a minor extent, often resulting in approximation or caricature, and tend to emulate the style of upper SES more effectively. Our findings (1) show how LLMs risk amplifying linguistic hierarchies and (2) call into question their validity for agent-based social simulation, survey experiments, and any research relying on language style as a social signal.]]></description>
<pubDate>Thu, 12 Feb 2026 13:36:38 +0000</pubDate>
</item>
<item>
<title><![CDATA[Who is the richest club in the championship? Detecting and Rewriting Underspecified Questions Improve QA Performance]]></title>
<link>http://arxiv.org/abs/2602.11938v1</link>
<guid>2602.11938v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.CL
Authors: Yunchong Huang, Gianni Barlacchi, Sandro Pezzelle
Institution: 
Published: 2026-02-12
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Large language models (LLMs) perform well on well-posed questions, yet standard question-answering (QA) benchmarks remain far from solved. We argue that this gap is partly due to underspecified questions - queries whose interpretation cannot be uniquely determined without additional context. To test this hypothesis, we introduce an LLM-based classifier to identify underspecified questions and apply it to several widely used QA datasets, finding that 16% to over 50% of benchmark questions are underspecified and that LLMs perform significantly worse on them. To isolate the effect of underspecification, we conduct a controlled rewriting experiment that serves as an upper-bound analysis, rewriting underspecified questions into fully specified variants while holding gold answers fixed. QA performance consistently improves under this setting, indicating that many apparent QA failures stem from question underspecification rather than model limitations. Our findings highlight underspecification as an important confound in QA evaluation and motivate greater attention to question clarity in benchmark design.]]></description>
<pubDate>Thu, 12 Feb 2026 13:36:23 +0000</pubDate>
</item>
<item>
<title><![CDATA[Extending Puzzle for Mixture-of-Experts Reasoning Models with Application to GPT-OSS Acceleration]]></title>
<link>http://arxiv.org/abs/2602.11937v1</link>
<guid>2602.11937v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.LG
Authors: Akhiad Bercovich, Nir Ailon, Vladimir Anisimov, Tomer Asida, Nave Assaf et al.
Institution: 
Published: 2026-02-12
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Reasoning-focused LLMs improve answer quality by generating longer reasoning traces, but the additional tokens dramatically increase serving cost, motivating inference optimization. We extend and apply Puzzle, a post-training neural architecture search (NAS) framework, to gpt-oss-120B to produce gpt-oss-puzzle-88B, a deployment-optimized derivative. Our approach combines heterogeneous MoE expert pruning, selective replacement of full-context attention with window attention, FP8 KV-cache quantization with calibrated scales, and post-training reinforcement learning to recover accuracy, while maintaining low generation length. In terms of per-token speeds, on an 8XH100 node we achieve 1.63X and 1.22X throughput speedups in long-context and short-context settings, respectively. gpt-oss-puzzle-88B also delivers throughput speedups of 2.82X on a single NVIDIA H100 GPU. However, because token counts can change with reasoning effort and model variants, per-token throughput (tok/s) and latency (ms/token) do not necessarily lead to end-to-end speedups: a 2X throughput gain is erased if traces grow 2X. Conversely, throughput gains can be spent on more reasoning tokens to improve accuracy; we therefore advocate request-level efficiency metrics that normalize throughput by tokens generated and trace an accuracy--speed frontier across reasoning efforts. We show that gpt-oss-puzzle-88B improves over gpt-oss-120B along the entire frontier, delivering up to 1.29X higher request-level efficiency. Across various benchmarks, gpt-oss-puzzle-88B matches or slightly exceeds the parent on suite-average accuracy across reasoning efforts, with retention ranging from 100.8% (high) to 108.2% (low), showing that post-training architecture search can substantially reduce inference costs without sacrificing quality.]]></description>
<pubDate>Thu, 12 Feb 2026 13:36:19 +0000</pubDate>
</item>
<item>
<title><![CDATA[Cross-Modal Robustness Transfer (CMRT): Training Robust Speech Translation Models Using Adversarial Text]]></title>
<link>http://arxiv.org/abs/2602.11933v1</link>
<guid>2602.11933v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.CL
Authors: Abderrahmane Issam, Yusuf Can Semerci, Jan Scholtes, Gerasimos Spanakis
Institution: 
Published: 2026-02-12
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

End-to-End Speech Translation (E2E-ST) has seen significant advancements, yet current models are primarily benchmarked on curated, "clean" datasets. This overlooks critical real-world challenges, such as morphological robustness to inflectional variations common in non-native or dialectal speech. In this work, we adapt a text-based adversarial attack targeting inflectional morphology to the speech domain and demonstrate that state-of-the-art E2E-ST models are highly vulnerable it. While adversarial training effectively mitigates such risks in text-based tasks, generating high-quality adversarial speech data remains computationally expensive and technically challenging. To address this, we propose Cross-Modal Robustness Transfer (CMRT), a framework that transfers adversarial robustness from the text modality to the speech modality. Our method eliminates the requirement for adversarial speech data during training. Extensive experiments across four language pairs demonstrate that CMRT improves adversarial robustness by an average of more than 3 BLEU points, establishing a new baseline for robust E2E-ST without the overhead of generating adversarial speech.]]></description>
<pubDate>Thu, 12 Feb 2026 13:30:12 +0000</pubDate>
</item>
<item>
<title><![CDATA[AdaptEvolve: Improving Efficiency of Evolutionary AI Agents through Adaptive Model Selection]]></title>
<link>http://arxiv.org/abs/2602.11931v1</link>
<guid>2602.11931v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.CL, cs.AI
Authors: Pretam Ray, Pratik Prabhanjan Brahma, Zicheng Liu, Emad Barsoum
Institution: 
Published: 2026-02-12
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Evolutionary agentic systems intensify the trade-off between computational efficiency and reasoning capability by repeatedly invoking large language models (LLMs) during inference. This setting raises a central question: how can an agent dynamically select an LLM that is sufficiently capable for the current generation step while remaining computationally efficient? While model cascades offer a practical mechanism for balancing this trade-off, existing routing strategies typically rely on static heuristics or external controllers and do not explicitly account for model uncertainty. We introduce AdaptEvolve: Adaptive LLM Selection for Multi-LLM Evolutionary Refinement within an evolutionary sequential refinement framework that leverages intrinsic generation confidence to estimate real-time solvability. Empirical results show that confidence-driven selection yields a favourable Pareto frontier, reducing total inference cost by an average of 37.9% across benchmarks while retaining 97.5% of the upper-bound accuracy of static large-model baselines. Our code is available at https://github.com/raypretam/adaptive_llm_selection.]]></description>
<pubDate>Thu, 12 Feb 2026 13:26:56 +0000</pubDate>
</item>
<item>
<title><![CDATA[Who Does What? Archetypes of Roles Assigned to LLMs During Human-AI Decision-Making]]></title>
<link>http://arxiv.org/abs/2602.11924v1</link>
<guid>2602.11924v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.HC, cs.AI
Authors: Shreya Chappidi, Jatinder Singh, Andra V. Krauze
Institution: 
Published: 2026-02-12
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

LLMs are increasingly supporting decision-making across high-stakes domains, requiring critical reflection on the socio-technical factors that shape how humans and LLMs are assigned roles and interact during human-in-the-loop decision-making. This paper introduces the concept of human-LLM archetypes -- defined as re-curring socio-technical interaction patterns that structure the roles of humans and LLMs in collaborative decision-making. We describe 17 human-LLM archetypes derived from a scoping literature review and thematic analysis of 113 LLM-supported decision-making papers. Then, we evaluate these diverse archetypes across real-world clinical diagnostic cases to examine the potential effects of adopting distinct human-LLM archetypes on LLM outputs and decision outcomes. Finally, we present relevant tradeoffs and design choices across human-LLM archetypes, including decision control, social hierarchies, cognitive forcing strategies, and information requirements. Through our analysis, we show that selection of human-LLM interaction archetype can influence LLM outputs and decisions, bringing important risks and considerations for the designers of human-AI decision-making systems]]></description>
<pubDate>Thu, 12 Feb 2026 13:23:04 +0000</pubDate>
</item>
<item>
<title><![CDATA[Learning Conditional Averages]]></title>
<link>http://arxiv.org/abs/2602.11920v1</link>
<guid>2602.11920v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.LG, stat.ML
Authors: Marco Bressan, Nataly Brukhim, Nicolo Cesa-Bianchi, Emmanuel Esposito, Yishay Mansour et al.
Institution: 
Published: 2026-02-12
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

We introduce the problem of learning conditional averages in the PAC framework. The learner receives a sample labeled by an unknown target concept from a known concept class, as in standard PAC learning. However, instead of learning the target concept itself, the goal is to predict, for each instance, the average label over its neighborhood -- an arbitrary subset of points that contains the instance. In the degenerate case where all neighborhoods are singletons, the problem reduces exactly to classic PAC learning. More generally, it extends PAC learning to a setting that captures learning tasks arising in several domains, including explainability, fairness, and recommendation systems. Our main contribution is a complete characterization of when conditional averages are learnable, together with sample complexity bounds that are tight up to logarithmic factors. The characterization hinges on the joint finiteness of two novel combinatorial parameters, which depend on both the concept class and the neighborhood system, and are closely related to the independence number of the associated neighborhood graph.]]></description>
<pubDate>Thu, 12 Feb 2026 13:20:29 +0000</pubDate>
</item>
<item>
<title><![CDATA[DynaHOI: Benchmarking Hand-Object Interaction for Dynamic Target]]></title>
<link>http://arxiv.org/abs/2602.11919v1</link>
<guid>2602.11919v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.CV, cs.AI
Authors: BoCheng Hu, Zhonghan Zhao, Kaiyue Zhou, Hongwei Wang, Gaoang Wang
Institution: 
Published: 2026-02-12
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Most existing hand motion generation benchmarks for hand-object interaction (HOI) focus on static objects, leaving dynamic scenarios with moving targets and time-critical coordination largely untested. To address this gap, we introduce the DynaHOI-Gym, a unified online closed-loop platform with parameterized motion generators and rollout-based metrics for dynamic capture evaluation. Built on DynaHOI-Gym, we release DynaHOI-10M, a large-scale benchmark with 10M frames and 180K hand capture trajectories, whose target motions are organized into 8 major categories and 22 fine-grained subcategories. We also provide a simple observe-before-act baseline (ObAct) that integrates short-term observations with the current frame via spatiotemporal attention to predict actions, achieving an 8.1% improvement in location success rate.]]></description>
<pubDate>Thu, 12 Feb 2026 13:19:41 +0000</pubDate>
</item>
<item>
<title><![CDATA[MEME: Modeling the Evolutionary Modes of Financial Markets]]></title>
<link>http://arxiv.org/abs/2602.11918v1</link>
<guid>2602.11918v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.AI
Authors: Taian Guo, Haiyang Shen, Junyu Luo, Zhongshi Xing, Hanchun Lian et al.
Institution: 
Published: 2026-02-12
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

LLMs have demonstrated significant potential in quantitative finance by processing vast unstructured data to emulate human-like analytical workflows. However, current LLM-based methods primarily follow either an Asset-Centric paradigm focused on individual stock prediction or a Market-Centric approach for portfolio allocation, often remaining agnostic to the underlying reasoning that drives market movements. In this paper, we propose a Logic-Oriented perspective, modeling the financial market as a dynamic, evolutionary ecosystem of competing investment narratives, termed Modes of Thought. To operationalize this view, we introduce MEME (Modeling the Evolutionary Modes of Financial Markets), designed to reconstruct market dynamics through the lens of evolving logics. MEME employs a multi-agent extraction module to transform noisy data into high-fidelity Investment Arguments and utilizes Gaussian Mixture Modeling to uncover latent consensus within a semantic space. To model semantic drift among different market conditions, we also implement a temporal evaluation and alignment mechanism to track the lifecycle and historical profitability of these modes. By prioritizing enduring market wisdom over transient anomalies, MEME ensures that portfolio construction is guided by robust reasoning. Extensive experiments on three heterogeneous Chinese stock pools from 2023 to 2025 demonstrate that MEME consistently outperforms seven SOTA baselines. Further ablation studies, sensitivity analysis, lifecycle case study and cost analysis validate MEME's capacity to identify and adapt to the evolving consensus of financial markets. Our implementation can be found at https://github.com/gta0804/MEME.]]></description>
<pubDate>Thu, 12 Feb 2026 13:16:05 +0000</pubDate>
</item>
<item>
<title><![CDATA[AlphaPROBE: Alpha Mining via Principled Retrieval and On-graph biased evolution]]></title>
<link>http://arxiv.org/abs/2602.11917v1</link>
<guid>2602.11917v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.AI
Authors: Taian Guo, Haiyang Shen, Junyu Luo, Binqi Chen, Hongjun Ding et al.
Institution: 
Published: 2026-02-12
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Extracting signals through alpha factor mining is a fundamental challenge in quantitative finance. Existing automated methods primarily follow two paradigms: Decoupled Factor Generation, which treats factor discovery as isolated events, and Iterative Factor Evolution, which focuses on local parent-child refinements. However, both paradigms lack a global structural view, often treating factor pools as unstructured collections or fragmented chains, which leads to redundant search and limited diversity. To address these limitations, we introduce AlphaPROBE (Alpha Mining via Principled Retrieval and On-graph Biased Evolution), a framework that reframes alpha mining as the strategic navigation of a Directed Acyclic Graph (DAG). By modeling factors as nodes and evolutionary links as edges, AlphaPROBE treats the factor pool as a dynamic, interconnected ecosystem. The framework consists of two core components: a Bayesian Factor Retriever that identifies high-potential seeds by balancing exploitation and exploration through a posterior probability model, and a DAG-aware Factor Generator that leverages the full ancestral trace of factors to produce context-aware, nonredundant optimizations. Extensive experiments on three major Chinese stock market datasets against 8 competitive baselines demonstrate that AlphaPROBE significantly gains enhanced performance in predictive accuracy, return stability and training efficiency. Our results confirm that leveraging global evolutionary topology is essential for efficient and robust automated alpha discovery. We have open-sourced our implementation at https://github.com/gta0804/AlphaPROBE.]]></description>
<pubDate>Thu, 12 Feb 2026 13:14:58 +0000</pubDate>
</item>
<item>
<title><![CDATA[TADA! Tuning Audio Diffusion Models through Activation Steering]]></title>
<link>http://arxiv.org/abs/2602.11910v1</link>
<guid>2602.11910v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.SD, cs.LG
Authors: ukasz Staniszewski, Katarzyna Zaleska, Mateusz Modrzejewski, Kamil Deja
Institution: 
Published: 2026-02-12
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Audio diffusion models can synthesize high-fidelity music from text, yet their internal mechanisms for representing high-level concepts remain poorly understood. In this work, we use activation patching to demonstrate that distinct semantic musical concepts, such as the presence of specific instruments, vocals, or genre characteristics, are controlled by a small, shared subset of attention layers in state-of-the-art audio diffusion architectures. Next, we demonstrate that applying Contrastive Activation Addition and Sparse Autoencoders in these layers enables more precise control over the generated audio, indicating a direct benefit of the specialization phenomenon. By steering activations of the identified layers, we can alter specific musical elements with high precision, such as modulating tempo or changing a track's mood.]]></description>
<pubDate>Thu, 12 Feb 2026 13:07:14 +0000</pubDate>
</item>
<item>
<title><![CDATA[Echo: Towards Advanced Audio Comprehension via Audio-Interleaved Reasoning]]></title>
<link>http://arxiv.org/abs/2602.11909v1</link>
<guid>2602.11909v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.SD, cs.LG
Authors: Daiqing Wu, Xuan Zhang, Dongbao Yang, Jiashu Yao, Longfei Chen et al.
Institution: 
Published: 2026-02-12
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

The maturation of Large Audio Language Models (LALMs) has raised growing expectations for them to comprehend complex audio much like humans. Current efforts primarily replicate text-based reasoning by contextualizing audio content through a one-time encoding, which introduces a critical information bottleneck. Drawing inspiration from human cognition, we propose audio-interleaved reasoning to break through this bottleneck. It treats audio as an active reasoning component, enabling sustained audio engagement and perception-grounded analysis. To instantiate it, we introduce a two-stage training framework, first teaching LALMs to localize salient audio segments through supervised fine-tuning, and then incentivizing proficient re-listening via reinforcement learning. In parallel, a structured data generation pipeline is developed to produce high-quality training data. Consequently, we present Echo, a LALM capable of dynamically re-listening to audio in demand during reasoning. On audio comprehension benchmarks, Echo achieves overall superiority in both challenging expert-level and general-purpose tasks. Comprehensive analysis further confirms the efficiency and generalizability of audio-interleaved reasoning, establishing it as a promising direction for advancing audio comprehension. Project page: https://github.com/wdqqdw/Echo.]]></description>
<pubDate>Thu, 12 Feb 2026 13:06:34 +0000</pubDate>
</item>
<item>
<title><![CDATA[When Should LLMs Be Less Specific? Selective Abstraction for Reliable Long-Form Text Generation]]></title>
<link>http://arxiv.org/abs/2602.11908v1</link>
<guid>2602.11908v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.AI, cs.CL, cs.LG
Authors: Shani Goren, Ido Galil, Ran El-Yaniv
Institution: 
Published: 2026-02-12
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

LLMs are widely used, yet they remain prone to factual errors that erode user trust and limit adoption in high-risk settings. One approach to mitigate this risk is to equip models with uncertainty estimation mechanisms that abstain when confidence is low. However, this binary "all-or-nothing" approach is excessively restrictive in long-form settings, often discarding valuable information. We introduce Selective Abstraction (SA), a framework that enables LLMs to trade specificity for reliability by selectively reducing the detail of uncertain content. We first formalize SA through the lenses of selective risk and coverage. We then propose Atom-wise Selective Abstraction, a claim-level instantiation that decomposes responses into atomic claims (short, self-contained statements each expressing a single fact) and replaces uncertain atoms with higher confidence, less specific abstractions. To evaluate this framework, we develop a novel end-to-end pipeline for open-ended generation that instantiates risk as factual correctness and measures coverage using an information-theoretic measure of retained information. Across six open-source models on the FactScore and LongFact-Objects benchmarks, atom-wise SA consistently outperforms existing baselines, improving the area under the risk-coverage curve (AURC) by up to 27.73% over claim removal, demonstrating that reducing specificity can boost accuracy and reliability while preserving most of their original meaning.]]></description>
<pubDate>Thu, 12 Feb 2026 13:06:14 +0000</pubDate>
</item>
<item>
<title><![CDATA[Leveraging LLMs to support co-evolution between definitions and instances of textual DSLs: A Systematic Evaluation]]></title>
<link>http://arxiv.org/abs/2602.11904v1</link>
<guid>2602.11904v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.SE, cs.AI
Authors: Weixing Zhang, Bowen Jiang, Yuhong Fu, Anne Koziolek, Regina Hebig et al.
Institution: 
Published: 2026-02-12
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Software languages evolve over time for reasons such as feature additions. When grammars evolve, textual instances that originally conformed to them may become outdated. While model-driven engineering provides many techniques for co-evolving models with metamodel changes, these approaches are not designed for textual DSLs and may lose human-relevant information such as layout and comments. This study systematically evaluates the potential of large language models (LLMs) for co-evolving grammars and instances of textual DSLs. Using Claude Sonnet 4.5 and GPT-5.2 across ten case languages with ten runs each, we assess both correctness and preservation of human-oriented information. Results show strong performance on small-scale cases ($\geq$94% precision and recall for instances requiring fewer than 20 modified lines), but performance degraded with scale: Claude maintains 85% recall at 40 lines, while GPT fails on the largest instances. Response time increases substantially with instance size, and grammar evolution complexity and deletion granularity affect performance more than change type. These findings clarify when LLM-based co-evolution is effective and where current limitations remain.]]></description>
<pubDate>Thu, 12 Feb 2026 13:01:01 +0000</pubDate>
</item>
<item>
<title><![CDATA[Learning Perceptual Representations for Gaming NR-VQA with Multi-Task FR Signals]]></title>
<link>http://arxiv.org/abs/2602.11903v1</link>
<guid>2602.11903v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.CV, cs.MM
Authors: Yu-Chih Chen, Michael Wang, Chieh-Dun Wen, Kai-Siang Ma, Avinab Saha et al.
Institution: 
Published: 2026-02-12
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

No-reference video quality assessment (NR-VQA) for gaming videos is challenging due to limited human-rated datasets and unique content characteristics including fast motion, stylized graphics, and compression artifacts. We present MTL-VQA, a multi-task learning framework that uses full-reference metrics as supervisory signals to learn perceptually meaningful features without human labels for pretraining. By jointly optimizing multiple full-reference (FR) objectives with adaptive task weighting, our approach learns shared representations that transfer effectively to NR-VQA. Experiments on gaming video datasets show MTL-VQA achieves performance competitive with state-of-the-art NR-VQA methods across both MOS-supervised and label-efficient/self-supervised settings.]]></description>
<pubDate>Thu, 12 Feb 2026 12:56:58 +0000</pubDate>
</item>
<item>
<title><![CDATA[Mitigating Mismatch within Reference-based Preference Optimization]]></title>
<link>http://arxiv.org/abs/2602.11902v1</link>
<guid>2602.11902v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.LG, cs.AI
Authors: Suqin Yuan, Xingrui Yu, Jiyang Zheng, Lei Feng, Dadong Wang et al.
Institution: 
Published: 2026-02-12
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Direct Preference Optimization (DPO) has become the de facto standard for offline preference alignment of large language models, but its reliance on a reference policy introduces a critical tension. DPO weighs each update relative to a reference, which stabilizes the training by regularizing the updates within a trusted region. This reliance becomes problematic for pessimistic pairs, where the reference model prefers the rejected response. For these pairs, DPO prematurely attenuates the gradient as soon as the policy margin ($_$) merely beats the reference margin ($_{\mathrm{ref}}$) even if the policy is still wrong ($_<0$). We name this failure premature satisfaction, which is a concrete form of the training-inference mismatch. Reference-free objectives remove this mismatch by optimizing the absolute margin, but at the cost of discarding the stabilizing signal of the reference. We mitigate this tension with Hybrid-DPO (HyPO), a drop-in modification to DPO that applies reference conditionally: HyPO behaves exactly like DPO when the reference is optimistic or neutral, and it treats the reference as neutral when it is pessimistic by replacing $_-_{\mathrm{ref}}$ with $_-\max\{0,_{\mathrm{ref}}\}$. This one-line change strictly strengthens per-example learning signals on pessimistic pairs while preserving DPO's objective form and computational cost. By conditionally debiasing the pessimistic reference signal, HyPO mitigates premature satisfaction; empirically, across preference alignment, HyPO improves inference-aligned metrics and achieves higher pairwise win rates. Our results provide evidence that direct preference alignment could be enhanced by conditionally debiasing the reference signal, rather than discarding it.]]></description>
<pubDate>Thu, 12 Feb 2026 12:55:51 +0000</pubDate>
</item>
<item>
<title><![CDATA[Benchmark Illusion: Disagreement among LLMs and Its Scientific Consequences]]></title>
<link>http://arxiv.org/abs/2602.11898v1</link>
<guid>2602.11898v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.CL
Authors: Eddie Yang, Dashun Wang
Institution: 
Published: 2026-02-12
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Benchmarks underpin how progress in large language models (LLMs) is measured and trusted. Yet our analyses reveal that apparent convergence in benchmark accuracy can conceal deep epistemic divergence. Using two major reasoning benchmarks - MMLU-Pro and GPQA - we show that LLMs achieving comparable accuracy still disagree on 16-66% of items, and 16-38% among top-performing frontier models. These discrepancies suggest distinct error profiles for different LLMs. When such models are used for scientific data annotation and inference, their hidden disagreements propagate into research results: in re-analyses of published studies in education and political science, switching the annotation model can change estimated treatment effects by more than 80%, and in some cases reverses their sign. Together, these findings illustrate a benchmark illusion, where equal accuracy may conceal disagreement, with model choice becoming a hidden yet consequential variable for scientific reproducibility.]]></description>
<pubDate>Thu, 12 Feb 2026 12:53:39 +0000</pubDate>
</item>
<item>
<title><![CDATA[Agentic AI for Cybersecurity: A Meta-Cognitive Architecture for Governable Autonomy]]></title>
<link>http://arxiv.org/abs/2602.11897v1</link>
<guid>2602.11897v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.CR, cs.AI
Authors: Andrei Kojukhov, Arkady Bovshover
Institution: 
Published: 2026-02-12
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Contemporary AI-driven cybersecurity systems are predominantly architected as model-centric detection and automation pipelines optimized for task-level performance metrics such as accuracy and response latency. While effective for bounded classification tasks, these architectures struggle to support accountable decision-making under adversarial uncertainty, where actions must be justified, governed, and aligned with organizational and regulatory constraints. This paper argues that cybersecurity orchestration should be reconceptualized as an agentic, multi-agent cognitive system, rather than a linear sequence of detection and response components. We introduce a conceptual architectural framework in which heterogeneous AI agents responsible for detection, hypothesis formation, contextual interpretation, explanation, and governance are coordinated through an explicit meta-cognitive judgement function. This function governs decision readiness and dynamically calibrates system autonomy when evidence is incomplete, conflicting, or operationally risky. By synthesizing distributed cognition theory, multi-agent systems research, and responsible AI governance frameworks, we demonstrate that modern security operations already function as distributed cognitive systems, albeit without an explicit organizing principle. Our contribution is to make this cognitive structure architecturally explicit and governable by embedding meta-cognitive judgement as a first-class system function. We discuss implications for security operations centers, accountable autonomy, and the design of next-generation AI-enabled cyber defence architectures. The proposed framework shifts the focus of AI in cybersecurity from optimizing isolated predictions to governing autonomy under uncertainty.]]></description>
<pubDate>Thu, 12 Feb 2026 12:52:49 +0000</pubDate>
</item>
<item>
<title><![CDATA[Universal Diffusion-Based Probabilistic Downscaling]]></title>
<link>http://arxiv.org/abs/2602.11893v1</link>
<guid>2602.11893v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.LG
Authors: Roberto Molinaro, Niall Siegenheim, Henry Martin, Mark Frey, Niels Poulsen et al.
Institution: 
Published: 2026-02-12
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

We introduce a universal diffusion-based downscaling framework that lifts deterministic low-resolution weather forecasts into probabilistic high-resolution predictions without any model-specific fine-tuning. A single conditional diffusion model is trained on paired coarse-resolution inputs (~25 km resolution) and high-resolution regional reanalysis targets (~5 km resolution), and is applied in a fully zero-shot manner to deterministic forecasts from heterogeneous upstream weather models. Focusing on near-surface variables, we evaluate probabilistic forecasts against independent in situ station observations over lead times up to 90 h. Across a diverse set of AI-based and numerical weather prediction (NWP) systems, the ensemble mean of the downscaled forecasts consistently improves upon each model's own raw deterministic forecast, and substantially larger gains are observed in probabilistic skill as measured by CRPS. These results demonstrate that diffusion-based downscaling provides a scalable, model-agnostic probabilistic interface for enhancing spatial resolution and uncertainty representation in operational weather forecasting pipelines.]]></description>
<pubDate>Thu, 12 Feb 2026 12:42:46 +0000</pubDate>
</item>
<item>
<title><![CDATA[LLM-based Triplet Extraction from Financial Reports]]></title>
<link>http://arxiv.org/abs/2602.11886v1</link>
<guid>2602.11886v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.CL
Authors: Dante Wesslund, Ville Stenstrm, Pontus Linde, Alexander Holmberg
Institution: 
Published: 2026-02-12
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Corporate financial reports are a valuable source of structured knowledge for Knowledge Graph construction, but the lack of annotated ground truth in this domain makes evaluation difficult. We present a semi-automated pipeline for Subject-Predicate-Object triplet extraction that uses ontology-driven proxy metrics, specifically Ontology Conformance and Faithfulness, instead of ground-truth-based evaluation. We compare a static, manually engineered ontology against a fully automated, document-specific ontology induction approach across different LLMs and two corporate annual reports. The automatically induced ontology achieves 100% schema conformance in all configurations, eliminating the ontology drift observed with the manual approach. We also propose a hybrid verification strategy that combines regex matching with an LLM-as-a-judge check, reducing apparent subject hallucination rates from 65.2% to 1.6% by filtering false positives caused by coreference resolution. Finally, we identify a systematic asymmetry between subject and object hallucinations, which we attribute to passive constructions and omitted agents in financial prose.]]></description>
<pubDate>Thu, 12 Feb 2026 12:36:10 +0000</pubDate>
</item>
<item>
<title><![CDATA[Where Bits Matter in World Model Planning: A Paired Mixed-Bit Study for Efficient Spatial Reasoning]]></title>
<link>http://arxiv.org/abs/2602.11882v1</link>
<guid>2602.11882v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.LG, cs.AI, cs.CV, cs.RO
Authors: Suraj Ranganath, Anish Patnaik, Vaishak Menon
Institution: 
Published: 2026-02-12
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Efficient spatial reasoning requires world models that remain reliable under tight precision budgets. We study whether low-bit planning behavior is determined mostly by total bitwidth or by where bits are allocated across modules. Using DINO-WM on the Wall planning task, we run a paired-goal mixed-bit evaluation across uniform, mixed, asymmetric, and layerwise variants under two planner budgets. We observe a consistent three-regime pattern: 8-bit and 6-bit settings remain close to FP16, 3-bit settings collapse, and 4-bit settings are allocation-sensitive. In that transition region, preserving encoder precision improves planning relative to uniform quantization, and near-size asymmetric variants show the same encoder-side direction. In a later strict 22-cell replication with smaller per-cell episode count, the mixed-versus-uniform INT4 sign becomes budget-conditioned, which further highlights the sensitivity of this transition regime. These findings motivate module-aware, budget-aware quantization policies as a broader research direction for efficient spatial reasoning. Code and run artifacts are available at https://github.com/suraj-ranganath/DINO-MBQuant.]]></description>
<pubDate>Thu, 12 Feb 2026 12:32:51 +0000</pubDate>
</item>
<item>
<title><![CDATA[From Atoms to Trees: Building a Structured Feature Forest with Hierarchical Sparse Autoencoders]]></title>
<link>http://arxiv.org/abs/2602.11881v1</link>
<guid>2602.11881v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.AI
Authors: Yifan Luo, Yang Zhan, Jiedong Jiang, Tianyang Liu, Mingrui Wu et al.
Institution: 
Published: 2026-02-12
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Sparse autoencoders (SAEs) have proven effective for extracting monosemantic features from large language models (LLMs), yet these features are typically identified in isolation. However, broad evidence suggests that LLMs capture the intrinsic structure of natural language, where the phenomenon of "feature splitting" in particular indicates that such structure is hierarchical. To capture this, we propose the Hierarchical Sparse Autoencoder (HSAE), which jointly learns a series of SAEs and the parent-child relationships between their features. HSAE strengthens the alignment between parent and child features through two novel mechanisms: a structural constraint loss and a random feature perturbation mechanism. Extensive experiments across various LLMs and layers demonstrate that HSAE consistently recovers semantically meaningful hierarchies, supported by both qualitative case studies and rigorous quantitative metrics. At the same time, HSAE preserves the reconstruction fidelity and interpretability of standard SAEs across different dictionary sizes. Our work provides a powerful, scalable tool for discovering and analyzing the multi-scale conceptual structures embedded in LLM representations.]]></description>
<pubDate>Thu, 12 Feb 2026 12:30:23 +0000</pubDate>
</item>
<item>
<title><![CDATA[SynthRAR: Ring Artifacts Reduction in CT with Unrolled Network and Synthetic Data Training]]></title>
<link>http://arxiv.org/abs/2602.11880v1</link>
<guid>2602.11880v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.CV, cs.AI
Authors: Hongxu Yang, Levente Lippenszky, Edina Timko, Gopal Avinash
Institution: 
Published: 2026-02-12
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Defective and inconsistent responses in CT detectors can cause ring and streak artifacts in the reconstructed images, making them unusable for clinical purposes. In recent years, several ring artifact reduction solutions have been proposed in the image domain or in the sinogram domain using supervised deep learning methods. However, these methods require dedicated datasets for training, leading to a high data collection cost. Furthermore, existing approaches focus exclusively on either image-space or sinogram-space correction, neglecting the intrinsic correlations from the forward operation of the CT geometry. Based on the theoretical analysis of non-ideal CT detector responses, the RAR problem is reformulated as an inverse problem by using an unrolled network, which considers non-ideal response together with linear forward-projection with CT geometry. Additionally, the intrinsic correlations of ring artifacts between the sinogram and image domains are leveraged through synthetic data derived from natural images, enabling the trained model to correct artifacts without requiring real-world clinical data. Extensive evaluations on diverse scanning geometries and anatomical regions demonstrate that the model trained on synthetic data consistently outperforms existing state-of-the-art methods.]]></description>
<pubDate>Thu, 12 Feb 2026 12:30:14 +0000</pubDate>
</item>
<item>
<title><![CDATA[Towards Fair and Comprehensive Evaluation of Routers in Collaborative LLM Systems]]></title>
<link>http://arxiv.org/abs/2602.11877v1</link>
<guid>2602.11877v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.CL, cs.AI
Authors: Wanxing Wu, He Zhu, Yixia Li, Lei Yang, Jiehui Zhao et al.
Institution: 
Published: 2026-02-12
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Large language models (LLMs) have achieved success, but cost and privacy constraints necessitate deploying smaller models locally while offloading complex queries to cloud-based models. Existing router evaluations are unsystematic, overlooking scenario-specific requirements and out-of-distribution robustness. We propose RouterXBench, a principled evaluation framework with three dimensions: router ability, scenario alignment, and cross-domain robustness. Unlike prior work that relies on output probabilities or external embeddings, we utilize internal hidden states that capture model uncertainty before answer generation. We introduce ProbeDirichlet, a lightweight router that aggregates cross-layer hidden states via learnable Dirichlet distributions with probabilistic training. Trained on multi-domain data, it generalizes robustly across in-domain and out-of-distribution scenarios. Our results show ProbeDirichlet achieves 16.68% and 18.86% relative improvements over the best baselines in router ability and high-accuracy scenarios, with consistent performance across model families, model scales, heterogeneous tasks, and agentic workflows.]]></description>
<pubDate>Thu, 12 Feb 2026 12:28:27 +0000</pubDate>
</item>
<item>
<title><![CDATA[DiffPlace: Street View Generation via Place-Controllable Diffusion Model Enhancing Place Recognition]]></title>
<link>http://arxiv.org/abs/2602.11875v1</link>
<guid>2602.11875v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.CV, cs.RO
Authors: Ji Li, Zhiwei Li, Shihao Li, Zhenjiang Yu, Boyang Wang et al.
Institution: 
Published: 2026-02-12
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Generative models have advanced significantly in realistic image synthesis, with diffusion models excelling in quality and stability. Recent multi-view diffusion models improve 3D-aware street view generation, but they struggle to produce place-aware and background-consistent urban scenes from text, BEV maps, and object bounding boxes. This limits their effectiveness in generating realistic samples for place recognition tasks. To address these challenges, we propose DiffPlace, a novel framework that introduces a place-ID controller to enable place-controllable multi-view image generation. The place-ID controller employs linear projection, perceiver transformer, and contrastive learning to map place-ID embeddings into a fixed CLIP space, allowing the model to synthesize images with consistent background buildings while flexibly modifying foreground objects and weather conditions. Extensive experiments, including quantitative comparisons and augmented training evaluations, demonstrate that DiffPlace outperforms existing methods in both generation quality and training support for visual place recognition. Our results highlight the potential of generative models in enhancing scene-level and place-aware synthesis, providing a valuable approach for improving place recognition in autonomous driving]]></description>
<pubDate>Thu, 12 Feb 2026 12:26:09 +0000</pubDate>
</item>
<item>
<title><![CDATA[DMAP: A Distribution Map for Text]]></title>
<link>http://arxiv.org/abs/2602.11871v1</link>
<guid>2602.11871v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.CL, cs.LG
Authors: Tom Kempton, Julia Rozanova, Parameswaran Kamalaruban, Maeve Madigan, Karolina Wresilo et al.
Institution: 
Published: 2026-02-12
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Large Language Models (LLMs) are a powerful tool for statistical text analysis, with derived sequences of next-token probability distributions offering a wealth of information. Extracting this signal typically relies on metrics such as perplexity, which do not adequately account for context; how one should interpret a given next-token probability is dependent on the number of reasonable choices encoded by the shape of the conditional distribution. In this work, we present DMAP, a mathematically grounded method that maps a text, via a language model, to a set of samples in the unit interval that jointly encode rank and probability information. This representation enables efficient, model-agnostic analysis and supports a range of applications. We illustrate its utility through three case studies: (i) validation of generation parameters to ensure data integrity, (ii) examining the role of probability curvature in machine-generated text detection, and (iii) a forensic analysis revealing statistical fingerprints left in downstream models that have been subject to post-training on synthetic data. Our results demonstrate that DMAP offers a unified statistical view of text that is simple to compute on consumer hardware, widely applicable, and provides a foundation for further research into text analysis with LLMs.]]></description>
<pubDate>Thu, 12 Feb 2026 12:21:24 +0000</pubDate>
</item>
<item>
<title><![CDATA[Intelligent AI Delegation]]></title>
<link>http://arxiv.org/abs/2602.11865v1</link>
<guid>2602.11865v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.AI
Authors: Nenad Tomaev, Matija Franklin, Simon Osindero
Institution: 
Published: 2026-02-12
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

AI agents are able to tackle increasingly complex tasks. To achieve more ambitious goals, AI agents need to be able to meaningfully decompose problems into manageable sub-components, and safely delegate their completion across to other AI agents and humans alike. Yet, existing task decomposition and delegation methods rely on simple heuristics, and are not able to dynamically adapt to environmental changes and robustly handle unexpected failures. Here we propose an adaptive framework for intelligent AI delegation - a sequence of decisions involving task allocation, that also incorporates transfer of authority, responsibility, accountability, clear specifications regarding roles and boundaries, clarity of intent, and mechanisms for establishing trust between the two (or more) parties. The proposed framework is applicable to both human and AI delegators and delegatees in complex delegation networks, aiming to inform the development of protocols in the emerging agentic web.]]></description>
<pubDate>Thu, 12 Feb 2026 12:11:42 +0000</pubDate>
</item>
<item>
<title><![CDATA[In-Context Function Learning in Large Language Models]]></title>
<link>http://arxiv.org/abs/2602.11863v1</link>
<guid>2602.11863v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.LG
Authors: Elif Akata, Konstantinos Voudouris, Vincent Fortuin, Eric Schulz
Institution: 
Published: 2026-02-12
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Large language models (LLMs) can learn from a few demonstrations provided at inference time. We study this in-context learning phenomenon through the lens of Gaussian Processes (GPs). We build controlled experiments where models observe sequences of multivariate scalar-valued function samples drawn from known GP priors. We evaluate prediction error in relation to the number of demonstrations and compare against two principled references: (i) an empirical GP-regression learner that gives a lower bound on achievable error, and (ii) the expected error of a 1-nearest-neighbor (1-NN) rule, which gives a data-driven upper bound. Across model sizes, we find that LLM learning curves are strongly influenced by the function-generating kernels and approach the GP lower bound as the number of demonstrations increases. We then study the inductive biases of these models using a likelihood-based analysis. We find that LLM predictions are most likely under less smooth GP kernels. Finally, we explore whether post-training can shift these inductive biases and improve sample-efficiency on functions sampled from GPs with smoother kernels. We find that both reinforcement learning and supervised fine-tuning can effectively shift inductive biases in the direction of the training data. Together, our framework quantifies the extent to which LLMs behave like GP learners and provides tools for steering their inductive biases for continuous function learning tasks.]]></description>
<pubDate>Thu, 12 Feb 2026 12:09:48 +0000</pubDate>
</item>
<item>
<title><![CDATA[A$^{2}$V-SLP: Alignment-Aware Variational Modeling for Disentangled Sign Language Production]]></title>
<link>http://arxiv.org/abs/2602.11861v1</link>
<guid>2602.11861v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.LG, cs.CL
Authors: Smeyye Meryem Tayrek, Enis Mcahid skender, Hacer Yalim Keles
Institution: 
Published: 2026-02-12
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Building upon recent structural disentanglement frameworks for sign language production, we propose A$^{2}$V-SLP, an alignment-aware variational framework that learns articulator-wise disentangled latent distributions rather than deterministic embeddings. A disentangled Variational Autoencoder (VAE) encodes ground-truth sign pose sequences and extracts articulator-specific mean and variance vectors, which are used as distributional supervision for training a non-autoregressive Transformer. Given text embeddings, the Transformer predicts both latent means and log-variances, while the VAE decoder reconstructs the final sign pose sequences through stochastic sampling at the decoding stage. This formulation maintains articulator-level representations by avoiding deterministic latent collapse through distributional latent modeling. In addition, we integrate a gloss attention mechanism to strengthen alignment between linguistic input and articulated motion. Experimental results show consistent gains over deterministic latent regression, achieving state-of-the-art back-translation performance and improved motion realism in a fully gloss-free setting.]]></description>
<pubDate>Thu, 12 Feb 2026 12:07:32 +0000</pubDate>
</item>
<item>
<title><![CDATA[Talk2DM: Enabling Natural Language Querying and Commonsense Reasoning for Vehicle-Road-Cloud Integrated Dynamic Maps with Large Language Models]]></title>
<link>http://arxiv.org/abs/2602.11860v1</link>
<guid>2602.11860v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.AI
Authors: Lu Tao, Jinxuan Luo, Yousuke Watanabe, Zhengshu Zhou, Yuhuan Lu et al.
Institution: 
Published: 2026-02-12
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Dynamic maps (DM) serve as the fundamental information infrastructure for vehicle-road-cloud (VRC) cooperative autonomous driving in China and Japan. By providing comprehensive traffic scene representations, DM overcome the limitations of standalone autonomous driving systems (ADS), such as physical occlusions. Although DM-enhanced ADS have been successfully deployed in real-world applications in Japan, existing DM systems still lack a natural-language-supported (NLS) human interface, which could substantially enhance human-DM interaction. To address this gap, this paper introduces VRCsim, a VRC cooperative perception (CP) simulation framework designed to generate streaming VRC-CP data. Based on VRCsim, we construct a question-answering data set, VRC-QA, focused on spatial querying and reasoning in mixed-traffic scenes. Building upon VRCsim and VRC-QA, we further propose Talk2DM, a plug-and-play module that extends VRC-DM systems with NLS querying and commonsense reasoning capabilities. Talk2DM is built upon a novel chain-of-prompt (CoP) mechanism that progressively integrates human-defined rules with the commonsense knowledge of large language models (LLMs). Experiments on VRC-QA show that Talk2DM can seamlessly switch across different LLMs while maintaining high NLS query accuracy, demonstrating strong generalization capability. Although larger models tend to achieve higher accuracy, they incur significant efficiency degradation. Our results reveal that Talk2DM, powered by Qwen3:8B, Gemma3:27B, and GPT-oss models, achieves over 93\% NLS query accuracy with an average response time of only 2-5 seconds, indicating strong practical potential.]]></description>
<pubDate>Thu, 12 Feb 2026 12:06:12 +0000</pubDate>
</item>
<item>
<title><![CDATA[Zooming without Zooming: Region-to-Image Distillation for Fine-Grained Multimodal Perception]]></title>
<link>http://arxiv.org/abs/2602.11858v1</link>
<guid>2602.11858v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.CV, cs.AI, cs.CL, cs.LG
Authors: Lai Wei, Liangbo He, Jun Lan, Lingzhong Dong, Yutong Cai et al.
Institution: 
Published: 2026-02-12
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Multimodal Large Language Models (MLLMs) excel at broad visual understanding but still struggle with fine-grained perception, where decisive evidence is small and easily overwhelmed by global context. Recent "Thinking-with-Images" methods alleviate this by iteratively zooming in and out regions of interest during inference, but incur high latency due to repeated tool calls and visual re-encoding. To address this, we propose Region-to-Image Distillation, which transforms zooming from an inference-time tool into a training-time primitive, thereby internalizing the benefits of agentic zooming into a single forward pass of an MLLM. In particular, we first zoom in to micro-cropped regions to let strong teacher models generate high-quality VQA data, and then distill this region-grounded supervision back to the full image. After training on such data, the smaller student model improves "single-glance" fine-grained perception without tool use. To rigorously evaluate this capability, we further present ZoomBench, a hybrid-annotated benchmark of 845 VQA data spanning six fine-grained perceptual dimensions, together with a dual-view protocol that quantifies the global--regional "zooming gap". Experiments show that our models achieve leading performance across multiple fine-grained perception benchmarks, and also improve general multimodal cognition on benchmarks such as visual reasoning and GUI agents. We further discuss when "Thinking-with-Images" is necessary versus when its gains can be distilled into a single forward pass. Our code is available at https://github.com/inclusionAI/Zooming-without-Zooming.]]></description>
<pubDate>Thu, 12 Feb 2026 12:00:35 +0000</pubDate>
</item>
<item>
<title><![CDATA[Scale-Invariant Fast Convergence in Games]]></title>
<link>http://arxiv.org/abs/2602.11857v1</link>
<guid>2602.11857v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.GT, cs.LG, stat.ML
Authors: Taira Tsuchiya, Haipeng Luo, Shinji Ito
Institution: 
Published: 2026-02-12
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Scale-invariance in games has recently emerged as a widely valued desirable property. Yet, almost all fast convergence guarantees in learning in games require prior knowledge of the utility scale. To address this, we develop learning dynamics that achieve fast convergence while being both scale-free, requiring no prior information about utilities, and scale-invariant, remaining unchanged under positive rescaling of utilities. For two-player zero-sum games, we obtain scale-free and scale-invariant dynamics with external regret bounded by $\tilde{O}(A_{\mathrm{diff}})$, where $A_{\mathrm{diff}}$ is the payoff range, which implies an $\tilde{O}(A_{\mathrm{diff}} / T)$ convergence rate to Nash equilibrium after $T$ rounds. For multiplayer general-sum games with $n$ players and $m$ actions, we obtain scale-free and scale-invariant dynamics with swap regret bounded by $O(U_{\mathrm{max}} \log T)$, where $U_{\mathrm{max}}$ is the range of the utilities, ignoring the dependence on the number of players and actions. This yields an $O(U_{\mathrm{max}} \log T / T)$ convergence rate to correlated equilibrium. Our learning dynamics are based on optimistic follow-the-regularized-leader with an adaptive learning rate that incorporates the squared path length of the opponents' gradient vectors, together with a new stopping-time analysis that exploits negative terms in regret bounds without scale-dependent tuning. For general-sum games, scale-free learning is enabled also by a technique called doubling clipping, which clips observed gradients based on past observations.]]></description>
<pubDate>Thu, 12 Feb 2026 11:57:20 +0000</pubDate>
</item>
<item>
<title><![CDATA[Robust Optimization Approach and Learning Based Hide-and-Seek Game for Resilient Network Design]]></title>
<link>http://arxiv.org/abs/2602.11854v1</link>
<guid>2602.11854v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.LG
Authors: Mohammad Khosravi, Setareh Maghsudi
Institution: 
Published: 2026-02-12
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

We study the design of resilient and reliable communication networks in which a signal can be transferred only up to a limited distance before its quality falls below an acceptable threshold. When excessive signal degradation occurs, regeneration is required through regenerators installed at selected network nodes. In this work, both network links and nodes are subject to uncertainty. The installation costs of regenerators are modeled using a budgeted uncertainty set. In addition, link lengths follow a dynamic budgeted uncertainty set introduced in this paper, where deviations may vary over time. Robust optimization seeks solutions whose performance is guaranteed under all scenarios represented by the underlying uncertainty set. Accordingly, the objective is to identify a minimum-cost subset of nodes for regenerator deployment that ensures full network connectivity, even under the worst possible realizations of uncertainty. To solve the problem, we first formulate it within a robust optimization framework, and then develop scalable solution methods based on column-and-constraint generation, Benders decomposition, and iterative robust optimization. In addition, we formulate a learning-based hide-and-seek game to further analyze the problem structure. The proposed approaches are evaluated against classical static budgeted robust models and deterministic worst-case formulations. Both theoretical analysis and computational results demonstrate the effectiveness and advantages of our methodology.]]></description>
<pubDate>Thu, 12 Feb 2026 11:48:24 +0000</pubDate>
</item>
<item>
<title><![CDATA[Prototype Transformer: Towards Language Model Architectures Interpretable by Design]]></title>
<link>http://arxiv.org/abs/2602.11852v1</link>
<guid>2602.11852v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.AI, cs.CL, cs.LG
Authors: Yordan Yordanov, Matteo Forasassi, Bayar Menzat, Ruizhi Wang, Chang Qi et al.
Institution: 
Published: 2026-02-12
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

While state-of-the-art language models (LMs) surpass the vast majority of humans in certain domains, their reasoning remains largely opaque, undermining trust in their output. Furthermore, while autoregressive LMs can output explicit reasoning, their true reasoning process is opaque, which introduces risks like deception and hallucination. In this work, we introduce the Prototype Transformer (ProtoT) -- an autoregressive LM architecture based on prototypes (parameter vectors), posed as an alternative to the standard self-attention-based transformers. ProtoT works by means of two-way communication between the input sequence and the prototypes, and we show that this leads to the prototypes automatically capturing nameable concepts (e.g. "woman") during training. They provide the potential to interpret the model's reasoning and allow for targeted edits of its behavior. Furthermore, by design, the prototypes create communication channels that aggregate contextual information at different time scales, aiding interpretability. In terms of computation scalability, ProtoT scales linearly with sequence length vs the quadratic scalability of SOTA self-attention transformers. Compared to baselines, ProtoT scales well with model and data size, and performs well on text generation and downstream tasks (GLUE). ProtoT exhibits robustness to input perturbations on par or better than some baselines, but differs from them by providing interpretable pathways showing how robustness and sensitivity arises. Reaching close to the performance of state-of-the-art architectures, ProtoT paves the way to creating well-performing autoregressive LMs interpretable by design.]]></description>
<pubDate>Thu, 12 Feb 2026 11:43:39 +0000</pubDate>
</item>
<item>
<title><![CDATA[Resource-Aware Deployment Optimization for Collaborative Intrusion Detection in Layered Networks]]></title>
<link>http://arxiv.org/abs/2602.11851v1</link>
<guid>2602.11851v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.CR, cs.AI
Authors: Andr Garca Gmez, Ines Rieger, Wolfgang Hotwagner, Max Landauer, Markus Wurzenberger et al.
Institution: 
Published: 2026-02-12
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Collaborative Intrusion Detection Systems (CIDS) are increasingly adopted to counter cyberattacks, as their collaborative nature enables them to adapt to diverse scenarios across heterogeneous environments. As distributed critical infrastructure operates in rapidly evolving environments, such as drones in both civil and military domains, there is a growing need for CIDS architectures that can flexibly accommodate these dynamic changes. In this study, we propose a novel CIDS framework designed for easy deployment across diverse distributed environments. The framework dynamically optimizes detector allocation per node based on available resources and data types, enabling rapid adaptation to new operational scenarios with minimal computational overhead. We first conducted a comprehensive literature review to identify key characteristics of existing CIDS architectures. Based on these insights and real-world use cases, we developed our CIDS framework, which we evaluated using several distributed datasets that feature different attack chains and network topologies. Notably, we introduce a public dataset based on a realistic cyberattack targeting a ground drone aimed at sabotaging critical infrastructure. Experimental results demonstrate that the proposed CIDS framework can achieve adaptive, efficient intrusion detection in distributed settings, automatically reconfiguring detectors to maintain an optimal configuration, without requiring heavy computation, since all experiments were conducted on edge devices.]]></description>
<pubDate>Thu, 12 Feb 2026 11:42:58 +0000</pubDate>
</item>
<item>
<title><![CDATA[Free Lunch for Stabilizing Rectified Flow Inversion]]></title>
<link>http://arxiv.org/abs/2602.11850v1</link>
<guid>2602.11850v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.CV, cs.LG
Authors: Chenru Wang, Beier Zhu, Chi Zhang
Institution: 
Published: 2026-02-12
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Rectified-Flow (RF)-based generative models have recently emerged as strong alternatives to traditional diffusion models, demonstrating state-of-the-art performance across various tasks. By learning a continuous velocity field that transforms simple noise into complex data, RF-based models not only enable high-quality generation, but also support training-free inversion, which facilitates downstream tasks such as reconstruction and editing. However, existing inversion methods, such as vanilla RF-based inversion, suffer from approximation errors that accumulate across timesteps, leading to unstable velocity fields and degraded reconstruction and editing quality. To address this challenge, we propose Proximal-Mean Inversion (PMI), a training-free gradient correction method that stabilizes the velocity field by guiding it toward a running average of past velocities, constrained within a theoretically derived spherical Gaussian. Furthermore, we introduce mimic-CFG, a lightweight velocity correction scheme for editing tasks, which interpolates between the current velocity and its projection onto the historical average, balancing editing effectiveness and structural consistency. Extensive experiments on PIE-Bench demonstrate that our methods significantly improve inversion stability, image reconstruction quality, and editing fidelity, while reducing the required number of neural function evaluations. Our approach achieves state-of-the-art performance on the PIE-Bench with enhanced efficiency and theoretical soundness.]]></description>
<pubDate>Thu, 12 Feb 2026 11:42:36 +0000</pubDate>
</item>
<item>
<title><![CDATA[WorldTree: Towards 4D Dynamic Worlds from Monocular Video using Tree-Chains]]></title>
<link>http://arxiv.org/abs/2602.11845v1</link>
<guid>2602.11845v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.CV
Authors: Qisen Wang, Yifan Zhao, Jia Li
Institution: 
Published: 2026-02-12
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Dynamic reconstruction has achieved remarkable progress, but there remain challenges in monocular input for more practical applications. The prevailing works attempt to construct efficient motion representations, but lack a unified spatiotemporal decomposition framework, suffering from either holistic temporal optimization or coupled hierarchical spatial composition. To this end, we propose WorldTree, a unified framework comprising Temporal Partition Tree (TPT) that enables coarse-to-fine optimization based on the inheritance-based partition tree structure for hierarchical temporal decomposition, and Spatial Ancestral Chains (SAC) that recursively query ancestral hierarchical structure to provide complementary spatial dynamics while specializing motion representations across ancestral nodes. Experimental results on different datasets indicate that our proposed method achieves 8.26% improvement of LPIPS on NVIDIA-LS and 9.09% improvement of mLPIPS on DyCheck compared to the second-best method. Code: https://github.com/iCVTEAM/WorldTree.]]></description>
<pubDate>Thu, 12 Feb 2026 11:38:35 +0000</pubDate>
</item>
<item>
<title><![CDATA[Improving Neural Retrieval with Attribution-Guided Query Rewriting]]></title>
<link>http://arxiv.org/abs/2602.11841v1</link>
<guid>2602.11841v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.IR, cs.AI, cs.LG
Authors: Moncef Garouani, Josiane Mothe
Institution: 
Published: 2026-02-12
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Neural retrievers are effective but brittle: underspecified or ambiguous queries can misdirect ranking even when relevant documents exist. Existing approaches address this brittleness only partially: LLMs rewrite queries without retriever feedback, and explainability methods identify misleading tokens but are used for post-hoc analysis. We close this loop and propose an attribution-guided query rewriting method that uses token-level explanations to guide query rewriting. For each query, we compute gradient-based token attributions from the retriever and then use these scores as soft guidance in a structured prompt to an LLM that clarifies weak or misleading query components while preserving intent. Evaluated on BEIR collections, the resulting rewrites consistently improve retrieval effectiveness over strong baselines, with larger gains for implicit or ambiguous information needs.]]></description>
<pubDate>Thu, 12 Feb 2026 11:34:06 +0000</pubDate>
</item>
<item>
<title><![CDATA[ULTRA:Urdu Language Transformer-based Recommendation Architecture]]></title>
<link>http://arxiv.org/abs/2602.11836v1</link>
<guid>2602.11836v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.IR, cs.AI
Authors: Alishbah Bashir, Fatima Qaiser, Ijaz Hussain
Institution: 
Published: 2026-02-12
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Urdu, as a low-resource language, lacks effective semantic content recommendation systems, particularly in the domain of personalized news retrieval. Existing approaches largely rely on lexical matching or language-agnostic techniques, which struggle to capture semantic intent and perform poorly under varying query lengths and information needs. This limitation results in reduced relevance and adaptability in Urdu content recommendation. We propose ULTRA (Urdu Language Transformer-based Recommendation Architecture),an adaptive semantic recommendation framework designed to address these challenges. ULTRA introduces a dual-embedding architecture with a query-length aware routing mechanism that dynamically distinguishes between short, intent-focused queries and longer, context-rich queries. Based on a threshold-driven decision process, user queries are routed to specialized semantic pipelines optimized for either title/headline-level or full-content/document level representations, ensuring appropriate semantic granularity during retrieval. The proposed system leverages transformer-based embeddings and optimized pooling strategies to move beyond surface-level keyword matching and enable context-aware similarity search. Extensive experiments conducted on a large-scale Urdu news corpus demonstrate that the proposed architecture consistently improves recommendation relevance across diverse query types. Results show gains in precision above 90% compared to single-pipeline baselines, highlighting the effectiveness of query-adaptive semantic alignment for low-resource languages. The findings establish ULTRA as a robust and generalizable content recommendation architecture, offering practical design insights for semantic retrieval systems in low-resource language settings.]]></description>
<pubDate>Thu, 12 Feb 2026 11:26:46 +0000</pubDate>
</item>
<item>
<title><![CDATA[EqDeepRx: Learning a Scalable MIMO Receiver]]></title>
<link>http://arxiv.org/abs/2602.11834v1</link>
<guid>2602.11834v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.LG
Authors: Mikko Honkala, Dani Korpi, Elias Raninen, Janne M. J. Huttunen
Institution: 
Published: 2026-02-12
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

While machine learning (ML)-based receiver algorithms have received a great deal of attention in the recent literature, they often suffer from poor scaling with increasing spatial multiplexing order and lack of explainability and generalization. This paper presents EqDeepRx, a practical deep-learning-aided multiple-input multiple-output (MIMO) receiver, which is built by augmenting linear receiver processing with carefully engineered ML blocks. At the core of the receiver model is a shared-weight DetectorNN that operates independently on each spatial stream or layer, enabling near-linear complexity scaling with respect to multiplexing order. To ensure better explainability and generalization, EqDeepRx retains conventional channel estimation and augments it with a lightweight DenoiseNN that learns frequency-domain smoothing. To reduce the dimensionality of the DetectorNN inputs, the receiver utilizes two linear equalizers in parallel: a linear minimum mean-square error (LMMSE) equalizer with interference-plus-noise covariance estimation and a regularized zero-forcing (RZF) equalizer. The parallel equalized streams are jointly consumed by the DetectorNN, after which a compact DemapperNN produces bit log-likelihood ratios for channel decoding. 5G/6G-compliant end-to-end simulations across multiple channel scenarios, pilot patterns, and inter-cell interference conditions show improved error rate and spectral efficiency over a conventional baseline, while maintaining low-complexity inference and support for different MIMO configurations without retraining.]]></description>
<pubDate>Thu, 12 Feb 2026 11:22:30 +0000</pubDate>
</item>
<item>
<title><![CDATA[JEPA-VLA: Video Predictive Embedding is Needed for VLA Models]]></title>
<link>http://arxiv.org/abs/2602.11832v1</link>
<guid>2602.11832v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.CV, cs.RO
Authors: Shangchen Miao, Ningya Feng, Jialong Wu, Ye Lin, Xu He et al.
Institution: 
Published: 2026-02-12
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Recent vision-language-action (VLA) models built upon pretrained vision-language models (VLMs) have achieved significant improvements in robotic manipulation. However, current VLAs still suffer from low sample efficiency and limited generalization. This paper argues that these limitations are closely tied to an overlooked component, pretrained visual representation, which offers insufficient knowledge on both aspects of environment understanding and policy prior. Through an in-depth analysis, we find that commonly used visual representations in VLAs, whether pretrained via language-image contrastive learning or image-based self-supervised learning, remain inadequate at capturing crucial, task-relevant environment information and at inducing effective policy priors, i.e., anticipatory knowledge of how the environment evolves under successful task execution. In contrast, we discover that predictive embeddings pretrained on videos, in particular V-JEPA 2, are adept at flexibly discarding unpredictable environment factors and encoding task-relevant temporal dynamics, thereby effectively compensating for key shortcomings of existing visual representations in VLAs. Building on these observations, we introduce JEPA-VLA, a simple yet effective approach that adaptively integrates predictive embeddings into existing VLAs. Our experiments demonstrate that JEPA-VLA yields substantial performance gains across a range of benchmarks, including LIBERO, LIBERO-plus, RoboTwin2.0, and real-robot tasks.]]></description>
<pubDate>Thu, 12 Feb 2026 11:20:43 +0000</pubDate>
</item>
<item>
<title><![CDATA[Towards Sustainable Investment Policies Informed by Opponent Shaping]]></title>
<link>http://arxiv.org/abs/2602.11829v1</link>
<guid>2602.11829v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.LG, cs.GT
Authors: Juan Agustin Duque, Razvan Ciuca, Ayoub Echchahed, Hugo Larochelle, Aaron Courville
Institution: 
Published: 2026-02-12
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Addressing climate change requires global coordination, yet rational economic actors often prioritize immediate gains over collective welfare, resulting in social dilemmas. InvestESG is a recently proposed multi-agent simulation that captures the dynamic interplay between investors and companies under climate risk. We provide a formal characterization of the conditions under which InvestESG exhibits an intertemporal social dilemma, deriving theoretical thresholds at which individual incentives diverge from collective welfare. Building on this, we apply Advantage Alignment, a scalable opponent shaping algorithm shown to be effective in general-sum games, to influence agent learning in InvestESG. We offer theoretical insights into why Advantage Alignment systematically favors socially beneficial equilibria by biasing learning dynamics toward cooperative outcomes. Our results demonstrate that strategically shaping the learning processes of economic agents can result in better outcomes that could inform policy mechanisms to better align market incentives with long-term sustainability goals.]]></description>
<pubDate>Thu, 12 Feb 2026 11:16:28 +0000</pubDate>
</item>
<item>
<title><![CDATA[CAAL: Confidence-Aware Active Learning for Heteroscedastic Atmospheric Regression]]></title>
<link>http://arxiv.org/abs/2602.11825v1</link>
<guid>2602.11825v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.LG
Authors: Fei Jiang, Jiyang Xia, Junjie Yu, Mingfei Sun, Hugh Coe et al.
Institution: 
Published: 2026-02-12
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Quantifying the impacts of air pollution on health and climate relies on key atmospheric particle properties such as toxicity and hygroscopicity. However, these properties typically require complex observational techniques or expensive particle-resolved numerical simulations, limiting the availability of labeled data. We therefore estimate these hard-to-measure particle properties from routinely available observations (e.g., air pollutant concentrations and meteorological conditions). Because routine observations only indirectly reflect particle composition and structure, the mapping from routine observations to particle properties is noisy and input-dependent, yielding a heteroscedastic regression setting. With a limited and costly labeling budget, the central challenge is to select which samples to measure or simulate. While active learning is a natural approach, most acquisition strategies rely on predictive uncertainty. Under heteroscedastic noise, this signal conflates reducible epistemic uncertainty with irreducible aleatoric uncertainty, causing limited budgets to be wasted in noise-dominated regions. To address this challenge, we propose a confidence-aware active learning framework (CAAL) for efficient and robust sample selection in heteroscedastic settings. CAAL consists of two components: a decoupled uncertainty-aware training objective that separately optimises the predictive mean and noise level to stabilise uncertainty estimation, and a confidence-aware acquisition function that dynamically weights epistemic uncertainty using predicted aleatoric uncertainty as a reliability signal. Experiments on particle-resolved numerical simulations and real atmospheric observations show that CAAL consistently outperforms standard AL baselines. The proposed framework provides a practical and general solution for the efficient expansion of high-cost atmospheric particle property databases.]]></description>
<pubDate>Thu, 12 Feb 2026 11:09:58 +0000</pubDate>
</item>
<item>
<title><![CDATA[Revis: Sparse Latent Steering to Mitigate Object Hallucination in Large Vision-Language Models]]></title>
<link>http://arxiv.org/abs/2602.11824v1</link>
<guid>2602.11824v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.AI, cs.LG
Authors: Jialin Wu, Wei Shi, Han Shen, Peigui Qi, Kunsheng Tang et al.
Institution: 
Published: 2026-02-12
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Despite the advanced capabilities of Large Vision-Language Models (LVLMs), they frequently suffer from object hallucination. One reason is that visual features and pretrained textual representations often become intertwined in the deeper network layers. To address this, we propose REVIS, a training-free framework designed to explicitly re-activate this suppressed visual information. Rooted in latent space geometry, REVIS extracts the pure visual information vector via orthogonal projection and employs a calibrated strategy to perform sparse intervention only at the precise depth where suppression occurs. This surgical approach effectively restores visual information with minimal computational cost. Empirical evaluations on standard benchmarks demonstrate that REVIS reduces object hallucination rates by approximately 19% compared to state-of-the-art baselines, while preserving general reasoning capabilities.]]></description>
<pubDate>Thu, 12 Feb 2026 11:07:44 +0000</pubDate>
</item>
<item>
<title><![CDATA[A Comparative Study of MAP and LMMSE Estimators for Blind Inverse Problems]]></title>
<link>http://arxiv.org/abs/2602.11814v1</link>
<guid>2602.11814v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.IT, cs.CV, cs.LG
Authors: Nathan Buskulic, Luca Calatroni
Institution: 
Published: 2026-02-12
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Maximum-a-posteriori (MAP) approaches are an effective framework for inverse problems with known forward operators, particularly when combined with expressive priors and careful parameter selection. In blind settings, however, their use becomes significantly less stable due to the inherent non-convexity of the problem and the potential non-identifiability of the solutions. (Linear) minimum mean square error (MMSE) estimators provide a compelling alternative that can circumvent these limitations. In this work, we study synthetic two-dimensional blind deconvolution problems under fully controlled conditions, with complete prior knowledge of both the signal and kernel distributions. We compare tailored MAP algorithms with simple LMMSE estimators whose functional form is closely related to that of an optimal Tikhonov estimator. Our results show that, even in these highly controlled settings, MAP methods remain unstable and require extensive parameter tuning, whereas the LMMSE estimator yields a robust and reliable baseline. Moreover, we demonstrate empirically that the LMMSE solution can serve as an effective initialization for MAP approaches, improving their performance and reducing sensitivity to regularization parameters, thereby opening the door to future theoretical and practical developments.]]></description>
<pubDate>Thu, 12 Feb 2026 10:49:45 +0000</pubDate>
</item>
<item>
<title><![CDATA[Predicting LLM Output Length via Entropy-Guided Representations]]></title>
<link>http://arxiv.org/abs/2602.11812v1</link>
<guid>2602.11812v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.AI
Authors: Huanyi Xie, Yubin Chen, Liangyu Wang, Lijie Hu, Di Wang
Institution: 
Published: 2026-02-12
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

The long-tailed distribution of sequence lengths in LLM serving and reinforcement learning (RL) sampling causes significant computational waste due to excessive padding in batched inference. Existing methods rely on auxiliary models for static length prediction, but they incur high overhead, generalize poorly, and fail in stochastic "one-to-many" sampling scenarios. We introduce a lightweight framework that reuses the main model's internal hidden states for efficient length prediction. Our framework features two core components: 1) Entropy-Guided Token Pooling (EGTP), which uses on-the-fly activations and token entropy for highly accurate static prediction with negligible cost, and 2) Progressive Length Prediction (PLP), which dynamically estimates the remaining length at each decoding step to handle stochastic generation. To validate our approach, we build and release ForeLen, a comprehensive benchmark with long-sequence, Chain-of-Thought, and RL data. On ForeLen, EGTP achieves state-of-the-art accuracy, reducing MAE by 29.16\% over the best baseline. Integrating our methods with a length-aware scheduler yields significant end-to-end throughput gains. Our work provides a new technical and evaluation baseline for efficient LLM inference.]]></description>
<pubDate>Thu, 12 Feb 2026 10:49:04 +0000</pubDate>
</item>
<item>
<title><![CDATA[How to Sample High Quality 3D Fractals for Action Recognition Pre-Training?]]></title>
<link>http://arxiv.org/abs/2602.11810v1</link>
<guid>2602.11810v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.CV, cs.LG
Authors: Marko Putak, Thomas B. Moeslund, Joakim Bruslund Haurum
Institution: 
Published: 2026-02-12
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Synthetic datasets are being recognized in the deep learning realm as a valuable alternative to exhaustively labeled real data. One such synthetic data generation method is Formula Driven Supervised Learning (FDSL), which can provide an infinite number of perfectly labeled data through a formula driven approach, such as fractals or contours. FDSL does not have common drawbacks like manual labor, privacy and other ethical concerns. In this work we generate 3D fractals using 3D Iterated Function Systems (IFS) for pre-training an action recognition model. The fractals are temporally transformed to form a video that is used as a pre-training dataset for downstream task of action recognition. We find that standard methods of generating fractals are slow and produce degenerate 3D fractals. Therefore, we systematically explore alternative ways of generating fractals and finds that overly-restrictive approaches, while generating aesthetically pleasing fractals, are detrimental for downstream task performance. We propose a novel method, Targeted Smart Filtering, to address both the generation speed and fractal diversity issue. The method reports roughly 100 times faster sampling speed and achieves superior downstream performance against other 3D fractal filtering methods.]]></description>
<pubDate>Thu, 12 Feb 2026 10:48:25 +0000</pubDate>
</item>
<item>
<title><![CDATA[Deep Kernel Fusion for Transformers]]></title>
<link>http://arxiv.org/abs/2602.11808v1</link>
<guid>2602.11808v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.LG
Authors: Zixi Zhang, Zhiwen Mo, Yiren Zhao, Robert Mullins
Institution: 
Published: 2026-02-12
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Agentic LLM inference with long contexts is increasingly limited by memory bandwidth rather than compute. In this setting, SwiGLU MLP blocks, whose large weights exceed cache capacity, become a major yet under-optimized bottleneck. We propose DeepFusionKernel, a deeply fused kernel that cuts HBM traffic and boosts cache reuse, delivering up to 13.2% speedup on H100 and 9.7% on A100 over SGLang. Integrated with SGLang and paired with a kernel scheduler, DeepFusionKernel ensures consistent accelerations over generation lengths, while remaining adaptable to diverse models, inference configurations, and hardware platforms.]]></description>
<pubDate>Thu, 12 Feb 2026 10:43:59 +0000</pubDate>
</item>
<item>
<title><![CDATA[PuYun-LDM: A Latent Diffusion Model for High-Resolution Ensemble Weather Forecasts]]></title>
<link>http://arxiv.org/abs/2602.11807v1</link>
<guid>2602.11807v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.AI
Authors: Lianjun Wu, Shengchen Zhu, Yuxuan Liu, Liuyu Kai, Xiaoduan Feng et al.
Institution: 
Published: 2026-02-12
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Latent diffusion models (LDMs) suffer from limited diffusability in high-resolution (<=0.25) ensemble weather forecasting, where diffusability characterizes how easily a latent data distribution can be modeled by a diffusion process. Unlike natural image fields, meteorological fields lack task-agnostic foundation models and explicit semantic structures, making VFM-based regularization inapplicable. Moreover, existing frequency-based approaches impose identical spectral regularization across channels under a homogeneity assumption, which leads to uneven regularization strength under the inter-variable spectral heterogeneity in multivariate meteorological data. To address these challenges, we propose a 3D Masked AutoEncoder (3D-MAE) that encodes weather-state evolution features as an additional conditioning for the diffusion model, together with a Variable-Aware Masked Frequency Modeling (VA-MFM) strategy that adaptively selects thresholds based on the spectral energy distribution of each variable. Together, we propose PuYun-LDM, which enhances latent diffusability and achieves superior performance to ENS at short lead times while remaining comparable to ENS at longer horizons. PuYun-LDM generates a 15-day global forecast with a 6-hour temporal resolution in five minutes on a single NVIDIA H200 GPU, while ensemble forecasts can be efficiently produced in parallel.]]></description>
<pubDate>Thu, 12 Feb 2026 10:43:20 +0000</pubDate>
</item>
<item>
<title><![CDATA[From Path Signatures to Sequential Modeling: Incremental Signature Contributions for Offline RL]]></title>
<link>http://arxiv.org/abs/2602.11805v1</link>
<guid>2602.11805v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.LG
Authors: Ziyi Zhao, Qingchuan Li, Yuxuan Xu
Institution: 
Published: 2026-02-12
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Path signatures embed trajectories into tensor algebra and constitute a universal, non-parametric representation of paths; however, in the standard form, they collapse temporal structure into a single global object, which limits their suitability for decision-making problems that require step-wise reactivity. We propose the Incremental Signature Contribution (ISC) method, which decomposes truncated path signatures into a temporally ordered sequence of elements in the tensor-algebra space, corresponding to incremental contributions induced by last path increments. This reconstruction preserves the algebraic structure and expressivity of signatures, while making their internal temporal evolution explicit, enabling processing signature-based representations via sequential modeling approaches. In contrast to full signatures, ISC is inherently sensitive to instantaneous trajectory updates, which is critical for sensitive and stability-requiring control dynamics. Building on this representation, we introduce ISC-Transformer (ISCT), an offline reinforcement learning model that integrates ISC into a standard Transformer architecture without further architectural modification. We evaluate ISCT on HalfCheetah, Walker2d, Hopper, and Maze2d, including settings with delayed rewards and downgraded datasets. The results demonstrate that ISC method provides a theoretically grounded and practically effective alternative to path processing for temporally sensitive control tasks.]]></description>
<pubDate>Thu, 12 Feb 2026 10:37:37 +0000</pubDate>
</item>
<item>
<title><![CDATA[Efficient Segment Anything with Depth-Aware Fusion and Limited Training Data]]></title>
<link>http://arxiv.org/abs/2602.11804v1</link>
<guid>2602.11804v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.CV
Authors: Yiming Zhou, Xuenjie Xie, Panfeng Li, Albrecht Kunz, Ahmad Osman et al.
Institution: 
Published: 2026-02-12
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Segment Anything Models (SAM) achieve impressive universal segmentation performance but require massive datasets (e.g., 11M images) and rely solely on RGB inputs. Recent efficient variants reduce computation but still depend on large-scale training. We propose a lightweight RGB-D fusion framework that augments EfficientViT-SAM with monocular depth priors. Depth maps are generated with a pretrained estimator and fused mid-level with RGB features through a dedicated depth encoder. Trained on only 11.2k samples (less than 0.1\% of SA-1B), our method achieves higher accuracy than EfficientViT-SAM, showing that depth cues provide strong geometric priors for segmentation.]]></description>
<pubDate>Thu, 12 Feb 2026 10:35:35 +0000</pubDate>
</item>
<item>
<title><![CDATA[TopoFair: Linking Topological Bias to Fairness in Link Prediction Benchmarks]]></title>
<link>http://arxiv.org/abs/2602.11802v1</link>
<guid>2602.11802v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.LG
Authors: Lilian Marey, Mathilde Perez, Tiphaine Viard, Charlotte Laclau
Institution: 
Published: 2026-02-12
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Graph link prediction (LP) plays a critical role in socially impactful applications, such as job recommendation and friendship formation. Ensuring fairness in this task is thus essential. While many fairness-aware methods manipulate graph structures to mitigate prediction disparities, the topological biases inherent to social graph structures remain poorly understood and are often reduced to homophily alone. This undermines the generalization potential of fairness interventions and limits their applicability across diverse network topologies. In this work, we propose a novel benchmarking framework for fair LP, centered on the structural biases of the underlying graphs. We begin by reviewing and formalizing a broad taxonomy of topological bias measures relevant to fairness in graphs. In parallel, we introduce a flexible graph generation method that simultaneously ensures fidelity to real-world graph patterns and enables controlled variation across a wide spectrum of structural biases. We apply this framework to evaluate both classical and fairness-aware LP models across multiple use cases. Our results provide a fine-grained empirical analysis of the interactions between predictive fairness and structural biases. This new perspective reveals the sensitivity of fairness interventions to beyond-homophily biases and underscores the need for structurally grounded fairness evaluations in graph learning.]]></description>
<pubDate>Thu, 12 Feb 2026 10:29:44 +0000</pubDate>
</item>
<item>
<title><![CDATA[SpaTeoGL: Spatiotemporal Graph Learning for Interpretable Seizure Onset Zone Analysis from Intracranial EEG]]></title>
<link>http://arxiv.org/abs/2602.11801v1</link>
<guid>2602.11801v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.LG
Authors: Elham Rostami, Aref Einizade, Taous-Meriem Laleg-Kirati
Institution: 
Published: 2026-02-12
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Accurate localization of the seizure onset zone (SOZ) from intracranial EEG (iEEG) is essential for epilepsy surgery but is challenged by complex spatiotemporal seizure dynamics. We propose SpaTeoGL, a spatiotemporal graph learning framework for interpretable seizure network analysis. SpaTeoGL jointly learns window-level spatial graphs capturing interactions among iEEG electrodes and a temporal graph linking time windows based on similarity of their spatial structure. The method is formulated within a smooth graph signal processing framework and solved via an alternating block coordinate descent algorithm with convergence guarantees. Experiments on a multicenter iEEG dataset with successful surgical outcomes show that SpaTeoGL is competitive with a baseline based on horizontal visibility graphs and logistic regression, while improving non-SOZ identification and providing interpretable insights into seizure onset and propagation dynamics.]]></description>
<pubDate>Thu, 12 Feb 2026 10:28:38 +0000</pubDate>
</item>
<item>
<title><![CDATA[Temporal Difference Learning with Constrained Initial Representations]]></title>
<link>http://arxiv.org/abs/2602.11800v1</link>
<guid>2602.11800v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.LG
Authors: Jiafei Lyu, Jingwen Yang, Zhongjian Qiao, Runze Liu, Zeyuan Liu et al.
Institution: 
Published: 2026-02-12
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Recently, there have been numerous attempts to enhance the sample efficiency of off-policy reinforcement learning (RL) agents when interacting with the environment, including architecture improvements and new algorithms. Despite these advances, they overlook the potential of directly constraining the initial representations of the input data, which can intuitively alleviate the distribution shift issue and stabilize training. In this paper, we introduce the Tanh function into the initial layer to fulfill such a constraint. We theoretically unpack the convergence property of the temporal difference learning with the Tanh function under linear function approximation. Motivated by theoretical insights, we present our Constrained Initial Representations framework, tagged CIR, which is made up of three components: (i) the Tanh activation along with normalization methods to stabilize representations; (ii) the skip connection module to provide a linear pathway from the shallow layer to the deep layer; (iii) the convex Q-learning that allows a more flexible value estimate and mitigates potential conservatism. Empirical results show that CIR exhibits strong performance on numerous continuous control tasks, even being competitive or surpassing existing strong baseline methods.]]></description>
<pubDate>Thu, 12 Feb 2026 10:27:57 +0000</pubDate>
</item>
<item>
<title><![CDATA[Hi-SAM: A Hierarchical Structure-Aware Multi-modal Framework for Large-Scale Recommendation]]></title>
<link>http://arxiv.org/abs/2602.11799v1</link>
<guid>2602.11799v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.AI
Authors: Pingjun Pan, Tingting Zhou, Peiyao Lu, Tingting Fei, Hongxiang Chen et al.
Institution: 
Published: 2026-02-12
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Multi-modal recommendation has gained traction as items possess rich attributes like text and images. Semantic ID-based approaches effectively discretize this information into compact tokens. However, two challenges persist: (1) Suboptimal Tokenization: existing methods (e.g., RQ-VAE) lack disentanglement between shared cross-modal semantics and modality-specific details, causing redundancy or collapse; (2) Architecture-Data Mismatch: vanilla Transformers treat semantic IDs as flat streams, ignoring the hierarchy of user interactions, items, and tokens. Expanding items into multiple tokens amplifies length and noise, biasing attention toward local details over holistic semantics. We propose Hi-SAM, a Hierarchical Structure-Aware Multi-modal framework with two designs: (1) Disentangled Semantic Tokenizer (DST): unifies modalities via geometry-aware alignment and quantizes them via a coarse-to-fine strategy. Shared codebooks distill consensus while modality-specific ones recover nuances from residuals, enforced by mutual information minimization; (2) Hierarchical Memory-Anchor Transformer (HMAT): splits positional encoding into inter- and intra-item subspaces via Hierarchical RoPE to restore hierarchy. It inserts Anchor Tokens to condense items into compact memory, retaining details for the current item while accessing history only through compressed summaries. Experiments on real-world datasets show consistent improvements over SOTA baselines, especially in cold-start scenarios. Deployed on a large-scale social platform serving millions of users, Hi-SAM achieved a 6.55% gain in the core online metric.]]></description>
<pubDate>Thu, 12 Feb 2026 10:26:15 +0000</pubDate>
</item>
<item>
<title><![CDATA[A Subword Embedding Approach for Variation Detection in Luxembourgish User Comments]]></title>
<link>http://arxiv.org/abs/2602.11795v1</link>
<guid>2602.11795v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.CL
Authors: Anne-Marie Lutgen, Alistair Plum, Christoph Purschke
Institution: 
Published: 2026-02-12
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

This paper presents an embedding-based approach to detecting variation without relying on prior normalisation or predefined variant lists. The method trains subword embeddings on raw text and groups related forms through combined cosine and n-gram similarity. This allows spelling and morphological diversity to be examined and analysed as linguistic structure rather than treated as noise. Using a large corpus of Luxembourgish user comments, the approach uncovers extensive lexical and orthographic variation that aligns with patterns described in dialectal and sociolinguistic research. The induced families capture systematic correspondences and highlight areas of regional and stylistic differentiation. The procedure does not strictly require manual annotation, but does produce transparent clusters that support both quantitative and qualitative analysis. The results demonstrate that distributional modelling can reveal meaningful patterns of variation even in ''noisy'' or low-resource settings, offering a reproducible methodological framework for studying language variety in multilingual and small-language contexts.]]></description>
<pubDate>Thu, 12 Feb 2026 10:19:50 +0000</pubDate>
</item>
<item>
<title><![CDATA[Latent-Variable Learning of SPDEs via Wiener Chaos]]></title>
<link>http://arxiv.org/abs/2602.11794v1</link>
<guid>2602.11794v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.LG
Authors: Sebastian Zeng, Andreas Petersson, Wolfgang Bock
Institution: 
Published: 2026-02-12
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

We study the problem of learning the law of linear stochastic partial differential equations (SPDEs) with additive Gaussian forcing from spatiotemporal observations. Most existing deep learning approaches either assume access to the driving noise or initial condition, or rely on deterministic surrogate models that fail to capture intrinsic stochasticity. We propose a structured latent-variable formulation that requires only observations of solution realizations and learns the underlying randomly forced dynamics. Our approach combines a spectral Galerkin projection with a truncated Wiener chaos expansion, yielding a principled separation between deterministic evolution and stochastic forcing. This reduces the infinite-dimensional SPDE to a finite system of parametrized ordinary differential equations governing latent temporal dynamics. The latent dynamics and stochastic forcing are jointly inferred through variational learning, allowing recovery of stochastic structure without explicit observation or simulation of noise during training. Empirical evaluation on synthetic data demonstrates state-of-the-art performance under comparable modeling assumptions across bounded and unbounded one-dimensional spatial domains.]]></description>
<pubDate>Thu, 12 Feb 2026 10:19:43 +0000</pubDate>
</item>
<item>
<title><![CDATA[More Haste, Less Speed: Weaker Single-Layer Watermark Improves Distortion-Free Watermark Ensembles]]></title>
<link>http://arxiv.org/abs/2602.11793v1</link>
<guid>2602.11793v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.CR, cs.CL
Authors: Ruibo Chen, Yihan Wu, Xuehao Cui, Jingqi Zhang, Heng Huang
Institution: 
Published: 2026-02-12
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Watermarking has emerged as a crucial technique for detecting and attributing content generated by large language models. While recent advancements have utilized watermark ensembles to enhance robustness, prevailing methods typically prioritize maximizing the strength of the watermark at every individual layer. In this work, we identify a critical limitation in this "stronger-is-better" approach: strong watermarks significantly reduce the entropy of the token distribution, which paradoxically weakens the effectiveness of watermarking in subsequent layers. We theoretically and empirically show that detectability is bounded by entropy and that watermark ensembles induce a monotonic decrease in both entropy and the expected green-list ratio across layers. To address this inherent trade-off, we propose a general framework that utilizes weaker single-layer watermarks to preserve the entropy required for effective multi-layer ensembling. Empirical evaluations demonstrate that this counter-intuitive strategy mitigates signal decay and consistently outperforms strong baselines in both detectability and robustness.]]></description>
<pubDate>Thu, 12 Feb 2026 10:18:16 +0000</pubDate>
</item>
<item>
<title><![CDATA[Detecting RLVR Training Data via Structural Convergence of Reasoning]]></title>
<link>http://arxiv.org/abs/2602.11792v1</link>
<guid>2602.11792v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.AI, cs.CL
Authors: Hongbo Zhang, Yue Yang, Jianhao Yan, Guangsheng Bao, Yue Zhang et al.
Institution: 
Published: 2026-02-12
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Reinforcement learning with verifiable rewards (RLVR) is central to training modern reasoning models, but the undisclosed training data raises concerns about benchmark contamination. Unlike pretraining methods, which optimize models using token-level probabilities, RLVR fine-tunes models based on reward feedback from self-generated reasoning trajectories, making conventional likelihood-based detection methods less effective. We show that RLVR induces a distinctive behavioral signature: prompts encountered during RLVR training result in more rigid and similar generations, while unseen prompts retain greater diversity. We introduce Min-$k$NN Distance, a simple black-box detector that quantifies this collapse by sampling multiple completions for a given prompt and computing the average of the $k$ smallest nearest-neighbor edit distances. Min-$k$NN Distance requires no access to the reference model or token probabilities. Experiments across multiple RLVR-trained reasoning models show that Min-$k$NN Distance reliably distinguishes RL-seen examples from unseen ones and outperforms existing membership inference and RL contamination detection baselines.]]></description>
<pubDate>Thu, 12 Feb 2026 10:17:32 +0000</pubDate>
</item>
<item>
<title><![CDATA[Beyond End-to-End Video Models: An LLM-Based Multi-Agent System for Educational Video Generation]]></title>
<link>http://arxiv.org/abs/2602.11790v1</link>
<guid>2602.11790v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.AI, cs.CL
Authors: Lingyong Yan, Jiulong Wu, Dong Xie, Weixian Shi, Deguo Xia et al.
Institution: 
Published: 2026-02-12
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Although recent end-to-end video generation models demonstrate impressive performance in visually oriented content creation, they remain limited in scenarios that require strict logical rigor and precise knowledge representation, such as instructional and educational media. To address this problem, we propose LAVES, a hierarchical LLM-based multi-agent system for generating high-quality instructional videos from educational problems. The LAVES formulates educational video generation as a multi-objective task that simultaneously demands correct step-by-step reasoning, pedagogically coherent narration, semantically faithful visual demonstrations, and precise audio--visual alignment. To address the limitations of prior approaches--including low procedural fidelity, high production cost, and limited controllability--LAVES decomposes the generation workflow into specialized agents coordinated by a central Orchestrating Agent with explicit quality gates and iterative critique mechanisms. Specifically, the Orchestrating Agent supervises a Solution Agent for rigorous problem solving, an Illustration Agent that produces executable visualization codes, and a Narration Agent for learner-oriented instructional scripts. In addition, all outputs from the working agents are subject to semantic critique, rule-based constraints, and tool-based compilation checks. Rather than directly synthesizing pixels, the system constructs a structured executable video script that is deterministically compiled into synchronized visuals and narration using template-driven assembly rules, enabling fully automated end-to-end production without manual editing. In large-scale deployments, LAVES achieves a throughput exceeding one million videos per day, delivering over a 95% reduction in cost compared to current industry-standard approaches while maintaining a high acceptance rate.]]></description>
<pubDate>Thu, 12 Feb 2026 10:14:36 +0000</pubDate>
</item>
<item>
<title><![CDATA[Decentralized Non-convex Stochastic Optimization with Heterogeneous Variance]]></title>
<link>http://arxiv.org/abs/2602.11789v1</link>
<guid>2602.11789v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.LG
Authors: Hongxu Chen, Ke Wei, Luo Luo
Institution: 
Published: 2026-02-12
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Decentralized optimization is critical for solving large-scale machine learning problems over distributed networks, where multiple nodes collaborate through local communication. In practice, the variances of stochastic gradient estimators often differ across nodes, yet their impact on algorithm design and complexity remains unclear. To address this issue, we propose D-NSS, a decentralized algorithm with node-specific sampling, and establish its sample complexity depending on the arithmetic mean of local standard deviations, achieving tighter bounds than existing methods that rely on the worst-case or quadratic mean. We further derive a matching sample complexity lower bound under heterogeneous variance, thereby proving the optimality of this dependence. Moreover, we extend the framework with a variance reduction technique and develop D-NSS-VR, which under the mean-squared smoothness assumption attains an improved sample complexity bound while preserving the arithmetic-mean dependence. Finally, numerical experiments validate the theoretical results and demonstrate the effectiveness of the proposed algorithms.]]></description>
<pubDate>Thu, 12 Feb 2026 10:13:53 +0000</pubDate>
</item>
<item>
<title><![CDATA[Evaluating LLM Safety Under Repeated Inference via Accelerated Prompt Stress Testing]]></title>
<link>http://arxiv.org/abs/2602.11786v1</link>
<guid>2602.11786v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.LG, cs.AI
Authors: Keita Broadwater
Institution: 
Published: 2026-02-12
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Traditional benchmarks for large language models (LLMs) primarily assess safety risk through breadth-oriented evaluation across diverse tasks. However, real-world deployment exposes a different class of risk: operational failures arising from repeated inference on identical or near-identical prompts rather than broad task generalization. In high-stakes settings, response consistency and safety under sustained use are critical. We introduce Accelerated Prompt Stress Testing (APST), a depth-oriented evaluation framework inspired by reliability engineering. APST repeatedly samples identical prompts under controlled operational conditions (e.g., decoding temperature) to surface latent failure modes including hallucinations, refusal inconsistency, and unsafe completions. Rather than treating failures as isolated events, APST models them as stochastic outcomes of independent inference events. We formalize safety failures using Bernoulli and binomial models to estimate per-inference failure probabilities, enabling quantitative comparison of reliability across models and decoding configurations. Applying APST to multiple instruction-tuned LLMs evaluated on AIR-BENCH-derived safety prompts, we find that models with similar benchmark-aligned scores can exhibit substantially different empirical failure rates under repeated sampling, particularly as temperature increases. These results demonstrate that shallow, single-sample evaluation can obscure meaningful reliability differences under sustained use. APST complements existing benchmarks by providing a practical framework for evaluating LLM safety and reliability under repeated inference, bridging benchmark alignment and deployment-oriented risk assessment.]]></description>
<pubDate>Thu, 12 Feb 2026 10:09:13 +0000</pubDate>
</item>
<item>
<title><![CDATA[Safe Fairness Guarantees Without Demographics in Classification: Spectral Uncertainty Set Perspective]]></title>
<link>http://arxiv.org/abs/2602.11785v1</link>
<guid>2602.11785v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.LG, cs.AI
Authors: Ainhize Barrainkua, Santiago Mazuelas, Novi Quadrianto, Jose A. Lozano
Institution: 
Published: 2026-02-12
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

As automated classification systems become increasingly prevalent, concerns have emerged over their potential to reinforce and amplify existing societal biases. In the light of this issue, many methods have been proposed to enhance the fairness guarantees of classifiers. Most of the existing interventions assume access to group information for all instances, a requirement rarely met in practice. Fairness without access to demographic information has often been approached through robust optimization techniques,which target worst-case outcomes over a set of plausible distributions known as the uncertainty set. However, their effectiveness is strongly influenced by the chosen uncertainty set. In fact, existing approaches often overemphasize outliers or overly pessimistic scenarios, compromising both overall performance and fairness. To overcome these limitations, we introduce SPECTRE, a minimax-fair method that adjusts the spectrum of a simple Fourier feature mapping and constrains the extent to which the worst-case distribution can deviate from the empirical distribution. We perform extensive experiments on the American Community Survey datasets involving 20 states. The safeness of SPECTRE comes as it provides the highest average values on fairness guarantees together with the smallest interquartile range in comparison to state-of-the-art approaches, even compared to those with access to demographic group information. In addition, we provide a theoretical analysis that derives computable bounds on the worst-case error for both individual groups and the overall population, as well as characterizes the worst-case distributions responsible for these extremal performances]]></description>
<pubDate>Thu, 12 Feb 2026 10:08:08 +0000</pubDate>
</item>
<item>
<title><![CDATA[FlowMind: Execute-Summarize for Structured Workflow Generation from LLM Reasoning]]></title>
<link>http://arxiv.org/abs/2602.11782v1</link>
<guid>2602.11782v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.AI, cs.SE
Authors: Yihao Liu, Ziyun Zhang, Zile He, Huaqian Cai
Institution: 
Published: 2026-02-12
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

LLMs can solve complex tasks through reasoning and tool use, but accurately translating these solutions into structured workflows remains challenging. We model workflows as sequences of tool use and reformulate the problem as designing a mechanism that can both solve tasks and reliably construct workflows. Prior approaches that build workflows during execution often suffer from inaccuracies due to interference between the two processes. We propose an Execute-Summarize(ES) framework that decouples task execution from workflow construction: the model first completes the task using available tools, then independently reconstructs a structured workflow from execution traces. This separation improves workflow accuracy and robustness. We introduce FlowBench and show through extensive experiments that our approach outperforms existing methods, providing a reliable paradigm for grounding free-form LLM reasoning into structured workflows.]]></description>
<pubDate>Thu, 12 Feb 2026 10:04:42 +0000</pubDate>
</item>
<item>
<title><![CDATA[RELATE: A Reinforcement Learning-Enhanced LLM Framework for Advertising Text Generation]]></title>
<link>http://arxiv.org/abs/2602.11780v1</link>
<guid>2602.11780v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.AI
Authors: Jinfang Wang, Jiajie Liu, Jianwei Wu, Ziqin Luo, Zhen Chen et al.
Institution: 
Published: 2026-02-12
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

In online advertising, advertising text plays a critical role in attracting user engagement and driving advertiser value. Existing industrial systems typically follow a two-stage paradigm, where candidate texts are first generated and subsequently aligned with online performance metrics such as click-through rate(CTR). This separation often leads to misaligned optimization objectives and low funnel efficiency, limiting global optimality.
  To address these limitations, we propose RELATE, a reinforcement learning-based end-to-end framework that unifies generation and objective alignment within a single model. Instead of decoupling text generation from downstream metric alignment, RELATE integrates performance and compliance objectives directly into the generation process via policy learning. To better capture ultimate advertiser value beyond click-level signals, We incorporate conversion-oriented metrics into the objective and jointly model them with compliance constraints as multi-dimensional rewards, enabling the model to generate high-quality ad texts that improve conversion performance under policy constraints.
  Extensive experiments on large-scale industrial datasets demonstrate that RELATE consistently outperforms baselines. Furthermore, online deployment on a production advertising platform yields statistically significant improvements in click-through conversion rate(CTCVR) under strict policy constraints, validating the robustness and real-world effectiveness of the proposed framework.]]></description>
<pubDate>Thu, 12 Feb 2026 10:00:55 +0000</pubDate>
</item>
<item>
<title><![CDATA[Temperature as a Meta-Policy: Adaptive Temperature in LLM Reinforcement Learning]]></title>
<link>http://arxiv.org/abs/2602.11779v1</link>
<guid>2602.11779v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.LG
Authors: Haoran Dang, Cuiling Lan, Hai Wan, Xibin Zhao, Yan Lu
Institution: 
Published: 2026-02-12
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Temperature is a crucial hyperparameter in large language models (LLMs), controlling the trade-off between exploration and exploitation during text generation. High temperatures encourage diverse but noisy outputs, while low temperatures produce focused outputs but may cause premature convergence. Yet static or heuristic temperature schedules fail to adapt to the dynamic demands of reinforcement learning (RL) throughout training, often limiting policy improvement. We propose Temperature Adaptive Meta Policy Optimization (TAMPO), a new framework that recasts temperature control as a learnable meta-policy. TAMPO operates through a hierarchical two-loop process. In the inner loop, the LLM policy is updated (e.g., using GRPO) with trajectories sampled at the temperature selected by the meta-policy. In the outer loop, meta-policy updates the distribution over candidate temperatures by rewarding those that maximize the likelihood of high-advantage trajectories. This trajectory-guided, reward-driven mechanism enables online adaptation without additional rollouts, directly aligning exploration with policy improvement. On five mathematical reasoning benchmarks, TAMPO outperforms baselines using fixed or heuristic temperatures, establishing temperature as an effective learnable meta-policy for adaptive exploration in LLM reinforcement learning. Accepted at ICLR 2026.]]></description>
<pubDate>Thu, 12 Feb 2026 09:59:58 +0000</pubDate>
</item>
<item>
<title><![CDATA[Rethinking the Value of Agent-Generated Tests for LLM-Based Software Engineering Agents]]></title>
<link>https://huggingface.co/papers/2602.07900</link>
<guid>2602.07900</guid>
<description><![CDATA[Source: HuggingFace
Tags: 
Authors: Zhi Chen, Zhensu Sun, Yuling Shi, Chao Peng, Xiaodong Gu
Institution: 
Published: 2026-02-08
Score: 3/10
Citations: 0
Upvotes: 3
GitHub: 
Stars: 0

Large Language Model (LLM) code agents increasingly resolve repository-level issues by iteratively editing code, invoking tools, and validating candidate patches. In these workflows, agents often write tests on the fly, a paradigm adopted by many high-ranking agents on the SWE-bench leaderboard. However, we observe that GPT-5.2, which writes almost no new tests, can even achieve performance comparable to top-ranking agents. This raises the critical question: whether such tests meaningfully improve issue resolution or merely mimic human testing practices while consuming a substantial interaction budget.
  To reveal the impact of agent-written tests, we present an empirical study that analyzes agent trajectories across six state-of-the-art LLMs on SWE-bench Verified. Our results show that while test writing is commonly adopted, but resolved and unresolved tasks within the same model exhibit similar test-writing frequencies Furthermore, these tests typically serve as observational feedback channels, where agents prefer value-revealing print statements significantly more than formal assertion-based checks. Based on these insights, we perform a controlled experiment by revising the prompts of four agents to either increase or reduce test writing. The results suggest that changes in the volume of agent-written tests do not significantly change final outcomes. Taken together, our study reveals that current test-writing practices may provide marginal utility in autonomous software engineering tasks.]]></description>
<pubDate>Sun, 08 Feb 2026 10:26:31 +0000</pubDate>
</item>
</channel>
</rss>