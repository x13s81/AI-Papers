<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
<channel>
<title>AI Papers - 2026-01-21</title>
<link>https://arxiv.org</link>
<description>AI papers as of 2026-01-21 - 242 papers</description>
<lastBuildDate>Wed, 21 Jan 2026 14:27:40 +0000</lastBuildDate>
<item>
<title><![CDATA[Spurious Rewards Paradox: Mechanistically Understanding How RLVR Activates Memorization Shortcuts in LLMs]]></title>
<link>https://huggingface.co/papers/2601.11061</link>
<guid>2601.11061</guid>
<description><![CDATA[Source: HuggingFace
Tags: 
Authors: Lecheng Yan, Ruizhe Li, Guanhua Chen, Qing Li, Jiahui Geng
Institution: 
Published: 2026-01-16
Score: 9/10
Citations: 0
Upvotes: 6
GitHub: 
Stars: 0

Reinforcement Learning with Verifiable Rewards (RLVR) is highly effective for enhancing LLM reasoning, yet recent evidence shows models like Qwen 2.5 achieve significant gains even with spurious or incorrect rewards. We investigate this phenomenon and identify a "Perplexity Paradox": spurious RLVR triggers a divergence where answer-token perplexity drops while prompt-side coherence degrades, suggesting the model is bypassing reasoning in favor of memorization. Using Path Patching, Logit Lens, JSD analysis, and Neural Differential Equations, we uncover a hidden Anchor-Adapter circuit that facilitates this shortcut. We localize a Functional Anchor in the middle layers (L18-20) that triggers the retrieval of memorized solutions, followed by Structural Adapters in later layers (L21+) that transform representations to accommodate the shortcut signal. Finally, we demonstrate that scaling specific MLP keys within this circuit allows for bidirectional causal steering-artificially amplifying or suppressing contamination-driven performance. Our results provide a mechanistic roadmap for identifying and mitigating data contamination in RLVR-tuned models. Code is available at https://github.com/idwts/How-RLVR-Activates-Memorization-Shortcuts.]]></description>
<pubDate>Fri, 16 Jan 2026 07:55:38 +0000</pubDate>
</item>
<item>
<title><![CDATA[Multiplex Thinking: Reasoning via Token-wise Branch-and-Merge]]></title>
<link>https://huggingface.co/papers/2601.08808</link>
<guid>2601.08808</guid>
<description><![CDATA[Source: HuggingFace
Tags: 
Authors: Yao Tang, Li Dong, Yaru Hao, Qingxiu Dong, Furu Wei
Institution: 
Published: 2026-01-13
Score: 8/10
Citations: 0
Upvotes: 33
GitHub: 
Stars: 0

Large language models often solve complex reasoning tasks more effectively with Chain-of-Thought (CoT), but at the cost of long, low-bandwidth token sequences. Humans, by contrast, often reason softly by maintaining a distribution over plausible next steps. Motivated by this, we propose Multiplex Thinking, a stochastic soft reasoning mechanism that, at each thinking step, samples K candidate tokens and aggregates their embeddings into a single continuous multiplex token. This preserves the vocabulary embedding prior and the sampling dynamics of standard discrete generation, while inducing a tractable probability distribution over multiplex rollouts. Consequently, multiplex trajectories can be directly optimized with on-policy reinforcement learning (RL). Importantly, Multiplex Thinking is self-adaptive: when the model is confident, the multiplex token is nearly discrete and behaves like standard CoT; when it is uncertain, it compactly represents multiple plausible next steps without increasing sequence length. Across challenging math reasoning benchmarks, Multiplex Thinking consistently outperforms strong discrete CoT and RL baselines from Pass@1 through Pass@1024, while producing shorter sequences. The code and checkpoints are available at https://github.com/GMLR-Penn/Multiplex-Thinking.]]></description>
<pubDate>Tue, 13 Jan 2026 18:48:00 +0000</pubDate>
</item>
<item>
<title><![CDATA[UniX: Unifying Autoregression and Diffusion for Chest X-Ray Understanding and Generation]]></title>
<link>https://huggingface.co/papers/2601.11522</link>
<guid>2601.11522</guid>
<description><![CDATA[Source: HuggingFace
Tags: 
Authors: Ruiheng Zhang, Jingfeng Yao, Huangxuan Zhao, Hao Yan, Xiao He
Institution: 
Published: 2026-01-16
Score: 8/10
Citations: 0
Upvotes: 15
GitHub: 
Stars: 0

Despite recent progress, medical foundation models still struggle to unify visual understanding and generation, as these tasks have inherently conflicting goals: semantic abstraction versus pixel-level reconstruction. Existing approaches, typically based on parameter-shared autoregressive architectures, frequently lead to compromised performance in one or both tasks. To address this, we present UniX, a next-generation unified medical foundation model for chest X-ray understanding and generation. UniX decouples the two tasks into an autoregressive branch for understanding and a diffusion branch for high-fidelity generation. Crucially, a cross-modal self-attention mechanism is introduced to dynamically guide the generation process with understanding features. Coupled with a rigorous data cleaning pipeline and a multi-stage training strategy, this architecture enables synergistic collaboration between tasks while leveraging the strengths of diffusion models for superior generation. On two representative benchmarks, UniX achieves a 46.1% improvement in understanding performance (Micro-F1) and a 24.2% gain in generation quality (FD-RadDino), using only a quarter of the parameters of LLM-CXR. By achieving performance on par with task-specific models, our work establishes a scalable paradigm for synergistic medical image understanding and generation. Codes and models are available at https://github.com/ZrH42/UniX.]]></description>
<pubDate>Fri, 16 Jan 2026 18:59:58 +0000</pubDate>
</item>
<item>
<title><![CDATA[Aligning Agentic World Models via Knowledgeable Experience Learning]]></title>
<link>https://huggingface.co/papers/2601.13247</link>
<guid>2601.13247</guid>
<description><![CDATA[Source: HuggingFace
Tags: 
Authors: Baochang Ren, Yunzhi Yao, Rui Sun, Shuofei Qiao, Ningyu Zhang
Institution: 
Published: 2026-01-19
Score: 8/10
Citations: 0
Upvotes: 12
GitHub: 
Stars: 0

Current Large Language Models (LLMs) exhibit a critical modal disconnect: they possess vast semantic knowledge but lack the procedural grounding to respect the immutable laws of the physical world. Consequently, while these agents implicitly function as world models, their simulations often suffer from physical hallucinations-generating plans that are logically sound but physically unexecutable. Existing alignment strategies predominantly rely on resource-intensive training or fine-tuning, which attempt to compress dynamic environmental rules into static model parameters. However, such parametric encapsulation is inherently rigid, struggling to adapt to the open-ended variability of physical dynamics without continuous, costly retraining. To bridge this gap, we introduce WorldMind, a framework that autonomously constructs a symbolic World Knowledge Repository by synthesizing environmental feedback. Specifically, it unifies Process Experience to enforce physical feasibility via prediction errors and Goal Experience to guide task optimality through successful trajectories. Experiments on EB-ALFRED and EB-Habitat demonstrate that WorldMind achieves superior performance compared to baselines with remarkable cross-model and cross-environment transferability.]]></description>
<pubDate>Mon, 19 Jan 2026 17:33:31 +0000</pubDate>
</item>
<item>
<title><![CDATA[PhysRVG: Physics-Aware Unified Reinforcement Learning for Video Generative Models]]></title>
<link>https://huggingface.co/papers/2601.11087</link>
<guid>2601.11087</guid>
<description><![CDATA[Source: HuggingFace
Tags: 
Authors: Qiyuan Zhang, Biao Gong, Shuai Tan, Zheng Zhang, Yujun Shen
Institution: 
Published: 2026-01-16
Score: 8/10
Citations: 0
Upvotes: 8
GitHub: 
Stars: 0

Physical principles are fundamental to realistic visual simulation, but remain a significant oversight in transformer-based video generation. This gap highlights a critical limitation in rendering rigid body motion, a core tenet of classical mechanics. While computer graphics and physics-based simulators can easily model such collisions using Newton formulas, modern pretrain-finetune paradigms discard the concept of object rigidity during pixel-level global denoising. Even perfectly correct mathematical constraints are treated as suboptimal solutions (i.e., conditions) during model optimization in post-training, fundamentally limiting the physical realism of generated videos. Motivated by these considerations, we introduce, for the first time, a physics-aware reinforcement learning paradigm for video generation models that enforces physical collision rules directly in high-dimensional spaces, ensuring the physics knowledge is strictly applied rather than treated as conditions. Subsequently, we extend this paradigm to a unified framework, termed Mimicry-Discovery Cycle (MDcycle), which allows substantial fine-tuning while fully preserving the model's ability to leverage physics-grounded feedback. To validate our approach, we construct new benchmark PhysRVGBench and perform extensive qualitative and quantitative experiments to thoroughly assess its effectiveness.]]></description>
<pubDate>Fri, 16 Jan 2026 08:40:10 +0000</pubDate>
</item>
<item>
<title><![CDATA[SIN-Bench: Tracing Native Evidence Chains in Long-Context Multimodal Scientific Interleaved Literature]]></title>
<link>https://huggingface.co/papers/2601.10108</link>
<guid>2601.10108</guid>
<description><![CDATA[Source: HuggingFace
Tags: 
Authors: Yiming Ren, Junjie Wang, Yuxin Meng, Yihang Shi, Zhiqiang Lin
Institution: 
Published: 2026-01-15
Score: 8/10
Citations: 0
Upvotes: 6
GitHub: 
Stars: 0

Evaluating whether multimodal large language models truly understand long-form scientific papers remains challenging: answer-only metrics and synthetic "Needle-In-A-Haystack" tests often reward answer matching without requiring a causal, evidence-linked reasoning trace in the document. We propose the "Fish-in-the-Ocean" (FITO) paradigm, which requires models to construct explicit cross-modal evidence chains within native scientific documents. To operationalize FITO, we build SIN-Data, a scientific interleaved corpus that preserves the native interleaving of text and figures. On top of it, we construct SIN-Bench with four progressive tasks covering evidence discovery (SIN-Find), hypothesis verification (SIN-Verify), grounded QA (SIN-QA), and evidence-anchored synthesis (SIN-Summary). We further introduce "No Evidence, No Score", scoring predictions when grounded to verifiable anchors and diagnosing evidence quality via matching, relevance, and logic. Experiments on eight MLLMs show that grounding is the primary bottleneck: Gemini-3-pro achieves the best average overall score (0.573), while GPT-5 attains the highest SIN-QA answer accuracy (0.767) but underperforms on evidence-aligned overall scores, exposing a gap between correctness and traceable support.]]></description>
<pubDate>Thu, 15 Jan 2026 06:25:25 +0000</pubDate>
</item>
<item>
<title><![CDATA[LightOnOCR: A 1B End-to-End Multilingual Vision-Language Model for State-of-the-Art OCR]]></title>
<link>https://huggingface.co/papers/2601.14251</link>
<guid>2601.14251</guid>
<description><![CDATA[Source: HuggingFace
Tags: 
Authors: Said Taghadouini, Adrien Cavaillès, Baptiste Aubertin
Institution: 
Published: 2026-01-20
Score: 8/10
Citations: 0
Upvotes: 4
GitHub: 
Stars: 0

We present LightOnOCR-2-1B, a 1B-parameter end-to-end multilingual vision--language model that converts document images (e.g., PDFs) into clean, naturally ordered text without brittle OCR pipelines. Trained on a large-scale, high-quality distillation mix with strong coverage of scans, French documents, and scientific PDFs, LightOnOCR-2 achieves state-of-the-art results on OlmOCR-Bench while being 9times smaller and substantially faster than prior best-performing models. We further extend the output format to predict normalized bounding boxes for embedded images, introducing localization during pretraining via a resume strategy and refining it with RLVR using IoU-based rewards. Finally, we improve robustness with checkpoint averaging and task-arithmetic merging. We release model checkpoints under Apache 2.0, and publicly release the dataset and LightOnOCR-bbox-bench evaluation under their respective licenses.]]></description>
<pubDate>Tue, 20 Jan 2026 18:58:32 +0000</pubDate>
</item>
<item>
<title><![CDATA[CLARE: Continual Learning for Vision-Language-Action Models via Autonomous Adapter Routing and Expansion]]></title>
<link>https://huggingface.co/papers/2601.09512</link>
<guid>2601.09512</guid>
<description><![CDATA[Source: HuggingFace
Tags: 
Authors: Ralf Römer, Yi Zhang, Angela P. Schoellig
Institution: 
Published: 2026-01-14
Score: 8/10
Citations: 0
Upvotes: 3
GitHub: 
Stars: 0

To teach robots complex manipulation tasks, it is now a common practice to fine-tune a pre-trained vision-language-action model (VLA) on task-specific data. However, since this recipe updates existing representations, it is unsuitable for long-term operation in the real world, where robots must continually adapt to new tasks and environments while retaining the knowledge they have already acquired. Existing continual learning methods for robotics commonly require storing previous data (exemplars), struggle with long task sequences, or rely on task identifiers for deployment. To address these limitations, we propose CLARE, a general, parameter-efficient framework for exemplar-free continual learning with VLAs. CLARE introduces lightweight modular adapters into selected feedforward layers and autonomously expands the model only where necessary when learning a new task, guided by layer-wise feature similarity. During deployment, an autoencoder-based routing mechanism dynamically activates the most relevant adapters without requiring task labels. Through extensive experiments on the LIBERO benchmark, we show that CLARE achieves high performance on new tasks without catastrophic forgetting of earlier tasks, significantly outperforming even exemplar-based methods. Code and data are available at https://tum-lsy.github.io/clare.]]></description>
<pubDate>Wed, 14 Jan 2026 14:23:42 +0000</pubDate>
</item>
<item>
<title><![CDATA[PhyRPR: Training-Free Physics-Constrained Video Generation]]></title>
<link>https://huggingface.co/papers/2601.09255</link>
<guid>2601.09255</guid>
<description><![CDATA[Source: HuggingFace
Tags: 
Authors: Yibo Zhao, Hengjia Li, Xiaofei He, Boxi Wu
Institution: 
Published: 2026-01-14
Score: 8/10
Citations: 0
Upvotes: 2
GitHub: 
Stars: 0

Recent diffusion-based video generation models can synthesize visually plausible videos, yet they often struggle to satisfy physical constraints. A key reason is that most existing approaches remain single-stage: they entangle high-level physical understanding with low-level visual synthesis, making it hard to generate content that require explicit physical reasoning. To address this limitation, we propose a training-free three-stage pipeline,PhyRPR:Phy\uline{Reason}--Phy\uline{Plan}--Phy\uline{Refine}, which decouples physical understanding from visual synthesis. Specifically, PhyReason uses a large multimodal model for physical state reasoning and an image generator for keyframe synthesis; PhyPlan deterministically synthesizes a controllable coarse motion scaffold; and PhyRefine injects this scaffold into diffusion sampling via a latent fusion strategy to refine appearance while preserving the planned dynamics. This staged design enables explicit physical control during generation. Extensive experiments under physics constraints show that our method consistently improves physical plausibility and motion controllability.]]></description>
<pubDate>Wed, 14 Jan 2026 07:41:56 +0000</pubDate>
</item>
<item>
<title><![CDATA[LIBERTy: A Causal Framework for Benchmarking Concept-Based Explanations of LLMs with Structural Counterfactuals]]></title>
<link>https://huggingface.co/papers/2601.10700</link>
<guid>2601.10700</guid>
<description><![CDATA[Source: HuggingFace
Tags: 
Authors: Gilat Toker, Nitay Calderon, Ohad Amosy, Roi Reichart
Institution: 
Published: 2026-01-15
Score: 8/10
Citations: 0
Upvotes: 1
GitHub: 
Stars: 0

Concept-based explanations quantify how high-level concepts (e.g., gender or experience) influence model behavior, which is crucial for decision-makers in high-stakes domains. Recent work evaluates the faithfulness of such explanations by comparing them to reference causal effects estimated from counterfactuals. In practice, existing benchmarks rely on costly human-written counterfactuals that serve as an imperfect proxy. To address this, we introduce a framework for constructing datasets containing structural counterfactual pairs: LIBERTy (LLM-based Interventional Benchmark for Explainability with Reference Targets). LIBERTy is grounded in explicitly defined Structured Causal Models (SCMs) of the text generation, interventions on a concept propagate through the SCM until an LLM generates the counterfactual. We introduce three datasets (disease detection, CV screening, and workplace violence prediction) together with a new evaluation metric, order-faithfulness. Using them, we evaluate a wide range of methods across five models and identify substantial headroom for improving concept-based explanations. LIBERTy also enables systematic analysis of model sensitivity to interventions: we find that proprietary LLMs show markedly reduced sensitivity to demographic concepts, likely due to post-training mitigation. Overall, LIBERTy provides a much-needed benchmark for developing faithful explainability methods.]]></description>
<pubDate>Thu, 15 Jan 2026 18:54:50 +0000</pubDate>
</item>
<item>
<title><![CDATA[ABC-Bench: Benchmarking Agentic Backend Coding in Real-World Development]]></title>
<link>https://huggingface.co/papers/2601.11077</link>
<guid>2601.11077</guid>
<description><![CDATA[Source: HuggingFace
Tags: 
Authors: Jie Yang, Honglin Guo, Li Ji, Jiazheng Zhou, Rui Zheng
Institution: 
Published: 2026-01-16
Score: 7/10
Citations: 0
Upvotes: 61
GitHub: 
Stars: 0

The evolution of Large Language Models (LLMs) into autonomous agents has expanded the scope of AI coding from localized code generation to complex, repository-level, and execution-driven problem solving. However, current benchmarks predominantly evaluate code logic in static contexts, neglecting the dynamic, full-process requirements of real-world engineering, particularly in backend development which demands rigorous environment configuration and service deployment. To address this gap, we introduce ABC-Bench, a benchmark explicitly designed to evaluate agentic backend coding within a realistic, executable workflow. Using a scalable automated pipeline, we curated 224 practical tasks spanning 8 languages and 19 frameworks from open-source repositories. Distinct from previous evaluations, ABC-Bench require the agents to manage the entire development lifecycle from repository exploration to instantiating containerized services and pass the external end-to-end API tests. Our extensive evaluation reveals that even state-of-the-art models struggle to deliver reliable performance on these holistic tasks, highlighting a substantial disparity between current model capabilities and the demands of practical backend engineering. Our code is available at https://github.com/OpenMOSS/ABC-Bench.]]></description>
<pubDate>Fri, 16 Jan 2026 08:23:52 +0000</pubDate>
</item>
<item>
<title><![CDATA[AgencyBench: Benchmarking the Frontiers of Autonomous Agents in 1M-Token Real-World Contexts]]></title>
<link>https://huggingface.co/papers/2601.11044</link>
<guid>2601.11044</guid>
<description><![CDATA[Source: HuggingFace
Tags: 
Authors: Keyu Li, Junhao Shi, Yang Xiao, Mohan Jiang, Jie Sun
Institution: 
Published: 2026-01-16
Score: 7/10
Citations: 0
Upvotes: 30
GitHub: 
Stars: 0

Large Language Models (LLMs) based autonomous agents demonstrate multifaceted capabilities to contribute substantially to economic production. However, existing benchmarks remain focused on single agentic capability, failing to capture long-horizon real-world scenarios. Moreover, the reliance on human-in-the-loop feedback for realistic tasks creates a scalability bottleneck, hindering automated rollout collection and evaluation. To bridge this gap, we introduce AgencyBench, a comprehensive benchmark derived from daily AI usage, evaluating 6 core agentic capabilities across 32 real-world scenarios, comprising 138 tasks with specific queries, deliverables, and rubrics. These scenarios require an average of 90 tool calls, 1 million tokens, and hours of execution time to resolve. To enable automated evaluation, we employ a user simulation agent to provide iterative feedback, and a Docker sandbox to conduct visual and functional rubric-based assessment. Experiments reveal that closed-source models significantly outperform open-source models (48.4% vs 32.1%). Further analysis reveals significant disparities across models in resource efficiency, feedback-driven self-correction, and specific tool-use preferences. Finally, we investigate the impact of agentic scaffolds, observing that proprietary models demonstrate superior performance within their native ecosystems (e.g., Claude-4.5-Opus via Claude-Agent-SDK), while open-source models exhibit distinct performance peaks, suggesting potential optimization for specific execution frameworks. AgencyBench serves as a critical testbed for next-generation agents, highlighting the necessity of co-optimizing model architecture with agentic frameworks. We believe this work sheds light on the future direction of autonomous agents, and we release the full benchmark and evaluation toolkit at https://github.com/GAIR-NLP/AgencyBench.]]></description>
<pubDate>Fri, 16 Jan 2026 07:22:20 +0000</pubDate>
</item>
<item>
<title><![CDATA[Toward Efficient Agents: Memory, Tool learning, and Planning]]></title>
<link>https://huggingface.co/papers/2601.14192</link>
<guid>2601.14192</guid>
<description><![CDATA[Source: HuggingFace
Tags: 
Authors: Xiaofang Yang, Lijun Li, Heng Zhou, Tong Zhu, Xiaoye Qu
Institution: 
Published: 2026-01-20
Score: 7/10
Citations: 0
Upvotes: 27
GitHub: 
Stars: 0

Recent years have witnessed increasing interest in extending large language models into agentic systems. While the effectiveness of agents has continued to improve, efficiency, which is crucial for real-world deployment, has often been overlooked. This paper therefore investigates efficiency from three core components of agents: memory, tool learning, and planning, considering costs such as latency, tokens, steps, etc. Aimed at conducting comprehensive research addressing the efficiency of the agentic system itself, we review a broad range of recent approaches that differ in implementation yet frequently converge on shared high-level principles including but not limited to bounding context via compression and management, designing reinforcement learning rewards to minimize tool invocation, and employing controlled search mechanisms to enhance efficiency, which we discuss in detail. Accordingly, we characterize efficiency in two complementary ways: comparing effectiveness under a fixed cost budget, and comparing cost at a comparable level of effectiveness. This trade-off can also be viewed through the Pareto frontier between effectiveness and cost. From this perspective, we also examine efficiency oriented benchmarks by summarizing evaluation protocols for these components and consolidating commonly reported efficiency metrics from both benchmark and methodological studies. Moreover, we discuss the key challenges and future directions, with the goal of providing promising insights.]]></description>
<pubDate>Tue, 20 Jan 2026 17:51:56 +0000</pubDate>
</item>
<item>
<title><![CDATA[When Personalization Misleads: Understanding and Mitigating Hallucinations in Personalized LLMs]]></title>
<link>https://huggingface.co/papers/2601.11000</link>
<guid>2601.11000</guid>
<description><![CDATA[Source: HuggingFace
Tags: 
Authors: Zhongxiang Sun, Yi Zhan, Chenglei Shen, Weijie Yu, Xiao Zhang
Institution: 
Published: 2026-01-16
Score: 7/10
Citations: 0
Upvotes: 24
GitHub: 
Stars: 0

Personalized large language models (LLMs) adapt model behavior to individual users to enhance user satisfaction, yet personalization can inadvertently distort factual reasoning. We show that when personalized LLMs face factual queries, there exists a phenomenon where the model generates answers aligned with a user's prior history rather than the objective truth, resulting in personalization-induced hallucinations that degrade factual reliability and may propagate incorrect beliefs, due to representational entanglement between personalization and factual representations. To address this issue, we propose Factuality-Preserving Personalized Steering (FPPS), a lightweight inference-time approach that mitigates personalization-induced factual distortions while preserving personalized behavior. We further introduce PFQABench, the first benchmark designed to jointly evaluate factual and personalized question answering under personalization. Experiments across multiple LLM backbones and personalization methods show that FPPS substantially improves factual accuracy while maintaining personalized performance.]]></description>
<pubDate>Fri, 16 Jan 2026 05:20:10 +0000</pubDate>
</item>
<item>
<title><![CDATA[MemoryRewardBench: Benchmarking Reward Models for Long-Term Memory Management in Large Language Models]]></title>
<link>https://huggingface.co/papers/2601.11969</link>
<guid>2601.11969</guid>
<description><![CDATA[Source: HuggingFace
Tags: 
Authors: Zecheng Tang, Baibei Ji, Ruoxi Sun, Haitian Wang, WangJie You
Institution: 
Published: 2026-01-17
Score: 7/10
Citations: 0
Upvotes: 23
GitHub: 
Stars: 0

Existing works increasingly adopt memory-centric mechanisms to process long contexts in a segment manner, and effective memory management is one of the key capabilities that enables large language models to effectively propagate information across the entire sequence. Therefore, leveraging reward models (RMs) to automatically and reliably evaluate memory quality is critical. In this work, we introduce MemoryRewardBench, the first benchmark to systematically study the ability of RMs to evaluate long-term memory management processes. MemoryRewardBench covers both long-context comprehension and long-form generation tasks, featuring 10 distinct settings with different memory management patterns, with context length ranging from 8K to 128K tokens. Evaluations on 13 cutting-edge RMs indicate a diminishing performance gap between open-source and proprietary models, with newer-generation models consistently outperforming their predecessors regardless of parameter count. We further expose the capabilities and fundamental limitations of current RMs in evaluating LLM memory management across diverse settings.]]></description>
<pubDate>Sat, 17 Jan 2026 09:04:53 +0000</pubDate>
</item>
<item>
<title><![CDATA[Medical SAM3: A Foundation Model for Universal Prompt-Driven Medical Image Segmentation]]></title>
<link>https://huggingface.co/papers/2601.10880</link>
<guid>2601.10880</guid>
<description><![CDATA[Source: HuggingFace
Tags: 
Authors: Chongcong Jiang, Tianxingjian Ding, Chuhan Song, Jiachen Tu, Ziyang Yan
Institution: 
Published: 2026-01-15
Score: 7/10
Citations: 0
Upvotes: 15
GitHub: 
Stars: 0

Promptable segmentation foundation models such as SAM3 have demonstrated strong generalization capabilities through interactive and concept-based prompting. However, their direct applicability to medical image segmentation remains limited by severe domain shifts, the absence of privileged spatial prompts, and the need to reason over complex anatomical and volumetric structures. Here we present Medical SAM3, a foundation model for universal prompt-driven medical image segmentation, obtained by fully fine-tuning SAM3 on large-scale, heterogeneous 2D and 3D medical imaging datasets with paired segmentation masks and text prompts. Through a systematic analysis of vanilla SAM3, we observe that its performance degrades substantially on medical data, with its apparent competitiveness largely relying on strong geometric priors such as ground-truth-derived bounding boxes. These findings motivate full model adaptation beyond prompt engineering alone. By fine-tuning SAM3's model parameters on 33 datasets spanning 10 medical imaging modalities, Medical SAM3 acquires robust domain-specific representations while preserving prompt-driven flexibility. Extensive experiments across organs, imaging modalities, and dimensionalities demonstrate consistent and significant performance gains, particularly in challenging scenarios characterized by semantic ambiguity, complex morphology, and long-range 3D context. Our results establish Medical SAM3 as a universal, text-guided segmentation foundation model for medical imaging and highlight the importance of holistic model adaptation for achieving robust prompt-driven segmentation under severe domain shift. Code and model will be made available at https://github.com/AIM-Research-Lab/Medical-SAM3.]]></description>
<pubDate>Thu, 15 Jan 2026 22:18:14 +0000</pubDate>
</item>
<item>
<title><![CDATA[Agentic-R: Learning to Retrieve for Agentic Search]]></title>
<link>https://huggingface.co/papers/2601.11888</link>
<guid>2601.11888</guid>
<description><![CDATA[Source: HuggingFace
Tags: 
Authors: Wenhan Liu, Xinyu Ma, Yutao Zhu, Yuchen Li, Daiting Shi
Institution: 
Published: 2026-01-17
Score: 7/10
Citations: 0
Upvotes: 7
GitHub: 
Stars: 0

Agentic search has recently emerged as a powerful paradigm, where an agent interleaves multi-step reasoning with on-demand retrieval to solve complex questions. Despite its success, how to design a retriever for agentic search remains largely underexplored. Existing search agents typically rely on similarity-based retrievers, while similar passages are not always useful for final answer generation. In this paper, we propose a novel retriever training framework tailored for agentic search. Unlike retrievers designed for single-turn retrieval-augmented generation (RAG) that only rely on local passage utility, we propose to use both local query-passage relevance and global answer correctness to measure passage utility in a multi-turn agentic search. We further introduce an iterative training strategy, where the search agent and the retriever are optimized bidirectionally and iteratively. Different from RAG retrievers that are only trained once with fixed questions, our retriever is continuously improved using evolving and higher-quality queries from the agent. Extensive experiments on seven single-hop and multi-hop QA benchmarks demonstrate that our retriever, termed , consistently outperforms strong baselines across different search agents. Our codes are available at: https://github.com/8421BCD/Agentic-R.]]></description>
<pubDate>Sat, 17 Jan 2026 02:59:54 +0000</pubDate>
</item>
<item>
<title><![CDATA[FantasyVLN: Unified Multimodal Chain-of-Thought Reasoning for Vision-Language Navigation]]></title>
<link>https://huggingface.co/papers/2601.13976</link>
<guid>2601.13976</guid>
<description><![CDATA[Source: HuggingFace
Tags: 
Authors: Jing Zuo, Lingzhou Mu, Fan Jiang, Chengcheng Ma, Mu Xu
Institution: 
Published: 2026-01-20
Score: 7/10
Citations: 0
Upvotes: 3
GitHub: 
Stars: 0

Achieving human-level performance in Vision-and-Language Navigation (VLN) requires an embodied agent to jointly understand multimodal instructions and visual-spatial context while reasoning over long action sequences. Recent works, such as NavCoT and NavGPT-2, demonstrate the potential of Chain-of-Thought (CoT) reasoning for improving interpretability and long-horizon planning. Moreover, multimodal extensions like OctoNav-R1 and CoT-VLA further validate CoT as a promising pathway toward human-like navigation reasoning. However, existing approaches face critical drawbacks: purely textual CoTs lack spatial grounding and easily overfit to sparse annotated reasoning steps, while multimodal CoTs incur severe token inflation by generating imagined visual observations, making real-time navigation impractical. In this work, we propose FantasyVLN, a unified implicit reasoning framework that preserves the benefits of CoT reasoning without explicit token overhead. Specifically, imagined visual tokens are encoded into a compact latent space using a pretrained Visual AutoRegressor (VAR) during CoT reasoning training, and the model jointly learns from textual, visual, and multimodal CoT modes under a unified multi-CoT strategy. At inference, our model performs direct instruction-to-action mapping while still enjoying reasoning-aware representations. Extensive experiments on LH-VLN show that our approach achieves reasoning-aware yet real-time navigation, improving success rates and efficiency while reducing inference latency by an order of magnitude compared to explicit CoT methods.]]></description>
<pubDate>Tue, 20 Jan 2026 13:54:10 +0000</pubDate>
</item>
<item>
<title><![CDATA[Language of Thought Shapes Output Diversity in Large Language Models]]></title>
<link>https://huggingface.co/papers/2601.11227</link>
<guid>2601.11227</guid>
<description><![CDATA[Source: HuggingFace
Tags: 
Authors: Shaoyang Xu, Wenxuan Zhang
Institution: 
Published: 2026-01-16
Score: 7/10
Citations: 0
Upvotes: 3
GitHub: 
Stars: 0

Output diversity is crucial for Large Language Models as it underpins pluralism and creativity. In this work, we reveal that controlling the language used during model thinking-the language of thought-provides a novel and structural source of output diversity. Our preliminary study shows that different thinking languages occupy distinct regions in a model's thinking space. Based on this observation, we study two repeated sampling strategies under multilingual thinking-Single-Language Sampling and Mixed-Language Sampling-and conduct diversity evaluation on outputs that are controlled to be in English, regardless of the thinking language used. Across extensive experiments, we demonstrate that switching the thinking language from English to non-English languages consistently increases output diversity, with a clear and consistent positive correlation such that languages farther from English in the thinking space yield larger gains. We further show that aggregating samples across multiple thinking languages yields additional improvements through compositional effects, and that scaling sampling with linguistic heterogeneity expands the model's diversity ceiling. Finally, we show that these findings translate into practical benefits in pluralistic alignment scenarios, leading to broader coverage of cultural knowledge and value orientations in LLM outputs. Our code is publicly available at https://github.com/iNLP-Lab/Multilingual-LoT-Diversity.]]></description>
<pubDate>Fri, 16 Jan 2026 12:14:16 +0000</pubDate>
</item>
<item>
<title><![CDATA[Fundamental Limitations of Favorable Privacy-Utility Guarantees for DP-SGD]]></title>
<link>https://huggingface.co/papers/2601.10237</link>
<guid>2601.10237</guid>
<description><![CDATA[Source: HuggingFace
Tags: 
Authors: Murat Bilgehan Ertan, Marten van Dijk
Institution: 
Published: 2026-01-15
Score: 7/10
Citations: 0
Upvotes: 2
GitHub: 
Stars: 0

Differentially Private Stochastic Gradient Descent (DP-SGD) is the dominant paradigm for private training, but its fundamental limitations under worst-case adversarial privacy definitions remain poorly understood. We analyze DP-SGD in the f-differential privacy framework, which characterizes privacy via hypothesis-testing trade-off curves, and study shuffled sampling over a single epoch with M gradient updates. We derive an explicit suboptimal upper bound on the achievable trade-off curve. This result induces a geometric lower bound on the separation κ which is the maximum distance between the mechanism's trade-off curve and the ideal random-guessing line. Because a large separation implies significant adversarial advantage, meaningful privacy requires small κ. However, we prove that enforcing a small separation imposes a strict lower bound on the Gaussian noise multiplier σ, which directly limits the achievable utility. In particular, under the standard worst-case adversarial model, shuffled DP-SGD must satisfy
  σge 1{2ln M} quadorquad κge 1{8}!left(1-1{4πln M}right),
  and thus cannot simultaneously achieve strong privacy and high utility. Although this bound vanishes asymptotically as M to infty, the convergence is extremely slow: even for practically relevant numbers of updates the required noise magnitude remains substantial. We further show that the same limitation extends to Poisson subsampling up to constant factors. Our experiments confirm that the noise levels implied by this bound leads to significant accuracy degradation at realistic training settings, thus showing a critical bottleneck in DP-SGD under standard worst-case adversarial assumptions.]]></description>
<pubDate>Thu, 15 Jan 2026 09:50:36 +0000</pubDate>
</item>
<item>
<title><![CDATA[Beyond Cosine Similarity: Taming Semantic Drift and Antonym Intrusion in a 15-Million Node Turkish Synonym Graph]]></title>
<link>https://huggingface.co/papers/2601.13251</link>
<guid>2601.13251</guid>
<description><![CDATA[Source: HuggingFace
Tags: 
Authors: Ebubekir Tosun, Mehmet Emin Buldur, Özay Ezerceli, Mahmoud ElHussieni
Institution: 
Published: 2026-01-19
Score: 7/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Neural embeddings have a notorious blind spot: they can't reliably tell synonyms apart from antonyms. Consequently, increasing similarity thresholds often fails to prevent opposites from being grouped together. We've built a large-scale semantic clustering system specifically designed to tackle this problem head on. Our pipeline chews through 15 million lexical items, evaluates a massive 520 million potential relationships, and ultimately generates 2.9 million high-precision semantic clusters. The system makes three primary contributions. First, we introduce a labeled dataset of 843,000 concept pairs spanning synonymy, antonymy, and co-hyponymy, constructed via Gemini 2.5-Flash LLM augmentation and verified using human-curated dictionary resources. Second, we propose a specialized three-way semantic relation discriminator that achieves 90% macro-F1, enabling robust disambiguation beyond raw embedding similarity. Third, we introduce a novel soft-to-hard clustering algorithm that mitigates semantic drift preventing erroneous transitive chains (e.g., hot -> spicy -> pain -> depression) while simultaneously resolving polysemy. Our approach employs a topology-aware two-stage expansion-pruning procedure with topological voting, ensuring that each term is assigned to exactly one semantically coherent cluster. The resulting resource enables high-precision semantic search and retrieval-augmented generation, particularly for morphologically rich and low-resource languages where existing synonym databases remain sparse.]]></description>
<pubDate>Mon, 19 Jan 2026 17:37:25 +0000</pubDate>
</item>
<item>
<title><![CDATA[Being-H0.5: Scaling Human-Centric Robot Learning for Cross-Embodiment Generalization]]></title>
<link>https://huggingface.co/papers/2601.12993</link>
<guid>2601.12993</guid>
<description><![CDATA[Source: HuggingFace
Tags: 
Authors: Hao Luo, Ye Wang, Wanpeng Zhang, Sipeng Zheng, Ziheng Xi
Institution: 
Published: 2026-01-19
Score: 6/10
Citations: 0
Upvotes: 37
GitHub: 
Stars: 0

We introduce Being-H0.5, a foundational Vision-Language-Action (VLA) model designed for robust cross-embodiment generalization across diverse robotic platforms. While existing VLAs often struggle with morphological heterogeneity and data scarcity, we propose a human-centric learning paradigm that treats human interaction traces as a universal "mother tongue" for physical interaction. To support this, we present UniHand-2.0, the largest embodied pre-training recipe to date, comprising over 35,000 hours of multimodal data across 30 distinct robotic embodiments. Our approach introduces a Unified Action Space that maps heterogeneous robot controls into semantically aligned slots, enabling low-resource robots to bootstrap skills from human data and high-resource platforms. Built upon this human-centric foundation, we design a unified sequential modeling and multi-task pre-training paradigm to bridge human demonstrations and robotic execution. Architecturally, Being-H0.5 utilizes a Mixture-of-Transformers design featuring a novel Mixture-of-Flow (MoF) framework to decouple shared motor primitives from specialized embodiment-specific experts. Finally, to make cross-embodiment policies stable in the real world, we introduce Manifold-Preserving Gating for robustness under sensory shift and Universal Async Chunking to universalize chunked control across embodiments with different latency and control profiles. We empirically demonstrate that Being-H0.5 achieves state-of-the-art results on simulated benchmarks, such as LIBERO (98.9%) and RoboCasa (53.9%), while also exhibiting strong cross-embodiment capabilities on five robotic platforms.]]></description>
<pubDate>Mon, 19 Jan 2026 12:20:38 +0000</pubDate>
</item>
<item>
<title><![CDATA[FutureOmni: Evaluating Future Forecasting from Omni-Modal Context for Multimodal LLMs]]></title>
<link>https://huggingface.co/papers/2601.13836</link>
<guid>2601.13836</guid>
<description><![CDATA[Source: HuggingFace
Tags: 
Authors: Qian Chen, Jinlan Fu, Changsong Li, See-Kiong Ng, Xipeng Qiu
Institution: 
Published: 2026-01-20
Score: 6/10
Citations: 0
Upvotes: 27
GitHub: 
Stars: 0

Although Multimodal Large Language Models (MLLMs) demonstrate strong omni-modal perception, their ability to forecast future events from audio-visual cues remains largely unexplored, as existing benchmarks focus mainly on retrospective understanding. To bridge this gap, we introduce FutureOmni, the first benchmark designed to evaluate omni-modal future forecasting from audio-visual environments. The evaluated models are required to perform cross-modal causal and temporal reasoning, as well as effectively leverage internal knowledge to predict future events. FutureOmni is constructed via a scalable LLM-assisted, human-in-the-loop pipeline and contains 919 videos and 1,034 multiple-choice QA pairs across 8 primary domains. Evaluations on 13 omni-modal and 7 video-only models show that current systems struggle with audio-visual future prediction, particularly in speech-heavy scenarios, with the best accuracy of 64.8% achieved by Gemini 3 Flash. To mitigate this limitation, we curate a 7K-sample instruction-tuning dataset and propose an Omni-Modal Future Forecasting (OFF) training strategy. Evaluations on FutureOmni and popular audio-visual and video-only benchmarks demonstrate that OFF enhances future forecasting and generalization. We publicly release all code (https://github.com/OpenMOSS/FutureOmni) and datasets (https://huggingface.co/datasets/OpenMOSS-Team/FutureOmni).]]></description>
<pubDate>Tue, 20 Jan 2026 10:47:20 +0000</pubDate>
</item>
<item>
<title><![CDATA[NAACL: Noise-AwAre Verbal Confidence Calibration for LLMs in RAG Systems]]></title>
<link>https://huggingface.co/papers/2601.11004</link>
<guid>2601.11004</guid>
<description><![CDATA[Source: HuggingFace
Tags: 
Authors: Jiayu Liu, Rui Wang, Qing Zong, Qingcheng Zeng, Tianshi Zheng
Institution: 
Published: 2026-01-16
Score: 6/10
Citations: 0
Upvotes: 24
GitHub: 
Stars: 0

Accurately assessing model confidence is essential for deploying large language models (LLMs) in mission-critical factual domains. While retrieval-augmented generation (RAG) is widely adopted to improve grounding, confidence calibration in RAG settings remains poorly understood. We conduct a systematic study across four benchmarks, revealing that LLMs exhibit poor calibration performance due to noisy retrieved contexts. Specifically, contradictory or irrelevant evidence tends to inflate the model's false certainty, leading to severe overconfidence. To address this, we propose NAACL Rules (Noise-AwAre Confidence CaLibration Rules) to provide a principled foundation for resolving overconfidence under noise. We further design NAACL, a noise-aware calibration framework that synthesizes supervision from about 2K HotpotQA examples guided by these rules. By performing supervised fine-tuning (SFT) with this data, NAACL equips models with intrinsic noise awareness without relying on stronger teacher models. Empirical results show that NAACL yields substantial gains, improving ECE scores by 10.9% in-domain and 8.0% out-of-domain. By bridging the gap between retrieval noise and verbal calibration, NAACL paves the way for both accurate and epistemically reliable LLMs.]]></description>
<pubDate>Fri, 16 Jan 2026 05:38:25 +0000</pubDate>
</item>
<item>
<title><![CDATA[ACoT-VLA: Action Chain-of-Thought for Vision-Language-Action Models]]></title>
<link>https://huggingface.co/papers/2601.11404</link>
<guid>2601.11404</guid>
<description><![CDATA[Source: HuggingFace
Tags: 
Authors: Linqing Zhong, Yi Liu, Yifei Wei, Ziyu Xiong, Maoqing Yao
Institution: 
Published: 2026-01-16
Score: 6/10
Citations: 0
Upvotes: 22
GitHub: 
Stars: 0

Vision-Language-Action (VLA) models have emerged as essential generalist robot policies for diverse manipulation tasks, conventionally relying on directly translating multimodal inputs into actions via Vision-Language Model (VLM) embeddings. Recent advancements have introduced explicit intermediary reasoning, such as sub-task prediction (language) or goal image synthesis (vision), to guide action generation. However, these intermediate reasoning are often indirect and inherently limited in their capacity to convey the full, granular information required for precise action execution. Instead, we posit that the most effective form of reasoning is one that deliberates directly in the action space. We introduce Action Chain-of-Thought (ACoT), a paradigm where the reasoning process itself is formulated as a structured sequence of coarse action intents that guide the final policy. In this paper, we propose ACoT-VLA, a novel architecture that materializes the ACoT paradigm. Specifically, we introduce two complementary components: an Explicit Action Reasoner (EAR) and Implicit Action Reasoner (IAR). The former proposes coarse reference trajectories as explicit action-level reasoning steps, while the latter extracts latent action priors from internal representations of multimodal input, co-forming an ACoT that conditions the downstream action head to enable grounded policy learning. Extensive experiments in real-world and simulation environments demonstrate the superiority of our proposed method, which achieves 98.5%, 84.1%, and 47.4% on LIBERO, LIBERO-Plus and VLABench, respectively.]]></description>
<pubDate>Fri, 16 Jan 2026 16:17:06 +0000</pubDate>
</item>
<item>
<title><![CDATA[Think3D: Thinking with Space for Spatial Reasoning]]></title>
<link>https://huggingface.co/papers/2601.13029</link>
<guid>2601.13029</guid>
<description><![CDATA[Source: HuggingFace
Tags: 
Authors: Zaibin Zhang, Yuhan Wu, Lianjie Jia, Yifan Wang, Zhongbo Zhang
Institution: 
Published: 2026-01-19
Score: 6/10
Citations: 0
Upvotes: 17
GitHub: 
Stars: 0

Understanding and reasoning about the physical world requires spatial intelligence: the ability to interpret geometry, perspective, and spatial relations beyond 2D perception. While recent vision large models (VLMs) excel at visual understanding, they remain fundamentally 2D perceivers and struggle with genuine 3D reasoning. We introduce Think3D, a framework that enables VLM agents to think with 3D space. By leveraging 3D reconstruction models that recover point clouds and camera poses from images or videos, Think3D allows the agent to actively manipulate space through camera-based operations and ego/global-view switching, transforming spatial reasoning into an interactive 3D chain-of-thought process. Without additional training, Think3D significantly improves the spatial reasoning performance of advanced models such as GPT-4.1 and Gemini 2.5 Pro, yielding average gains of +7.8% on BLINK Multi-view and MindCube, and +4.7% on VSI-Bench. We further show that smaller models, which struggle with spatial exploration, benefit significantly from a reinforcement learning policy that enables the model to select informative viewpoints and operations. With RL, the benefit from tool usage increases from +0.7% to +6.8%. Our findings demonstrate that training-free, tool-augmented spatial exploration is a viable path toward more flexible and human-like 3D reasoning in multimodal agents, establishing a new dimension of multimodal intelligence. Code and weights are released at https://github.com/zhangzaibin/spagent.]]></description>
<pubDate>Mon, 19 Jan 2026 13:13:54 +0000</pubDate>
</item>
<item>
<title><![CDATA[Future Optical Flow Prediction Improves Robot Control & Video Generation]]></title>
<link>https://huggingface.co/papers/2601.10781</link>
<guid>2601.10781</guid>
<description><![CDATA[Source: HuggingFace
Tags: 
Authors: Kanchana Ranasinghe, Honglu Zhou, Yu Fang, Luyu Yang, Le Xue
Institution: 
Published: 2026-01-15
Score: 6/10
Citations: 0
Upvotes: 15
GitHub: 
Stars: 0

Future motion representations, such as optical flow, offer immense value for control and generative tasks. However, forecasting generalizable spatially dense motion representations remains a key challenge, and learning such forecasting from noisy, real-world data remains relatively unexplored. We introduce FOFPred, a novel language-conditioned optical flow forecasting model featuring a unified Vision-Language Model (VLM) and Diffusion architecture. This unique combination enables strong multimodal reasoning with pixel-level generative fidelity for future motion prediction. Our model is trained on web-scale human activity data-a highly scalable but unstructured source. To extract meaningful signals from this noisy video-caption data, we employ crucial data preprocessing techniques and our unified architecture with strong image pretraining. The resulting trained model is then extended to tackle two distinct downstream tasks in control and generation. Evaluations across robotic manipulation and video generation under language-driven settings establish the cross-domain versatility of FOFPred, confirming the value of a unified VLM-Diffusion architecture and scalable learning from diverse web data for future optical flow prediction.]]></description>
<pubDate>Thu, 15 Jan 2026 18:49:48 +0000</pubDate>
</item>
<item>
<title><![CDATA[ShapeR: Robust Conditional 3D Shape Generation from Casual Captures]]></title>
<link>https://huggingface.co/papers/2601.11514</link>
<guid>2601.11514</guid>
<description><![CDATA[Source: HuggingFace
Tags: 
Authors: Yawar Siddiqui, Duncan Frost, Samir Aroudj, Armen Avetisyan, Henry Howard-Jenkins
Institution: 
Published: 2026-01-16
Score: 6/10
Citations: 0
Upvotes: 13
GitHub: 
Stars: 0

Recent advances in 3D shape generation have achieved impressive results, but most existing methods rely on clean, unoccluded, and well-segmented inputs. Such conditions are rarely met in real-world scenarios. We present ShapeR, a novel approach for conditional 3D object shape generation from casually captured sequences. Given an image sequence, we leverage off-the-shelf visual-inertial SLAM, 3D detection algorithms, and vision-language models to extract, for each object, a set of sparse SLAM points, posed multi-view images, and machine-generated captions. A rectified flow transformer trained to effectively condition on these modalities then generates high-fidelity metric 3D shapes. To ensure robustness to the challenges of casually captured data, we employ a range of techniques including on-the-fly compositional augmentations, a curriculum training scheme spanning object- and scene-level datasets, and strategies to handle background clutter. Additionally, we introduce a new evaluation benchmark comprising 178 in-the-wild objects across 7 real-world scenes with geometry annotations. Experiments show that ShapeR significantly outperforms existing approaches in this challenging setting, achieving an improvement of 2.7x in Chamfer distance compared to state of the art.]]></description>
<pubDate>Fri, 16 Jan 2026 18:51:24 +0000</pubDate>
</item>
<item>
<title><![CDATA[The Assistant Axis: Situating and Stabilizing the Default Persona of Language Models]]></title>
<link>https://huggingface.co/papers/2601.10387</link>
<guid>2601.10387</guid>
<description><![CDATA[Source: HuggingFace
Tags: 
Authors: Christina Lu, Jack Gallagher, Jonathan Michala, Kyle Fish, Jack Lindsey
Institution: 
Published: 2026-01-15
Score: 6/10
Citations: 0
Upvotes: 9
GitHub: 
Stars: 0

Large language models can represent a variety of personas but typically default to a helpful Assistant identity cultivated during post-training. We investigate the structure of the space of model personas by extracting activation directions corresponding to diverse character archetypes. Across several different models, we find that the leading component of this persona space is an "Assistant Axis," which captures the extent to which a model is operating in its default Assistant mode. Steering towards the Assistant direction reinforces helpful and harmless behavior; steering away increases the model's tendency to identify as other entities. Moreover, steering away with more extreme values often induces a mystical, theatrical speaking style. We find this axis is also present in pre-trained models, where it primarily promotes helpful human archetypes like consultants and coaches and inhibits spiritual ones. Measuring deviations along the Assistant Axis predicts "persona drift," a phenomenon where models slip into exhibiting harmful or bizarre behaviors that are uncharacteristic of their typical persona. We find that persona drift is often driven by conversations demanding meta-reflection on the model's processes or featuring emotionally vulnerable users. We show that restricting activations to a fixed region along the Assistant Axis can stabilize model behavior in these scenarios -- and also in the face of adversarial persona-based jailbreaks. Our results suggest that post-training steers models toward a particular region of persona space but only loosely tethers them to it, motivating work on training and steering strategies that more deeply anchor models to a coherent persona.]]></description>
<pubDate>Thu, 15 Jan 2026 13:40:06 +0000</pubDate>
</item>
<item>
<title><![CDATA[KAGE-Bench: Fast Known-Axis Visual Generalization Evaluation for Reinforcement Learning]]></title>
<link>https://huggingface.co/papers/2601.14232</link>
<guid>2601.14232</guid>
<description><![CDATA[Source: HuggingFace
Tags: 
Authors: Egor Cherepanov, Daniil Zelezetsky, Alexey K. Kovalev, Aleksandr I. Panov
Institution: 
Published: 2026-01-20
Score: 6/10
Citations: 0
Upvotes: 7
GitHub: 
Stars: 0

Pixel-based reinforcement learning agents often fail under purely visual distribution shift even when latent dynamics and rewards are unchanged, but existing benchmarks entangle multiple sources of shift and hinder systematic analysis. We introduce KAGE-Env, a JAX-native 2D platformer that factorizes the observation process into independently controllable visual axes while keeping the underlying control problem fixed. By construction, varying a visual axis affects performance only through the induced state-conditional action distribution of a pixel policy, providing a clean abstraction for visual generalization. Building on this environment, we define KAGE-Bench, a benchmark of six known-axis suites comprising 34 train-evaluation configuration pairs that isolate individual visual shifts. Using a standard PPO-CNN baseline, we observe strong axis-dependent failures, with background and photometric shifts often collapsing success, while agent-appearance shifts are comparatively benign. Several shifts preserve forward motion while breaking task completion, showing that return alone can obscure generalization failures. Finally, the fully vectorized JAX implementation enables up to 33M environment steps per second on a single GPU, enabling fast and reproducible sweeps over visual factors. Code: https://avanturist322.github.io/KAGEBench/.]]></description>
<pubDate>Tue, 20 Jan 2026 18:44:28 +0000</pubDate>
</item>
<item>
<title><![CDATA[PersonalAlign: Hierarchical Implicit Intent Alignment for Personalized GUI Agent with Long-Term User-Centric Records]]></title>
<link>https://huggingface.co/papers/2601.09636</link>
<guid>2601.09636</guid>
<description><![CDATA[Source: HuggingFace
Tags: 
Authors: Yibo Lyu, Gongwei Chen, Rui Shao, Weili Guan, Liqiang Nie
Institution: 
Published: 2026-01-14
Score: 6/10
Citations: 0
Upvotes: 6
GitHub: 
Stars: 0

While GUI agents have shown strong performance under explicit and completion instructions, real-world deployment requires aligning with users' more complex implicit intents. In this work, we highlight Hierarchical Implicit Intent Alignment for Personalized GUI Agent (PersonalAlign), a new agent task that requires agents to leverage long-term user records as persistent context to resolve omitted preferences in vague instructions and anticipate latent routines by user state for proactive assistance. To facilitate this study, we introduce AndroidIntent, a benchmark designed to evaluate agents' ability in resolving vague instructions and providing proactive suggestions through reasoning over long-term user records. We annotated 775 user-specific preferences and 215 routines from 20k long-term records across different users for evaluation. Furthermore, we introduce Hierarchical Intent Memory Agent (HIM-Agent), which maintains a continuously updating personal memory and hierarchically organizes user preferences and routines for personalization. Finally, we evaluate a range of GUI agents on AndroidIntent, including GPT-5, Qwen3-VL, and UI-TARS, further results show that HIM-Agent significantly improves both execution and proactive performance by 15.7% and 7.3%.]]></description>
<pubDate>Wed, 14 Jan 2026 17:12:48 +0000</pubDate>
</item>
<item>
<title><![CDATA[PRiSM: Benchmarking Phone Realization in Speech Models]]></title>
<link>https://huggingface.co/papers/2601.14046</link>
<guid>2601.14046</guid>
<description><![CDATA[Source: HuggingFace
Tags: 
Authors: Shikhar Bharadwaj, Chin-Jou Li, Yoonjae Kim, Kwanghee Choi, Eunjung Yeo
Institution: 
Published: 2026-01-20
Score: 6/10
Citations: 0
Upvotes: 3
GitHub: 
Stars: 0

Phone recognition (PR) serves as the atomic interface for language-agnostic modeling for cross-lingual speech processing and phonetic analysis. Despite prolonged efforts in developing PR systems, current evaluations only measure surface-level transcription accuracy. We introduce PRiSM, the first open-source benchmark designed to expose blind spots in phonetic perception through intrinsic and extrinsic evaluation of PR systems. PRiSM standardizes transcription-based evaluation and assesses downstream utility in clinical, educational, and multilingual settings with transcription and representation probes. We find that diverse language exposure during training is key to PR performance, encoder-CTC models are the most stable, and specialized PR models still outperform Large Audio Language Models. PRiSM releases code, recipes, and datasets to move the field toward multilingual speech models with robust phonetic ability: https://github.com/changelinglab/prism.]]></description>
<pubDate>Tue, 20 Jan 2026 15:00:36 +0000</pubDate>
</item>
<item>
<title><![CDATA[A BERTology View of LLM Orchestrations: Token- and Layer-Selective Probes for Efficient Single-Pass Classification]]></title>
<link>https://huggingface.co/papers/2601.13288</link>
<guid>2601.13288</guid>
<description><![CDATA[Source: HuggingFace
Tags: 
Authors: Gonzalo Ariel Meyoyan, Luciano Del Corro
Institution: 
Published: 2026-01-19
Score: 6/10
Citations: 0
Upvotes: 2
GitHub: 
Stars: 0

Production LLM systems often rely on separate models for safety and other classification-heavy steps, increasing latency, VRAM footprint, and operational complexity. We instead reuse computation already paid for by the serving LLM: we train lightweight probes on its hidden states and predict labels in the same forward pass used for generation. We frame classification as representation selection over the full token-layer hidden-state tensor, rather than committing to a fixed token or fixed layer (e.g., first-token logits or final-layer pooling). To implement this, we introduce a two-stage aggregator that (i) summarizes tokens within each layer and (ii) aggregates across layer summaries to form a single representation for classification. We instantiate this template with direct pooling, a 100K-parameter scoring-attention gate, and a downcast multi-head self-attention (MHA) probe with up to 35M trainable parameters. Across safety and sentiment benchmarks our probes improve over logit-only reuse (e.g., MULI) and are competitive with substantially larger task-specific baselines, while preserving near-serving latency and avoiding the VRAM and latency costs of a separate guard-model pipeline.]]></description>
<pubDate>Mon, 19 Jan 2026 18:40:29 +0000</pubDate>
</item>
<item>
<title><![CDATA[SciCoQA: Quality Assurance for Scientific Paper--Code Alignment]]></title>
<link>https://huggingface.co/papers/2601.12910</link>
<guid>2601.12910</guid>
<description><![CDATA[Source: HuggingFace
Tags: 
Authors: Tim Baumgärtner, Iryna Gurevych
Institution: 
Published: 2026-01-19
Score: 6/10
Citations: 0
Upvotes: 1
GitHub: 
Stars: 0

We present SciCoQA, a dataset for detecting discrepancies between scientific publications and their codebases to ensure faithful implementations. We construct SciCoQA from GitHub issues and reproducibility papers, and to scale our dataset, we propose a synthetic data generation method for constructing paper-code discrepancies. We analyze the paper-code discrepancies in detail and propose discrepancy types and categories to better understand the occurring mismatches. In total, our dataset consists of 611 paper-code discrepancies (81 real, 530 synthetic), spanning diverse computational science disciplines, including AI, Physics, Quantitative Biology, and others. Our evaluation of 21 LLMs highlights the difficulty of SciCoQA, particularly for instances involving omitted paper details, long-context inputs, and data outside the models' pre-training corpus. The best performing model in our evaluation, GPT-5, can only detect 45.7\% of real-world paper-code discrepancies.]]></description>
<pubDate>Mon, 19 Jan 2026 10:04:33 +0000</pubDate>
</item>
<item>
<title><![CDATA[Finally Outshining the Random Baseline: A Simple and Effective Solution for Active Learning in 3D Biomedical Imaging]]></title>
<link>https://huggingface.co/papers/2601.13677</link>
<guid>2601.13677</guid>
<description><![CDATA[Source: HuggingFace
Tags: 
Authors: Carsten T. Lüth, Jeremias Traub, Kim-Celine Kahl, Till J. Bungert, Lukas Klein
Institution: 
Published: 2026-01-20
Score: 6/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Active learning (AL) has the potential to drastically reduce annotation costs in 3D biomedical image segmentation, where expert labeling of volumetric data is both time-consuming and expensive. Yet, existing AL methods are unable to consistently outperform improved random sampling baselines adapted to 3D data, leaving the field without a reliable solution. We introduce Class-stratified Scheduled Power Predictive Entropy (ClaSP PE), a simple and effective query strategy that addresses two key limitations of standard uncertainty-based AL methods: class imbalance and redundancy in early selections. ClaSP PE combines class-stratified querying to ensure coverage of underrepresented structures and log-scale power noising with a decaying schedule to enforce query diversity in early-stage AL and encourage exploitation later. In our evaluation on 24 experimental settings using four 3D biomedical datasets within the comprehensive nnActive benchmark, ClaSP PE is the only method that generally outperforms improved random baselines in terms of both segmentation quality with statistically significant gains, whilst remaining annotation efficient. Furthermore, we explicitly simulate the real-world application by testing our method on four previously unseen datasets without manual adaptation, where all experiment parameters are set according to predefined guidelines. The results confirm that ClaSP PE robustly generalizes to novel tasks without requiring dataset-specific tuning. Within the nnActive framework, we present compelling evidence that an AL method can consistently outperform random baselines adapted to 3D segmentation, in terms of both performance and annotation efficiency in a realistic, close-to-production scenario. Our open-source implementation and clear deployment guidelines make it readily applicable in practice. Code is at https://github.com/MIC-DKFZ/nnActive.]]></description>
<pubDate>Tue, 20 Jan 2026 07:29:50 +0000</pubDate>
</item>
<item>
<title><![CDATA[Advances and Frontiers of LLM-based Issue Resolution in Software Engineering: A Comprehensive Survey]]></title>
<link>https://huggingface.co/papers/2601.11655</link>
<guid>2601.11655</guid>
<description><![CDATA[Source: HuggingFace
Tags: 
Authors: Caihua Li, Lianghong Guo, Yanlin Wang, Daya Guo, Wei Tao
Institution: 
Published: 2026-01-15
Score: 5/10
Citations: 0
Upvotes: 41
GitHub: 
Stars: 0

Issue resolution, a complex Software Engineering (SWE) task integral to real-world development, has emerged as a compelling challenge for artificial intelligence. The establishment of benchmarks like SWE-bench revealed this task as profoundly difficult for large language models, thereby significantly accelerating the evolution of autonomous coding agents. This paper presents a systematic survey of this emerging domain. We begin by examining data construction pipelines, covering automated collection and synthesis approaches. We then provide a comprehensive analysis of methodologies, spanning training-free frameworks with their modular components to training-based techniques, including supervised fine-tuning and reinforcement learning. Subsequently, we discuss critical analyses of data quality and agent behavior, alongside practical applications. Finally, we identify key challenges and outline promising directions for future research. An open-source repository is maintained at https://github.com/DeepSoftwareAnalytics/Awesome-Issue-Resolution to serve as a dynamic resource in this field.]]></description>
<pubDate>Thu, 15 Jan 2026 18:55:03 +0000</pubDate>
</item>
<item>
<title><![CDATA[Unlocking Implicit Experience: Synthesizing Tool-Use Trajectories from Text]]></title>
<link>https://huggingface.co/papers/2601.10355</link>
<guid>2601.10355</guid>
<description><![CDATA[Source: HuggingFace
Tags: 
Authors: Zhihao Xu, Rumei Li, Jiahuan Li, Rongxiang Weng, Jingang Wang
Institution: 
Published: 2026-01-15
Score: 5/10
Citations: 0
Upvotes: 36
GitHub: 
Stars: 0

Enabling Large Language Models (LLMs) to effectively utilize tools in multi-turn interactions is essential for building capable autonomous agents. However, acquiring diverse and realistic multi-turn tool-use data remains a significant challenge. In this work, we propose a novel text-based paradigm. We observe that textual corpora naturally contain rich, multi-step problem-solving experiences, which can serve as an untapped, scalable, and authentic data source for multi-turn tool-use tasks. Based on this insight, we introduce GEM, a data synthesis pipeline that enables the generation and extraction of multi-turn tool-use trajectories from text corpora through a four-stage process: relevance filtering, workflow & tool extraction, trajectory grounding, and complexity refinement. To reduce the computational cost, we further train a specialized Trajectory Synthesizer via supervised fine-tuning. This model distills the complex generation pipeline into an efficient, end-to-end trajectory generator. Experiments demonstrate that our GEM-32B achieve a 16.5% improvement on the BFCL V3 Multi-turn benchmark. Our models partially surpass the performance of models trained on τ - bench (Airline and Retail) in-domain data, highlighting the superior generalization capability derived from our text-based synthesis paradigm. Notably, our Trajectory Synthesizer matches the quality of the full pipeline while significantly reducing inference latency and costs.]]></description>
<pubDate>Thu, 15 Jan 2026 12:58:46 +0000</pubDate>
</item>
<item>
<title><![CDATA[OmniTransfer: All-in-one Framework for Spatio-temporal Video Transfer]]></title>
<link>https://huggingface.co/papers/2601.14250</link>
<guid>2601.14250</guid>
<description><![CDATA[Source: HuggingFace
Tags: 
Authors: Pengze Zhang, Yanze Wu, Mengtian Li, Xu Bai, Songtao Zhao
Institution: 
Published: 2026-01-20
Score: 5/10
Citations: 0
Upvotes: 24
GitHub: 
Stars: 0

Videos convey richer information than images or text, capturing both spatial and temporal dynamics. However, most existing video customization methods rely on reference images or task-specific temporal priors, failing to fully exploit the rich spatio-temporal information inherent in videos, thereby limiting flexibility and generalization in video generation. To address these limitations, we propose OmniTransfer, a unified framework for spatio-temporal video transfer. It leverages multi-view information across frames to enhance appearance consistency and exploits temporal cues to enable fine-grained temporal control. To unify various video transfer tasks, OmniTransfer incorporates three key designs: Task-aware Positional Bias that adaptively leverages reference video information to improve temporal alignment or appearance consistency; Reference-decoupled Causal Learning separating reference and target branches to enable precise reference transfer while improving efficiency; and Task-adaptive Multimodal Alignment using multimodal semantic guidance to dynamically distinguish and tackle different tasks. Extensive experiments show that OmniTransfer outperforms existing methods in appearance (ID and style) and temporal transfer (camera movement and video effects), while matching pose-guided methods in motion transfer without using pose, establishing a new paradigm for flexible, high-fidelity video generation.]]></description>
<pubDate>Tue, 20 Jan 2026 18:58:11 +0000</pubDate>
</item>
<item>
<title><![CDATA[ToolPRMBench: Evaluating and Advancing Process Reward Models for Tool-using Agents]]></title>
<link>https://huggingface.co/papers/2601.12294</link>
<guid>2601.12294</guid>
<description><![CDATA[Source: HuggingFace
Tags: 
Authors: Dawei Li, Yuguang Yao, Zhen Tan, Huan Liu, Ruocheng Guo
Institution: 
Published: 2026-01-18
Score: 5/10
Citations: 0
Upvotes: 13
GitHub: 
Stars: 0

Reward-guided search methods have demonstrated strong potential in enhancing tool-using agents by effectively guiding sampling and exploration over complex action spaces. As a core design, those search methods utilize process reward models (PRMs) to provide step-level rewards, enabling more fine-grained monitoring. However, there is a lack of systematic and reliable evaluation benchmarks for PRMs in tool-using settings. In this paper, we introduce ToolPRMBench, a large-scale benchmark specifically designed to evaluate PRMs for tool-using agents. ToolPRMBench is built on top of several representative tool-using benchmarks and converts agent trajectories into step-level test cases. Each case contains the interaction history, a correct action, a plausible but incorrect alternative, and relevant tool metadata. We respectively utilize offline sampling to isolate local single-step errors and online sampling to capture realistic multi-step failures from full agent rollouts. A multi-LLM verification pipeline is proposed to reduce label noise and ensure data quality. We conduct extensive experiments across large language models, general PRMs, and tool-specialized PRMs on ToolPRMBench. The results reveal clear differences in PRM effectiveness and highlight the potential of specialized PRMs for tool-using. Code and data will be released at https://github.com/David-Li0406/ToolPRMBench.]]></description>
<pubDate>Sun, 18 Jan 2026 07:48:36 +0000</pubDate>
</item>
<item>
<title><![CDATA[Entropy Sentinel: Continuous LLM Accuracy Monitoring from Decoding Entropy Traces in STEM]]></title>
<link>https://huggingface.co/papers/2601.09001</link>
<guid>2601.09001</guid>
<description><![CDATA[Source: HuggingFace
Tags: 
Authors: Pedro Memoli Buffa, Luciano Del Corro
Institution: 
Published: 2026-01-13
Score: 5/10
Citations: 0
Upvotes: 13
GitHub: 
Stars: 0

Deploying LLMs raises two coupled challenges: (1) monitoring - estimating where a model underperforms as traffic and domains drift - and (2) improvement - prioritizing data acquisition to close the largest performance gaps. We test whether an inference-time signal can estimate slice-level accuracy under domain shift. For each response, we compute an output-entropy profile from final-layer next-token probabilities (from top-k logprobs) and summarize it with eleven statistics. A lightweight classifier predicts instance correctness, and averaging predicted probabilities yields a domain-level accuracy estimate. We evaluate on ten STEM reasoning benchmarks with exhaustive train/test compositions (k in {1,2,3,4}; all "10 choose k" combinations), across nine LLMs from six families (3B-20B). Estimates often track held-out benchmark accuracy, and several models show near-monotonic ordering of domains. Output-entropy profiles are thus an accessible signal for scalable monitoring and for targeting data acquisition.]]></description>
<pubDate>Tue, 13 Jan 2026 21:54:38 +0000</pubDate>
</item>
<item>
<title><![CDATA[YaPO: Learnable Sparse Activation Steering Vectors for Domain Adaptation]]></title>
<link>https://huggingface.co/papers/2601.08441</link>
<guid>2601.08441</guid>
<description><![CDATA[Source: HuggingFace
Tags: 
Authors: Abdelaziz Bounhar, Rania Hossam Elmohamady Elbadry, Hadi Abdine, Preslav Nakov, Michalis Vazirgiannis
Institution: 
Published: 2026-01-13
Score: 5/10
Citations: 0
Upvotes: 6
GitHub: 
Stars: 0

Steering Large Language Models (LLMs) through activation interventions has emerged as a lightweight alternative to fine-tuning for alignment and personalization. Recent work on Bi-directional Preference Optimization (BiPO) shows that dense steering vectors can be learned directly from preference data in a Direct Preference Optimization (DPO) fashion, enabling control over truthfulness, hallucinations, and safety behaviors. However, dense steering vectors often entangle multiple latent factors due to neuron multi-semanticity, limiting their effectiveness and stability in fine-grained settings such as cultural alignment, where closely related values and behaviors (e.g., among Middle Eastern cultures) must be distinguished. In this paper, we propose Yet another Policy Optimization (YaPO), a reference-free method that learns sparse steering vectors in the latent space of a Sparse Autoencoder (SAE). By optimizing sparse codes, YaPO produces disentangled, interpretable, and efficient steering directions. Empirically, we show that YaPO converges faster, achieves stronger performance, and exhibits improved training stability compared to dense steering baselines. Beyond cultural alignment, YaPO generalizes to a range of alignment-related behaviors, including hallucination, wealth-seeking, jailbreak, and power-seeking. Importantly, YaPO preserves general knowledge, with no measurable degradation on MMLU. Overall, our results show that YaPO provides a general recipe for efficient, stable, and fine-grained alignment of LLMs, with broad applications to controllability and domain adaptation. The associated code and data are publicly availablehttps://github.com/MBZUAI-Paris/YaPO.]]></description>
<pubDate>Tue, 13 Jan 2026 11:10:13 +0000</pubDate>
</item>
<item>
<title><![CDATA[CoDance: An Unbind-Rebind Paradigm for Robust Multi-Subject Animation]]></title>
<link>https://huggingface.co/papers/2601.11096</link>
<guid>2601.11096</guid>
<description><![CDATA[Source: HuggingFace
Tags: 
Authors: Shuai Tan, Biao Gong, Ke Ma, Yutong Feng, Qiyuan Zhang
Institution: 
Published: 2026-01-16
Score: 5/10
Citations: 0
Upvotes: 6
GitHub: 
Stars: 0

Character image animation is gaining significant importance across various domains, driven by the demand for robust and flexible multi-subject rendering. While existing methods excel in single-person animation, they struggle to handle arbitrary subject counts, diverse character types, and spatial misalignment between the reference image and the driving poses. We attribute these limitations to an overly rigid spatial binding that forces strict pixel-wise alignment between the pose and reference, and an inability to consistently rebind motion to intended subjects. To address these challenges, we propose CoDance, a novel Unbind-Rebind framework that enables the animation of arbitrary subject counts, types, and spatial configurations conditioned on a single, potentially misaligned pose sequence. Specifically, the Unbind module employs a novel pose shift encoder to break the rigid spatial binding between the pose and the reference by introducing stochastic perturbations to both poses and their latent features, thereby compelling the model to learn a location-agnostic motion representation. To ensure precise control and subject association, we then devise a Rebind module, leveraging semantic guidance from text prompts and spatial guidance from subject masks to direct the learned motion to intended characters. Furthermore, to facilitate comprehensive evaluation, we introduce a new multi-subject CoDanceBench. Extensive experiments on CoDanceBench and existing datasets show that CoDance achieves SOTA performance, exhibiting remarkable generalization across diverse subjects and spatial layouts. The code and weights will be open-sourced.]]></description>
<pubDate>Fri, 16 Jan 2026 08:53:09 +0000</pubDate>
</item>
<item>
<title><![CDATA[More Images, More Problems? A Controlled Analysis of VLM Failure Modes]]></title>
<link>https://huggingface.co/papers/2601.07812</link>
<guid>2601.07812</guid>
<description><![CDATA[Source: HuggingFace
Tags: 
Authors: Anurag Das, Adrian Bulat, Alberto Baldrati, Ioannis Maniadis Metaxas, Bernt Schiele
Institution: 
Published: 2026-01-12
Score: 5/10
Citations: 0
Upvotes: 5
GitHub: 
Stars: 0

Large Vision Language Models (LVLMs) have demonstrated remarkable capabilities, yet their proficiency in understanding and reasoning over multiple images remains largely unexplored. While existing benchmarks have initiated the evaluation of multi-image models, a comprehensive analysis of their core weaknesses and their causes is still lacking. In this work, we introduce MIMIC (Multi-Image Model Insights and Challenges), a new benchmark designed to rigorously evaluate the multi-image capabilities of LVLMs. Using MIMIC, we conduct a series of diagnostic experiments that reveal pervasive issues: LVLMs often fail to aggregate information across images and struggle to track or attend to multiple concepts simultaneously. To address these failures, we propose two novel complementary remedies. On the data side, we present a procedural data-generation strategy that composes single-image annotations into rich, targeted multi-image training examples. On the optimization side, we analyze layer-wise attention patterns and derive an attention-masking scheme tailored for multi-image inputs. Experiments substantially improved cross-image aggregation, while also enhancing performance on existing multi-image benchmarks, outperforming prior state of the art across tasks. Data and code will be made available at https://github.com/anurag-198/MIMIC.]]></description>
<pubDate>Mon, 12 Jan 2026 18:45:13 +0000</pubDate>
</item>
<item>
<title><![CDATA[On the Evidentiary Limits of Membership Inference for Copyright Auditing]]></title>
<link>https://huggingface.co/papers/2601.12937</link>
<guid>2601.12937</guid>
<description><![CDATA[Source: HuggingFace
Tags: 
Authors: Murat Bilgehan Ertan, Emirhan Böge, Min Chen, Kaleel Mahmood, Marten van Dijk
Institution: 
Published: 2026-01-19
Score: 5/10
Citations: 0
Upvotes: 2
GitHub: 
Stars: 0

As large language models (LLMs) are trained on increasingly opaque corpora, membership inference attacks (MIAs) have been proposed to audit whether copyrighted texts were used during training, despite growing concerns about their reliability under realistic conditions. We ask whether MIAs can serve as admissible evidence in adversarial copyright disputes where an accused model developer may obfuscate training data while preserving semantic content, and formalize this setting through a judge-prosecutor-accused communication protocol. To test robustness under this protocol, we introduce SAGE (Structure-Aware SAE-Guided Extraction), a paraphrasing framework guided by Sparse Autoencoders (SAEs) that rewrites training data to alter lexical structure while preserving semantic content and downstream utility. Our experiments show that state-of-the-art MIAs degrade when models are fine-tuned on SAGE-generated paraphrases, indicating that their signals are not robust to semantics-preserving transformations. While some leakage remains in certain fine-tuning regimes, these results suggest that MIAs are brittle in adversarial settings and insufficient, on their own, as a standalone mechanism for copyright auditing of LLMs.]]></description>
<pubDate>Mon, 19 Jan 2026 10:46:51 +0000</pubDate>
</item>
<item>
<title><![CDATA[METIS: Mentoring Engine for Thoughtful Inquiry & Solutions]]></title>
<link>https://huggingface.co/papers/2601.13075</link>
<guid>2601.13075</guid>
<description><![CDATA[Source: HuggingFace
Tags: 
Authors: Abhinav Rajeev Kumar, Dhruv Trehan, Paras Chopra
Institution: 
Published: 2026-01-19
Score: 5/10
Citations: 0
Upvotes: 1
GitHub: 
Stars: 0

Many students lack access to expert research mentorship. We ask whether an AI mentor can move undergraduates from an idea to a paper. We build METIS, a tool-augmented, stage-aware assistant with literature search, curated guidelines, methodology checks, and memory. We evaluate METIS against GPT-5 and Claude Sonnet 4.5 across six writing stages using LLM-as-a-judge pairwise preferences, student-persona rubrics, short multi-turn tutoring, and evidence/compliance checks. On 90 single-turn prompts, LLM judges preferred METIS to Claude Sonnet 4.5 in 71% and to GPT-5 in 54%. Student scores (clarity/actionability/constraint-fit; 90 prompts x 3 judges) are higher across stages. In multi-turn sessions (five scenarios/agent), METIS yields slightly higher final quality than GPT-5. Gains concentrate in document-grounded stages (D-F), consistent with stage-aware routing and groundings failure modes include premature tool routing, shallow grounding, and occasional stage misclassification.]]></description>
<pubDate>Mon, 19 Jan 2026 14:10:35 +0000</pubDate>
</item>
<item>
<title><![CDATA[A Hybrid Protocol for Large-Scale Semantic Dataset Generation in Low-Resource Languages: The Turkish Semantic Relations Corpus]]></title>
<link>https://huggingface.co/papers/2601.13253</link>
<guid>2601.13253</guid>
<description><![CDATA[Source: HuggingFace
Tags: 
Authors: Ebubekir Tosun, Mehmet Emin Buldur, Özay Ezerceli, Mahmoud ElHussieni
Institution: 
Published: 2026-01-19
Score: 5/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

We present a hybrid methodology for generating large-scale semantic relationship datasets in low-resource languages, demonstrated through a comprehensive Turkish semantic relations corpus. Our approach integrates three phases: (1) FastText embeddings with Agglomerative Clustering to identify semantic clusters, (2) Gemini 2.5-Flash for automated semantic relationship classification, and (3) integration with curated dictionary sources. The resulting dataset comprises 843,000 unique Turkish semantic pairs across three relationship types (synonyms, antonyms, co-hyponyms) representing a 10x scale increase over existing resources at minimal cost ($65). We validate the dataset through two downstream tasks: an embedding model achieving 90% top-1 retrieval accuracy and a classification model attaining 90% F1-macro. Our scalable protocol addresses critical data scarcity in Turkish NLP and demonstrates applicability to other low-resource languages. We publicly release the dataset and models.]]></description>
<pubDate>Mon, 19 Jan 2026 17:38:52 +0000</pubDate>
</item>
<item>
<title><![CDATA[Your Group-Relative Advantage Is Biased]]></title>
<link>https://huggingface.co/papers/2601.08521</link>
<guid>2601.08521</guid>
<description><![CDATA[Source: HuggingFace
Tags: 
Authors: Fengkai Yang, Zherui Chen, Xiaohan Wang, Xiaodong Lu, Jiajun Chai
Institution: 
Published: 2026-01-13
Score: 4/10
Citations: 0
Upvotes: 128
GitHub: 
Stars: 0

Reinforcement Learning from Verifier Rewards (RLVR) has emerged as a widely used approach for post-training large language models on reasoning tasks, with group-based methods such as GRPO and its variants gaining broad adoption. These methods rely on group-relative advantage estimation to avoid learned critics, yet its theoretical properties remain poorly understood.
  In this work, we uncover a fundamental issue of group-based RL: the group-relative advantage estimator is inherently biased relative to the true (expected) advantage. We provide the first theoretical analysis showing that it systematically underestimates advantages for hard prompts and overestimates them for easy prompts, leading to imbalanced exploration and exploitation. To address this issue, we propose History-Aware Adaptive Difficulty Weighting (HA-DW), an adaptive reweighting scheme that adjusts advantage estimates based on an evolving difficulty anchor and training dynamics. Both theoretical analysis and experiments on five mathematical reasoning benchmarks demonstrate that HA-DW consistently improves performance when integrated into GRPO and its variants. Our results suggest that correcting biased advantage estimation is critical for robust and efficient RLVR training.]]></description>
<pubDate>Tue, 13 Jan 2026 13:03:15 +0000</pubDate>
</item>
<item>
<title><![CDATA[The Poisoned Apple Effect: Strategic Manipulation of Mediated Markets via Technology Expansion of AI Agents]]></title>
<link>https://huggingface.co/papers/2601.11496</link>
<guid>2601.11496</guid>
<description><![CDATA[Source: HuggingFace
Tags: 
Authors: Eilam Shapira, Roi Reichart, Moshe Tennenholtz
Institution: 
Published: 2026-01-16
Score: 4/10
Citations: 0
Upvotes: 43
GitHub: 
Stars: 0

The integration of AI agents into economic markets fundamentally alters the landscape of strategic interaction. We investigate the economic implications of expanding the set of available technologies in three canonical game-theoretic settings: bargaining (resource division), negotiation (asymmetric information trade), and persuasion (strategic information transmission). We find that simply increasing the choice of AI delegates can drastically shift equilibrium payoffs and regulatory outcomes, often creating incentives for regulators to proactively develop and release technologies. Conversely, we identify a strategic phenomenon termed the "Poisoned Apple" effect: an agent may release a new technology, which neither they nor their opponent ultimately uses, solely to manipulate the regulator's choice of market design in their favor. This strategic release improves the releaser's welfare at the expense of their opponent and the regulator's fairness objectives. Our findings demonstrate that static regulatory frameworks are vulnerable to manipulation via technology expansion, necessitating dynamic market designs that adapt to the evolving landscape of AI capabilities.]]></description>
<pubDate>Fri, 16 Jan 2026 18:18:03 +0000</pubDate>
</item>
<item>
<title><![CDATA[PubMed-OCR: PMC Open Access OCR Annotations]]></title>
<link>https://huggingface.co/papers/2601.11425</link>
<guid>2601.11425</guid>
<description><![CDATA[Source: HuggingFace
Tags: 
Authors: Hunter Heidenreich, Yosheb Getachew, Olivia Dinica, Ben Elliott
Institution: 
Published: 2026-01-16
Score: 4/10
Citations: 0
Upvotes: 6
GitHub: 
Stars: 0

PubMed-OCR is an OCR-centric corpus of scientific articles derived from PubMed Central Open Access PDFs. Each page image is annotated with Google Cloud Vision and released in a compact JSON schema with word-, line-, and paragraph-level bounding boxes. The corpus spans 209.5K articles (1.5M pages; ~1.3B words) and supports layout-aware modeling, coordinate-grounded QA, and evaluation of OCR-dependent pipelines. We analyze corpus characteristics (e.g., journal coverage and detected layout features) and discuss limitations, including reliance on a single OCR engine and heuristic line reconstruction. We release the data and schema to facilitate downstream research and invite extensions.]]></description>
<pubDate>Fri, 16 Jan 2026 16:44:50 +0000</pubDate>
</item>
<item>
<title><![CDATA[What Matters in Data Curation for Multimodal Reasoning? Insights from the DCVLR Challenge]]></title>
<link>https://huggingface.co/papers/2601.10922</link>
<guid>2601.10922</guid>
<description><![CDATA[Source: HuggingFace
Tags: 
Authors: Yosub Shin, Michael Buriek, Boris Sobolev, Pavel Bushuyeu, Vikas Kumar
Institution: 
Published: 2026-01-16
Score: 4/10
Citations: 0
Upvotes: 1
GitHub: 
Stars: 0

We study data curation for multimodal reasoning through the NeurIPS 2025 Data Curation for Vision-Language Reasoning (DCVLR) challenge, which isolates dataset selection by fixing the model and training protocol. Using a compact curated dataset derived primarily from Walton Multimodal Cold Start, our submission placed first in the challenge. Through post-competition ablations, we show that difficulty-based example selection on an aligned base dataset is the dominant driver of performance gains. Increasing dataset size does not reliably improve mean accuracy under the fixed training recipe, but mainly reduces run-to-run variance, while commonly used diversity and synthetic augmentation heuristics provide no additional benefit and often degrade performance. These results characterize DCVLR as a saturation-regime evaluation and highlight the central role of alignment and difficulty in data-efficient multimodal reasoning.]]></description>
<pubDate>Fri, 16 Jan 2026 00:50:01 +0000</pubDate>
</item>
<item>
<title><![CDATA[Implicit Neural Representation Facilitates Unified Universal Vision Encoding]]></title>
<link>http://arxiv.org/abs/2601.14256v1</link>
<guid>2601.14256v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.CV
Authors: Matthew Gwilliam, Xiao Wang, Xuefeng Hu, Zhenheng Yang
Institution: 
Published: 2026-01-20
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Models for image representation learning are typically designed for either recognition or generation. Various forms of contrastive learning help models learn to convert images to embeddings that are useful for classification, detection, and segmentation. On the other hand, models can be trained to reconstruct images with pixel-wise, perceptual, and adversarial losses in order to learn a latent space that is useful for image generation. We seek to unify these two directions with a first-of-its-kind model that learns representations which are simultaneously useful for recognition and generation. We train our model as a hyper-network for implicit neural representation, which learns to map images to model weights for fast, accurate reconstruction. We further integrate our INR hyper-network with knowledge distillation to improve its generalization and performance. Beyond the novel training design, the model also learns an unprecedented compressed embedding space with outstanding performance for various visual tasks. The complete model competes with state-of-the-art results for image representation learning, while also enabling generative capabilities with its high-quality tiny embeddings. The code is available at https://github.com/tiktok/huvr.]]></description>
<pubDate>Tue, 20 Jan 2026 18:59:57 +0000</pubDate>
</item>
<item>
<title><![CDATA[VideoMaMa: Mask-Guided Video Matting via Generative Prior]]></title>
<link>http://arxiv.org/abs/2601.14255v1</link>
<guid>2601.14255v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.CV, cs.AI
Authors: Sangbeom Lim, Seoung Wug Oh, Jiahui Huang, Heeji Yoon, Seungryong Kim et al.
Institution: 
Published: 2026-01-20
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Generalizing video matting models to real-world videos remains a significant challenge due to the scarcity of labeled data. To address this, we present Video Mask-to-Matte Model (VideoMaMa) that converts coarse segmentation masks into pixel accurate alpha mattes, by leveraging pretrained video diffusion models. VideoMaMa demonstrates strong zero-shot generalization to real-world footage, even though it is trained solely on synthetic data. Building on this capability, we develop a scalable pseudo-labeling pipeline for large-scale video matting and construct the Matting Anything in Video (MA-V) dataset, which offers high-quality matting annotations for more than 50K real-world videos spanning diverse scenes and motions. To validate the effectiveness of this dataset, we fine-tune the SAM2 model on MA-V to obtain SAM2-Matte, which outperforms the same model trained on existing matting datasets in terms of robustness on in-the-wild videos. These findings emphasize the importance of large-scale pseudo-labeled video matting and showcase how generative priors and accessible segmentation cues can drive scalable progress in video matting research.]]></description>
<pubDate>Tue, 20 Jan 2026 18:59:56 +0000</pubDate>
</item>
<item>
<title><![CDATA[Motion 3-to-4: 3D Motion Reconstruction for 4D Synthesis]]></title>
<link>http://arxiv.org/abs/2601.14253v1</link>
<guid>2601.14253v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.CV
Authors: Hongyuan Chen, Xingyu Chen, Youjia Zhang, Zexiang Xu, Anpei Chen
Institution: 
Published: 2026-01-20
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

We present Motion 3-to-4, a feed-forward framework for synthesising high-quality 4D dynamic objects from a single monocular video and an optional 3D reference mesh. While recent advances have significantly improved 2D, video, and 3D content generation, 4D synthesis remains difficult due to limited training data and the inherent ambiguity of recovering geometry and motion from a monocular viewpoint. Motion 3-to-4 addresses these challenges by decomposing 4D synthesis into static 3D shape generation and motion reconstruction. Using a canonical reference mesh, our model learns a compact motion latent representation and predicts per-frame vertex trajectories to recover complete, temporally coherent geometry. A scalable frame-wise transformer further enables robustness to varying sequence lengths. Evaluations on both standard benchmarks and a new dataset with accurate ground-truth geometry show that Motion 3-to-4 delivers superior fidelity and spatial consistency compared to prior work. Project page is available at https://motion3-to-4.github.io/.]]></description>
<pubDate>Tue, 20 Jan 2026 18:59:48 +0000</pubDate>
</item>
<item>
<title><![CDATA[Which Reasoning Trajectories Teach Students to Reason Better? A Simple Metric of Informative Alignment]]></title>
<link>http://arxiv.org/abs/2601.14249v1</link>
<guid>2601.14249v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.CL
Authors: Yuming Yang, Mingyoung Lai, Wanxu Zhao, Xiaoran Fan, Zhiheng Xi et al.
Institution: 
Published: 2026-01-20
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Long chain-of-thought (CoT) trajectories provide rich supervision signals for distilling reasoning from teacher to student LLMs. However, both prior work and our experiments show that trajectories from stronger teachers do not necessarily yield better students, highlighting the importance of data-student suitability in distillation. Existing methods assess suitability primarily through student likelihood, favoring trajectories that closely align with the model's current behavior but overlooking more informative ones. Addressing this, we propose Rank-Surprisal Ratio (RSR), a simple metric that captures both alignment and informativeness to assess the suitability of a reasoning trajectory. RSR is motivated by the observation that effective trajectories typically combine low absolute probability with relatively high-ranked tokens under the student model, balancing learning signal strength and behavioral alignment. Concretely, RSR is defined as the ratio of a trajectory's average token-wise rank to its average negative log-likelihood, and is straightforward to compute and interpret. Across five student models and reasoning trajectories from 11 diverse teachers, RSR strongly correlates with post-training performance (average Spearman 0.86), outperforming existing metrics. We further demonstrate its practical utility in both trajectory selection and teacher selection.]]></description>
<pubDate>Tue, 20 Jan 2026 18:58:10 +0000</pubDate>
</item>
<item>
<title><![CDATA[Soft Tail-dropping for Adaptive Visual Tokenization]]></title>
<link>http://arxiv.org/abs/2601.14246v1</link>
<guid>2601.14246v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.CV
Authors: Zeyuan Chen, Kai Zhang, Zhuowen Tu, Yuanjun Xiong
Institution: 
Published: 2026-01-20
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

We present Soft Tail-dropping Adaptive Tokenizer (STAT), a 1D discrete visual tokenizer that adaptively chooses the number of output tokens per image according to its structural complexity and level of detail. STAT encodes an image into a sequence of discrete codes together with per-token keep probabilities. Beyond standard autoencoder objectives, we regularize these keep probabilities to be monotonically decreasing along the sequence and explicitly align their distribution with an image-level complexity measure. As a result, STAT produces length-adaptive 1D visual tokens that are naturally compatible with causal 1D autoregressive (AR) visual generative models. On ImageNet-1k, equipping vanilla causal AR models with STAT yields competitive or superior visual generation quality compared to other probabilistic model families, while also exhibiting favorable scaling behavior that has been elusive in prior vanilla AR visual generation attempts.]]></description>
<pubDate>Tue, 20 Jan 2026 18:57:19 +0000</pubDate>
</item>
<item>
<title><![CDATA[Jet-RL: Enabling On-Policy FP8 Reinforcement Learning with Unified Training and Rollout Precision Flow]]></title>
<link>http://arxiv.org/abs/2601.14243v1</link>
<guid>2601.14243v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.LG, cs.CL
Authors: Haocheng Xi, Charlie Ruan, Peiyuan Liao, Yujun Lin, Han Cai et al.
Institution: 
Published: 2026-01-20
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Reinforcement learning (RL) is essential for enhancing the complex reasoning capabilities of large language models (LLMs). However, existing RL training pipelines are computationally inefficient and resource-intensive, with the rollout phase accounting for over 70% of total training time. Quantized RL training, particularly using FP8 precision, offers a promising approach to mitigating this bottleneck. A commonly adopted strategy applies FP8 precision during rollout while retaining BF16 precision for training. In this work, we present the first comprehensive study of FP8 RL training and demonstrate that the widely used BF16-training + FP8-rollout strategy suffers from severe training instability and catastrophic accuracy collapse under long-horizon rollouts and challenging tasks. Our analysis shows that these failures stem from the off-policy nature of the approach, which introduces substantial numerical mismatch between training and inference. Motivated by these observations, we propose Jet-RL, an FP8 RL training framework that enables robust and stable RL optimization. The key idea is to adopt a unified FP8 precision flow for both training and rollout, thereby minimizing numerical discrepancies and eliminating the need for inefficient inter-step calibration. Extensive experiments validate the effectiveness of Jet-RL: our method achieves up to 33% speedup in the rollout phase, up to 41% speedup in the training phase, and a 16% end-to-end speedup over BF16 training, while maintaining stable convergence across all settings and incurring negligible accuracy degradation.]]></description>
<pubDate>Tue, 20 Jan 2026 18:54:31 +0000</pubDate>
</item>
<item>
<title><![CDATA[APEX-Agents]]></title>
<link>http://arxiv.org/abs/2601.14242v1</link>
<guid>2601.14242v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.CL, cs.AI, cs.LG
Authors: Bertie Vidgen, Austin Mann, Abby Fennelly, John Wright Stanly, Lucas Rothman et al.
Institution: 
Published: 2026-01-20
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

We introduce the AI Productivity Index for Agents (APEX-Agents), a benchmark for assessing whether AI agents can execute long-horizon, cross-application tasks created by investment banking analysts, management consultants, and corporate lawyers. APEX-Agents requires agents to navigate realistic work environments with files and tools. We test eight agents for the leaderboard using Pass@1. Gemini 3 Flash (Thinking=High) achieves the highest score of 24.0%, followed by GPT-5.2 (Thinking=High), Claude Opus 4.5 (Thinking=High), and Gemini 3 Pro (Thinking=High). We open source the APEX-Agents benchmark (n=480) with all prompts, rubrics, gold outputs, files, and metadata. We also open-source Archipelago, our infrastructure for agent execution and evaluation.]]></description>
<pubDate>Tue, 20 Jan 2026 18:53:44 +0000</pubDate>
</item>
<item>
<title><![CDATA[Spatiotemporal Wildfire Prediction and Reinforcement Learning for Helitack Suppression]]></title>
<link>http://arxiv.org/abs/2601.14238v1</link>
<guid>2601.14238v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.LG
Authors: Shaurya Mathur, Shreyas Bellary Manjunath, Nitin Kulkarni, Alina Vereshchaka
Institution: 
Published: 2026-01-20
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Wildfires are growing in frequency and intensity, devastating ecosystems and communities while causing billions of dollars in suppression costs and economic damage annually in the U.S. Traditional wildfire management is mostly reactive, addressing fires only after they are detected. We introduce \textit{FireCastRL}, a proactive artificial intelligence (AI) framework that combines wildfire forecasting with intelligent suppression strategies. Our framework first uses a deep spatiotemporal model to predict wildfire ignition. For high-risk predictions, we deploy a pre-trained reinforcement learning (RL) agent to execute real-time suppression tactics with helitack units inside a physics-informed 3D simulation. The framework generates a threat assessment report to help emergency responders optimize resource allocation and planning. In addition, we are publicly releasing a large-scale, spatiotemporal dataset containing $\mathbf{9.5}$ million samples of environmental variables for wildfire prediction. Our work demonstrates how deep learning and RL can be combined to support both forecasting and tactical wildfire response. More details can be found at https://sites.google.com/view/firecastrl.]]></description>
<pubDate>Tue, 20 Jan 2026 18:50:12 +0000</pubDate>
</item>
<item>
<title><![CDATA[Opportunities in AI/ML for the Rubin LSST Dark Energy Science Collaboration]]></title>
<link>http://arxiv.org/abs/2601.14235v1</link>
<guid>2601.14235v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.AI, cs.LG, stat.ML
Authors:  LSST Dark Energy Science Collaboration, Eric Aubourg, Camille Avestruz, Matthew R. Becker, Biswajit Biswas et al.
Institution: 
Published: 2026-01-20
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

The Vera C. Rubin Observatory's Legacy Survey of Space and Time (LSST) will produce unprecedented volumes of heterogeneous astronomical data (images, catalogs, and alerts) that challenge traditional analysis pipelines. The LSST Dark Energy Science Collaboration (DESC) aims to derive robust constraints on dark energy and dark matter from these data, requiring methods that are statistically powerful, scalable, and operationally reliable. Artificial intelligence and machine learning (AI/ML) are already embedded across DESC science workflows, from photometric redshifts and transient classification to weak lensing inference and cosmological simulations. Yet their utility for precision cosmology hinges on trustworthy uncertainty quantification, robustness to covariate shift and model misspecification, and reproducible integration within scientific pipelines. This white paper surveys the current landscape of AI/ML across DESC's primary cosmological probes and cross-cutting analyses, revealing that the same core methodologies and fundamental challenges recur across disparate science cases. Since progress on these cross-cutting challenges would benefit multiple probes simultaneously, we identify key methodological research priorities, including Bayesian inference at scale, physics-informed methods, validation frameworks, and active learning for discovery. With an eye on emerging techniques, we also explore the potential of the latest foundation model methodologies and LLM-driven agentic AI systems to reshape DESC workflows, provided their deployment is coupled with rigorous evaluation and governance. Finally, we discuss critical software, computing, data infrastructure, and human capital requirements for the successful deployment of these new methodologies, and consider associated risks and opportunities for broader coordination with external actors.]]></description>
<pubDate>Tue, 20 Jan 2026 18:46:42 +0000</pubDate>
</item>
<item>
<title><![CDATA[Q-learning with Adjoint Matching]]></title>
<link>http://arxiv.org/abs/2601.14234v1</link>
<guid>2601.14234v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.LG, cs.AI, cs.RO, stat.ML
Authors: Qiyang Li, Sergey Levine
Institution: 
Published: 2026-01-20
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

We propose Q-learning with Adjoint Matching (QAM), a novel TD-based reinforcement learning (RL) algorithm that tackles a long-standing challenge in continuous-action RL: efficient optimization of an expressive diffusion or flow-matching policy with respect to a parameterized Q-function. Effective optimization requires exploiting the first-order information of the critic, but it is challenging to do so for flow or diffusion policies because direct gradient-based optimization via backpropagation through their multi-step denoising process is numerically unstable. Existing methods work around this either by only using the value and discarding the gradient information, or by relying on approximations that sacrifice policy expressivity or bias the learned policy. QAM sidesteps both of these challenges by leveraging adjoint matching, a recently proposed technique in generative modeling, which transforms the critic's action gradient to form a step-wise objective function that is free from unstable backpropagation, while providing an unbiased, expressive policy at the optimum. Combined with temporal-difference backup for critic learning, QAM consistently outperforms prior approaches on hard, sparse reward tasks in both offline and offline-to-online RL.]]></description>
<pubDate>Tue, 20 Jan 2026 18:45:34 +0000</pubDate>
</item>
<item>
<title><![CDATA[MASCOT: Towards Multi-Agent Socio-Collaborative Companion Systems]]></title>
<link>http://arxiv.org/abs/2601.14230v1</link>
<guid>2601.14230v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.CL, cs.AI, cs.HC
Authors: Yiyang Wang, Yiqiao Jin, Alex Cabral, Josiah Hester
Institution: 
Published: 2026-01-20
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Multi-agent systems (MAS) have recently emerged as promising socio-collaborative companions for emotional and cognitive support. However, these systems frequently suffer from persona collapse--where agents revert to generic, homogenized assistant behaviors--and social sycophancy, which produces redundant, non-constructive dialogue. We propose MASCOT, a generalizable framework for multi-perspective socio-collaborative companions. MASCOT introduces a novel bi-level optimization strategy to harmonize individual and collective behaviors: 1) Persona-Aware Behavioral Alignment, an RLAIF-driven pipeline that finetunes individual agents for strict persona fidelity to prevent identity loss; and 2) Collaborative Dialogue Optimization, a meta-policy guided by group-level rewards to ensure diverse and productive discourse. Extensive evaluations across psychological support and workplace domains demonstrate that MASCOT significantly outperforms state-of-the-art baselines, achieving improvements of up to +14.1 in Persona Consistency and +10.6 in Social Contribution. Our framework provides a practical roadmap for engineering the next generation of socially intelligent multi-agent systems.]]></description>
<pubDate>Tue, 20 Jan 2026 18:44:04 +0000</pubDate>
</item>
<item>
<title><![CDATA[Attention-Based Offline Reinforcement Learning and Clustering for Interpretable Sepsis Treatment]]></title>
<link>http://arxiv.org/abs/2601.14228v1</link>
<guid>2601.14228v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.LG
Authors: Punit Kumar, Vaibhav Saran, Divyesh Patel, Nitin Kulkarni, Alina Vereshchaka
Institution: 
Published: 2026-01-20
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Sepsis remains one of the leading causes of mortality in intensive care units, where timely and accurate treatment decisions can significantly impact patient outcomes. In this work, we propose an interpretable decision support framework. Our system integrates four core components: (1) a clustering-based stratification module that categorizes patients into low, intermediate, and high-risk groups upon ICU admission, using clustering with statistical validation; (2) a synthetic data augmentation pipeline leveraging variational autoencoders (VAE) and diffusion models to enrich underrepresented trajectories such as fluid or vasopressor administration; (3) an offline reinforcement learning (RL) agent trained using Advantage Weighted Regression (AWR) with a lightweight attention encoder and supported by an ensemble models for conservative, safety-aware treatment recommendations; and (4) a rationale generation module powered by a multi-modal large language model (LLM), which produces natural-language justifications grounded in clinical context and retrieved expert knowledge. Evaluated on the MIMIC-III and eICU datasets, our approach achieves high treatment accuracy while providing clinicians with interpretable and robust policy recommendations.]]></description>
<pubDate>Tue, 20 Jan 2026 18:41:44 +0000</pubDate>
</item>
<item>
<title><![CDATA[Deep Learning Approaches to Quantum Error Mitigation]]></title>
<link>http://arxiv.org/abs/2601.14226v1</link>
<guid>2601.14226v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.LG
Authors: Leonardo Placidi, Ifan Williams, Enrico Rinaldi, Daniel Mills, Cristina Cîrstoiu et al.
Institution: 
Published: 2026-01-20
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

We present a systematic investigation of deep learning methods applied to quantum error mitigation of noisy output probability distributions from measured quantum circuits. We compare different architectures, from fully connected neural networks to transformers, and we test different design/training modalities, identifying sequence-to-sequence, attention-based models as the most effective on our datasets. These models consistently produce mitigated distributions that are closer to the ideal outputs when tested on both simulated and real device data obtained from IBM superconducting quantum processing units (QPU) up to five qubits. Across several different circuit depths, our approach outperforms other baseline error mitigation techniques. We perform a series of ablation studies to examine: how different input features (circuit, device properties, noisy output statistics) affect performance; cross-dataset generalization across circuit families; and transfer learning to a different IBM QPU. We observe that generalization performance across similar devices with the same architecture works effectively, without needing to fully retrain models.]]></description>
<pubDate>Tue, 20 Jan 2026 18:40:22 +0000</pubDate>
</item>
<item>
<title><![CDATA[Generalization and Completeness of Stochastic Local Search Algorithms]]></title>
<link>http://arxiv.org/abs/2601.14212v1</link>
<guid>2601.14212v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.NE, cs.CL
Authors: Daniel Loscos, Narciso Marti-Oliet, Ismael Rodriguez
Institution: 
Published: 2026-01-20
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

We generalize Stochastic Local Search (SLS) heuristics into a unique formal model. This model has two key components: a common structure designed to be as large as possible and a parametric structure intended to be as small as possible. Each heuristic is obtained by instantiating the parametric part in a different way. Particular instances for Genetic Algorithms (GA), Ant Colony Optimization (ACO), and Particle Swarm Optimization (PSO) are presented. Then, we use our model to prove the Turing-completeness of SLS algorithms in general. The proof uses our framework to construct a GA able to simulate any Turing machine. This Turing-completeness implies that determining any non-trivial property concerning the relationship between the inputs and the computed outputs is undecidable for GA and, by extension, for the general set of SLS methods (although not necessarily for each particular method). Similar proofs are more informally presented for PSO and ACO.]]></description>
<pubDate>Tue, 20 Jan 2026 18:17:45 +0000</pubDate>
</item>
<item>
<title><![CDATA[HALT: Hallucination Assessment via Latent Testing]]></title>
<link>http://arxiv.org/abs/2601.14210v1</link>
<guid>2601.14210v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.CL
Authors: Rohan Bhatnagar, Youran Sun, Chi Andrew Zhang, Yixin Wen, Haizhao Yang
Institution: 
Published: 2026-01-20
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Hallucination in large language models (LLMs) can be understood as a failure of faithful readout: although internal representations may encode uncertainty about a query, decoding pressures still yield a fluent answer. We propose lightweight residual probes that read hallucination risk directly from intermediate hidden states of question tokens, motivated by the hypothesis that these layers retain epistemic signals that are attenuated in the final decoding stage. The probe is a small auxiliary network whose computation is orders of magnitude cheaper than token generation and can be evaluated fully in parallel with inference, enabling near-instantaneous hallucination risk estimation with effectively zero added latency in low-risk cases. We deploy the probe as an agentic critic for fast selective generation and routing, allowing LLMs to immediately answer confident queries while delegating uncertain ones to stronger verification pipelines. Across four QA benchmarks and multiple LLM families, the method achieves strong AUROC and AURAC, generalizes under dataset shift, and reveals interpretable structure in intermediate representations, positioning fast internal uncertainty readout as a principled foundation for reliable agentic AI.]]></description>
<pubDate>Tue, 20 Jan 2026 18:16:10 +0000</pubDate>
</item>
<item>
<title><![CDATA[InT: Self-Proposed Interventions Enable Credit Assignment in LLM Reasoning]]></title>
<link>http://arxiv.org/abs/2601.14209v1</link>
<guid>2601.14209v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.LG, cs.AI, cs.CL
Authors: Matthew Y. R. Yang, Hao Bai, Ian Wu, Gene Yang, Amrith Setlur et al.
Institution: 
Published: 2026-01-20
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Outcome-reward reinforcement learning (RL) has proven effective at improving the reasoning capabilities of large language models (LLMs). However, standard RL assigns credit only at the level of the final answer, penalizing entire reasoning traces when the outcome is incorrect and uniformly reinforcing all steps when it is correct. As a result, correct intermediate steps may be discouraged in failed traces, while spurious steps may be reinforced in successful ones. We refer to this failure mode as the problem of credit assignment. While a natural remedy is to train a process reward model, accurately optimizing such models to identify corrective reasoning steps remains challenging. We introduce Intervention Training (InT), a training paradigm in which the model performs fine-grained credit assignment on its own reasoning traces by proposing short, targeted corrections that steer trajectories toward higher reward. Using reference solutions commonly available in mathematical reasoning datasets and exploiting the fact that verifying a model-generated solution is easier than generating a correct one from scratch, the model identifies the first error in its reasoning and proposes a single-step intervention to redirect the trajectory toward the correct solution. We then apply supervised fine-tuning (SFT) to the on-policy rollout up to the point of error concatenated with the intervention, localizing error to the specific step that caused failure. We show that the resulting model serves as a far better initialization for RL training. After running InT and subsequent fine-tuning with RL, we improve accuracy by nearly 14% over a 4B-parameter base model on IMO-AnswerBench, outperforming larger open-source models such as gpt-oss-20b.]]></description>
<pubDate>Tue, 20 Jan 2026 18:15:38 +0000</pubDate>
</item>
<item>
<title><![CDATA[Rig-Aware 3D Reconstruction of Vehicle Undercarriages using Gaussian Splatting]]></title>
<link>http://arxiv.org/abs/2601.14208v1</link>
<guid>2601.14208v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.CV, cs.GR, cs.LG
Authors: Nitin Kulkarni, Akhil Devarashetti, Charlie Cluss, Livio Forte, Dan Buckmaster et al.
Institution: 
Published: 2026-01-20
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Inspecting the undercarriage of used vehicles is a labor-intensive task that requires inspectors to crouch or crawl underneath each vehicle to thoroughly examine it. Additionally, online buyers rarely see undercarriage photos. We present an end-to-end pipeline that utilizes a three-camera rig to capture videos of the undercarriage as the vehicle drives over it, and produces an interactive 3D model of the undercarriage. The 3D model enables inspectors and customers to rotate, zoom, and slice through the undercarriage, allowing them to detect rust, leaks, or impact damage in seconds, thereby improving both workplace safety and buyer confidence. Our primary contribution is a rig-aware Structure-from-Motion (SfM) pipeline specifically designed to overcome the challenges of wide-angle lens distortion and low-parallax scenes. Our method overcomes the challenges of wide-angle lens distortion and low-parallax scenes by integrating precise camera calibration, synchronized video streams, and strong geometric priors from the camera rig. We use a constrained matching strategy with learned components, the DISK feature extractor, and the attention-based LightGlue matcher to generate high-quality sparse point clouds that are often unattainable with standard SfM pipelines. These point clouds seed the Gaussian splatting process to generate photorealistic undercarriage models that render in real-time. Our experiments and ablation studies demonstrate that our design choices are essential to achieve state-of-the-art quality.]]></description>
<pubDate>Tue, 20 Jan 2026 18:13:03 +0000</pubDate>
</item>
<item>
<title><![CDATA[Copy-Trasform-Paste: Zero-Shot Object-Object Alignment Guided by Vision-Language and Geometric Constraints]]></title>
<link>http://arxiv.org/abs/2601.14207v1</link>
<guid>2601.14207v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.GR, cs.CV
Authors: Rotem Gatenyo, Ohad Fried
Institution: 
Published: 2026-01-20
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

We study zero-shot 3D alignment of two given meshes, using a text prompt describing their spatial relation -- an essential capability for content creation and scene assembly. Earlier approaches primarily rely on geometric alignment procedures, while recent work leverages pretrained 2D diffusion models to model language-conditioned object-object spatial relationships. In contrast, we directly optimize the relative pose at test time, updating translation, rotation, and isotropic scale with CLIP-driven gradients via a differentiable renderer, without training a new model. Our framework augments language supervision with geometry-aware objectives: a variant of soft-Iterative Closest Point (ICP) term to encourage surface attachment and a penetration loss to discourage interpenetration. A phased schedule strengthens contact constraints over time, and camera control concentrates the optimization on the interaction region. To enable evaluation, we curate a benchmark containing diverse categories and relations, and compare against baselines. Our method outperforms all alternatives, yielding semantically faithful and physically plausible alignments.]]></description>
<pubDate>Tue, 20 Jan 2026 18:12:55 +0000</pubDate>
</item>
<item>
<title><![CDATA[Differentiated Pickup Point Offering for Emission Reduction in Last-Mile Delivery]]></title>
<link>http://arxiv.org/abs/2601.14196v1</link>
<guid>2601.14196v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.LG
Authors: Albina Galiullina, Wouter van Heeswijk, Tom van Woensel
Institution: 
Published: 2026-01-20
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Pickup points are widely recognized as a sustainable alternative to home delivery, as consolidating orders at pickup locations can shorten delivery routes and improve first-attempt success rates. However, these benefits may be negated when customers drive to pick up their orders. This study proposes a Differentiated Pickup Point Offering (DPO) policy that aims to jointly reduce emissions from delivery truck routes and customer travel. Under DPO, each arriving customer is offered a single recommended pickup point, rather than an unrestricted choice among all locations, while retaining the option of home delivery. We study this problem in a dynamic and stochastic setting, where the pickup point offered to each customer depends on previously realized customer locations and delivery choices. To design effective DPO policies, we adopt a reinforcement learning-based approach that accounts for spatial relationships between customers and pickup points and their implications for future route consolidation. Computational experiments show that differentiated pickup point offerings can substantially reduce total carbon emissions. The proposed policies reduce total emissions by up to 9% relative to home-only delivery and by 2% on average compared with alternative policies, including unrestricted pickup point choice and nearest pickup point assignment. Differentiated offerings are particularly effective in dense urban settings with many pickup points and short inter-location distances. Moreover, explicitly accounting for the dynamic nature of customer arrivals and choices is especially important when customers are less inclined to choose pickup point delivery over home delivery.]]></description>
<pubDate>Tue, 20 Jan 2026 18:00:42 +0000</pubDate>
</item>
<item>
<title><![CDATA[IIR-VLM: In-Context Instance-level Recognition for Large Vision-Language Models]]></title>
<link>http://arxiv.org/abs/2601.14188v1</link>
<guid>2601.14188v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.CV
Authors: Liang Shi, Wei Li, Kevin M Beussman, Lin Chen, Yun Fu
Institution: 
Published: 2026-01-20
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Instance-level recognition (ILR) concerns distinguishing individual instances from one another, with person re-identification as a prominent example. Despite the impressive visual perception capabilities of modern VLMs, we find their performance on ILR unsatisfactory, often dramatically underperforming domain-specific ILR models. This limitation hinders many practical application of VLMs, e.g. where recognizing familiar people and objects is crucial for effective visual understanding. Existing solutions typically learn to recognize instances one at a time using instance-specific datasets, which not only incur substantial data collection and training costs but also struggle with fine-grained discrimination. In this work, we propose IIR-VLM, a VLM enhanced for In-context Instance-level Recognition. We integrate pre-trained ILR expert models as auxiliary visual encoders to provide specialized features for learning diverse instances, which enables VLMs to learn new instances in-context in a one-shot manner. Further, IIR-VLM leverages this knowledge for instance-aware visual understanding. We validate IIR-VLM's efficacy on existing instance personalization benchmarks. Finally, we demonstrate its superior ILR performance on a challenging new benchmark, which assesses ILR capabilities across varying difficulty and diverse categories, with person, face, pet and general objects as the instances at task.]]></description>
<pubDate>Tue, 20 Jan 2026 17:45:24 +0000</pubDate>
</item>
<item>
<title><![CDATA[Progressive self-supervised blind-spot denoising method for LDCT denoising]]></title>
<link>http://arxiv.org/abs/2601.14180v1</link>
<guid>2601.14180v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.CV
Authors: Yichao Liu, Yueyang Teng, Junwen Guo
Institution: 
Published: 2026-01-20
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Self-supervised learning is increasingly investigated for low-dose computed tomography (LDCT) image denoising, as it alleviates the dependence on paired normal-dose CT (NDCT) data, which are often difficult to acquire in clinical practice. In this paper, we propose a novel self-supervised training strategy that relies exclusively on LDCT images. We introduce a step-wise blind-spot denoising mechanism that enforces conditional independence in a progressive manner, enabling more fine-grained denoising learning. In addition, we add Gaussian noise to LDCT images, which acts as a regularization and mitigates overfitting. Extensive experiments on the Mayo LDCT dataset demonstrate that the proposed method consistently outperforms existing self-supervised approaches and achieves performance comparable to, or better than, several representative supervised denoising methods.]]></description>
<pubDate>Tue, 20 Jan 2026 17:35:02 +0000</pubDate>
</item>
<item>
<title><![CDATA[A model of errors in transformers]]></title>
<link>http://arxiv.org/abs/2601.14175v1</link>
<guid>2601.14175v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.LG, cs.AI, cs.CL
Authors: Suvrat Raju, Praneeth Netrapalli
Institution: 
Published: 2026-01-20
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

We study the error rate of LLMs on tasks like arithmetic that require a deterministic output, and repetitive processing of tokens drawn from a small set of alternatives. We argue that incorrect predictions arise when small errors in the attention mechanism accumulate to cross a threshold, and use this insight to derive a quantitative two-parameter relationship between the accuracy and the complexity of the task. The two parameters vary with the prompt and the model; they can be interpreted in terms of an elementary noise rate, and the number of plausible erroneous tokens that can be predicted. Our analysis is inspired by an ``effective field theory'' perspective: the LLM's many raw parameters can be reorganized into just two parameters that govern the error rate. We perform extensive empirical tests, using Gemini 2.5 Flash, Gemini 2.5 Pro and DeepSeek R1, and find excellent agreement between the predicted and observed accuracy for a variety of tasks, although we also identify deviations in some cases. Our model provides an alternative to suggestions that errors made by LLMs on long repetitive tasks indicate the ``collapse of reasoning'', or an inability to express ``compositional'' functions. Finally, we show how to construct prompts to reduce the error rate.]]></description>
<pubDate>Tue, 20 Jan 2026 17:27:03 +0000</pubDate>
</item>
<item>
<title><![CDATA[Penalizing Localized Dirichlet Energies in Low Rank Tensor Products]]></title>
<link>http://arxiv.org/abs/2601.14173v1</link>
<guid>2601.14173v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.LG, stat.ML
Authors: Paris A. Karakasis, Nicholas D. Sidiropoulos
Institution: 
Published: 2026-01-20
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

We study low-rank tensor-product B-spline (TPBS) models for regression tasks and investigate Dirichlet energy as a measure of smoothness. We show that TPBS models admit a closed-form expression for the Dirichlet energy, and reveal scenarios where perfect interpolation is possible with exponentially small Dirichlet energy. This renders global Dirichlet energy-based regularization ineffective. To address this limitation, we propose a novel regularization strategy based on local Dirichlet energies defined on small hypercubes centered at the training points. Leveraging pretrained TPBS models, we also introduce two estimators for inference from incomplete samples. Comparative experiments with neural networks demonstrate that TPBS models outperform neural networks in the overfitting regime for most datasets, and maintain competitive performance otherwise. Overall, TPBS models exhibit greater robustness to overfitting and consistently benefit from regularization, while neural networks are more sensitive to overfitting and less effective in leveraging regularization.]]></description>
<pubDate>Tue, 20 Jan 2026 17:25:47 +0000</pubDate>
</item>
<item>
<title><![CDATA[Human Values in a Single Sentence: Moral Presence, Hierarchies, and Transformer Ensembles on the Schwartz Continuum]]></title>
<link>http://arxiv.org/abs/2601.14172v1</link>
<guid>2601.14172v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.CL, cs.AI
Authors: Víctor Yeste, Paolo Rosso
Institution: 
Published: 2026-01-20
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

We study sentence-level identification of the 19 values in the Schwartz motivational continuum as a concrete formulation of human value detection in text. The setting - out-of-context sentences from news and political manifestos - features sparse moral cues and severe class imbalance. This combination makes fine-grained sentence-level value detection intrinsically difficult, even for strong modern neural models. We first operationalize a binary moral presence task ("does any value appear?") and show that it is learnable from single sentences (positive-class F1 $\approx$ 0.74 with calibrated thresholds). We then compare a presence-gated hierarchy to a direct multi-label classifier under matched compute, both based on DeBERTa-base and augmented with lightweight signals (prior-sentence context, LIWC-22/eMFD/MJD lexica, and topic features). The hierarchy does not outperform direct prediction, indicating that gate recall limits downstream gains. We also benchmark instruction-tuned LLMs - Gemma 2 9B, Llama 3.1 8B, Mistral 8B, and Qwen 2.5 7B - in zero-/few-shot and QLoRA setups and build simple ensembles; a soft-vote supervised ensemble reaches macro-F1 0.332, significantly surpassing the best single supervised model and exceeding prior English-only baselines. Overall, in this scenario, lightweight signals and small ensembles yield the most reliable improvements, while hierarchical gating offers limited benefit. We argue that, under an 8 GB single-GPU constraint and at the 7-9B scale, carefully tuned supervised encoders remain a strong and compute-efficient baseline for structured human value detection, and we outline how richer value structure and sentence-in-document context could further improve performance.]]></description>
<pubDate>Tue, 20 Jan 2026 17:25:33 +0000</pubDate>
</item>
<item>
<title><![CDATA[Paper2Rebuttal: A Multi-Agent Framework for Transparent Author Response Assistance]]></title>
<link>http://arxiv.org/abs/2601.14171v1</link>
<guid>2601.14171v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.AI
Authors: Qianli Ma, Chang Guo, Zhiheng Tian, Siyu Wang, Jipeng Xiao et al.
Institution: 
Published: 2026-01-20
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Writing effective rebuttals is a high-stakes task that demands more than linguistic fluency, as it requires precise alignment between reviewer intent and manuscript details. Current solutions typically treat this as a direct-to-text generation problem, suffering from hallucination, overlooked critiques, and a lack of verifiable grounding. To address these limitations, we introduce $\textbf{RebuttalAgent}$, the first multi-agents framework that reframes rebuttal generation as an evidence-centric planning task. Our system decomposes complex feedback into atomic concerns and dynamically constructs hybrid contexts by synthesizing compressed summaries with high-fidelity text while integrating an autonomous and on-demand external search module to resolve concerns requiring outside literature. By generating an inspectable response plan before drafting, $\textbf{RebuttalAgent}$ ensures that every argument is explicitly anchored in internal or external evidence. We validate our approach on the proposed $\textbf{RebuttalBench}$ and demonstrate that our pipeline outperforms strong baselines in coverage, faithfulness, and strategic coherence, offering a transparent and controllable assistant for the peer review process. Code will be released.]]></description>
<pubDate>Tue, 20 Jan 2026 17:23:51 +0000</pubDate>
</item>
<item>
<title><![CDATA[ASBA: A-line State Space Model and B-line Attention for Sparse Optical Doppler Tomography Reconstruction]]></title>
<link>http://arxiv.org/abs/2601.14165v1</link>
<guid>2601.14165v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.CV
Authors: Zhenghong Li, Wensheng Cheng, Congwu Du, Yingtian Pan, Zhaozheng Yin et al.
Institution: 
Published: 2026-01-20
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Optical Doppler Tomography (ODT) is an emerging blood flow analysis technique. A 2D ODT image (B-scan) is generated by sequentially acquiring 1D depth-resolved raw A-scans (A-line) along the lateral axis (B-line), followed by Doppler phase-subtraction analysis. To ensure high-fidelity B-scan images, current practices rely on dense sampling, which prolongs scanning time, increases storage demands, and limits the capture of rapid blood flow dynamics. Recent studies have explored sparse sampling of raw A-scans to alleviate these limitations, but their effectiveness is hindered by the conservative sampling rates and the uniform modeling of flow and background signals. In this study, we introduce a novel blood flow-aware network, named ASBA (A-line ROI State space model and B-line phase Attention), to reconstruct ODT images from highly sparsely sampled raw A-scans. Specifically, we propose an A-line ROI state space model to extract sparsely distributed flow features along the A-line, and a B-line phase attention to capture long-range flow signals along each B-line based on phase difference. Moreover, we introduce a flow-aware weighted loss function that encourages the network to prioritize the accurate reconstruction of flow signals. Extensive experiments on real animal data demonstrate that the proposed approach clearly outperforms existing state-of-the-art reconstruction methods.]]></description>
<pubDate>Tue, 20 Jan 2026 17:17:02 +0000</pubDate>
</item>
<item>
<title><![CDATA[One-Shot Refiner: Boosting Feed-forward Novel View Synthesis via One-Step Diffusion]]></title>
<link>http://arxiv.org/abs/2601.14161v1</link>
<guid>2601.14161v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.CV
Authors: Yitong Dong, Qi Zhang, Minchao Jiang, Zhiqiang Wu, Qingnan Fan et al.
Institution: 
Published: 2026-01-20
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

We present a novel framework for high-fidelity novel view synthesis (NVS) from sparse images, addressing key limitations in recent feed-forward 3D Gaussian Splatting (3DGS) methods built on Vision Transformer (ViT) backbones. While ViT-based pipelines offer strong geometric priors, they are often constrained by low-resolution inputs due to computational costs. Moreover, existing generative enhancement methods tend to be 3D-agnostic, resulting in inconsistent structures across views, especially in unseen regions. To overcome these challenges, we design a Dual-Domain Detail Perception Module, which enables handling high-resolution images without being limited by the ViT backbone, and endows Gaussians with additional features to store high-frequency details. We develop a feature-guided diffusion network, which can preserve high-frequency details during the restoration process. We introduce a unified training strategy that enables joint optimization of the ViT-based geometric backbone and the diffusion-based refinement module. Experiments demonstrate that our method can maintain superior generation quality across multiple datasets.]]></description>
<pubDate>Tue, 20 Jan 2026 17:11:55 +0000</pubDate>
</item>
<item>
<title><![CDATA[Domain-Adaptation through Synthetic Data: Fine-Tuning Large Language Models for German Law]]></title>
<link>http://arxiv.org/abs/2601.14160v1</link>
<guid>2601.14160v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.CL, cs.AI
Authors: Ali Hamza Bashir, Muhammad Rehan Khalid, Kostadin Cvejoski, Jana Birr, Jule Berghaus et al.
Institution: 
Published: 2026-01-20
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Large language models (LLMs) often struggle in specialized domains such as legal reasoning due to limited expert knowledge, resulting in factually incorrect outputs or hallucinations. This paper presents an effective method for adapting advanced LLMs to German legal question answering through a novel synthetic data generation approach. In contrast to costly human-annotated resources or unreliable synthetic alternatives, our approach systematically produces high-quality, diverse, and legally accurate question-answer pairs directly from authoritative German statutes. Using rigorous automated filtering methods and parameter-efficient fine-tuning techniques, we demonstrate that LLMs adapted with our synthetic dataset significantly outperform their baseline counterparts on German legal question answering tasks. Our results highlight the feasibility of using carefully designed synthetic data as a robust alternative to manual annotation in high-stakes, knowledge-intensive domains.]]></description>
<pubDate>Tue, 20 Jan 2026 17:11:51 +0000</pubDate>
</item>
<item>
<title><![CDATA[ConceptCaps -- a Distilled Concept Dataset for Interpretability in Music Models]]></title>
<link>http://arxiv.org/abs/2601.14157v1</link>
<guid>2601.14157v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.SD, cs.AI, cs.LG
Authors: Bruno Sienkiewicz, Łukasz Neumann, Mateusz Modrzejewski
Institution: 
Published: 2026-01-20
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Concept-based interpretability methods like TCAV require clean, well-separated positive and negative examples for each concept. Existing music datasets lack this structure: tags are sparse, noisy, or ill-defined. We introduce ConceptCaps, a dataset of 23k music-caption-audio triplets with explicit labels from a 200-attribute taxonomy. Our pipeline separates semantic modeling from text generation: a VAE learns plausible attribute co-occurrence patterns, a fine-tuned LLM converts attribute lists into professional descriptions, and MusicGen synthesizes corresponding audio. This separation improves coherence and controllability over end-to-end approaches. We validate the dataset through audio-text alignment (CLAP), linguistic quality metrics (BERTScore, MAUVE), and TCAV analysis confirming that concept probes recover musically meaningful patterns. Dataset and code are available online.]]></description>
<pubDate>Tue, 20 Jan 2026 17:04:08 +0000</pubDate>
</item>
<item>
<title><![CDATA[LLM Augmented Intervenable Multimodal Adaptor for Post-operative Complication Prediction in Lung Cancer Surgery]]></title>
<link>http://arxiv.org/abs/2601.14154v1</link>
<guid>2601.14154v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.CV, cs.AI
Authors: Shubham Pandey, Bhavin Jawade, Srirangaraj Setlur, Venu Govindaraju, Kenneth Seastedt
Institution: 
Published: 2026-01-20
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Postoperative complications remain a critical concern in clinical practice, adversely affecting patient outcomes and contributing to rising healthcare costs. We present MIRACLE, a deep learning architecture for prediction of risk of postoperative complications in lung cancer surgery by integrating preoperative clinical and radiological data. MIRACLE employs a hyperspherical embedding space fusion of heterogeneous inputs, enabling the extraction of robust, discriminative features from both structured clinical records and high-dimensional radiological images. To enhance transparency of prediction and clinical utility, we incorporate an interventional deep learning module in MIRACLE, that not only refines predictions but also provides interpretable and actionable insights, allowing domain experts to interactively adjust recommendations based on clinical expertise. We validate our approach on POC-L, a real-world dataset comprising 3,094 lung cancer patients who underwent surgery at Roswell Park Comprehensive Cancer Center. Our results demonstrate that MIRACLE outperforms various traditional machine learning models and contemporary large language models (LLM) variants alone, for personalized and explainable postoperative risk management.]]></description>
<pubDate>Tue, 20 Jan 2026 16:58:12 +0000</pubDate>
</item>
<item>
<title><![CDATA[Lost in the Prompt Order: Revealing the Limitations of Causal Attention in Language Models]]></title>
<link>http://arxiv.org/abs/2601.14152v1</link>
<guid>2601.14152v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.CL, cs.AI, cs.LG
Authors: Hyunjong Ok, Jaeho Lee
Institution: 
Published: 2026-01-20
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Large language models exhibit surprising sensitivity to the structure of the prompt, but the mechanisms underlying this sensitivity remain poorly understood. In this work, we conduct an in-depth investigation on a striking case: in multiple-choice question answering, placing context before the questions and options (CQO) outperforms the reverse order (QOC) by over 14%p, consistently over a wide range of models and datasets. Through systematic architectural analysis, we identify causal attention as the core mechanism: in QOC prompts, the causal mask prevents option tokens from attending to context, creating an information bottleneck where context becomes invisible to options.]]></description>
<pubDate>Tue, 20 Jan 2026 16:54:22 +0000</pubDate>
</item>
<item>
<title><![CDATA[TwinBrainVLA: Unleashing the Potential of Generalist VLMs for Embodied Tasks via Asymmetric Mixture-of-Transformers]]></title>
<link>http://arxiv.org/abs/2601.14133v1</link>
<guid>2601.14133v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.RO, cs.CV
Authors: Bin Yu, Shijie Lian, Xiaopeng Lin, Yuliang Wei, Zhaolong Shen et al.
Institution: 
Published: 2026-01-20
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Standard Vision-Language-Action (VLA) models typically fine-tune a monolithic Vision-Language Model (VLM) backbone explicitly for robotic control. However, this approach creates a critical tension between maintaining high-level general semantic understanding and learning low-level, fine-grained sensorimotor skills, often leading to "catastrophic forgetting" of the model's open-world capabilities. To resolve this conflict, we introduce TwinBrainVLA, a novel architecture that coordinates a generalist VLM retaining universal semantic understanding and a specialist VLM dedicated to embodied proprioception for joint robotic control. TwinBrainVLA synergizes a frozen "Left Brain", which retains robust general visual reasoning, with a trainable "Right Brain", specialized for embodied perception, via a novel Asymmetric Mixture-of-Transformers (AsyMoT) mechanism. This design allows the Right Brain to dynamically query semantic knowledge from the frozen Left Brain and fuse it with proprioceptive states, providing rich conditioning for a Flow-Matching Action Expert to generate precise continuous controls. Extensive experiments on SimplerEnv and RoboCasa benchmarks demonstrate that TwinBrainVLA achieves superior manipulation performance compared to state-of-the-art baselines while explicitly preserving the comprehensive visual understanding capabilities of the pre-trained VLM, offering a promising direction for building general-purpose robots that simultaneously achieve high-level semantic understanding and low-level physical dexterity.]]></description>
<pubDate>Tue, 20 Jan 2026 16:30:07 +0000</pubDate>
</item>
<item>
<title><![CDATA[GIC-DLC: Differentiable Logic Circuits for Hardware-Friendly Grayscale Image Compression]]></title>
<link>http://arxiv.org/abs/2601.14130v1</link>
<guid>2601.14130v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.CV
Authors: Till Aczel, David F. Jenny, Simon Bührer, Andreas Plesner, Antonio Di Maio et al.
Institution: 
Published: 2026-01-20
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Neural image codecs achieve higher compression ratios than traditional hand-crafted methods such as PNG or JPEG-XL, but often incur substantial computational overhead, limiting their deployment on energy-constrained devices such as smartphones, cameras, and drones. We propose Grayscale Image Compression with Differentiable Logic Circuits (GIC-DLC), a hardware-aware codec where we train lookup tables to combine the flexibility of neural networks with the efficiency of Boolean operations. Experiments on grayscale benchmark datasets show that GIC-DLC outperforms traditional codecs in compression efficiency while allowing substantial reductions in energy consumption and latency. These results demonstrate that learned compression can be hardware-friendly, offering a promising direction for low-power image compression on edge devices.]]></description>
<pubDate>Tue, 20 Jan 2026 16:29:23 +0000</pubDate>
</item>
<item>
<title><![CDATA[The Side Effects of Being Smart: Safety Risks in MLLMs' Multi-Image Reasoning]]></title>
<link>http://arxiv.org/abs/2601.14127v1</link>
<guid>2601.14127v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.CV, cs.CL
Authors: Renmiao Chen, Yida Lu, Shiyao Cui, Xuan Ouyang, Victor Shea-Jay Huang et al.
Institution: 
Published: 2026-01-20
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

As Multimodal Large Language Models (MLLMs) acquire stronger reasoning capabilities to handle complex, multi-image instructions, this advancement may pose new safety risks. We study this problem by introducing MIR-SafetyBench, the first benchmark focused on multi-image reasoning safety, which consists of 2,676 instances across a taxonomy of 9 multi-image relations. Our extensive evaluations on 19 MLLMs reveal a troubling trend: models with more advanced multi-image reasoning can be more vulnerable on MIR-SafetyBench. Beyond attack success rates, we find that many responses labeled as safe are superficial, often driven by misunderstanding or evasive, non-committal replies. We further observe that unsafe generations exhibit lower attention entropy than safe ones on average. This internal signature suggests a possible risk that models may over-focus on task solving while neglecting safety constraints. Our code and data are available at https://github.com/thu-coai/MIR-SafetyBench.]]></description>
<pubDate>Tue, 20 Jan 2026 16:24:18 +0000</pubDate>
</item>
<item>
<title><![CDATA[Style Transfer as Bias Mitigation: Diffusion Models for Synthetic Mental Health Text for Arabic]]></title>
<link>http://arxiv.org/abs/2601.14124v1</link>
<guid>2601.14124v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.CL, cs.AI
Authors: Saad Mankarious, Aya Zirikly
Institution: 
Published: 2026-01-20
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Synthetic data offers a promising solution for mitigating data scarcity and demographic bias in mental health analysis, yet existing approaches largely rely on pretrained large language models (LLMs), which may suffer from limited output diversity and propagate biases inherited from their training data. In this work, we propose a pretraining-free diffusion-based approach for synthetic text generation that frames bias mitigation as a style transfer problem. Using the CARMA Arabic mental health corpus, which exhibits a substantial gender imbalance, we focus on male-to-female style transfer to augment underrepresented female-authored content. We construct five datasets capturing varying linguistic and semantic aspects of gender expression in Arabic and train separate diffusion models for each setting. Quantitative evaluations demonstrate consistently high semantic fidelity between source and generated text, alongside meaningful surface-level stylistic divergence, while qualitative analysis confirms linguistically plausible gender transformations. Our results show that diffusion-based style transfer can generate high-entropy, semantically faithful synthetic data without reliance on pretrained LLMs, providing an effective and flexible framework for mitigating gender bias in sensitive, low-resource mental health domains.]]></description>
<pubDate>Tue, 20 Jan 2026 16:21:41 +0000</pubDate>
</item>
<item>
<title><![CDATA[A Systematic Analysis of Chunking Strategies for Reliable Question Answering]]></title>
<link>http://arxiv.org/abs/2601.14123v1</link>
<guid>2601.14123v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.CL, cs.IR
Authors: Sofia Bennani, Charles Moslonka
Institution: 
Published: 2026-01-20
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

We study how document chunking choices impact the reliability of Retrieval-Augmented Generation (RAG) systems in industry. While practice often relies on heuristics, our end-to-end evaluation on Natural Questions systematically varies chunking method (token, sentence, semantic, code), chunk size, overlap, and context length. We use a standard industrial setup: SPLADE retrieval and a Mistral-8B generator. We derive actionable lessons for cost-efficient deployment: (i) overlap provides no measurable benefit and increases indexing cost; (ii) sentence chunking is the most cost-effective method, matching semantic chunking up to ~5k tokens; (iii) a "context cliff" reduces quality beyond ~2.5k tokens; and (iv) optimal context depends on the goal (semantic quality peaks at small contexts; exact match at larger ones).]]></description>
<pubDate>Tue, 20 Jan 2026 16:19:58 +0000</pubDate>
</item>
<item>
<title><![CDATA[NewsRECON: News article REtrieval for image CONtextualization]]></title>
<link>http://arxiv.org/abs/2601.14121v1</link>
<guid>2601.14121v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.CL
Authors: Jonathan Tonglet, Iryna Gurevych, Tinne Tuytelaars, Marie-Francine Moens
Institution: 
Published: 2026-01-20
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Identifying when and where a news image was taken is crucial for journalists and forensic experts to produce credible stories and debunk misinformation. While many existing methods rely on reverse image search (RIS) engines, these tools often fail to return results, thereby limiting their practical applicability. In this work, we address the challenging scenario where RIS evidence is unavailable. We introduce NewsRECON, a method that links images to relevant news articles to infer their date and location from article metadata. NewsRECON leverages a corpus of over 90,000 articles and integrates: (1) a bi-encoder for retrieving event-relevant articles; (2) two cross-encoders for reranking articles by location and event consistency. Experiments on the TARA and 5Pils-OOC show that NewsRECON outperforms prior work and can be combined with a multimodal large language model to achieve new SOTA results in the absence of RIS evidence. We make our code available.]]></description>
<pubDate>Tue, 20 Jan 2026 16:15:53 +0000</pubDate>
</item>
<item>
<title><![CDATA[Riemannian Liquid Spatio-Temporal Graph Network]]></title>
<link>http://arxiv.org/abs/2601.14115v1</link>
<guid>2601.14115v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.LG, cs.AI
Authors: Liangsi Lu, Jingchao Wang, Zhaorong Dai, Hanqian Liu, Yang Shi
Institution: 
Published: 2026-01-20
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Liquid Time-Constant networks (LTCs), a type of continuous-time graph neural network, excel at modeling irregularly-sampled dynamics but are fundamentally confined to Euclidean space. This limitation introduces significant geometric distortion when representing real-world graphs with inherent non-Euclidean structures (e.g., hierarchies and cycles), degrading representation quality. To overcome this limitation, we introduce the Riemannian Liquid Spatio-Temporal Graph Network (RLSTG), a framework that unifies continuous-time liquid dynamics with the geometric inductive biases of Riemannian manifolds. RLSTG models graph evolution through an Ordinary Differential Equation (ODE) formulated directly on a curved manifold, enabling it to faithfully capture the intrinsic geometry of both structurally static and dynamic spatio-temporal graphs. Moreover, we provide rigorous theoretical guarantees for RLSTG, extending stability theorems of LTCs to the Riemannian domain and quantifying its expressive power via state trajectory analysis. Extensive experiments on real-world benchmarks demonstrate that, by combining advanced temporal dynamics with a Riemannian spatial representation, RLSTG achieves superior performance on graphs with complex structures. Project Page: https://rlstg.github.io]]></description>
<pubDate>Tue, 20 Jan 2026 16:09:05 +0000</pubDate>
</item>
<item>
<title><![CDATA[Learning to Explain: Supervised Token Attribution from Transformer Attention Patterns]]></title>
<link>http://arxiv.org/abs/2601.14112v1</link>
<guid>2601.14112v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.CL, cs.LG
Authors: George Mihaila
Institution: 
Published: 2026-01-20
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Explainable AI (XAI) has become critical as transformer-based models are deployed in high-stakes applications including healthcare, legal systems, and financial services, where opacity hinders trust and accountability. Transformers self-attention mechanisms have proven valuable for model interpretability, with attention weights successfully used to understand model focus and behavior (Xu et al., 2015); (Wiegreffe and Pinter, 2019). However, existing attention-based explanation methods rely on manually defined aggregation strategies and fixed attribution rules (Abnar and Zuidema, 2020a); (Chefer et al., 2021), while model-agnostic approaches (LIME, SHAP) treat the model as a black box and incur significant computational costs through input perturbation. We introduce Explanation Network (ExpNet), a lightweight neural network that learns an explicit mapping from transformer attention patterns to token-level importance scores. Unlike prior methods, ExpNet discovers optimal attention feature combinations automatically rather than relying on predetermined rules. We evaluate ExpNet in a challenging cross-task setting and benchmark it against a broad spectrum of model-agnostic methods and attention-based techniques spanning four methodological families.]]></description>
<pubDate>Tue, 20 Jan 2026 16:06:34 +0000</pubDate>
</item>
<item>
<title><![CDATA[PMCE: Probabilistic Multi-Granularity Semantics with Caption-Guided Enhancement for Few-Shot Learning]]></title>
<link>http://arxiv.org/abs/2601.14111v1</link>
<guid>2601.14111v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.CV
Authors: Jiaying Wu, Can Gao, Jinglu Hu, Hui Li, Xiaofeng Cao et al.
Institution: 
Published: 2026-01-20
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Few-shot learning aims to identify novel categories from only a handful of labeled samples, where prototypes estimated from scarce data are often biased and generalize poorly. Semantic-based methods alleviate this by introducing coarse class-level information, but they are mostly applied on the support side, leaving query representations unchanged. In this paper, we present PMCE, a Probabilistic few-shot framework that leverages Multi-granularity semantics with Caption-guided Enhancement. PMCE constructs a nonparametric knowledge bank that stores visual statistics for each category as well as CLIP-encoded class name embeddings of the base classes. At meta-test time, the most relevant base classes are retrieved based on the similarities of class name embeddings for each novel category. These statistics are then aggregated into category-specific prior information and fused with the support set prototypes via a simple MAP update. Simultaneously, a frozen BLIP captioner provides label-free instance-level image descriptions, and a lightweight enhancer trained on base classes optimizes both support prototypes and query features under an inductive protocol with a consistency regularization to stabilize noisy captions. Experiments on four benchmarks show that PMCE consistently improves over strong baselines, achieving up to 7.71% absolute gain over the strongest semantic competitor on MiniImageNet in the 1-shot setting. Our code is available at https://anonymous.4open.science/r/PMCE-275D]]></description>
<pubDate>Tue, 20 Jan 2026 16:06:23 +0000</pubDate>
</item>
<item>
<title><![CDATA[Truth with a Twist: The Rhetoric of Persuasion in Professional vs. Community-Authored Fact-Checks]]></title>
<link>http://arxiv.org/abs/2601.14105v1</link>
<guid>2601.14105v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.CL
Authors: Olesya Razuvayevskaya, Kalina Bontcheva
Institution: 
Published: 2026-01-20
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

This study presents the first large-scale comparison of persuasion techniques present in crowd- versus professionally-written debunks. Using extensive datasets from Community Notes (CNs), EUvsDisinfo, and the Database of Known Fakes (DBKF), we quantify the prevalence and types of persuasion techniques across these fact-checking ecosystems. Contrary to prior hypothesis that community-produced debunks rely more heavily on subjective or persuasive wording, we find no evidence that CNs contain a higher average number of persuasion techniques than professional fact-checks. We additionally identify systematic rhetorical differences between CNs and professional debunking efforts, reflecting differences in institutional norms and topical coverage. Finally, we examine how the crowd evaluates persuasive language in CNs and show that, although notes with more persuasive elements receive slightly higher overall helpfulness ratings, crowd raters are effective at penalising the use of particular problematic rhetorical means]]></description>
<pubDate>Tue, 20 Jan 2026 16:04:09 +0000</pubDate>
</item>
<item>
<title><![CDATA[Diffusion-Guided Backdoor Attacks in Real-World Reinforcement Learning]]></title>
<link>http://arxiv.org/abs/2601.14104v1</link>
<guid>2601.14104v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.RO, cs.CV
Authors: Tairan Huang, Qingqing Ye, Yulin Jin, Jiawei Lian, Yi Wang et al.
Institution: 
Published: 2026-01-20
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Backdoor attacks embed hidden malicious behaviors in reinforcement learning (RL) policies and activate them using triggers at test time. Most existing attacks are validated only in simulation, while their effectiveness in real-world robotic systems remains unclear. In physical deployment, safety-constrained control pipelines such as velocity limiting, action smoothing, and collision avoidance suppress abnormal actions, causing strong attenuation of conventional backdoor attacks. We study this previously overlooked problem and propose a diffusion-guided backdoor attack framework (DGBA) for real-world RL. We design small printable visual patch triggers placed on the floor and generate them using a conditional diffusion model that produces diverse patch appearances under real-world visual variations. We treat the robot control stack as a black-box system. We further introduce an advantage-based poisoning strategy that injects triggers only at decision-critical training states. We evaluate our method on a TurtleBot3 mobile robot and demonstrate reliable activation of targeted attacks while preserving normal task performance. Demo videos and code are available in the supplementary material.]]></description>
<pubDate>Tue, 20 Jan 2026 16:03:51 +0000</pubDate>
</item>
<item>
<title><![CDATA[Interp3D: Correspondence-aware Interpolation for Generative Textured 3D Morphing]]></title>
<link>http://arxiv.org/abs/2601.14103v1</link>
<guid>2601.14103v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.CV
Authors: Xiaolu Liu, Yicong Li, Qiyuan He, Jiayin Zhu, Wei Ji et al.
Institution: 
Published: 2026-01-20
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Textured 3D morphing seeks to generate smooth and plausible transitions between two 3D assets, preserving both structural coherence and fine-grained appearance. This ability is crucial not only for advancing 3D generation research but also for practical applications in animation, editing, and digital content creation. Existing approaches either operate directly on geometry, limiting them to shape-only morphing while neglecting textures, or extend 2D interpolation strategies into 3D, which often causes semantic ambiguity, structural misalignment, and texture blurring. These challenges underscore the necessity to jointly preserve geometric consistency, texture alignment, and robustness throughout the transition process. To address this, we propose Interp3D, a novel training-free framework for textured 3D morphing. It harnesses generative priors and adopts a progressive alignment principle to ensure both geometric fidelity and texture coherence. Starting from semantically aligned interpolation in condition space, Interp3D enforces structural consistency via SLAT (Structured Latent)-guided structure interpolation, and finally transfers appearance details through fine-grained texture fusion. For comprehensive evaluations, we construct a dedicated dataset, Interp3DData, with graded difficulty levels and assess generation results from fidelity, transition smoothness, and plausibility. Both quantitative metrics and human studies demonstrate the significant advantages of our proposed approach over previous methods. Source code is available at https://github.com/xiaolul2/Interp3D.]]></description>
<pubDate>Tue, 20 Jan 2026 16:03:22 +0000</pubDate>
</item>
<item>
<title><![CDATA[Curriculum-Based Strategies for Efficient Cross-Domain Action Recognition]]></title>
<link>http://arxiv.org/abs/2601.14101v1</link>
<guid>2601.14101v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.CV
Authors: Emily Kim, Allen Wu, Jessica Hodgins
Institution: 
Published: 2026-01-20
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Despite significant progress in human action recognition, generalizing to diverse viewpoints remains a challenge. Most existing datasets are captured from ground-level perspectives, and models trained on them often struggle to transfer to drastically different domains such as aerial views. This paper examines how curriculum-based training strategies can improve generalization to unseen real aerial-view data without using any real aerial data during training.
  We explore curriculum learning for cross-view action recognition using two out-of-domain sources: synthetic aerial-view data and real ground-view data. Our results on the evaluation on order of training (fine-tuning on synthetic aerial data vs. real ground data) shows that fine-tuning on real ground data but differ in how they transition from synthetic to real. The first uses a two-stage curriculum with direct fine-tuning, while the second applies a progressive curriculum that expands the dataset in multiple stages before fine-tuning. We evaluate both methods on the REMAG dataset using SlowFast (CNN-based) and MViTv2 (Transformer-based) architectures.
  Results show that combining the two out-of-domain datasets clearly outperforms training on a single domain, whether real ground-view or synthetic aerial-view. Both curriculum strategies match the top-1 accuracy of simple dataset combination while offering efficiency gains. With the two-step fine-tuning method, SlowFast achieves up to a 37% reduction in iterations and MViTv2 up to a 30% reduction compared to simple combination. The multi-step progressive approach further reduces iterations, by up to 9% for SlowFast and 30% for MViTv2, relative to the two-step method. These findings demonstrate that curriculum-based training can maintain comparable performance (top-1 accuracy within 3% range) while improving training efficiency in cross-view action recognition.]]></description>
<pubDate>Tue, 20 Jan 2026 16:01:57 +0000</pubDate>
</item>
<item>
<title><![CDATA[Causal feature selection framework for stable soft sensor modeling based on time-delayed cross mapping]]></title>
<link>http://arxiv.org/abs/2601.14099v1</link>
<guid>2601.14099v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.LG, cs.AI
Authors: Shi-Shun Chen, Xiao-Yang Li, Enrico Zio
Institution: 
Published: 2026-01-20
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Soft sensor modeling plays a crucial role in process monitoring. Causal feature selection can enhance the performance of soft sensor models in industrial applications. However, existing methods ignore two critical characteristics of industrial processes. Firstly, causal relationships between variables always involve time delays, whereas most causal feature selection methods investigate causal relationships in the same time dimension. Secondly, variables in industrial processes are often interdependent, which contradicts the decorrelation assumption of traditional causal inference methods. Consequently, soft sensor models based on existing causal feature selection approaches often lack sufficient accuracy and stability. To overcome these challenges, this paper proposes a causal feature selection framework based on time-delayed cross mapping. Time-delayed cross mapping employs state space reconstruction to effectively handle interdependent variables in causality analysis, and considers varying causal strength across time delay. Time-delayed convergent cross mapping (TDCCM) is introduced for total causal inference, and time-delayed partial cross mapping (TDPCM) is developed for direct causal inference. Then, in order to achieve automatic feature selection, an objective feature selection strategy is presented. The causal threshold is automatically determined based on the model performance on the validation set, and the causal features are then selected. Two real-world case studies show that TDCCM achieves the highest average performance, while TDPCM improves soft sensor stability and performance in the worst scenario. The code is publicly available at https://github.com/dirge1/TDPCM.]]></description>
<pubDate>Tue, 20 Jan 2026 15:58:51 +0000</pubDate>
</item>
<item>
<title><![CDATA[Remapping and navigation of an embedding space via error minimization: a fundamental organizational principle of cognition in natural and artificial systems]]></title>
<link>http://arxiv.org/abs/2601.14096v1</link>
<guid>2601.14096v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.AI
Authors: Benedikt Hartl, Léo Pio-Lopez, Chris Fields, Michael Levin
Institution: 
Published: 2026-01-20
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

The emerging field of diverse intelligence seeks an integrated view of problem-solving in agents of very different provenance, composition, and substrates. From subcellular chemical networks to swarms of organisms, and across evolved, engineered, and chimeric systems, it is hypothesized that scale-invariant principles of decision-making can be discovered. We propose that cognition in both natural and synthetic systems can be characterized and understood by the interplay between two equally important invariants: (1) the remapping of embedding spaces, and (2) the navigation within these spaces. Biological collectives, from single cells to entire organisms (and beyond), remap transcriptional, morphological, physiological, or 3D spaces to maintain homeostasis and regenerate structure, while navigating these spaces through distributed error correction. Modern Artificial Intelligence (AI) systems, including transformers, diffusion models, and neural cellular automata enact analogous processes by remapping data into latent embeddings and refining them iteratively through contextualization. We argue that this dual principle - remapping and navigation of embedding spaces via iterative error minimization - constitutes a substrate-independent invariant of cognition. Recognizing this shared mechanism not only illuminates deep parallels between living systems and artificial models, but also provides a unifying framework for engineering adaptive intelligence across scales.]]></description>
<pubDate>Tue, 20 Jan 2026 15:57:36 +0000</pubDate>
</item>
<item>
<title><![CDATA[Optimizing Energy and Data Collection in UAV-aided IoT Networks using Attention-based Multi-Objective Reinforcement Learning]]></title>
<link>http://arxiv.org/abs/2601.14092v1</link>
<guid>2601.14092v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.LG, cs.NI
Authors: Babacar Toure, Dimitrios Tsilimantos, Omid Esrafilian, Marios Kountouris
Institution: MIT
Published: 2026-01-20
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Due to their adaptability and mobility, Unmanned Aerial Vehicles (UAVs) are becoming increasingly essential for wireless network services, particularly for data harvesting tasks. In this context, Artificial Intelligence (AI)-based approaches have gained significant attention for addressing UAV path planning tasks in large and complex environments, bridging the gap with real-world deployments. However, many existing algorithms suffer from limited training data, which hampers their performance in highly dynamic environments. Moreover, they often overlook the inherently multi-objective nature of the task, treating it in an overly simplistic manner. To address these limitations, we propose an attention-based Multi-Objective Reinforcement Learning (MORL) architecture that explicitly handles the trade-off between data collection and energy consumption in urban environments, even without prior knowledge of wireless channel conditions. Our method develops a single model capable of adapting to varying trade-off preferences and dynamic scenario parameters without the need for fine-tuning or retraining. Extensive simulations show that our approach achieves substantial improvements in performance, model compactness, sample efficiency, and most importantly, generalization to previously unseen scenarios, outperforming existing RL solutions.]]></description>
<pubDate>Tue, 20 Jan 2026 15:55:11 +0000</pubDate>
</item>
<item>
<title><![CDATA[Zero-shot adaptable task planning for autonomous construction robots: a comparative study of lightweight single and multi-AI agent systems]]></title>
<link>http://arxiv.org/abs/2601.14091v1</link>
<guid>2601.14091v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.RO, cs.AI
Authors: Hossein Naderi, Alireza Shojaei, Lifu Huang, Philip Agee, Kereshmeh Afsari et al.
Institution: 
Published: 2026-01-20
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Robots are expected to play a major role in the future construction industry but face challenges due to high costs and difficulty adapting to dynamic tasks. This study explores the potential of foundation models to enhance the adaptability and generalizability of task planning in construction robots. Four models are proposed and implemented using lightweight, open-source large language models (LLMs) and vision language models (VLMs). These models include one single agent and three multi-agent teams that collaborate to create robot action plans. The models are evaluated across three construction roles: Painter, Safety Inspector, and Floor Tiling. Results show that the four-agent team outperforms the state-of-the-art GPT-4o in most metrics while being ten times more cost-effective. Additionally, teams with three and four agents demonstrate the improved generalizability. By discussing how agent behaviors influence outputs, this study enhances the understanding of AI teams and supports future research in diverse unstructured environments beyond construction.]]></description>
<pubDate>Tue, 20 Jan 2026 15:54:33 +0000</pubDate>
</item>
<item>
<title><![CDATA['1'-bit Count-based Sorting Unit to Reduce Link Power in DNN Accelerators]]></title>
<link>http://arxiv.org/abs/2601.14087v1</link>
<guid>2601.14087v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.AR, cs.AI, cs.LG
Authors: Ruichi Han, Yizhi Chen, Tong Lei, Jordi Altayo Gonzalez, Ahmed Hemani
Institution: 
Published: 2026-01-20
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Interconnect power consumption remains a bottleneck in Deep Neural Network (DNN) accelerators. While ordering data based on '1'-bit counts can mitigate this via reduced switching activity, practical hardware sorting implementations remain underexplored. This work proposes the hardware implementation of a comparison-free sorting unit optimized for Convolutional Neural Networks (CNN). By leveraging approximate computing to group population counts into coarse-grained buckets, our design achieves hardware area reductions while preserving the link power benefits of data reordering. Our approximate sorting unit achieves up to 35.4% area reduction while maintaining 19.50\% BT reduction compared to 20.42% of precise implementation.]]></description>
<pubDate>Tue, 20 Jan 2026 15:47:36 +0000</pubDate>
</item>
<item>
<title><![CDATA[Two-Stream temporal transformer for video action classification]]></title>
<link>http://arxiv.org/abs/2601.14086v1</link>
<guid>2601.14086v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.CV, cs.AI, cs.LG
Authors: Nattapong Kurpukdee, Adrian G. Bors
Institution: 
Published: 2026-01-20
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Motion representation plays an important role in video understanding and has many applications including action recognition, robot and autonomous guidance or others. Lately, transformer networks, through their self-attention mechanism capabilities, have proved their efficiency in many applications. In this study, we introduce a new two-stream transformer video classifier, which extracts spatio-temporal information from content and optical flow representing movement information. The proposed model identifies self-attention features across the joint optical flow and temporal frame domain and represents their relationships within the transformer encoder mechanism. The experimental results show that our proposed methodology provides excellent classification results on three well-known video datasets of human activities.]]></description>
<pubDate>Tue, 20 Jan 2026 15:47:00 +0000</pubDate>
</item>
<item>
<title><![CDATA[DermaBench: A Clinician-Annotated Benchmark Dataset for Dermatology Visual Question Answering and Reasoning]]></title>
<link>http://arxiv.org/abs/2601.14084v1</link>
<guid>2601.14084v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.CV, cs.AI, cs.CL
Authors: Abdurrahim Yilmaz, Ozan Erdem, Ece Gokyayla, Ayda Acar, Burc Bugra Dagtas et al.
Institution: 
Published: 2026-01-20
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Vision-language models (VLMs) are increasingly important in medical applications; however, their evaluation in dermatology remains limited by datasets that focus primarily on image-level classification tasks such as lesion recognition. While valuable for recognition, such datasets cannot assess the full visual understanding, language grounding, and clinical reasoning capabilities of multimodal models. Visual question answering (VQA) benchmarks are required to evaluate how models interpret dermatological images, reason over fine-grained morphology, and generate clinically meaningful descriptions. We introduce DermaBench, a clinician-annotated dermatology VQA benchmark built on the Diverse Dermatology Images (DDI) dataset. DermaBench comprises 656 clinical images from 570 unique patients spanning Fitzpatrick skin types I-VI. Using a hierarchical annotation schema with 22 main questions (single-choice, multi-choice, and open-ended), expert dermatologists annotated each image for diagnosis, anatomic site, lesion morphology, distribution, surface features, color, and image quality, together with open-ended narrative descriptions and summaries, yielding approximately 14.474 VQA-style annotations. DermaBench is released as a metadata-only dataset to respect upstream licensing and is publicly available at Harvard Dataverse.]]></description>
<pubDate>Tue, 20 Jan 2026 15:44:57 +0000</pubDate>
</item>
<item>
<title><![CDATA[VENI: Variational Encoder for Natural Illumination]]></title>
<link>http://arxiv.org/abs/2601.14079v1</link>
<guid>2601.14079v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.CV
Authors: Paul Walker, James A. D. Gardner, Andreea Ardelean, William A. P. Smith, Bernhard Egger
Institution: MIT
Published: 2026-01-20
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Inverse rendering is an ill-posed problem, but priors like illumination priors, can simplify it. Existing work either disregards the spherical and rotation-equivariant nature of illumination environments or does not provide a well-behaved latent space. We propose a rotation-equivariant variational autoencoder that models natural illumination on the sphere without relying on 2D projections. To preserve the SO(2)-equivariance of environment maps, we use a novel Vector Neuron Vision Transformer (VN-ViT) as encoder and a rotation-equivariant conditional neural field as decoder. In the encoder, we reduce the equivariance from SO(3) to SO(2) using a novel SO(2)-equivariant fully connected layer, an extension of Vector Neurons. We show that our SO(2)-equivariant fully connected layer outperforms standard Vector Neurons when used in our SO(2)-equivariant model. Compared to previous methods, our variational autoencoder enables smoother interpolation in latent space and offers a more well-behaved latent space.]]></description>
<pubDate>Tue, 20 Jan 2026 15:38:02 +0000</pubDate>
</item>
<item>
<title><![CDATA[MooneyMaker: A Python package to create ambiguous two-tone images]]></title>
<link>http://arxiv.org/abs/2601.14077v1</link>
<guid>2601.14077v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.CV
Authors: Lars C. Reining, Thabo Matthies, Luisa Haussner, Rabea Turon, Thomas S. A. Wallis
Institution: 
Published: 2026-01-20
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Mooney images are high-contrast, two-tone visual stimuli, created by thresholding photographic images. They allow researchers to separate image content from image understanding, making them valuable for studying visual perception. An ideal Mooney image for this purpose achieves a specific balance: it initially appears unrecognizable but becomes fully interpretable to the observer after seeing the original template. Researchers traditionally created these stimuli manually using subjective criteria, which is labor-intensive and can introduce inconsistencies across studies. Automated generation techniques now offer an alternative to this manual approach. Here, we present MooneyMaker, an open-source Python package that automates the generation of ambiguous Mooney images using several complementary approaches. Users can choose between various generation techniques that range from approaches based on image statistics to deep learning models. These models strategically alter edge information to increase initial ambiguity. The package lets users create two-tone images with multiple methods and directly compare the results visually. In an experiment, we validate MooneyMaker by generating Mooney images using different techniques and assess their recognizability for human observers before and after disambiguating them by presenting the template images. Our results reveal that techniques with lower initial recognizability are associated with higher post-template recognition (i.e. a larger disambiguation effect). To help vision scientists build effective databases of Mooney stimuli, we provide practical guidelines for technique selection. By standardizing the generation process, MooneyMaker supports more consistent and reproducible visual perception research.]]></description>
<pubDate>Tue, 20 Jan 2026 15:37:15 +0000</pubDate>
</item>
<item>
<title><![CDATA[Unsupervised Video Class-Incremental Learning via Deep Embedded Clustering Management]]></title>
<link>http://arxiv.org/abs/2601.14069v1</link>
<guid>2601.14069v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.CV, cs.AI, cs.LG
Authors: Nattapong Kurpukdee, Adrian G. Bors
Institution: 
Published: 2026-01-20
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Unsupervised video class incremental learning (uVCIL) represents an important learning paradigm for learning video information without forgetting, and without considering any data labels. Prior approaches have focused on supervised class-incremental learning, relying on using the knowledge of labels and task boundaries, which is costly, requires human annotation, or is simply not a realistic option. In this paper, we propose a simple yet effective approach to address the uVCIL. We first consider a deep feature extractor network, providing a set of representative video features during each task without assuming any class or task information. We then progressively build a series of deep clusters from the extracted features. During the successive task learning, the model updated from the previous task is used as an initial state in order to transfer knowledge to the current learning task. We perform in-depth evaluations on three standard video action recognition datasets, including UCF101, HMDB51, and Something-to-Something V2, by ignoring the labels from the supervised setting. Our approach significantly outperforms other baselines on all datasets.]]></description>
<pubDate>Tue, 20 Jan 2026 15:25:41 +0000</pubDate>
</item>
<item>
<title><![CDATA[VERIDAH: Solving Enumeration Anomaly Aware Vertebra Labeling across Imaging Sequences]]></title>
<link>http://arxiv.org/abs/2601.14066v1</link>
<guid>2601.14066v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.CV
Authors: Hendrik Möller, Hanna Schoen, Robert Graf, Matan Atad, Nathan Molinier et al.
Institution: 
Published: 2026-01-20
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

The human spine commonly consists of seven cervical, twelve thoracic, and five lumbar vertebrae. However, enumeration anomalies may result in individuals having eleven or thirteen thoracic vertebrae and four or six lumbar vertebrae. Although the identification of enumeration anomalies has potential clinical implications for chronic back pain and operation planning, the thoracolumbar junction is often poorly assessed and rarely described in clinical reports. Additionally, even though multiple deep-learning-based vertebra labeling algorithms exist, there is a lack of methods to automatically label enumeration anomalies. Our work closes that gap by introducing "Vertebra Identification with Anomaly Handling" (VERIDAH), a novel vertebra labeling algorithm based on multiple classification heads combined with a weighted vertebra sequence prediction algorithm. We show that our approach surpasses existing models on T2w TSE sagittal (98.30% vs. 94.24% of subjects with all vertebrae correctly labeled, p < 0.001) and CT imaging (99.18% vs. 77.26% of subjects with all vertebrae correctly labeled, p < 0.001) and works in arbitrary field-of-view images. VERIDAH correctly labeled the presence 2 Möller et al. of thoracic enumeration anomalies in 87.80% and 96.30% of T2w and CT images, respectively, and lumbar enumeration anomalies in 94.48% and 97.22% for T2w and CT, respectively. Our code and models are available at: https://github.com/Hendrik-code/spineps.]]></description>
<pubDate>Tue, 20 Jan 2026 15:22:59 +0000</pubDate>
</item>
<item>
<title><![CDATA[XCR-Bench: A Multi-Task Benchmark for Evaluating Cultural Reasoning in LLMs]]></title>
<link>http://arxiv.org/abs/2601.14063v1</link>
<guid>2601.14063v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.CL, cs.AI, cs.CY
Authors: Mohsinul Kabir, Tasnim Ahmed, Md Mezbaur Rahman, Shaoxiong Ji, Hassan Alhuzali et al.
Institution: 
Published: 2026-01-20
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Cross-cultural competence in large language models (LLMs) requires the ability to identify Culture-Specific Items (CSIs) and to adapt them appropriately across cultural contexts. Progress in evaluating this capability has been constrained by the scarcity of high-quality CSI-annotated corpora with parallel cross-cultural sentence pairs. To address this limitation, we introduce XCR-Bench, a Cross(X)-Cultural Reasoning Benchmark consisting of 4.9k parallel sentences and 1,098 unique CSIs, spanning three distinct reasoning tasks with corresponding evaluation metrics. Our corpus integrates Newmark's CSI framework with Hall's Triad of Culture, enabling systematic analysis of cultural reasoning beyond surface-level artifacts and into semi-visible and invisible cultural elements such as social norms, beliefs, and values. Our findings show that state-of-the-art LLMs exhibit consistent weaknesses in identifying and adapting CSIs related to social etiquette and cultural reference. Additionally, we find evidence that LLMs encode regional and ethno-religious biases even within a single linguistic setting during cultural adaptation. We release our corpus and code to facilitate future research on cross-cultural NLP.]]></description>
<pubDate>Tue, 20 Jan 2026 15:21:18 +0000</pubDate>
</item>
<item>
<title><![CDATA[Demystifying the trend of the healthcare index: Is historical price a key driver?]]></title>
<link>http://arxiv.org/abs/2601.14062v1</link>
<guid>2601.14062v1</guid>
<description><![CDATA[Source: arXiv
Tags: stat.AP, stat.ML
Authors: Payel Sadhukhan, Samrat Gupta, Subhasis Ghosh, Tanujit Chakraborty
Institution: 
Published: 2026-01-20
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Healthcare sector indices consolidate the economic health of pharmaceutical, biotechnology, and healthcare service firms. The short-term movements in these indices are closely intertwined with capital allocation decisions affecting research and development investment, drug availability, and long-term health outcomes. This research investigates whether historical open-high-low-close (OHLC) index data contain sufficient information for predicting the directional movement of the opening index on the subsequent trading day. The problem is formulated as a supervised classification task involving a one-step-ahead rolling window. A diverse feature set is constructed, comprising original prices, volatility-based technical indicators, and a novel class of nowcasting features derived from mutual OHLC ratios. The framework is evaluated on data from healthcare indices in the U.S. and Indian markets over a five-year period spanning multiple economic phases, including the COVID-19 pandemic. The results demonstrate robust predictive performance, with accuracy exceeding 0.8 and Matthews correlation coefficients above 0.6. Notably, the proposed nowcasting features have emerged as a key determinant of the market movement. We have employed the Shapley-based explainability paradigm to further elucidate the contribution of the features: outcomes reveal the dominant role of the nowcasting features, followed by a more moderate contribution of original prices. This research offers a societal utility: the proposed features and model for short-term forecasting of healthcare indices can reduce information asymmetry and support a more stable and equitable health economy.]]></description>
<pubDate>Tue, 20 Jan 2026 15:20:59 +0000</pubDate>
</item>
<item>
<title><![CDATA[Fine-Grained Zero-Shot Composed Image Retrieval with Complementary Visual-Semantic Integration]]></title>
<link>http://arxiv.org/abs/2601.14060v1</link>
<guid>2601.14060v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.CV
Authors: Yongcong Ye, Kai Zhang, Yanghai Zhang, Enhong Chen, Longfei Li et al.
Institution: 
Published: 2026-01-20
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Zero-shot composed image retrieval (ZS-CIR) is a rapidly growing area with significant practical applications, allowing users to retrieve a target image by providing a reference image and a relative caption describing the desired modifications. Existing ZS-CIR methods often struggle to capture fine-grained changes and integrate visual and semantic information effectively. They primarily rely on either transforming the multimodal query into a single text using image-to-text models or employing large language models for target image description generation, approaches that often fail to capture complementary visual information and complete semantic context. To address these limitations, we propose a novel Fine-Grained Zero-Shot Composed Image Retrieval method with Complementary Visual-Semantic Integration (CVSI). Specifically, CVSI leverages three key components: (1) Visual Information Extraction, which not only extracts global image features but also uses a pre-trained mapping network to convert the image into a pseudo token, combining it with the modification text and the objects most likely to be added. (2) Semantic Information Extraction, which involves using a pre-trained captioning model to generate multiple captions for the reference image, followed by leveraging an LLM to generate the modified captions and the objects most likely to be added. (3) Complementary Information Retrieval, which integrates information extracted from both the query and database images to retrieve the target image, enabling the system to efficiently handle retrieval queries in a variety of situations. Extensive experiments on three public datasets (e.g., CIRR, CIRCO, and FashionIQ) demonstrate that CVSI significantly outperforms existing state-of-the-art methods. Our code is available at https://github.com/yyc6631/CVSI.]]></description>
<pubDate>Tue, 20 Jan 2026 15:17:14 +0000</pubDate>
</item>
<item>
<title><![CDATA[POCI-Diff: Position Objects Consistently and Interactively with 3D-Layout Guided Diffusion]]></title>
<link>http://arxiv.org/abs/2601.14056v1</link>
<guid>2601.14056v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.CV, cs.AI
Authors: Andrea Rigo, Luca Stornaiuolo, Weijie Wang, Mauro Martino, Bruno Lepri et al.
Institution: 
Published: 2026-01-20
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

We propose a diffusion-based approach for Text-to-Image (T2I) generation with consistent and interactive 3D layout control and editing. While prior methods improve spatial adherence using 2D cues or iterative copy-warp-paste strategies, they often distort object geometry and fail to preserve consistency across edits. To address these limitations, we introduce a framework for Positioning Objects Consistently and Interactively (POCI-Diff), a novel formulation for jointly enforcing 3D geometric constraints and instance-level semantic binding within a unified diffusion process. Our method enables explicit per-object semantic control by binding individual text descriptions to specific 3D bounding boxes through Blended Latent Diffusion, allowing one-shot synthesis of complex multi-object scenes. We further propose a warping-free generative editing pipeline that supports object insertion, removal, and transformation via regeneration rather than pixel deformation. To preserve object identity and consistency across edits, we condition the diffusion process on reference images using IP-Adapter, enabling coherent object appearance throughout interactive 3D editing while maintaining global scene coherence. Experimental results demonstrate that POCI-Diff produces high-quality images consistent with the specified 3D layouts and edits, outperforming state-of-the-art methods in both visual fidelity and layout adherence while eliminating warping-induced geometric artifacts.]]></description>
<pubDate>Tue, 20 Jan 2026 15:13:43 +0000</pubDate>
</item>
<item>
<title><![CDATA[Decoder-Free Supervoxel GNN for Accurate Brain-Tumor Localization in Multi-Modal MRI]]></title>
<link>http://arxiv.org/abs/2601.14055v1</link>
<guid>2601.14055v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.CV, cs.AI
Authors: Andrea Protani, Marc Molina Van Den Bosch, Lorenzo Giusti, Heloisa Barbosa Da Silva, Paolo Cacace et al.
Institution: 
Published: 2026-01-20
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Modern vision backbones for 3D medical imaging typically process dense voxel grids through parameter-heavy encoder-decoder structures, a design that allocates a significant portion of its parameters to spatial reconstruction rather than feature learning. Our approach introduces SVGFormer, a decoder-free pipeline built upon a content-aware grouping stage that partitions the volume into a semantic graph of supervoxels. Its hierarchical encoder learns rich node representations by combining a patch-level Transformer with a supervoxel-level Graph Attention Network, jointly modeling fine-grained intra-region features and broader inter-regional dependencies. This design concentrates all learnable capacity on feature encoding and provides inherent, dual-scale explainability from the patch to the region level. To validate the framework's flexibility, we trained two specialized models on the BraTS dataset: one for node-level classification and one for tumor proportion regression. Both models achieved strong performance, with the classification model achieving a F1-score of 0.875 and the regression model a MAE of 0.028, confirming the encoder's ability to learn discriminative and localized features. Our results establish that a graph-based, encoder-only paradigm offers an accurate and inherently interpretable alternative for 3D medical image representation.]]></description>
<pubDate>Tue, 20 Jan 2026 15:13:04 +0000</pubDate>
</item>
<item>
<title><![CDATA[SecureSplit: Mitigating Backdoor Attacks in Split Learning]]></title>
<link>http://arxiv.org/abs/2601.14054v1</link>
<guid>2601.14054v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.CR, cs.DC, cs.LG
Authors: Zhihao Dou, Dongfei Cui, Weida Wang, Anjun Gao, Yueyang Quan et al.
Institution: 
Published: 2026-01-20
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Split Learning (SL) offers a framework for collaborative model training that respects data privacy by allowing participants to share the same dataset while maintaining distinct feature sets. However, SL is susceptible to backdoor attacks, in which malicious clients subtly alter their embeddings to insert hidden triggers that compromise the final trained model. To address this vulnerability, we introduce SecureSplit, a defense mechanism tailored to SL. SecureSplit applies a dimensionality transformation strategy to accentuate subtle differences between benign and poisoned embeddings, facilitating their separation. With this enhanced distinction, we develop an adaptive filtering approach that uses a majority-based voting scheme to remove contaminated embeddings while preserving clean ones. Rigorous experiments across four datasets (CIFAR-10, MNIST, CINIC-10, and ImageNette), five backdoor attack scenarios, and seven alternative defenses confirm the effectiveness of SecureSplit under various challenging conditions.]]></description>
<pubDate>Tue, 20 Jan 2026 15:07:28 +0000</pubDate>
</item>
<item>
<title><![CDATA[LLMOrbit: A Circular Taxonomy of Large Language Models -From Scaling Walls to Agentic AI Systems]]></title>
<link>http://arxiv.org/abs/2601.14053v1</link>
<guid>2601.14053v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.LG, cs.AI, cs.CV, cs.MA
Authors: Badri N. Patro, Vijay S. Agneeswaran
Institution: 
Published: 2026-01-20
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

The field of artificial intelligence has undergone a revolution from foundational Transformer architectures to reasoning-capable systems approaching human-level performance. We present LLMOrbit, a comprehensive circular taxonomy navigating the landscape of large language models spanning 2019-2025. This survey examines over 50 models across 15 organizations through eight interconnected orbital dimensions, documenting architectural innovations, training methodologies, and efficiency patterns defining modern LLMs, generative AI, and agentic systems. We identify three critical crises: (1) data scarcity (9-27T tokens depleted by 2026-2028), (2) exponential cost growth ($3M to $300M+ in 5 years), and (3) unsustainable energy consumption (22x increase), establishing the scaling wall limiting brute-force approaches. Our analysis reveals six paradigms breaking this wall: (1) test-time compute (o1, DeepSeek-R1 achieve GPT-4 performance with 10x inference compute), (2) quantization (4-8x compression), (3) distributed edge computing (10x cost reduction), (4) model merging, (5) efficient training (ORPO reduces memory 50%), and (6) small specialized models (Phi-4 14B matches larger models). Three paradigm shifts emerge: (1) post-training gains (RLHF, GRPO, pure RL contribute substantially, DeepSeek-R1 achieving 79.8% MATH), (2) efficiency revolution (MoE routing 18x efficiency, Multi-head Latent Attention 8x KV cache compression enables GPT-4-level performance at <$0.30/M tokens), and (3) democratization (open-source Llama 3 88.6% MMLU surpasses GPT-4 86.4%). We provide insights into techniques (RLHF, PPO, DPO, GRPO, ORPO), trace evolution from passive generation to tool-using agents (ReAct, RAG, multi-agent systems), and analyze post-training innovations.]]></description>
<pubDate>Tue, 20 Jan 2026 15:06:19 +0000</pubDate>
</item>
<item>
<title><![CDATA[Vision Also You Need: Navigating Out-of-Distribution Detection with Multimodal Large Language Model]]></title>
<link>http://arxiv.org/abs/2601.14052v1</link>
<guid>2601.14052v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.CV
Authors: Haoran Xu, Yanlin Liu, Zizhao Tong, Jiaze Li, Kexue Fu et al.
Institution: 
Published: 2026-01-20
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Out-of-Distribution (OOD) detection is a critical task that has garnered significant attention. The emergence of CLIP has spurred extensive research into zero-shot OOD detection, often employing a training-free approach. Current methods leverage expert knowledge from large language models (LLMs) to identify potential outliers. However, these approaches tend to over-rely on knowledge in the text space, neglecting the inherent challenges involved in detecting out-of-distribution samples in the image space. In this paper, we propose a novel pipeline, MM-OOD, which leverages the multimodal reasoning capabilities of MLLMs and their ability to conduct multi-round conversations for enhanced outlier detection. Our method is designed to improve performance in both near OOD and far OOD tasks. Specifically, (1) for near OOD tasks, we directly feed ID images and corresponding text prompts into MLLMs to identify potential outliers; and (2) for far OOD tasks, we introduce the sketch-generate-elaborate framework: first, we sketch outlier exposure using text prompts, then generate corresponding visual OOD samples, and finally elaborate by using multimodal prompts. Experiments demonstrate that our method achieves significant improvements on widely used multimodal datasets such as Food-101, while also validating its scalability on ImageNet-1K.]]></description>
<pubDate>Tue, 20 Jan 2026 15:06:10 +0000</pubDate>
</item>
<item>
<title><![CDATA[Kakugo: Distillation of Low-Resource Languages into Small Language Models]]></title>
<link>http://arxiv.org/abs/2601.14051v1</link>
<guid>2601.14051v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.CL, cs.AI, cs.LG
Authors: Peter Devine, Mardhiyah Sanni, Farid Adilazuarda, Julieta Gil Loizaga, Barry Haddow
Institution: 
Published: 2026-01-20
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

We present Kakugo, a novel and cost-effective pipeline designed to train general-purpose Small Language Models (SLMs) for low-resource languages using only the language name as input. By using a large teacher model to generate synthetic prompts and translate instruction datasets, we produced training data and SLMs for 54 low-resource languages. Evaluations across a diverse set of general natural language processing tasks, including translation, classification, and question answering, demonstrate that our pipeline consistently improves performance over base models. With a total generation and training cost of under $50 per language, Kakugo offers an accessible method for communities to develop language-specific AI.]]></description>
<pubDate>Tue, 20 Jan 2026 15:05:44 +0000</pubDate>
</item>
<item>
<title><![CDATA[Understanding Multilingualism in Mixture-of-Experts LLMs: Routing Mechanism, Expert Specialization, and Layerwise Steering]]></title>
<link>http://arxiv.org/abs/2601.14050v1</link>
<guid>2601.14050v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.CL
Authors: Yuxin Chen, Zhengzhou Cai, Xiangtian Ji, Weixiang Zhao, An Zhang et al.
Institution: 
Published: 2026-01-20
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Mixture-of-Experts (MoE) architectures have shown strong multilingual capabilities, yet the internal mechanisms underlying performance gains and cross-language differences remain insufficiently understood. In this work, we conduct a systematic analysis of MoE models, examining routing behavior and expert specialization across languages and network depth. Our analysis reveals that multilingual processing in MoE models is highly structured: routing aligns with linguistic families, expert utilization follows a clear layerwise pattern, and high-resource languages rely on shared experts while low-resource languages depend more on language-exclusive experts despite weaker performance. Layerwise interventions further show that early and late MoE layers support language-specific processing, whereas middle layers serve as language-agnostic capacity hubs. Building on these insights, we propose a routing-guided steering method that adaptively guides routing behavior in middle layers toward shared experts associated with dominant languages at inference time, leading to consistent multilingual performance improvements, particularly for linguistically related language pairs. Our code is available at https://github.com/conctsai/Multilingualism-in-Mixture-of-Experts-LLMs.]]></description>
<pubDate>Tue, 20 Jan 2026 15:04:25 +0000</pubDate>
</item>
<item>
<title><![CDATA[Collective intelligence in science: direct elicitation of diverse information from experts with unknown information structure]]></title>
<link>http://arxiv.org/abs/2601.14047v1</link>
<guid>2601.14047v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.GT, cs.AI, cs.MA, cs.SI
Authors: Alexey V. Osipov, Nikolay N. Osipov
Institution: 
Published: 2026-01-20
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Suppose we need a deep collective analysis of an open scientific problem: there is a complex scientific hypothesis and a large online group of mutually unrelated experts with relevant private information of a diverse and unpredictable nature. This information may be results of experts' individual experiments, original reasoning of some of them, results of AI systems they use, etc. We propose a simple mechanism based on a self-resolving play-money prediction market entangled with a chat. We show that such a system can easily be brought to an equilibrium where participants directly share their private information on the hypothesis through the chat and trade as if the market were resolved in accordance with the truth of the hypothesis. This approach will lead to efficient aggregation of relevant information in a completely interpretable form even if the ground truth cannot be established and experts initially know nothing about each other and cannot perform complex Bayesian calculations. Finally, by rewarding the experts with some real assets proportionally to the play money they end up with, we can get an innovative way to fund large-scale collaborative studies of any type.]]></description>
<pubDate>Tue, 20 Jan 2026 15:01:55 +0000</pubDate>
</item>
<item>
<title><![CDATA[Weather-R1: Logically Consistent Reinforcement Fine-Tuning for Multimodal Reasoning in Meteorology]]></title>
<link>http://arxiv.org/abs/2601.14044v1</link>
<guid>2601.14044v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.CV
Authors: Kaiyu Wu, Pucheng Han, Hualong Zhang, Naigeng Wu, Keze Wang
Institution: 
Published: 2026-01-20
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

While Vision Language Models (VLMs) show advancing reasoning capabilities, their application in meteorology is constrained by a domain gap and a reasoning faithfulness gap. Specifically, mainstream Reinforcement Fine-Tuning (RFT) can induce Self-Contradictory Reasoning (Self-Contra), where the model's reasoning contradicts its final answer, which is unacceptable in such a high-stakes domain. To address these challenges, we construct WeatherQA, a novel multimodal reasoning benchmark in meteorology. We also propose Logically Consistent Reinforcement Fine-Tuning (LoCo-RFT), which resolves Self-Contra by introducing a logical consistency reward. Furthermore, we introduce Weather-R1, the first reasoning VLM with logical faithfulness in meteorology, to the best of our knowledge. Experiments demonstrate that Weather-R1 improves performance on WeatherQA by 9.8 percentage points over the baseline, outperforming Supervised Fine-Tuning and RFT, and even surpassing the original Qwen2.5-VL-32B. These results highlight the effectiveness of our LoCo-RFT and the superiority of Weather-R1. Our benchmark and code are available at https://github.com/Marcowky/Weather-R1.]]></description>
<pubDate>Tue, 20 Jan 2026 15:00:15 +0000</pubDate>
</item>
<item>
<title><![CDATA[Federated Balanced Learning]]></title>
<link>http://arxiv.org/abs/2601.14042v1</link>
<guid>2601.14042v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.CV, cs.LG
Authors: Jiaze Li, Haoran Xu, Wanyi Wu, Changwei Wang, Shuaiguang Li et al.
Institution: 
Published: 2026-01-20
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Federated learning is a paradigm of joint learning in which clients collaborate by sharing model parameters instead of data. However, in the non-iid setting, the global model experiences client drift, which can seriously affect the final performance of the model. Previous methods tend to correct the global model that has already deviated based on the loss function or gradient, overlooking the impact of the client samples. In this paper, we rethink the role of the client side and propose Federated Balanced Learning, i.e., FBL, to prevent this issue from the beginning through sample balance on the client side. Technically, FBL allows unbalanced data on the client side to achieve sample balance through knowledge filling and knowledge sampling using edge-side generation models, under the limitation of a fixed number of data samples on clients. Furthermore, we design a Knowledge Alignment Strategy to bridge the gap between synthetic and real data, and a Knowledge Drop Strategy to regularize our method. Meanwhile, we scale our method to real and complex scenarios, allowing different clients to adopt various methods, and extend our framework to further improve performance. Numerous experiments show that our method outperforms state-of-the-art baselines. The code is released upon acceptance.]]></description>
<pubDate>Tue, 20 Jan 2026 15:00:10 +0000</pubDate>
</item>
<item>
<title><![CDATA[Top 10 Open Challenges Steering the Future of Diffusion Language Model and Its Variants]]></title>
<link>http://arxiv.org/abs/2601.14041v1</link>
<guid>2601.14041v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.CL, cs.AI
Authors: Yunhe Wang, Kai Han, Huiling Zhen, Yuchuan Tian, Hanting Chen et al.
Institution: 
Published: 2026-01-20
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

The paradigm of Large Language Models (LLMs) is currently defined by auto-regressive (AR) architectures, which generate text through a sequential ``brick-by-brick'' process. Despite their success, AR models are inherently constrained by a causal bottleneck that limits global structural foresight and iterative refinement. Diffusion Language Models (DLMs) offer a transformative alternative, conceptualizing text generation as a holistic, bidirectional denoising process akin to a sculptor refining a masterpiece. However, the potential of DLMs remains largely untapped as they are frequently confined within AR-legacy infrastructures and optimization frameworks. In this Perspective, we identify ten fundamental challenges ranging from architectural inertia and gradient sparsity to the limitations of linear reasoning that prevent DLMs from reaching their ``GPT-4 moment''. We propose a strategic roadmap organized into four pillars: foundational infrastructure, algorithmic optimization, cognitive reasoning, and unified multimodal intelligence. By shifting toward a diffusion-native ecosystem characterized by multi-scale tokenization, active remasking, and latent thinking, we can move beyond the constraints of the causal horizon. We argue that this transition is essential for developing next-generation AI capable of complex structural reasoning, dynamic self-correction, and seamless multimodal integration.]]></description>
<pubDate>Tue, 20 Jan 2026 14:58:23 +0000</pubDate>
</item>
<item>
<title><![CDATA[Generalizing Abstention for Noise-Robust Learning in Medical Image Segmentation]]></title>
<link>http://arxiv.org/abs/2601.14039v1</link>
<guid>2601.14039v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.CV, cs.AI
Authors: Wesam Moustafa, Hossam Elsafty, Helen Schneider, Lorenz Sparrenberg, Rafet Sifa
Institution: 
Published: 2026-01-20
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Label noise is a critical problem in medical image segmentation, often arising from the inherent difficulty of manual annotation. Models trained on noisy data are prone to overfitting, which degrades their generalization performance. While a number of methods and strategies have been proposed to mitigate noisy labels in the segmentation domain, this area remains largely under-explored. The abstention mechanism has proven effective in classification tasks by enhancing the capabilities of Cross Entropy, yet its potential in segmentation remains unverified. In this paper, we address this gap by introducing a universal and modular abstention framework capable of enhancing the noise-robustness of a diverse range of loss functions. Our framework improves upon prior work with two key components: an informed regularization term to guide abstention behaviour, and a more flexible power-law-based auto-tuning algorithm for the abstention penalty. We demonstrate the framework's versatility by systematically integrating it with three distinct loss functions to create three novel, noise-robust variants: GAC, SAC, and ADS. Experiments on the CaDIS and DSAD medical datasets show our methods consistently and significantly outperform their non-abstaining baselines, especially under high noise levels. This work establishes that enabling models to selectively ignore corrupted samples is a powerful and generalizable strategy for building more reliable segmentation models. Our code is publicly available at https://github.com/wemous/abstention-for-segmentation.]]></description>
<pubDate>Tue, 20 Jan 2026 14:57:56 +0000</pubDate>
</item>
<item>
<title><![CDATA[Correcting and Quantifying Systematic Errors in 3D Box Annotations for Autonomous Driving]]></title>
<link>http://arxiv.org/abs/2601.14038v1</link>
<guid>2601.14038v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.CV
Authors: Alexandre Justo Miro, Ludvig af Klinteberg, Bogdan Timus, Aron Asefaw, Ajinkya Khoche et al.
Institution: 
Published: 2026-01-20
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Accurate ground truth annotations are critical to supervised learning and evaluating the performance of autonomous vehicle systems. These vehicles are typically equipped with active sensors, such as LiDAR, which scan the environment in predefined patterns. 3D box annotation based on data from such sensors is challenging in dynamic scenarios, where objects are observed at different timestamps, hence different positions. Without proper handling of this phenomenon, systematic errors are prone to being introduced in the box annotations. Our work is the first to discover such annotation errors in widely used, publicly available datasets. Through our novel offline estimation method, we correct the annotations so that they follow physically feasible trajectories and achieve spatial and temporal consistency with the sensor data. For the first time, we define metrics for this problem; and we evaluate our method on the Argoverse 2, MAN TruckScenes, and our proprietary datasets. Our approach increases the quality of box annotations by more than 17% in these datasets. Furthermore, we quantify the annotation errors in them and find that the original annotations are misplaced by up to 2.5 m, with highly dynamic objects being the most affected. Finally, we test the impact of the errors in benchmarking and find that the impact is larger than the improvements that state-of-the-art methods typically achieve with respect to the previous state-of-the-art methods; showing that accurate annotations are essential for correct interpretation of performance. Our code is available at https://github.com/alexandre-justo-miro/annotation-correction-3D-boxes.]]></description>
<pubDate>Tue, 20 Jan 2026 14:57:48 +0000</pubDate>
</item>
<item>
<title><![CDATA[PAC-Private Responses with Adversarial Composition]]></title>
<link>http://arxiv.org/abs/2601.14033v1</link>
<guid>2601.14033v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.LG, cs.CR
Authors: Xiaochen Zhu, Mayuri Sridhar, Srinivas Devadas
Institution: 
Published: 2026-01-20
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Modern machine learning models are increasingly deployed behind APIs. This renders standard weight-privatization methods (e.g. DP-SGD) unnecessarily noisy at the cost of utility. While model weights may vary significantly across training datasets, model responses to specific inputs are much lower dimensional and more stable. This motivates enforcing privacy guarantees directly on model outputs.
  We approach this under PAC privacy, which provides instance-based privacy guarantees for arbitrary black-box functions by controlling mutual information (MI). Importantly, PAC privacy explicitly rewards output stability with reduced noise levels. However, a central challenge remains: response privacy requires composing a large number of adaptively chosen, potentially adversarial queries issued by untrusted users, where existing composition results on PAC privacy are inadequate. We introduce a new algorithm that achieves adversarial composition via adaptive noise calibration and prove that mutual information guarantees accumulate linearly under adaptive and adversarial querying.
  Experiments across tabular, vision, and NLP tasks show that our method achieves high utility at extremely small per-query privacy budgets. On CIFAR-10, we achieve 87.79% accuracy with a per-step MI budget of $2^{-32}$. This enables serving one million queries while provably bounding membership inference attack (MIA) success rates to 51.08% -- the same guarantee of $(0.04, 10^{-5})$-DP. Furthermore, we show that private responses can be used to label public data to distill a publishable privacy-preserving model; using an ImageNet subset as a public dataset, our model distilled from 210,000 responses achieves 91.86% accuracy on CIFAR-10 with MIA success upper-bounded by 50.49%, which is comparable to $(0.02,10^{-5})$-DP.]]></description>
<pubDate>Tue, 20 Jan 2026 14:53:39 +0000</pubDate>
</item>
<item>
<title><![CDATA[RM-Distiller: Exploiting Generative LLM for Reward Model Distillation]]></title>
<link>http://arxiv.org/abs/2601.14032v1</link>
<guid>2601.14032v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.CL
Authors: Hongli Zhou, Hui Huang, Wei Liu, Chenglong Wang, Xingyuan Bu et al.
Institution: 
Published: 2026-01-20
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Reward models (RMs) play a pivotal role in aligning large language models (LLMs) with human preferences. Due to the difficulty of obtaining high-quality human preference annotations, distilling preferences from generative LLMs has emerged as a standard practice. However, existing approaches predominantly treat teacher models as simple binary annotators, failing to fully exploit the rich knowledge and capabilities for RM distillation. To address this, we propose RM-Distiller, a framework designed to systematically exploit the multifaceted capabilities of teacher LLMs: (1) Refinement capability, which synthesizes highly correlated response pairs to create fine-grained and contrastive signals. (2) Scoring capability, which guides the RM in capturing precise preference strength via a margin-aware optimization objective. (3) Generation capability, which incorporates the teacher's generative distribution to regularize the RM to preserve its fundamental linguistic knowledge. Extensive experiments demonstrate that RM-Distiller significantly outperforms traditional distillation methods both on RM benchmarks and reinforcement learning-based alignment, proving that exploiting multifaceted teacher capabilities is critical for effective reward modeling. To the best of our knowledge, this is the first systematic research on RM distillation from generative LLMs.]]></description>
<pubDate>Tue, 20 Jan 2026 14:53:32 +0000</pubDate>
</item>
<item>
<title><![CDATA[Intermittent time series forecasting: local vs global models]]></title>
<link>http://arxiv.org/abs/2601.14031v1</link>
<guid>2601.14031v1</guid>
<description><![CDATA[Source: arXiv
Tags: stat.ML, cs.LG
Authors: Stefano Damato, Nicolò Rubattu, Dario Azzimonti, Giorgio Corani
Institution: 
Published: 2026-01-20
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Intermittent time series, characterised by the presence of a significant amount of zeros, constitute a large percentage of inventory items in supply chain. Probabilistic forecasts are needed to plan the inventory levels; the predictive distribution should cover non-negative values, have a mass in zero and a long upper tail. Intermittent time series are commonly forecast using local models, which are trained individually on each time series. In the last years global models, which are trained on a large collection of time series, have become popular for time series forecasting. Global models are often based on neural networks. However, they have not yet been exhaustively tested on intermittent time series. We carry out the first study comparing state-of-the-art local (iETS, TweedieGP) and global models (D-Linear, DeepAR, Transformers) on intermittent time series. For neural networks models we consider three different distribution heads suitable for intermittent time series: negative binomial, hurdle-shifted negative binomial and Tweedie. We use, for the first time, the last two distribution heads with neural networks. We perform experiments on five large datasets comprising more than 40'000 real-world time series. Among neural networks D-Linear provides best accuracy; it also consistently outperforms the local models. Moreover, it has also low computational requirements. Transformers-based architectures are instead much more computationally demanding and less accurate. Among the distribution heads, the Tweedie provides the best estimates of the highest quantiles, while the negative binomial offers overall the best performance.]]></description>
<pubDate>Tue, 20 Jan 2026 14:53:24 +0000</pubDate>
</item>
<item>
<title><![CDATA[Likelihood-Separable Diffusion Inference for Multi-Image MRI Super-Resolution]]></title>
<link>http://arxiv.org/abs/2601.14030v1</link>
<guid>2601.14030v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.CV
Authors: Samuel W. Remedios, Zhangxing Bian, Shuwen Wei, Aaron Carass, Jerry L. Prince et al.
Institution: 
Published: 2026-01-20
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Diffusion models are the current state-of-the-art for solving inverse problems in imaging. Their impressive generative capability allows them to approximate sampling from a prior distribution, which alongside a known likelihood function permits posterior sampling without retraining the model. While recent methods have made strides in advancing the accuracy of posterior sampling, the majority focuses on single-image inverse problems. However, for modalities such as magnetic resonance imaging (MRI), it is common to acquire multiple complementary measurements, each low-resolution along a different axis. In this work, we generalize common diffusion-based inverse single-image problem solvers for multi-image super-resolution (MISR) MRI. We show that the DPS likelihood correction allows an exactly-separable gradient decomposition across independently acquired measurements, enabling MISR without constructing a joint operator, modifying the diffusion model, or increasing network function evaluations. We derive MISR versions of DPS, DMAP, DPPS, and diffusion-based PnP/ADMM, and demonstrate substantial gains over SISR across $4\times/8\times/16\times$ anisotropic degradations. Our results achieve state-of-the-art super-resolution of anisotropic MRI volumes and, critically, enable reconstruction of near-isotropic anatomy from routine 2D multi-slice acquisitions, which are otherwise highly degraded in orthogonal views.]]></description>
<pubDate>Tue, 20 Jan 2026 14:53:20 +0000</pubDate>
</item>
<item>
<title><![CDATA[Numina-Lean-Agent: An Open and General Agentic Reasoning System for Formal Mathematics]]></title>
<link>http://arxiv.org/abs/2601.14027v1</link>
<guid>2601.14027v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.AI
Authors: Junqi Liu, Zihao Zhou, Zekai Zhu, Marco Dos Santos, Weikun He et al.
Institution: 
Published: 2026-01-20
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Agentic systems have recently become the dominant paradigm for formal theorem proving, achieving strong performance by coordinating multiple models and tools. However, existing approaches often rely on task-specific pipelines and trained formal provers, limiting their flexibility and reproducibility. In this paper, we propose the paradigm that directly uses a general coding agent as a formal math reasoner. This paradigm is motivated by (1) A general coding agent provides a natural interface for diverse reasoning tasks beyond proving, (2) Performance can be improved by simply replacing the underlying base model, without training, and (3) MCP enables flexible extension and autonomous calling of specialized tools, avoiding complex design. Based on this paradigm, we introduce Numina-Lean-Agent, which combines Claude Code with Numina-Lean-MCP to enable autonomous interaction with Lean, retrieval of relevant theorems, informal proving and auxiliary reasoning tools. Using Claude Opus 4.5 as the base model, Numina-Lean-Agent solves all problems in Putnam 2025 (12 / 12), matching the best closed-source system. Beyond benchmark evaluation, we further demonstrate its generality by interacting with mathematicians to successfully formalize the Brascamp-Lieb theorem. We release Numina-Lean-Agent and all solutions at https://github.com/project-numina/numina-lean-agent.]]></description>
<pubDate>Tue, 20 Jan 2026 14:51:45 +0000</pubDate>
</item>
<item>
<title><![CDATA[Universal Approximation Theorem for Input-Connected Multilayer Perceptrons]]></title>
<link>http://arxiv.org/abs/2601.14026v1</link>
<guid>2601.14026v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.LG, cs.NE
Authors: Vugar Ismailov
Institution: 
Published: 2026-01-20
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

We introduce the Input-Connected Multilayer Perceptron (IC-MLP), a feedforward neural network architecture in which each hidden neuron receives, in addition to the outputs of the preceding layer, a direct affine connection from the raw input. We first study this architecture in the univariate setting and give an explicit and systematic description of IC-MLPs with an arbitrary finite number of hidden layers, including iterated formulas for the network functions. In this setting, we prove a universal approximation theorem showing that deep IC-MLPs can approximate any continuous function on a closed interval of the real line if and only if the activation function is nonlinear. We then extend the analysis to vector-valued inputs and establish a corresponding universal approximation theorem for continuous functions on compact subsets of $\mathbb{R}^n$.]]></description>
<pubDate>Tue, 20 Jan 2026 14:48:45 +0000</pubDate>
</item>
<item>
<title><![CDATA[Credible CO2 Comparisons: A Machine Learning Approach to Vehicle Powertrain Assessment]]></title>
<link>http://arxiv.org/abs/2601.14022v1</link>
<guid>2601.14022v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.LG, cs.AI
Authors: Rodrigo Pereira David, Luciano Araujo Dourado Filho, Daniel Marques da Silva, João Alfredo Cal-Braz
Institution: 
Published: 2026-01-20
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Decarbonizing road transport requires consistent and transparent methods for comparing CO2 emissions across vehicle technologies. This paper proposes a machine learning-based framework for like-for-like operational assessment of internal combustion engine vehicles (ICEVs) and electric vehicles (EVs) under identical, real-world driving conditions. The approach isolates technology-specific effects by holding the observed speed profile and environmental context fixed, enabling direct comparison of powertrain performance. Recurrent neural network models are trained independently for each domain to learn the mapping from contextual driving variables (speed, acceleration, temperature) to internal actuation variables (torque, throttle) and instantaneous CO2-equivalent emission rates. This structure allows the construction of counterfactual scenarios that answer: What emissions would an EV have generated if it had followed the same driving profile as an ICEV? By aligning both vehicle types on a unified instantaneous emissions metric, the framework enables fair and reproducible evaluation of powertrain technologies. It offers a scalable foundation for credible, data-driven assessments of vehicle carbon performance under real-world operating conditions.]]></description>
<pubDate>Tue, 20 Jan 2026 14:43:21 +0000</pubDate>
</item>
<item>
<title><![CDATA[MATE: Matryoshka Audio-Text Embeddings for Open-Vocabulary Keyword Spotting]]></title>
<link>http://arxiv.org/abs/2601.14012v1</link>
<guid>2601.14012v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.AI
Authors: Youngmoon Jung, Myunghun Jung, Joon-Young Yang, Yong-Hyeok Lee, Jaeyoung Roh et al.
Institution: 
Published: 2026-01-20
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Open-vocabulary keyword spotting (KWS) with text-based enrollment has emerged as a flexible alternative to fixed-phrase triggers. Prior utterance-level matching methods, from an embedding-learning standpoint, learn embeddings at a single fixed dimensionality. We depart from this design and propose Matryoshka Audio-Text Embeddings (MATE), a dual-encoder framework that encodes multiple embedding granularities within a single vector via nested sub-embeddings ("prefixes"). Specifically, we introduce a PCA-guided prefix alignment: PCA-compressed versions of the full text embedding for each prefix size serve as teacher targets to align both audio and text prefixes. This alignment concentrates salient keyword cues in lower-dimensional prefixes, while higher dimensions add detail. MATE is trained with standard deep metric learning objectives for audio-text KWS, and is loss-agnostic. To our knowledge, this is the first application of matryoshka-style embeddings to KWS, achieving state-of-the-art results on WSJ and LibriPhrase without any inference overhead.]]></description>
<pubDate>Tue, 20 Jan 2026 14:30:40 +0000</pubDate>
</item>
<item>
<title><![CDATA[BACH-V: Bridging Abstract and Concrete Human-Values in Large Language Models]]></title>
<link>http://arxiv.org/abs/2601.14007v1</link>
<guid>2601.14007v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.CL
Authors: Junyu Zhang, Yipeng Kang, Jiong Guo, Jiayu Zhan, Junqi Wang
Institution: 
Published: 2026-01-20
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Do large language models (LLMs) genuinely understand abstract concepts, or merely manipulate them as statistical patterns? We introduce an abstraction-grounding framework that decomposes conceptual understanding into three capacities: interpretation of abstract concepts (Abstract-Abstract, A-A), grounding of abstractions in concrete events (Abstract-Concrete, A-C), and application of abstract principles to regulate concrete decisions (Concrete-Concrete, C-C). Using human values as a testbed - given their semantic richness and centrality to alignment - we employ probing (detecting value traces in internal activations) and steering (modifying representations to shift behavior). Across six open-source LLMs and ten value dimensions, probing shows that diagnostic probes trained solely on abstract value descriptions reliably detect the same values in concrete event narratives and decision reasoning, demonstrating cross-level transfer. Steering reveals an asymmetry: intervening on value representations causally shifts concrete judgments and decisions (A-C, C-C), yet leaves abstract interpretations unchanged (A-A), suggesting that encoded abstract values function as stable anchors rather than malleable activations. These findings indicate LLMs maintain structured value representations that bridge abstraction and action, providing a mechanistic and operational foundation for building value-driven autonomous AI systems with more transparent, generalizable alignment and control.]]></description>
<pubDate>Tue, 20 Jan 2026 14:26:58 +0000</pubDate>
</item>
<item>
<title><![CDATA[Locate, Steer, and Improve: A Practical Survey of Actionable Mechanistic Interpretability in Large Language Models]]></title>
<link>http://arxiv.org/abs/2601.14004v1</link>
<guid>2601.14004v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.CL
Authors: Hengyuan Zhang, Zhihao Zhang, Mingyang Wang, Zunhai Su, Yiwei Wang et al.
Institution: 
Published: 2026-01-20
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Mechanistic Interpretability (MI) has emerged as a vital approach to demystify the opaque decision-making of Large Language Models (LLMs). However, existing reviews primarily treat MI as an observational science, summarizing analytical insights while lacking a systematic framework for actionable intervention. To bridge this gap, we present a practical survey structured around the pipeline: "Locate, Steer, and Improve." We formally categorize Localizing (diagnosis) and Steering (intervention) methods based on specific Interpretable Objects to establish a rigorous intervention protocol. Furthermore, we demonstrate how this framework enables tangible improvements in Alignment, Capability, and Efficiency, effectively operationalizing MI as an actionable methodology for model optimization. The curated paper list of this work is available at https://github.com/rattlesnakey/Awesome-Actionable-MI-Survey.]]></description>
<pubDate>Tue, 20 Jan 2026 14:23:23 +0000</pubDate>
</item>
<item>
<title><![CDATA[Auditory Brain Passage Retrieval: Cross-Sensory EEG Training for Neural Information Retrieval]]></title>
<link>http://arxiv.org/abs/2601.14001v1</link>
<guid>2601.14001v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.IR, cs.LG
Authors: Niall McGuire, Yashar Moshfeghi
Institution: 
Published: 2026-01-20
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Query formulation from internal information needs remains fundamentally challenging across all Information Retrieval paradigms due to cognitive complexity and physical impairments. Brain Passage Retrieval (BPR) addresses this by directly mapping EEG signals to passage representations without intermediate text translation. However, existing BPR research exclusively uses visual stimuli, leaving critical questions unanswered: Can auditory EEG enable effective retrieval for voice-based interfaces and visually impaired users? Can training on combined EEG datasets from different sensory modalities improve performance despite severe data scarcity? We present the first systematic investigation of auditory EEG for BPR and evaluate cross-sensory training benefits. Using dual encoder architectures with four pooling strategies (CLS, mean, max, multi-vector), we conduct controlled experiments comparing auditory-only, visual-only, and combined training on the Alice (auditory) and Nieuwland (visual) datasets. Results demonstrate that auditory EEG consistently outperforms visual EEG, and cross-sensory training with CLS pooling achieves substantial improvements over individual training: 31% in MRR (0.474), 43% in Hit@1 (0.314), and 28% in Hit@10 (0.858). Critically, combined auditory EEG models surpass BM25 text baselines (MRR: 0.474 vs 0.428), establishing neural queries as competitive with traditional retrieval whilst enabling accessible interfaces. These findings validate auditory neural interfaces for IR tasks and demonstrate that cross-sensory training addresses data scarcity whilst outperforming single-modality approaches Code: https://github.com/NiallMcguire/Audio_BPR]]></description>
<pubDate>Tue, 20 Jan 2026 14:22:41 +0000</pubDate>
</item>
<item>
<title><![CDATA[Group-Invariant Unsupervised Skill Discovery: Symmetry-aware Skill Representations for Generalizable Behavior]]></title>
<link>http://arxiv.org/abs/2601.14000v1</link>
<guid>2601.14000v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.RO, cs.LG
Authors: Junwoo Chang, Joseph Park, Roberto Horowitz, Jongmin Lee, Jongeun Choi
Institution: 
Published: 2026-01-20
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Unsupervised skill discovery aims to acquire behavior primitives that improve exploration and accelerate downstream task learning. However, existing approaches often ignore the geometric symmetries of physical environments, leading to redundant behaviors and sample inefficiency. To address this, we introduce Group-Invariant Skill Discovery (GISD), a framework that explicitly embeds group structure into the skill discovery objective. Our approach is grounded in a theoretical guarantee: we prove that in group-symmetric environments, the standard Wasserstein dependency measure admits a globally optimal solution comprised of an equivariant policy and a group-invariant scoring function. Motivated by this, we formulate the Group-Invariant Wasserstein dependency measure, which restricts the optimization to this symmetry-aware subspace without loss of optimality. Practically, we parameterize the scoring function using a group Fourier representation and define the intrinsic reward via the alignment of equivariant latent features, ensuring that the discovered skills generalize systematically under group transformations. Experiments on state-based and pixel-based locomotion benchmarks demonstrate that GISD achieves broader state-space coverage and improved efficiency in downstream task learning compared to a strong baseline.]]></description>
<pubDate>Tue, 20 Jan 2026 14:21:18 +0000</pubDate>
</item>
<item>
<title><![CDATA[DAME: Duration-Aware Matryoshka Embedding for Duration-Robust Speaker Verification]]></title>
<link>http://arxiv.org/abs/2601.13999v1</link>
<guid>2601.13999v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.AI
Authors: Youngmoon Jung, Joon-Young Yang, Ju-ho Kim, Jaeyoung Roh, Chang Woo Han et al.
Institution: 
Published: 2026-01-20
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Short-utterance speaker verification remains challenging due to limited speaker-discriminative cues in short speech segments. While existing methods focus on enhancing speaker encoders, the embedding learning strategy still forces a single fixed-dimensional representation reused for utterances of any length, leaving capacity misaligned with the information available at different durations. We propose Duration-Aware Matryoshka Embedding (DAME), a model-agnostic framework that builds a nested hierarchy of sub-embeddings aligned to utterance durations: lower-dimensional representations capture compact speaker traits from short utterances, while higher dimensions encode richer details from longer speech. DAME supports both training from scratch and fine-tuning, and serves as a direct alternative to conventional large-margin fine-tuning, consistently improving performance across durations. On the VoxCeleb1-O/E/H and VOiCES evaluation sets, DAME consistently reduces the equal error rate on 1-s and other short-duration trials, while maintaining full-length performance with no additional inference cost. These gains generalize across various speaker encoder architectures under both general training and fine-tuning setups.]]></description>
<pubDate>Tue, 20 Jan 2026 14:20:44 +0000</pubDate>
</item>
<item>
<title><![CDATA[From Tags to Trees: Structuring Fine-Grained Knowledge for Controllable Data Selection in LLM Instruction Tuning]]></title>
<link>http://arxiv.org/abs/2601.13995v1</link>
<guid>2601.13995v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.CL
Authors: Zihan Niu, Wenping Hu, Junmin Chen, Xiyue Wang, Tong Xu et al.
Institution: 
Published: 2026-01-20
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Effective and controllable data selection is critical for LLM instruction tuning, especially with massive open-source datasets. Existing approaches primarily rely on instance-level quality scores, or diversity metrics based on embedding clusters or semantic tags. However, constrained by the flatness of embedding spaces or the coarseness of tags, these approaches overlook fine-grained knowledge and its intrinsic hierarchical dependencies, consequently hindering precise data valuation and knowledge-aligned sampling. To address this challenge, we propose Tree-aware Aligned Global Sampling (TAGS), a unified framework that leverages a knowledge tree built from fine-grained tags, thereby enabling joint control of global quality, diversity, and target alignment. Using an LLM-based tagger, we extract atomic knowledge concepts, which are organized into a global tree through bottom-up hierarchical clustering. By grounding data instances onto this tree, a tree-aware metric then quantifies data quality and diversity, facilitating effective sampling. Our controllable sampling strategy maximizes tree-level information gain and enforces leaf-level alignment via KL-divergence for specific domains. Extensive experiments demonstrate that TAGS significantly outperforms state-of-the-art baselines. Notably, it surpasses the full-dataset model by \textbf{+5.84\%} using only \textbf{5\%} of the data, while our aligned sampling strategy further boosts average performance by \textbf{+4.24\%}.]]></description>
<pubDate>Tue, 20 Jan 2026 14:06:51 +0000</pubDate>
</item>
<item>
<title><![CDATA[torch-sla: Differentiable Sparse Linear Algebra with Adjoint Solvers and Sparse Tensor Parallelism for PyTorch]]></title>
<link>http://arxiv.org/abs/2601.13994v1</link>
<guid>2601.13994v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.DC, cs.AI
Authors: Mingyuan Chi
Institution: 
Published: 2026-01-20
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Industrial scientific computing predominantly uses sparse matrices to represent unstructured data -- finite element meshes, graphs, point clouds. We present \torchsla{}, an open-source PyTorch library that enables GPU-accelerated, scalable, and differentiable sparse linear algebra. The library addresses three fundamental challenges: (1) GPU acceleration for sparse linear solves, nonlinear solves (Newton, Picard, Anderson), and eigenvalue computation; (2) Multi-GPU scaling via domain decomposition with halo exchange, reaching \textbf{400 million DOF linear solve on 3 GPUs}; and (3) Adjoint-based differentiation} achieving $\mathcal{O}(1)$ computational graph nodes (for autograd) and $\mathcal{O}(\text{nnz})$ memory -- independent of solver iterations. \torchsla{} supports multiple backends (SciPy, cuDSS, PyTorch-native) and seamlessly integrates with PyTorch autograd for end-to-end differentiable simulations. Code is available at https://github.com/walkerchi/torch-sla.]]></description>
<pubDate>Tue, 20 Jan 2026 14:06:01 +0000</pubDate>
</item>
<item>
<title><![CDATA["The Whole Is Greater Than the Sum of Its Parts": A Compatibility-Aware Multi-Teacher CoT Distillation Framework]]></title>
<link>http://arxiv.org/abs/2601.13992v1</link>
<guid>2601.13992v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.CL, cs.AI
Authors: Jin Cui, Jiaqi Guo, Jiepeng Zhou, Ruixuan Yang, Jiayi Lu et al.
Institution: 
Published: 2026-01-20
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Chain-of-Thought (CoT) reasoning empowers Large Language Models (LLMs) with remarkable capabilities but typically requires prohibitive parameter scales. CoT distillation has emerged as a promising paradigm to transfer reasoning prowess into compact Student Models (SLMs), but existing approaches often rely on a solitary teacher, capping the student's potential since individual LLMs often exhibit distinct capability biases and may suffer from catastrophic forgetting. While leveraging diverse teachers seems appealing, effectively fusing their supervisions remains challenging: teacher-student incompatibility risks amplifying hallucinations, and passive supervision fails to ensure genuine logic internalization. To address this, we introduce COMPACT, a framework that adaptively fuses supervisions from different teachers by dynamically weighting teacher gradients based on the student's real-time compatibility evaluated by a multi-dimensional metric: (1) Graph-based Consensus to filter misleading rationales by identifying mainstream reasoning paths; (2) Mutual-Information-based Adaptability to detect "epiphany moments" for genuinely understanding the reasoning process rather than merely imitating; and (3) Loss-based Difficulty to assess student receptivity to the teacher's guidance and prevent negative transfer. Extensive experiments and latent space analysis demonstrate that COMPACT effectively integrates diverse reasoning capabilities without damaging the model's original knowledge structure, achieving state-of-the-art performance on various benchmarks while mitigating catastrophic forgetting.]]></description>
<pubDate>Tue, 20 Jan 2026 14:05:19 +0000</pubDate>
</item>
<item>
<title><![CDATA[A universal linearized subspace refinement framework for neural networks]]></title>
<link>http://arxiv.org/abs/2601.13989v1</link>
<guid>2601.13989v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.LG
Authors: Wenbo Cao, Weiwei Zhang
Institution: 
Published: 2026-01-20
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Neural networks are predominantly trained using gradient-based methods, yet in many applications their final predictions remain far from the accuracy attainable within the model's expressive capacity. We introduce Linearized Subspace Refinement (LSR), a general and architecture-agnostic framework that exploits the Jacobian-induced linear residual model at a fixed trained network state. By solving a reduced direct least-squares problem within this subspace, LSR computes a subspace-optimal solution of the linearized residual model, yielding a refined linear predictor with substantially improved accuracy over standard gradient-trained solutions, without modifying network architectures, loss formulations, or training procedures. Across supervised function approximation, data-driven operator learning, and physics-informed operator fine-tuning, we show that gradient-based training often fails to access this attainable accuracy, even when local linearization yields a convex problem. This observation indicates that loss-induced numerical ill-conditioning, rather than nonconvexity or model expressivity, can constitute a dominant practical bottleneck. In contrast, one-shot LSR systematically exposes accuracy levels not fully exploited by gradient-based training, frequently achieving order-of-magnitude error reductions. For operator-constrained problems with composite loss structures, we further introduce Iterative LSR, which alternates one-shot LSR with supervised nonlinear alignment, transforming ill-conditioned residual minimization into numerically benign fitting steps and yielding accelerated convergence and improved accuracy. By bridging nonlinear neural representations with reduced-order linear solvers at fixed linearization points, LSR provides a numerically grounded and broadly applicable refinement framework for supervised learning, operator learning, and scientific computing.]]></description>
<pubDate>Tue, 20 Jan 2026 14:03:28 +0000</pubDate>
</item>
<item>
<title><![CDATA[SHARE: A Fully Unsupervised Framework for Single Hyperspectral Image Restoration]]></title>
<link>http://arxiv.org/abs/2601.13987v1</link>
<guid>2601.13987v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.CV
Authors: Jiangwei Xie, Zhang Wen, Mike Davies, Dongdong Chen
Institution: 
Published: 2026-01-20
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Hyperspectral image (HSI) restoration is a fundamental challenge in computational imaging and computer vision. It involves ill-posed inverse problems, such as inpainting and super-resolution. Although deep learning methods have transformed the field through data-driven learning, their effectiveness hinges on access to meticulously curated ground-truth datasets. This fundamentally restricts their applicability in real-world scenarios where such data is unavailable. This paper presents SHARE (Single Hyperspectral Image Restoration with Equivariance), a fully unsupervised framework that unifies geometric equivariance principles with low-rank spectral modelling to eliminate the need for ground truth. SHARE's core concept is to exploit the intrinsic invariance of hyperspectral structures under differentiable geometric transformations (e.g. rotations and scaling) to derive self-supervision signals through equivariance consistency constraints. Our novel Dynamic Adaptive Spectral Attention (DASA) module further enhances this paradigm shift by explicitly encoding the global low-rank property of HSI and adaptively refining local spectral-spatial correlations through learnable attention mechanisms. Extensive experiments on HSI inpainting and super-resolution tasks demonstrate the effectiveness of SHARE. Our method outperforms many state-of-the-art unsupervised approaches and achieves performance comparable to that of supervised methods. We hope that our approach will shed new light on HSI restoration and broader scientific imaging scenarios. The code will be released at https://github.com/xuwayyy/SHARE.]]></description>
<pubDate>Tue, 20 Jan 2026 14:01:13 +0000</pubDate>
</item>
<item>
<title><![CDATA[Equivariant Learning for Unsupervised Image Dehazing]]></title>
<link>http://arxiv.org/abs/2601.13986v1</link>
<guid>2601.13986v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.CV
Authors: Zhang Wen, Jiangwei Xie, Dongdong Chen
Institution: 
Published: 2026-01-20
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Image Dehazing (ID) aims to produce a clear image from an observation contaminated by haze. Current ID methods typically rely on carefully crafted priors or extensive haze-free ground truth, both of which are expensive or impractical to acquire, particularly in the context of scientific imaging. We propose a new unsupervised learning framework called Equivariant Image Dehazing (EID) that exploits the symmetry of image signals to restore clarity to hazy observations. By enforcing haze consistency and systematic equivariance, EID can recover clear patterns directly from raw, hazy images. Additionally, we propose an adversarial learning strategy to model unknown haze physics and facilitate EID learning. Experiments on two scientific image dehazing benchmarks (including cell microscopy and medical endoscopy) and on natural image dehazing have demonstrated that EID significantly outperforms state-of-the-art approaches. By unifying equivariant learning with modelling haze physics, we hope that EID will enable more versatile and effective haze removal in scientific imaging. Code and datasets will be published.]]></description>
<pubDate>Tue, 20 Jan 2026 14:01:07 +0000</pubDate>
</item>
<item>
<title><![CDATA[Harmonizing the Deep: A Unified Information Pipeline for Robust Marine Biodiversity Assessment Across Heterogeneous Domains]]></title>
<link>http://arxiv.org/abs/2601.13975v1</link>
<guid>2601.13975v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.CV, cs.LG
Authors: Marco Piccolo, Qiwei Han, Astrid van Toor, Joachim Vanneste
Institution: 
Published: 2026-01-20
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Marine biodiversity monitoring requires scalability and reliability across complex underwater environments to support conservation and invasive-species management. Yet existing detection solutions often exhibit a pronounced deployment gap, with performance degrading sharply when transferred to new sites. This work establishes the foundational detection layer for a multi-year invasive species monitoring initiative targeting Arctic and Atlantic marine ecosystems. We address this challenge by developing a Unified Information Pipeline that standardises heterogeneous datasets into a comparable information flow and evaluates a fixed, deployment-relevant detector under controlled cross-domain protocols. Across multiple domains, we find that structural factors, such as scene composition, object density, and contextual redundancy, explain cross-domain performance loss more strongly than visual degradation such as turbidity, with sparse scenes inducing a characteristic "Context Collapse" failure mode. We further validate operational feasibility by benchmarking inference on low-cost edge hardware, showing that runtime optimisation enables practical sampling rates for remote monitoring. The results shift emphasis from image enhancement toward structure-aware reliability, providing a democratised tool for consistent marine ecosystem assessment.]]></description>
<pubDate>Tue, 20 Jan 2026 13:51:55 +0000</pubDate>
</item>
<item>
<title><![CDATA[STEC: A Reference-Free Spatio-Temporal Entropy Coverage Metric for Evaluating Sampled Video Frames]]></title>
<link>http://arxiv.org/abs/2601.13974v1</link>
<guid>2601.13974v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.CV
Authors: Shih-Yao Lin
Institution: 
Published: 2026-01-20
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Frame sampling is a fundamental component in video understanding and video--language model pipelines, yet evaluating the quality of sampled frames remains challenging. Existing evaluation metrics primarily focus on perceptual quality or reconstruction fidelity, and are not designed to assess whether a set of sampled frames adequately captures informative and representative video content.
  We propose Spatio-Temporal Entropy Coverage (STEC), a simple and non-reference metric for evaluating the effectiveness of video frame sampling. STEC builds upon Spatio-Temporal Frame Entropy (STFE), which measures per-frame spatial information via entropy-based structural complexity, and evaluates sampled frames based on their temporal coverage and redundancy. By jointly modeling spatial information strength, temporal dispersion, and non-redundancy, STEC provides a principled and lightweight measure of sampling quality.
  Experiments on the MSR-VTT test-1k benchmark demonstrate that STEC clearly differentiates common sampling strategies, including random, uniform, and content-aware methods. We further show that STEC reveals robustness patterns across individual videos that are not captured by average performance alone, highlighting its practical value as a general-purpose evaluation tool for efficient video understanding.
  We emphasize that STEC is not designed to predict downstream task accuracy, but to provide a task-agnostic diagnostic signal for analyzing frame sampling behavior under constrained budgets.]]></description>
<pubDate>Tue, 20 Jan 2026 13:51:33 +0000</pubDate>
</item>
<item>
<title><![CDATA[Autonomous Knowledge Graph Exploration with Adaptive Breadth-Depth Retrieval]]></title>
<link>http://arxiv.org/abs/2601.13969v1</link>
<guid>2601.13969v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.AI, cs.IR, cs.LG
Authors: Joaquín Polonuer, Lucas Vittor, Iñaki Arango, Ayush Noori, David A. Clifton et al.
Institution: Harvard
Published: 2026-01-20
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Retrieving evidence for language model queries from knowledge graphs requires balancing broad search across the graph with multi-hop traversal to follow relational links. Similarity-based retrievers provide coverage but remain shallow, whereas traversal-based methods rely on selecting seed nodes to start exploration, which can fail when queries span multiple entities and relations. We introduce ARK: Adaptive Retriever of Knowledge, an agentic KG retriever that gives a language model control over this breadth-depth tradeoff using a two-operation toolset: global lexical search over node descriptors and one-hop neighborhood exploration that composes into multi-hop traversal. ARK alternates between breadth-oriented discovery and depth-oriented expansion without depending on a fragile seed selection, a pre-set hop depth, or requiring retrieval training. ARK adapts tool use to queries, using global search for language-heavy queries and neighborhood exploration for relation-heavy queries. On STaRK, ARK reaches 59.1% average Hit@1 and 67.4 average MRR, improving average Hit@1 by up to 31.4% and average MRR by up to 28.0% over retrieval-based and agentic training-free methods. Finally, we distill ARK's tool-use trajectories from a large teacher into an 8B model via label-free imitation, improving Hit@1 by +7.0, +26.6, and +13.5 absolute points over the base 8B model on AMAZON, MAG, and PRIME datasets, respectively, while retaining up to 98.5% of the teacher's Hit@1 rate.]]></description>
<pubDate>Tue, 20 Jan 2026 13:46:37 +0000</pubDate>
</item>
<item>
<title><![CDATA[RL-BioAug: Label-Efficient Reinforcement Learning for Self-Supervised EEG Representation Learning]]></title>
<link>http://arxiv.org/abs/2601.13964v1</link>
<guid>2601.13964v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.LG, cs.AI
Authors: Cheol-Hui Lee, Hwa-Yeon Lee, Dong-Joo Kim
Institution: 
Published: 2026-01-20
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

The quality of data augmentation serves as a critical determinant for the performance of contrastive learning in EEG tasks. Although this paradigm is promising for utilizing unlabeled data, static or random augmentation strategies often fail to preserve intrinsic information due to the non-stationarity of EEG signals where statistical properties change over time. To address this, we propose RL-BioAug, a framework that leverages a label-efficient reinforcement learning (RL) agent to autonomously determine optimal augmentation policies. While utilizing only a minimal fraction (10\%) of labeled data to guide the agent's policy, our method enables the encoder to learn robust representations in a strictly self-supervised manner. Experimental results demonstrate that RL-BioAug significantly outperforms the random selection strategy, achieving substantial improvements of 9.69\% and 8.80\% in Macro-F1 score on the Sleep-EDFX and CHB-MIT datasets, respectively. Notably, this agent mainly chose optimal strategies for each task -- for example, Time Masking with a 62\% probability for sleep stage classification and Crop \& Resize with a 77\% probability for seizure detection. Our framework suggests its potential to replace conventional heuristic-based augmentations and establish a new autonomous paradigm for data augmentation. The source code is available at \href{https://github.com/dlcjfgmlnasa/RL-BioAug}{https://github.com/dlcjfgmlnasa/RL-BioAug}.]]></description>
<pubDate>Tue, 20 Jan 2026 13:38:01 +0000</pubDate>
</item>
<item>
<title><![CDATA[DExTeR: Weakly Semi-Supervised Object Detection with Class and Instance Experts for Medical Imaging]]></title>
<link>http://arxiv.org/abs/2601.13954v1</link>
<guid>2601.13954v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.CV
Authors: Adrien Meyer, Didier Mutter, Nicolas Padoy
Institution: 
Published: 2026-01-20
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Detecting anatomical landmarks in medical imaging is essential for diagnosis and intervention guidance. However, object detection models rely on costly bounding box annotations, limiting scalability. Weakly Semi-Supervised Object Detection (WSSOD) with point annotations proposes annotating each instance with a single point, minimizing annotation time while preserving localization signals. A Point-to-Box teacher model, trained on a small box-labeled subset, converts these point annotations into pseudo-box labels to train a student detector. Yet, medical imagery presents unique challenges, including overlapping anatomy, variable object sizes, and elusive structures, which hinder accurate bounding box inference. To overcome these challenges, we introduce DExTeR (DETR with Experts), a transformer-based Point-to-Box regressor tailored for medical imaging. Built upon Point-DETR, DExTeR encodes single-point annotations as object queries, refining feature extraction with the proposed class-guided deformable attention, which guides attention sampling using point coordinates and class labels to capture class-specific characteristics. To improve discrimination in complex structures, it introduces CLICK-MoE (CLass, Instance, and Common Knowledge Mixture of Experts), decoupling class and instance representations to reduce confusion among adjacent or overlapping instances. Finally, we implement a multi-point training strategy which promotes prediction consistency across different point placements, improving robustness to annotation variability. DExTeR achieves state-of-the-art performance across three datasets spanning different medical domains (endoscopy, chest X-rays, and endoscopic ultrasound) highlighting its potential to reduce annotation costs while maintaining high detection accuracy.]]></description>
<pubDate>Tue, 20 Jan 2026 13:27:14 +0000</pubDate>
</item>
<item>
<title><![CDATA[Differentiable Logic Synthesis: Spectral Coefficient Selection via Sinkhorn-Constrained Composition]]></title>
<link>http://arxiv.org/abs/2601.13953v1</link>
<guid>2601.13953v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.LG, cs.AR, cs.LO
Authors: Gorgi Pavlov
Institution: 
Published: 2026-01-20
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Learning precise Boolean logic via gradient descent remains challenging: neural networks typically converge to "fuzzy" approximations that degrade under quantization. We introduce Hierarchical Spectral Composition, a differentiable architecture that selects spectral coefficients from a frozen Boolean Fourier basis and composes them via Sinkhorn-constrained routing with column-sign modulation. Our approach draws on recent insights from Manifold-Constrained Hyper-Connections (mHC), which demonstrated that projecting routing matrices onto the Birkhoff polytope preserves identity mappings and stabilizes large-scale training. We adapt this framework to logic synthesis, adding column-sign modulation to enable Boolean negation -- a capability absent in standard doubly stochastic routing.
  We validate our approach across four phases of increasing complexity: (1) For n=2 (16 Boolean operations over 4-dim basis), gradient descent achieves 100% accuracy with zero routing drift and zero-loss quantization to ternary masks. (2) For n=3 (10 three-variable operations), gradient descent achieves 76% accuracy, but exhaustive enumeration over 3^8 = 6561 configurations proves that optimal ternary masks exist for all operations (100% accuracy, 39% sparsity). (3) For n=4 (10 four-variable operations over 16-dim basis), spectral synthesis -- combining exact Walsh-Hadamard coefficients, ternary quantization, and MCMC refinement with parallel tempering -- achieves 100% accuracy on all operations. This progression establishes (a) that ternary polynomial threshold representations exist for all tested functions, and (b) that finding them requires methods beyond pure gradient descent as dimensionality grows. All operations enable single-cycle combinational logic inference at 10,959 MOps/s on GPU, demonstrating viability for hardware-efficient neuro-symbolic logic synthesis.]]></description>
<pubDate>Tue, 20 Jan 2026 13:26:52 +0000</pubDate>
</item>
<item>
<title><![CDATA[VTONGuard: Automatic Detection and Authentication of AI-Generated Virtual Try-On Content]]></title>
<link>http://arxiv.org/abs/2601.13951v1</link>
<guid>2601.13951v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.CV
Authors: Shengyi Wu, Yan Hong, Shengyao Chen, Zheng Wang, Xianbing Sun et al.
Institution: 
Published: 2026-01-20
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

With the rapid advancement of generative AI, virtual try-on (VTON) systems are becoming increasingly common in e-commerce and digital entertainment. However, the growing realism of AI-generated try-on content raises pressing concerns about authenticity and responsible use. To address this, we present VTONGuard, a large-scale benchmark dataset containing over 775,000 real and synthetic try-on images. The dataset covers diverse real-world conditions, including variations in pose, background, and garment styles, and provides both authentic and manipulated examples. Based on this benchmark, we conduct a systematic evaluation of multiple detection paradigms under unified training and testing protocols. Our results reveal each method's strengths and weaknesses and highlight the persistent challenge of cross-paradigm generalization. To further advance detection, we design a multi-task framework that integrates auxiliary segmentation to enhance boundary-aware feature learning, achieving the best overall performance on VTONGuard. We expect this benchmark to enable fair comparisons, facilitate the development of more robust detection models, and promote the safe and responsible deployment of VTON technologies in practice.]]></description>
<pubDate>Tue, 20 Jan 2026 13:26:06 +0000</pubDate>
</item>
<item>
<title><![CDATA[Stream-Voice-Anon: Enhancing Utility of Real-Time Speaker Anonymization via Neural Audio Codec and Language Models]]></title>
<link>http://arxiv.org/abs/2601.13948v1</link>
<guid>2601.13948v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.AI
Authors: Nikita Kuzmin, Songting Liu, Kong Aik Lee, Eng Siong Chng
Institution: 
Published: 2026-01-20
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Protecting speaker identity is crucial for online voice applications, yet streaming speaker anonymization (SA) remains underexplored. Recent research has demonstrated that neural audio codec (NAC) provides superior speaker feature disentanglement and linguistic fidelity. NAC can also be used with causal language models (LM) to enhance linguistic fidelity and prompt control for streaming tasks. However, existing NAC-based online LM systems are designed for voice conversion (VC) rather than anonymization, lacking the techniques required for privacy protection. Building on these advances, we present Stream-Voice-Anon, which adapts modern causal LM-based NAC architectures specifically for streaming SA by integrating anonymization techniques. Our anonymization approach incorporates pseudo-speaker representation sampling, a speaker embedding mixing and diverse prompt selection strategies for LM conditioning that leverage the disentanglement properties of quantized content codes to prevent speaker information leakage. Additionally, we compare dynamic and fixed delay configurations to explore latency-privacy trade-offs in real-time scenarios. Under the VoicePrivacy 2024 Challenge protocol, Stream-Voice-Anon achieves substantial improvements in intelligibility (up to 46% relative WER reduction) and emotion preservation (up to 28% UAR relative) compared to the previous state-of-the-art streaming method DarkStream while maintaining comparable latency (180ms vs 200ms) and privacy protection against lazy-informed attackers, though showing 15% relative degradation against semi-informed attackers.]]></description>
<pubDate>Tue, 20 Jan 2026 13:23:44 +0000</pubDate>
</item>
<item>
<title><![CDATA[Efficient Coordination with the System-Level Shared State: An Embodied-AI Native Modular Framework]]></title>
<link>http://arxiv.org/abs/2601.13945v1</link>
<guid>2601.13945v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.RO, cs.LG
Authors: Yixuan Deng, Tongrun Wu, Donghao Wu, Zeyu Wei, Jiayuan Wang et al.
Institution: 
Published: 2026-01-20
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

As Embodied AI systems move from research prototypes to real world deployments, they tend to evolve rapidly while remaining reliable under workload changes and partial failures. In practice, many deployments are only partially decoupled: middleware moves messages, but shared context and feedback semantics are implicit, causing interface drift, cross-module interference, and brittle recovery at scale. We present ANCHOR, a modular framework that makes decoupling and robustness explicit system-level primitives. ANCHOR separates (i) Canonical Records, an evolvable contract for the standardized shared state, from (ii) a communication bus for many-to-many dissemination and feedback-oriented coordination, forming an inspectable end-to-end loop. We validate closed-loop feasibility on a de-identified workflow instantiation, characterize latency distributions under varying payload sizes and publish rates, and demonstrate automatic stream resumption after hard crashes and restarts even with shared-memory loss. Overall, ANCHOR turns ad-hoc integration glue into explicit contracts, enabling controlled degradation under load and self-healing recovery for scalable deployment of closed-loop AI systems.]]></description>
<pubDate>Tue, 20 Jan 2026 13:21:52 +0000</pubDate>
</item>
<item>
<title><![CDATA[Glance-or-Gaze: Incentivizing LMMs to Adaptively Focus Search via Reinforcement Learning]]></title>
<link>http://arxiv.org/abs/2601.13942v1</link>
<guid>2601.13942v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.CV, cs.AI
Authors: Hongbo Bai, Yujin Zhou, Yile Wu, Chi-Min Chan, Pengcheng Wen et al.
Institution: 
Published: 2026-01-20
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Large Multimodal Models (LMMs) have achieved remarkable success in visual understanding, yet they struggle with knowledge-intensive queries involving long-tail entities or evolving information due to static parametric knowledge. Recent search-augmented approaches attempt to address this limitation, but existing methods rely on indiscriminate whole-image retrieval that introduces substantial visual redundancy and noise, and lack deep iterative reflection, limiting their effectiveness on complex visual queries. To overcome these challenges, we propose Glance-or-Gaze (GoG), a fully autonomous framework that shifts from passive perception to active visual planning. GoG introduces a Selective Gaze mechanism that dynamically chooses whether to glance at global context or gaze into high-value regions, filtering irrelevant information before retrieval. We design a dual-stage training strategy: Reflective GoG Behavior Alignment via supervised fine-tuning instills the fundamental GoG paradigm, while Complexity-Adaptive Reinforcement Learning further enhances the model's capability to handle complex queries through iterative reasoning. Experiments across six benchmarks demonstrate state-of-the-art performance. Ablation studies confirm that both Selective Gaze and complexity-adaptive RL are essential for effective visual search. We will release our data and models for further exploration soon.]]></description>
<pubDate>Tue, 20 Jan 2026 13:18:18 +0000</pubDate>
</item>
<item>
<title><![CDATA[IF-GEO: Conflict-Aware Instruction Fusion for Multi-Query Generative Engine Optimization]]></title>
<link>http://arxiv.org/abs/2601.13938v1</link>
<guid>2601.13938v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.IR, cs.AI
Authors: Heyang Zhou, JiaJia Chen, Xiaolu Chen, Jie Bao, Zhen Chen et al.
Institution: 
Published: 2026-01-20
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

As Generative Engines revolutionize information retrieval by synthesizing direct answers from retrieved sources, ensuring source visibility becomes a significant challenge. Improving it through targeted content revisions is a practical strategy termed Generative Engine Optimization (GEO). However, optimizing a document for diverse queries presents a constrained optimization challenge where heterogeneous queries often impose conflicting and competing revision requirements under a limited content budget. To address this challenge, we propose IF-GEO, a "diverge-then-converge" framework comprising two phases: (i) mining distinct optimization preferences from representative latent queries; (ii) synthesizing a Global Revision Blueprint for guided editing by coordinating preferences via conflict-aware instruction fusion. To explicitly quantify IF-GEO's objective of cross-query stability, we introduce risk-aware stability metrics. Experiments on multi-query benchmarks demonstrate that IF-GEO achieves substantial performance gains while maintaining robustness across diverse retrieval scenarios.]]></description>
<pubDate>Tue, 20 Jan 2026 13:13:39 +0000</pubDate>
</item>
<item>
<title><![CDATA[TrackletGPT: A Language-like GPT Framework for White Matter Tract Segmentation]]></title>
<link>http://arxiv.org/abs/2601.13935v1</link>
<guid>2601.13935v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.CV, cs.LG
Authors: Anoushkrit Goel, Simroop Singh, Ankita Joshi, Ranjeet Ranjan Jha, Chirag Ahuja et al.
Institution: 
Published: 2026-01-20
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

White Matter Tract Segmentation is imperative for studying brain structural connectivity, neurological disorders and neurosurgery. This task remains complex, as tracts differ among themselves, across subjects and conditions, yet have similar 3D structure across hemispheres and subjects. To address these challenges, we propose TrackletGPT, a language-like GPT framework which reintroduces sequential information in tokens using tracklets. TrackletGPT generalises seamlessly across datasets, is fully automatic, and encodes granular sub-streamline segments, Tracklets, scaling and refining GPT models in Tractography Segmentation. Based on our experiments, TrackletGPT outperforms state-of-the-art methods on average DICE, Overlap and Overreach scores on TractoInferno and HCP datasets, even on inter-dataset experiments.]]></description>
<pubDate>Tue, 20 Jan 2026 13:09:52 +0000</pubDate>
</item>
<item>
<title><![CDATA[Towards Effective Negation Modeling in Joint Audio-Text Models for Music]]></title>
<link>http://arxiv.org/abs/2601.13931v1</link>
<guid>2601.13931v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.SD, cs.IR, cs.LG
Authors: Yannis Vasilakis, Rachel Bittner, Johan Pauwels
Institution: 
Published: 2026-01-20
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Joint audio-text models are widely used for music retrieval, yet they struggle with semantic phenomena such as negation. Negation is fundamental for distinguishing the absence (or presence) of musical elements (e.g., "with vocals" vs. "without vocals"), but current systems fail to represent this reliably. In this work, we investigate and mitigate this limitation by training CLAP models from scratch on the Million Song Dataset with LP-MusicCaps-MSD captions. We introduce negation through text augmentation and a dissimilarity-based contrastive loss, designed to explicitly separate original and negated captions in the joint embedding space. To evaluate progress, we propose two protocols that frame negation modeling as retrieval and binary classification tasks. Experiments demonstrate that both methods, individually and combined, improve negation handling while largely preserving retrieval performance.]]></description>
<pubDate>Tue, 20 Jan 2026 13:06:48 +0000</pubDate>
</item>
<item>
<title><![CDATA[SCG With Your Phone: Diagnosis of Rhythmic Spectrum Disorders in Field Conditions]]></title>
<link>http://arxiv.org/abs/2601.13926v1</link>
<guid>2601.13926v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.LG
Authors: Peter Golenderov, Yaroslav Matushenko, Anastasia Tushina, Michal Barodkin
Institution: 
Published: 2026-01-20
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Aortic valve opening (AO) events are crucial for detecting frequency and rhythm disorders, especially in real-world settings where seismocardiography (SCG) signals collected via consumer smartphones are subject to noise, motion artifacts, and variability caused by device heterogeneity. In this work, we present a robust deep-learning framework for SCG segmentation and rhythm analysis using accelerometer recordings obtained with consumer smartphones. We develop an enhanced U-Net v3 architecture that integrates multi-scale convolutions, residual connections, and attention gates, enabling reliable segmentation of noisy SCG signals. A dedicated post-processing pipeline converts probability masks into precise AO timestamps, whereas a novel adaptive 3D-to-1D projection method ensures robustness to arbitrary smartphone orientation. Experimental results demonstrate that the proposed method achieves consistently high accuracy and robustness across various device types and unsupervised data-collection conditions. Our approach enables practical, low-cost, and automated cardiac-rhythm monitoring using everyday mobile devices, paving the way for scalable, field-deployable cardiovascular assessment and future multimodal diagnostic systems.]]></description>
<pubDate>Tue, 20 Jan 2026 12:58:31 +0000</pubDate>
</item>
<item>
<title><![CDATA[Automatic Prompt Optimization for Dataset-Level Feature Discovery]]></title>
<link>http://arxiv.org/abs/2601.13922v1</link>
<guid>2601.13922v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.CL
Authors: Adrian Cosma, Oleg Szehr, David Kletz, Alessandro Antonucci, Olivier Pelletier
Institution: 
Published: 2026-01-20
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Feature extraction from unstructured text is a critical step in many downstream classification pipelines, yet current approaches largely rely on hand-crafted prompts or fixed feature schemas. We formulate feature discovery as a dataset-level prompt optimization problem: given a labelled text corpus, the goal is to induce a global set of interpretable and discriminative feature definitions whose realizations optimize a downstream supervised learning objective. To this end, we propose a multi-agent prompt optimization framework in which language-model agents jointly propose feature definitions, extract feature values, and evaluate feature quality using dataset-level performance and interpretability feedback. Instruction prompts are iteratively refined based on this structured feedback, enabling optimization over prompts that induce shared feature sets rather than per-example predictions. This formulation departs from prior prompt optimization methods that rely on per-sample supervision and provides a principled mechanism for automatic feature discovery from unstructured text.]]></description>
<pubDate>Tue, 20 Jan 2026 12:51:03 +0000</pubDate>
</item>
<item>
<title><![CDATA[Asymmetric regularization mechanism for GAN training with Variational Inequalities]]></title>
<link>http://arxiv.org/abs/2601.13920v1</link>
<guid>2601.13920v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.GT, cs.AI, cs.LG
Authors: Spyridon C. Giagtzoglou, Mark H. M. Winands, Barbara Franci
Institution: 
Published: 2026-01-20
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

We formulate the training of generative adversarial networks (GANs) as a Nash equilibrium seeking problem. To stabilize the training process and find a Nash equilibrium, we propose an asymmetric regularization mechanism based on the classic Tikhonov step and on a novel zero-centered gradient penalty. Under smoothness and a local identifiability condition induced by a Gauss-Newton Gramian, we obtain explicit Lipschitz and (strong)-monotonicity constants for the regularized operator. These constants ensure last-iterate linear convergence of a single-call Extrapolation-from-the-Past (EFTP) method. Empirical simulations on an academic example show that, even when strong monotonicity cannot be achieved, the asymmetric regularization is enough to converge to an equilibrium and stabilize the trajectory.]]></description>
<pubDate>Tue, 20 Jan 2026 12:50:18 +0000</pubDate>
</item>
<item>
<title><![CDATA[HyperWalker: Dynamic Hypergraph-Based Deep Diagnosis for Multi-Hop Clinical Modeling across EHR and X-Ray in Medical VLMs]]></title>
<link>http://arxiv.org/abs/2601.13919v1</link>
<guid>2601.13919v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.CL, cs.CV
Authors: Yuezhe Yang, Hao Wang, Yige Peng, Jinman Kim, Lei Bi
Institution: 
Published: 2026-01-20
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Automated clinical diagnosis remains a core challenge in medical AI, which usually requires models to integrate multi-modal data and reason across complex, case-specific contexts. Although recent methods have advanced medical report generation (MRG) and visual question answering (VQA) with medical vision-language models (VLMs), these methods, however, predominantly operate under a sample-isolated inference paradigm, as such processing cases independently without access to longitudinal electronic health records (EHRs) or structurally related patient examples. This paradigm limits reasoning to image-derived information alone, which ignores external complementary medical evidence for potentially more accurate diagnosis. To overcome this limitation, we propose \textbf{HyperWalker}, a \textit{Deep Diagnosis} framework that reformulates clinical reasoning via dynamic hypergraphs and test-time training. First, we construct a dynamic hypergraph, termed \textbf{iBrochure}, to model the structural heterogeneity of EHR data and implicit high-order associations among multimodal clinical information. Within this hypergraph, a reinforcement learning agent, \textbf{Walker}, navigates to and identifies optimal diagnostic paths. To ensure comprehensive coverage of diverse clinical characteristics in test samples, we incorporate a \textit{linger mechanism}, a multi-hop orthogonal retrieval strategy that iteratively selects clinically complementary neighborhood cases reflecting distinct clinical attributes. Experiments on MRG with MIMIC and medical VQA on EHRXQA demonstrate that HyperWalker achieves state-of-the-art performance. Code is available at: https://github.com/Bean-Young/HyperWalker]]></description>
<pubDate>Tue, 20 Jan 2026 12:48:09 +0000</pubDate>
</item>
<item>
<title><![CDATA[AgentEHR: Advancing Autonomous Clinical Decision-Making via Retrospective Summarization]]></title>
<link>http://arxiv.org/abs/2601.13918v1</link>
<guid>2601.13918v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.CL
Authors: Yusheng Liao, Chuan Xuan, Yutong Cai, Lina Yang, Zhe Chen et al.
Institution: 
Published: 2026-01-20
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Large Language Models have demonstrated profound utility in the medical domain. However, their application to autonomous Electronic Health Records~(EHRs) navigation remains constrained by a reliance on curated inputs and simplified retrieval tasks. To bridge the gap between idealized experimental settings and realistic clinical environments, we present AgentEHR. This benchmark challenges agents to execute complex decision-making tasks, such as diagnosis and treatment planning, requiring long-range interactive reasoning directly within raw and high-noise databases. In tackling these tasks, we identify that existing summarization methods inevitably suffer from critical information loss and fractured reasoning continuity. To address this, we propose RetroSum, a novel framework that unifies a retrospective summarization mechanism with an evolving experience strategy. By dynamically re-evaluating interaction history, the retrospective mechanism prevents long-context information loss and ensures unbroken logical coherence. Additionally, the evolving strategy bridges the domain gap by retrieving accumulated experience from a memory bank. Extensive empirical evaluations demonstrate that RetroSum achieves performance gains of up to 29.16% over competitive baselines, while significantly decreasing total interaction errors by up to 92.3%.]]></description>
<pubDate>Tue, 20 Jan 2026 12:48:04 +0000</pubDate>
</item>
<item>
<title><![CDATA[On the Role of Rotation Equivariance in Monocular 3D Human Pose Estimation]]></title>
<link>http://arxiv.org/abs/2601.13913v1</link>
<guid>2601.13913v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.CV
Authors: Pavlo Melnyk, Cuong Le, Urs Waldmann, Per-Erik Forssén, Bastian Wandt
Institution: 
Published: 2026-01-20
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Estimating 3D from 2D is one of the central tasks in computer vision. In this work, we consider the monocular setting, i.e. single-view input, for 3D human pose estimation (HPE). Here, the task is to predict a 3D point set of human skeletal joints from a single 2D input image. While by definition this is an ill-posed problem, recent work has presented methods that solve it with up to several-centimetre error. Typically, these methods employ a two-step approach, where the first step is to detect the 2D skeletal joints in the input image, followed by the step of 2D-to-3D lifting. We find that common lifting models fail when encountering a rotated input. We argue that learning a single human pose along with its in-plane rotations is considerably easier and more geometrically grounded than directly learning a point-to-point mapping. Furthermore, our intuition is that endowing the model with the notion of rotation equivariance without explicitly constraining its parameter space should lead to a more straightforward learning process than one with equivariance by design. Utilising the common HPE benchmarks, we confirm that the 2D rotation equivariance per se improves the model performance on human poses akin to rotations in the image plane, and can be efficiently and straightforwardly learned by augmentation, outperforming state-of-the-art equivariant-by-design methods.]]></description>
<pubDate>Tue, 20 Jan 2026 12:41:08 +0000</pubDate>
</item>
<item>
<title><![CDATA[PREFAB: PREFerence-based Affective Modeling for Low-Budget Self-Annotation]]></title>
<link>http://arxiv.org/abs/2601.13904v1</link>
<guid>2601.13904v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.AI, cs.HC
Authors: Jaeyoung Moon, Youjin Choi, Yucheon Park, David Melhart, Georgios N. Yannakakis et al.
Institution: 
Published: 2026-01-20
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Self-annotation is the gold standard for collecting affective state labels in affective computing. Existing methods typically rely on full annotation, requiring users to continuously label affective states across entire sessions. While this process yields fine-grained data, it is time-consuming, cognitively demanding, and prone to fatigue and errors. To address these issues, we present PREFAB, a low-budget retrospective self-annotation method that targets affective inflection regions rather than full annotation. Grounded in the peak-end rule and ordinal representations of emotion, PREFAB employs a preference-learning model to detect relative affective changes, directing annotators to label only selected segments while interpolating the remainder of the stimulus. We further introduce a preview mechanism that provides brief contextual cues to assist annotation. We evaluate PREFAB through a technical performance study and a 25-participant user study. Results show that PREFAB outperforms baselines in modeling affective inflections while mitigating workload (and conditionally mitigating temporal burden). Importantly PREFAB improves annotator confidence without degrading annotation quality.]]></description>
<pubDate>Tue, 20 Jan 2026 12:30:13 +0000</pubDate>
</item>
<item>
<title><![CDATA[Towards Visually Explaining Statistical Tests with Applications in Biomedical Imaging]]></title>
<link>http://arxiv.org/abs/2601.13899v1</link>
<guid>2601.13899v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.CV
Authors: Masoumeh Javanbakhat, Piotr Komorowski, Dilyara Bareeva, Wei-Chang Lai, Wojciech Samek et al.
Institution: 
Published: 2026-01-20
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Deep neural two-sample tests have recently shown strong power for detecting distributional differences between groups, yet their black-box nature limits interpretability and practical adoption in biomedical analysis. Moreover, most existing post-hoc explainability methods rely on class labels, making them unsuitable for label-free statistical testing settings. We propose an explainable deep statistical testing framework that augments deep two-sample tests with sample-level and feature-level explanations, revealing which individual samples and which input features drive statistically significant group differences. Our method highlights which image regions and which individual samples contribute most to the detected group difference, providing spatial and instance-wise insight into the test's decision. Applied to biomedical imaging data, the proposed framework identifies influential samples and highlights anatomically meaningful regions associated with disease-related variation. This work bridges statistical inference and explainable AI, enabling interpretable, label-free population analysis in medical imaging.]]></description>
<pubDate>Tue, 20 Jan 2026 12:27:23 +0000</pubDate>
</item>
<item>
<title><![CDATA[TractRLFusion: A GPT-Based Multi-Critic Policy Fusion Framework for Fiber Tractography]]></title>
<link>http://arxiv.org/abs/2601.13897v1</link>
<guid>2601.13897v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.LG, cs.AI
Authors: Ankita Joshi, Ashutosh Sharma, Anoushkrit Goel, Ranjeet Ranjan Jha, Chirag Ahuja et al.
Institution: 
Published: 2026-01-20
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Tractography plays a pivotal role in the non-invasive reconstruction of white matter fiber pathways, providing vital information on brain connectivity and supporting precise neurosurgical planning. Although traditional methods relied mainly on classical deterministic and probabilistic approaches, recent progress has benefited from supervised deep learning (DL) and deep reinforcement learning (DRL) to improve tract reconstruction. A persistent challenge in tractography is accurately reconstructing white matter tracts while minimizing spurious connections. To address this, we propose TractRLFusion, a novel GPT-based policy fusion framework that integrates multiple RL policies through a data-driven fusion strategy. Our method employs a two-stage training data selection process for effective policy fusion, followed by a multi-critic fine-tuning phase to enhance robustness and generalization. Experiments on HCP, ISMRM, and TractoInferno datasets demonstrate that TractRLFusion outperforms individual RL policies as well as state-of-the-art classical and DRL methods in accuracy and anatomical reliability.]]></description>
<pubDate>Tue, 20 Jan 2026 12:26:38 +0000</pubDate>
</item>
<item>
<title><![CDATA[OmniOVCD: Streamlining Open-Vocabulary Change Detection with SAM 3]]></title>
<link>http://arxiv.org/abs/2601.13895v1</link>
<guid>2601.13895v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.CV, cs.AI
Authors: Xu Zhang, Danyang Li, Yingjie Xia, Xiaohang Dong, Hualong Yu et al.
Institution: 
Published: 2026-01-20
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Change Detection (CD) is a fundamental task in remote sensing. It monitors the evolution of land cover over time. Based on this, Open-Vocabulary Change Detection (OVCD) introduces a new requirement. It aims to reduce the reliance on predefined categories. Existing training-free OVCD methods mostly use CLIP to identify categories. These methods also need extra models like DINO to extract features. However, combining different models often causes problems in matching features and makes the system unstable. Recently, the Segment Anything Model 3 (SAM 3) is introduced. It integrates segmentation and identification capabilities within one promptable model, which offers new possibilities for the OVCD task. In this paper, we propose OmniOVCD, a standalone framework designed for OVCD. By leveraging the decoupled output heads of SAM 3, we propose a Synergistic Fusion to Instance Decoupling (SFID) strategy. SFID first fuses the semantic, instance, and presence outputs of SAM 3 to construct land-cover masks, and then decomposes them into individual instance masks for change comparison. This design preserves high accuracy in category recognition and maintains instance-level consistency across images. As a result, the model can generate accurate change masks. Experiments on four public benchmarks (LEVIR-CD, WHU-CD, S2Looking, and SECOND) demonstrate SOTA performance, achieving IoU scores of 67.2, 66.5, 24.5, and 27.1 (class-average), respectively, surpassing all previous methods.]]></description>
<pubDate>Tue, 20 Jan 2026 12:25:41 +0000</pubDate>
</item>
<item>
<title><![CDATA[Multi-Objective Hierarchical Optimization with Large Language Models]]></title>
<link>http://arxiv.org/abs/2601.13892v1</link>
<guid>2601.13892v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.LG
Authors: Andrej Schwanke, Lyubomir Ivanov, David Salinas, Frank Hutter, Arber Zela
Institution: 
Published: 2026-01-20
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Despite their widespread adoption in various domains, especially due to their powerful reasoning capabilities, Large Language Models (LLMs) are not the off-the-shelf choice to drive multi-objective optimization yet. Conventional strategies rank high in benchmarks due to their intrinsic capabilities to handle numerical inputs and careful modelling choices that balance exploration and Pareto-front exploitation, as well as handle multiple (conflicting) objectives. In this paper, we close this gap by leveraging LLMs as surrogate models and candidate samplers inside a structured hierarchical search strategy. By adaptively partitioning the input space into disjoint hyperrectangular regions and ranking them with a composite score function, we restrict the generative process of the LLM to specific, high-potential sub-spaces, hence making the problem easier to solve as the LLM doesn't have to reason about the global structure of the problem, but only locally instead. We show that under standard regularity assumptions, our algorithm generates candidate solutions that converge to the true Pareto set in Hausdorff distance. Empirically, it consistently outperforms the global LLM-based multi-objective optimizer and is on par with standard evolutionary and Bayesian optimization algorithm on synthetic and real-world benchmarks.]]></description>
<pubDate>Tue, 20 Jan 2026 12:10:13 +0000</pubDate>
</item>
<item>
<title><![CDATA[Human Simulation Computation: A Human-Inspired Framework for Adaptive AI Systems]]></title>
<link>http://arxiv.org/abs/2601.13887v1</link>
<guid>2601.13887v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.AI
Authors: Hong Su
Institution: 
Published: 2026-01-20
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Large language models (LLMs) have demonstrated strong capabilities in knowledge representation and reasoning based on textual data. However, their reliance on language material alone limits their ability to adapt, verify reasoning outcomes, and operate effectively in open and dynamic real-world environments. In this paper, we propose Human Simulation Computation (HSC), a human-inspired computational framework that models intelligence as a continuous, closed-loop process involving thinking, action, learning, reflection, and activity scheduling, collectively referred to as the internal reasoning process. HSC emphasizes active participation both within the internal reasoning process and in interactions with the environment, where actions are used not only to achieve goals but also to automatically refine and improve internal reasoning mechanisms without external intervention. Furthermore, HSC incorporates commonly used human thinking strategies across all stages of the internal reasoning process, such as main-feature-oriented reasoning, scope expansion through action, and on-time learning driven by environmental feedback. Through theoretical analysis, we argue that human simulation strategies cannot be fully learned from language material alone, and that human-like reasoning processes and action-grounded reasoning methods are essential for robust adaptation and effective interaction with real-world environments.]]></description>
<pubDate>Tue, 20 Jan 2026 12:00:04 +0000</pubDate>
</item>
<item>
<title><![CDATA[Revisiting Multi-Task Visual Representation Learning]]></title>
<link>http://arxiv.org/abs/2601.13886v1</link>
<guid>2601.13886v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.CV
Authors: Shangzhe Di, Zhonghua Zhai, Weidi Xie
Institution: 
Published: 2026-01-20
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Current visual representation learning remains bifurcated: vision-language models (e.g., CLIP) excel at global semantic alignment but lack spatial precision, while self-supervised methods (e.g., MAE, DINO) capture intricate local structures yet struggle with high-level semantic context. We argue that these paradigms are fundamentally complementary and can be integrated into a principled multi-task framework, further enhanced by dense spatial supervision. We introduce MTV, a multi-task visual pretraining framework that jointly optimizes a shared backbone across vision-language contrastive, self-supervised, and dense spatial objectives. To mitigate the need for manual annotations, we leverage high-capacity "expert" models -- such as Depth Anything V2 and OWLv2 -- to synthesize dense, structured pseudo-labels at scale. Beyond the framework, we provide a systematic investigation into the mechanics of multi-task visual learning, analyzing: (i) the marginal gain of each objective, (ii) task synergies versus interference, and (iii) scaling behavior across varying data and model scales. Our results demonstrate that MTV achieves "best-of-both-worlds" performance, significantly enhancing fine-grained spatial reasoning without compromising global semantic understanding. Our findings suggest that multi-task learning, fueled by high-quality pseudo-supervision, is a scalable path toward more general visual encoders.]]></description>
<pubDate>Tue, 20 Jan 2026 11:59:19 +0000</pubDate>
</item>
<item>
<title><![CDATA[Confident Rankings with Fewer Items: Adaptive LLM Evaluation with Continuous Scores]]></title>
<link>http://arxiv.org/abs/2601.13885v1</link>
<guid>2601.13885v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.CL, cs.AI
Authors: Esma Balkır, Alice Pernthaller, Marco Basaldella, José Hernández-Orallo, Nigel Collier
Institution: 
Published: 2026-01-20
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Computerized Adaptive Testing (CAT) has proven effective for efficient LLM evaluation on multiple-choice benchmarks, but modern LLM evaluation increasingly relies on generation tasks where outputs are scored continuously rather than marked correct/incorrect. We present a principled extension of IRT-based adaptive testing to continuous bounded scores (ROUGE, BLEU, LLM-as-a-Judge) by replacing the Bernoulli response distribution with a heteroskedastic normal distribution. Building on this, we introduce an uncertainty aware ranker with adaptive stopping criteria that achieves reliable model ranking while testing as few items and as cheaply as possible. We validate our method on five benchmarks spanning n-gram-based, embedding-based, and LLM-as-judge metrics. Our method uses 2% of the items while improving ranking correlation by 0.12 τ over random sampling, with 95% accuracy on confident predictions.]]></description>
<pubDate>Tue, 20 Jan 2026 11:59:13 +0000</pubDate>
</item>
<item>
<title><![CDATA[OpenLearnLM Benchmark: A Unified Framework for Evaluating Knowledge, Skill, and Attitude in Educational Large Language Models]]></title>
<link>http://arxiv.org/abs/2601.13882v1</link>
<guid>2601.13882v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.CL
Authors: Unggi Lee, Sookbun Lee, Heungsoo Choi, Jinseo Lee, Haeun Park et al.
Institution: 
Published: 2026-01-20
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Large Language Models are increasingly deployed as educational tools, yet existing benchmarks focus on narrow skills and lack grounding in learning sciences. We introduce OpenLearnLM Benchmark, a theory-grounded framework evaluating LLMs across three dimensions derived from educational assessment theory: Knowledge (curriculum-aligned content and pedagogical understanding), Skills (scenario-based competencies organized through a four-level center-role-scenario-subscenario hierarchy), and Attitude (alignment consistency and deception resistance). Our benchmark comprises 124K+ items spanning multiple subjects, educational roles, and difficulty levels based on Bloom's taxonomy. The Knowledge domain prioritizes authentic assessment items from established benchmarks, while the Attitude domain adapts Anthropic's Alignment Faking methodology to detect behavioral inconsistency under varying monitoring conditions. Evaluation of seven frontier models reveals distinct capability profiles: Claude-Opus-4.5 excels in practical skills despite lower content knowledge, while Grok-4.1-fast leads in knowledge but shows alignment concerns. Notably, no single model dominates all dimensions, validating the necessity of multi-axis evaluation. OpenLearnLM provides an open, comprehensive framework for advancing LLM readiness in authentic educational contexts.]]></description>
<pubDate>Tue, 20 Jan 2026 11:53:31 +0000</pubDate>
</item>
<item>
<title><![CDATA[LifeAgentBench: A Multi-dimensional Benchmark and Agent for Personal Health Assistants in Digital Health]]></title>
<link>http://arxiv.org/abs/2601.13880v1</link>
<guid>2601.13880v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.AI
Authors: Ye Tian, Zihao Wang, Onat Gungor, Xiaoran Fan, Tajana Rosing
Institution: 
Published: 2026-01-20
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Personalized digital health support requires long-horizon, cross-dimensional reasoning over heterogeneous lifestyle signals, and recent advances in mobile sensing and large language models (LLMs) make such support increasingly feasible. However, the capabilities of current LLMs in this setting remain unclear due to the lack of systematic benchmarks. In this paper, we introduce LifeAgentBench, a large-scale QA benchmark for long-horizon, cross-dimensional, and multi-user lifestyle health reasoning, containing 22,573 questions spanning from basic retrieval to complex reasoning. We release an extensible benchmark construction pipeline and a standardized evaluation protocol to enable reliable and scalable assessment of LLM-based health assistants. We then systematically evaluate 11 leading LLMs on LifeAgentBench and identify key bottlenecks in long-horizon aggregation and cross-dimensional reasoning. Motivated by these findings, we propose LifeAgent as a strong baseline agent for health assistant that integrates multi-step evidence retrieval with deterministic aggregation, achieving significant improvements compared with two widely used baselines. Case studies further demonstrate its potential in realistic daily-life scenarios. The benchmark is publicly available at https://anonymous.4open.science/r/LifeAgentBench-CE7B.]]></description>
<pubDate>Tue, 20 Jan 2026 11:51:58 +0000</pubDate>
</item>
<item>
<title><![CDATA[Chain-of-Thought Compression Should Not Be Blind: V-Skip for Efficient Multimodal Reasoning via Dual-Path Anchoring]]></title>
<link>http://arxiv.org/abs/2601.13879v1</link>
<guid>2601.13879v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.MM, cs.CL, cs.CV
Authors: Dongxu Zhang, Yiding Sun, Cheng Tan, Wenbiao Yan, Ning Yang et al.
Institution: 
Published: 2026-01-20
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

While Chain-of-Thought (CoT) reasoning significantly enhances the performance of Multimodal Large Language Models (MLLMs), its autoregressive nature incurs prohibitive latency constraints. Current efforts to mitigate this via token compression often fail by blindly applying text-centric metrics to multimodal contexts. We identify a critical failure mode termed Visual Amnesia, where linguistically redundant tokens are erroneously pruned, leading to hallucinations. To address this, we introduce V-Skip that reformulates token pruning as a Visual-Anchored Information Bottleneck (VA-IB) optimization problem. V-Skip employs a dual-path gating mechanism that weighs token importance through both linguistic surprisal and cross-modal attention flow, effectively rescuing visually salient anchors. Extensive experiments on Qwen2-VL and Llama-3.2 families demonstrate that V-Skip achieves a $2.9\times$ speedup with negligible accuracy loss. Specifically, it preserves fine-grained visual details, outperforming other baselines over 30\% on the DocVQA.]]></description>
<pubDate>Tue, 20 Jan 2026 11:45:38 +0000</pubDate>
</item>
<item>
<title><![CDATA[Pedagogical Alignment for Vision-Language-Action Models: A Comprehensive Framework for Data, Architecture, and Evaluation in Education]]></title>
<link>http://arxiv.org/abs/2601.13876v1</link>
<guid>2601.13876v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.CL
Authors: Unggi Lee, Jahyun Jeong, Sunyoung Shin, Haeun Park, Jeongsu Moon et al.
Institution: 
Published: 2026-01-20
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Science demonstrations are important for effective STEM education, yet teachers face challenges in conducting them safely and consistently across multiple occasions, where robotics can be helpful. However, current Vision-Language-Action (VLA) models require substantial computational resources and sacrifice language generation capabilities to maximize efficiency, making them unsuitable for resource-constrained educational settings that require interpretable, explanation-generating systems. We present \textit{Pedagogical VLA Framework}, a framework that applies pedagogical alignment to lightweight VLA models through four components: text healing to restore language generation capabilities, large language model (LLM) distillation to transfer pedagogical knowledge, safety training for educational environments, and pedagogical evaluation adjusted to science education contexts. We evaluate Pedagogical VLA Framework across five science demonstrations spanning physics, chemistry, biology, and earth science, using an evaluation framework developed in collaboration with science education experts. Our evaluation assesses both task performance (success rate, protocol compliance, efficiency, safety) and pedagogical quality through teacher surveys and LLM-as-Judge assessment. We additionally provide qualitative analysis of generated texts. Experimental results demonstrate that Pedagogical VLA Framework achieves comparable task performance to baseline models while producing contextually appropriate educational explanations.]]></description>
<pubDate>Tue, 20 Jan 2026 11:43:15 +0000</pubDate>
</item>
<item>
<title><![CDATA[Unified Unbiased Variance Estimation for MMD: Robust Finite-Sample Performance with Imbalanced Data and Exact Acceleration under Null and Alternative Hypotheses]]></title>
<link>http://arxiv.org/abs/2601.13874v1</link>
<guid>2601.13874v1</guid>
<description><![CDATA[Source: arXiv
Tags: stat.ML, cs.LG
Authors: Shijie Zhong, Jiangfeng Fu, Yikun Yang
Institution: 
Published: 2026-01-20
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

The maximum mean discrepancy (MMD) is a kernel-based nonparametric statistic for two-sample testing, whose inferential accuracy depends critically on variance characterization. Existing work provides various finite-sample estimators of the MMD variance, often differing under the null and alternative hypotheses and across balanced or imbalanced sampling schemes. In this paper, we study the variance of the MMD statistic through its U-statistic representation and Hoeffding decomposition, and establish a unified finite-sample characterization covering different hypotheses and sample configurations. Building on this analysis, we propose an exact acceleration method for the univariate case under the Laplacian kernel, which reduces the overall computational complexity from $\mathcal O(n^2)$ to $\mathcal O(n \log n)$.]]></description>
<pubDate>Tue, 20 Jan 2026 11:41:32 +0000</pubDate>
</item>
<item>
<title><![CDATA[OCCAM: Class-Agnostic, Training-Free, Prior-Free and Multi-Class Object Counting]]></title>
<link>http://arxiv.org/abs/2601.13871v1</link>
<guid>2601.13871v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.CV
Authors: Michail Spanakis, Iason Oikonomidis, Antonis Argyros
Institution: 
Published: 2026-01-20
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Class-Agnostic object Counting (CAC) involves counting instances of objects from arbitrary classes within an image. Due to its practical importance, CAC has received increasing attention in recent years. Most existing methods assume a single object class per image, rely on extensive training of large deep learning models and address the problem by incorporating additional information, such as visual exemplars or text prompts. In this paper, we present OCCAM, the first training-free approach to CAC that operates without the need of any supplementary information. Moreover, our approach addresses the multi-class variant of the problem, as it is capable of counting the object instances in each and every class among arbitrary object classes within an image. We leverage Segment Anything Model 2 (SAM2), a foundation model, and a custom threshold-based variant of the First Integer Neighbor Clustering Hierarchy (FINCH) algorithm to achieve competitive performance on widely used benchmark datasets, FSC-147 and CARPK. We propose a synthetic multi-class dataset and F1 score as a more suitable evaluation metric. The code for our method and the proposed synthetic dataset will be made publicly available at https://mikespanak.github.io/OCCAM_counter.]]></description>
<pubDate>Tue, 20 Jan 2026 11:36:38 +0000</pubDate>
</item>
<item>
<title><![CDATA[HardSecBench: Benchmarking the Security Awareness of LLMs for Hardware Code Generation]]></title>
<link>http://arxiv.org/abs/2601.13864v1</link>
<guid>2601.13864v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.CR, cs.AI
Authors: Qirui Chen, Jingxian Shuai, Shuangwu Chen, Shenghao Ye, Zijian Wen et al.
Institution: 
Published: 2026-01-20
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Large language models (LLMs) are being increasingly integrated into practical hardware and firmware development pipelines for code generation. Existing studies have primarily focused on evaluating the functional correctness of LLM-generated code, yet paid limited attention to its security issues. However, LLM-generated code that appears functionally sound may embed security flaws which could induce catastrophic damages after deployment. This critical research gap motivates us to design a benchmark for assessing security awareness under realistic specifications. In this work, we introduce HardSecBench, a benchmark with 924 tasks spanning Verilog Register Transfer Level (RTL) and firmware-level C, covering 76 hardware-relevant Common Weakness Enumeration (CWE) entries. Each task includes a structured specification, a secure reference implementation, and executable tests. To automate artifact synthesis, we propose a multi-agent pipeline that decouples synthesis from verification and grounds evaluation in execution evidence, enabling reliable evaluation. Using HardSecBench, we evaluate a range of LLMs on hardware and firmware code generation and find that models often satisfy functional requirements while still leaving security risks. We also find that security results vary with prompting. These findings highlight pressing challenges and offer actionable insights for future advancements in LLM-assisted hardware design. Our data and code will be released soon.]]></description>
<pubDate>Tue, 20 Jan 2026 11:27:40 +0000</pubDate>
</item>
<item>
<title><![CDATA[Probabilistic Deep Discriminant Analysis for Wind Blade Segmentation]]></title>
<link>http://arxiv.org/abs/2601.13852v1</link>
<guid>2601.13852v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.CV, cs.LG
Authors: Raül Pérez-Gonzalo, Andreas Espersen, Antonio Agudo
Institution: 
Published: 2026-01-20
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Linear discriminant analysis improves class separability but struggles with non-linearly separable data. To overcome this, we introduce Deep Discriminant Analysis (DDA), which directly optimizes the Fisher criterion utilizing deep networks. To ensure stable training and avoid computational instabilities, we incorporate signed between-class variance, bound outputs with a sigmoid function, and convert multiplicative relationships into additive ones. We present two stable DDA loss functions and augment them with a probability loss, resulting in Probabilistic DDA (PDDA). PDDA effectively minimizes class overlap in output distributions, producing highly confident predictions with reduced within-class variance. When applied to wind blade segmentation, PDDA showcases notable advances in performance and consistency, critical for wind energy maintenance. To our knowledge, this is the first application of DDA to image segmentation.]]></description>
<pubDate>Tue, 20 Jan 2026 11:03:51 +0000</pubDate>
</item>
<item>
<title><![CDATA[Inverting Self-Organizing Maps: A Unified Activation-Based Framework]]></title>
<link>http://arxiv.org/abs/2601.13851v1</link>
<guid>2601.13851v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.LG, stat.ML
Authors: Alessandro Londei, Matteo Benati, Denise Lanzieri, Vittorio Loreto
Institution: 
Published: 2026-01-20
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Self-Organizing Maps provide topology-preserving projections of high-dimensional data and have been widely used for visualization, clustering, and vector quantization. In this work, we show that the activation pattern of a SOM - the squared distances to its prototypes - can be inverted to recover the exact input under mild geometric conditions. This follows from a classical fact in Euclidean distance geometry: a point in $D$ dimensions is uniquely determined by its distances to $D{+}1$ affinely independent references. We derive the corresponding linear system and characterize the conditions under which the inversion is well-posed. Building upon this mechanism, we introduce the Manifold-Aware Unified SOM Inversion and Control (MUSIC) update rule, which enables controlled, semantically meaningful trajectories in latent space. MUSIC modifies squared distances to selected prototypes while preserving others, resulting in a deterministic geometric flow aligned with the SOM's piecewise-linear structure. Tikhonov regularization stabilizes the update rule and ensures smooth motion on high-dimensional datasets. Unlike variational or probabilistic generative models, MUSIC does not rely on sampling, latent priors, or encoder-decoder architectures. If no perturbation is applied, inversion recovers the exact input; when a target cluster or prototype is specified, MUSIC produces coherent semantic variations while remaining on the data manifold. This leads to a new perspective on data augmentation and controllable latent exploration based solely on prototype geometry. We validate the approach using synthetic Gaussian mixtures, the MNIST and the Faces in the Wild dataset. Across all settings, MUSIC produces smooth, interpretable trajectories that reveal the underlying geometry of the learned manifold, illustrating the advantages of SOM-based inversion over unsupervised clustering.]]></description>
<pubDate>Tue, 20 Jan 2026 11:02:54 +0000</pubDate>
</item>
<item>
<title><![CDATA[Co-Initialization of Control Filter and Secondary Path via Meta-Learning for Active Noise Control]]></title>
<link>http://arxiv.org/abs/2601.13849v1</link>
<guid>2601.13849v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.LG
Authors: Ziyi Yang, Li Rao, Zhengding Luo, Dongyuan Shi, Qirui Huang et al.
Institution: 
Published: 2026-01-20
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Active noise control (ANC) must adapt quickly when the acoustic environment changes, yet early performance is largely dictated by initialization. We address this with a Model-Agnostic Meta-Learning (MAML) co-initialization that jointly sets the control filter and the secondary-path model for FxLMS-based ANC while keeping the runtime algorithm unchanged. The initializer is pre-trained on a small set of measured paths using short two-phase inner loops that mimic identification followed by residual-noise reduction, and is applied by simply setting the learned initial coefficients. In an online secondary path modeling FxLMS testbed, it yields lower early-stage error, shorter time-to-target, reduced auxiliary-noise energy, and faster recovery after path changes than a baseline without re-initialization. The method provides a simple fast start for feedforward ANC under environment changes, requiring a small set of paths to pre-train.]]></description>
<pubDate>Tue, 20 Jan 2026 11:02:03 +0000</pubDate>
</item>
<item>
<title><![CDATA[Virtual Urbanism: An AI-Driven Framework for Quantifying Urban Identity. A Tokyo-Based Pilot Study Using Diffusion-Generated Synthetic Environments]]></title>
<link>http://arxiv.org/abs/2601.13846v1</link>
<guid>2601.13846v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.AI, cs.CY, cs.LG
Authors: Glinskaya Maria
Institution: 
Published: 2026-01-20
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

This paper introduces Virtual Urbanism (VU), a multimodal AI-driven analytical framework for quantifying urban identity through the medium of synthetic urban replicas. The framework aims to advance computationally tractable urban identity metrics. To demonstrate feasibility, the pilot study Virtual Urbanism and Tokyo Microcosms is presented. A pipeline integrating Stable Diffusion and LoRA models was used to produce synthetic replicas of nine Tokyo areas rendered as dynamic synthetic urban sequences, excluding existing orientation markers to elicit core identity-forming elements. Human-evaluation experiments (I) assessed perceptual legitimacy of replicas; (II) quantified area-level identity; (III) derived core identity-forming elements. Results showed a mean identification accuracy of ~81%, confirming the validity of the replicas. Urban Identity Level (UIL) metric enabled assessment of identity levels across areas, while semantic analysis revealed culturally embedded typologies as core identity-forming elements, positioning VU as a viable framework for AI-augmented urban analysis, outlining a path toward automated, multi-parameter identity metrics.]]></description>
<pubDate>Tue, 20 Jan 2026 10:59:44 +0000</pubDate>
</item>
<item>
<title><![CDATA[Optimal L2 Regularization in High-dimensional Continual Linear Regression]]></title>
<link>http://arxiv.org/abs/2601.13844v1</link>
<guid>2601.13844v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.LG
Authors: Gilad Karpel, Edward Moroshko, Ran Levinstein, Ron Meir, Daniel Soudry et al.
Institution: 
Published: 2026-01-20
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

We study generalization in an overparameterized continual linear regression setting, where a model is trained with L2 (isotropic) regularization across a sequence of tasks. We derive a closed-form expression for the expected generalization loss in the high-dimensional regime that holds for arbitrary linear teachers. We demonstrate that isotropic regularization mitigates label noise under both single-teacher and multiple i.i.d. teacher settings, whereas prior work accommodating multiple teachers either did not employ regularization or used memory-demanding methods. Furthermore, we prove that the optimal fixed regularization strength scales nearly linearly with the number of tasks $T$, specifically as $T/\ln T$. To our knowledge, this is the first such result in theoretical continual learning. Finally, we validate our theoretical findings through experiments on linear regression and neural networks, illustrating how this scaling law affects generalization and offering a practical recipe for the design of continual learning systems.]]></description>
<pubDate>Tue, 20 Jan 2026 10:58:14 +0000</pubDate>
</item>
<item>
<title><![CDATA[DisasterVQA: A Visual Question Answering Benchmark Dataset for Disaster Scenes]]></title>
<link>http://arxiv.org/abs/2601.13839v1</link>
<guid>2601.13839v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.CV
Authors: Aisha Al-Mohannadi, Ayisha Firoz, Yin Yang, Muhammad Imran, Ferda Ofli
Institution: 
Published: 2026-01-20
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Social media imagery provides a low-latency source of situational information during natural and human-induced disasters, enabling rapid damage assessment and response. While Visual Question Answering (VQA) has shown strong performance in general-purpose domains, its suitability for the complex and safety-critical reasoning required in disaster response remains unclear. We introduce DisasterVQA, a benchmark dataset designed for perception and reasoning in crisis contexts. DisasterVQA consists of 1,395 real-world images and 4,405 expert-curated question-answer pairs spanning diverse events such as floods, wildfires, and earthquakes. Grounded in humanitarian frameworks including FEMA ESF and OCHA MIRA, the dataset includes binary, multiple-choice, and open-ended questions covering situational awareness and operational decision-making tasks. We benchmark seven state-of-the-art vision-language models and find performance variability across question types, disaster categories, regions, and humanitarian tasks. Although models achieve high accuracy on binary questions, they struggle with fine-grained quantitative reasoning, object counting, and context-sensitive interpretation, particularly for underrepresented disaster scenarios. DisasterVQA provides a challenging and practical benchmark to guide the development of more robust and operationally meaningful vision-language models for disaster response. The dataset is publicly available at https://zenodo.org/records/18267770.]]></description>
<pubDate>Tue, 20 Jan 2026 10:50:46 +0000</pubDate>
</item>
<item>
<title><![CDATA[FastGHA: Generalized Few-Shot 3D Gaussian Head Avatars with Real-Time Animation]]></title>
<link>http://arxiv.org/abs/2601.13837v1</link>
<guid>2601.13837v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.CV
Authors: Xinya Ji, Sebastian Weiss, Manuel Kansy, Jacek Naruniec, Xun Cao et al.
Institution: 
Published: 2026-01-20
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Despite recent progress in 3D Gaussian-based head avatar modeling, efficiently generating high fidelity avatars remains a challenge. Current methods typically rely on extensive multi-view capture setups or monocular videos with per-identity optimization during inference, limiting their scalability and ease of use on unseen subjects. To overcome these efficiency drawbacks, we propose \OURS, a feed-forward method to generate high-quality Gaussian head avatars from only a few input images while supporting real-time animation. Our approach directly learns a per-pixel Gaussian representation from the input images, and aggregates multi-view information using a transformer-based encoder that fuses image features from both DINOv3 and Stable Diffusion VAE. For real-time animation, we extend the explicit Gaussian representations with per-Gaussian features and introduce a lightweight MLP-based dynamic network to predict 3D Gaussian deformations from expression codes. Furthermore, to enhance geometric smoothness of the 3D head, we employ point maps from a pre-trained large reconstruction model as geometry supervision. Experiments show that our approach significantly outperforms existing methods in both rendering quality and inference efficiency, while supporting real-time dynamic avatar animation.]]></description>
<pubDate>Tue, 20 Jan 2026 10:49:49 +0000</pubDate>
</item>
<item>
<title><![CDATA[The Role of Prosodic and Lexical Cues in Turn-Taking with Self-Supervised Speech Representations]]></title>
<link>http://arxiv.org/abs/2601.13835v1</link>
<guid>2601.13835v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.CL
Authors: Sam OConnor Russell, Delphine Charuau, Naomi Harte
Institution: 
Published: 2026-01-20
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Fluid turn-taking remains a key challenge in human-robot interaction. Self-supervised speech representations (S3Rs) have driven many advances, but it remains unclear whether S3R-based turn-taking models rely on prosodic cues, lexical cues or both. We introduce a vocoder-based approach to control prosody and lexical cues in speech more cleanly than prior work. This allows us to probe the voice-activity projection model, an S3R-based turn-taking model. We find that prediction on prosody-matched, unintelligible noise is similar to accuracy on clean speech. This reveals both prosodic and lexical cues support turn-taking, but either can be used in isolation. Hence, future models may only require prosody, providing privacy and potential performance benefits. When either prosodic or lexical information is disrupted, the model exploits the other without further training, indicating they are encoded in S3Rs with limited interdependence. Results are consistent in CPC-based and wav2vec2.0 S3Rs. We discuss our findings and highlight a number of directions for future work. All code is available to support future research.]]></description>
<pubDate>Tue, 20 Jan 2026 10:45:12 +0000</pubDate>
</item>
<item>
<title><![CDATA[ELSA: Efficient LLM-Centric Split Aggregation for Privacy-Aware Hierarchical Federated Learning over Resource-Constrained Edge Networks]]></title>
<link>http://arxiv.org/abs/2601.13824v1</link>
<guid>2601.13824v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.LG
Authors: Xiaohong Yang, Tong Xie, Minghui Liwang, Chikai Shang, Yang Lu et al.
Institution: 
Published: 2026-01-20
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Training large language models (LLMs) at the network edge faces fundamental challenges arising from device resource constraints, severe data heterogeneity, and heightened privacy risks. To address these, we propose ELSA (Efficient LLM-centric Split Aggregation), a novel framework that systematically integrates split learning (SL) and hierarchical federated learning (HFL) for distributed LLM fine-tuning over resource-constrained edge networks. ELSA introduces three key innovations. First, it employs a task-agnostic, behavior-aware client clustering mechanism that constructs semantic fingerprints using public probe inputs and symmetric KL divergence, further enhanced by prediction-consistency-based trust scoring and latency-aware edge assignment to jointly address data heterogeneity, client unreliability, and communication constraints. Second, it splits the LLM into three parts across clients and edge servers, with the cloud used only for adapter aggregation, enabling an effective balance between on-device computation cost and global convergence stability. Third, it incorporates a lightweight communication scheme based on computational sketches combined with semantic subspace orthogonal perturbation (SS-OP) to reduce communication overhead while mitigating privacy leakage during model exchanges. Experiments across diverse NLP tasks demonstrate that ELSA consistently outperforms state-of-the-art methods in terms of adaptability, convergence behavior, and robustness, establishing a scalable and privacy-aware solution for edge-side LLM fine-tuning under resource constraints.]]></description>
<pubDate>Tue, 20 Jan 2026 10:33:19 +0000</pubDate>
</item>
<item>
<title><![CDATA[Device Association and Resource Allocation for Hierarchical Split Federated Learning in Space-Air-Ground Integrated Network]]></title>
<link>http://arxiv.org/abs/2601.13817v1</link>
<guid>2601.13817v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.DC, cs.LG
Authors: Haitao Zhao, Xiaoyu Tang, Bo Xu, Jinlong Sun, Linghao Zhang
Institution: 
Published: 2026-01-20
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

6G facilitates deployment of Federated Learning (FL) in the Space-Air-Ground Integrated Network (SAGIN), yet FL confronts challenges such as resource constrained and unbalanced data distribution. To address these issues, this paper proposes a Hierarchical Split Federated Learning (HSFL) framework and derives its upper bound of loss function. To minimize the weighted sum of training loss and latency, we formulate a joint optimization problem that integrates device association, model split layer selection, and resource allocation. We decompose the original problem into several subproblems, where an iterative optimization algorithm for device association and resource allocation based on brute-force split point search is proposed. Simulation results demonstrate that the proposed algorithm can effectively balance training efficiency and model accuracy for FL in SAGIN.]]></description>
<pubDate>Tue, 20 Jan 2026 10:24:10 +0000</pubDate>
</item>
<item>
<title><![CDATA[Discriminant Learning-based Colorspace for Blade Segmentation]]></title>
<link>http://arxiv.org/abs/2601.13816v1</link>
<guid>2601.13816v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.CV, cs.LG
Authors: Raül Pérez-Gonzalo, Andreas Espersen, Antonio Agudo
Institution: 
Published: 2026-01-20
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Suboptimal color representation often hinders accurate image segmentation, yet many modern algorithms neglect this critical preprocessing step. This work presents a novel multidimensional nonlinear discriminant analysis algorithm, Colorspace Discriminant Analysis (CSDA), for improved segmentation. Extending Linear Discriminant Analysis into a deep learning context, CSDA customizes color representation by maximizing multidimensional signed inter-class separability while minimizing intra-class variability through a generalized discriminative loss. To ensure stable training, we introduce three alternative losses that enable end-to-end optimization of both the discriminative colorspace and segmentation process. Experiments on wind turbine blade data demonstrate significant accuracy gains, emphasizing the importance of tailored preprocessing in domain-specific segmentation.]]></description>
<pubDate>Tue, 20 Jan 2026 10:23:23 +0000</pubDate>
</item>
<item>
<title><![CDATA[DroneVLA: VLA based Aerial Manipulation]]></title>
<link>http://arxiv.org/abs/2601.13809v1</link>
<guid>2601.13809v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.RO, cs.AI
Authors: Fawad Mehboob, Monijesu James, Amir Habel, Jeffrin Sam, Miguel Altamirano Cabrera et al.
Institution: 
Published: 2026-01-20
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

As aerial platforms evolve from passive observers to active manipulators, the challenge shifts toward designing intuitive interfaces that allow non-expert users to command these systems naturally. This work introduces a novel concept of autonomous aerial manipulation system capable of interpreting high-level natural language commands to retrieve objects and deliver them to a human user. The system is intended to integrate a MediaPipe based on Grounding DINO and a Vision-Language-Action (VLA) model with a custom-built drone equipped with a 1-DOF gripper and an Intel RealSense RGB-D camera. VLA performs semantic reasoning to interpret the intent of a user prompt and generates a prioritized task queue for grasping of relevant objects in the scene. Grounding DINO and dynamic A* planning algorithm are used to navigate and safely relocate the object. To ensure safe and natural interaction during the handover phase, the system employs a human-centric controller driven by MediaPipe. This module provides real-time human pose estimation, allowing the drone to employ visual servoing to maintain a stable, distinct position directly in front of the user, facilitating a comfortable handover. We demonstrate the system's efficacy through real-world experiments for localization and navigation, which resulted in a 0.164m, 0.070m, and 0.084m of max, mean euclidean, and root-mean squared errors, respectively, highlighting the feasibility of VLA for aerial manipulation operations.]]></description>
<pubDate>Tue, 20 Jan 2026 10:08:00 +0000</pubDate>
</item>
<item>
<title><![CDATA[Knowledge Graph-Assisted LLM Post-Training for Enhanced Legal Reasoning]]></title>
<link>http://arxiv.org/abs/2601.13806v1</link>
<guid>2601.13806v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.CL, cs.LG
Authors: Dezhao Song, Guglielmo Bonifazi, Frank Schilder, Jonathan Richard Schwarz
Institution: 
Published: 2026-01-20
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

LLM post-training has primarily relied on large text corpora and human feedback, without capturing the structure of domain knowledge. This has caused models to struggle dealing with complex reasoning tasks, especially for high-stakes professional domains. In Law, reasoning requires deep understanding of the relations between various legal concepts, a key component missing in current LLM post-training. In this paper, we propose a knowledge graph (KG)-assisted approach for enhancing LLMs' reasoning capability in Legal that is generalizable to other high-stakes domains. We model key legal concepts by following the \textbf{IRAC} (Issue, Rule, Analysis and Conclusion) framework, and construct a KG with 12K legal cases. We then produce training data using our IRAC KG, and conduct both Supervised Fine-Tuning (SFT) and Direct Preference Optimization (DPO) with three state-of-the-art (SOTA) LLMs (30B, 49B and 70B), varying architecture and base model family. Our post-trained models obtained better average performance on 4/5 diverse legal benchmarks (14 tasks) than baselines. In particular, our 70B DPO model achieved the best score on 4/6 reasoning tasks, among baselines and a 141B SOTA legal LLM, demonstrating the effectiveness of our KG for enhancing LLMs' legal reasoning capability.]]></description>
<pubDate>Tue, 20 Jan 2026 10:06:34 +0000</pubDate>
</item>
<item>
<title><![CDATA[Habibi: Laying the Open-Source Foundation of Unified-Dialectal Arabic Speech Synthesis]]></title>
<link>http://arxiv.org/abs/2601.13802v1</link>
<guid>2601.13802v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.CL, cs.SD
Authors: Yushen Chen, Junzhe Liu, Yujie Tu, Zhikang Niu, Yuzhe Liang et al.
Institution: 
Published: 2026-01-20
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

A notable gap persists in speech synthesis research and development for Arabic dialects, particularly from a unified modeling perspective. Despite its high practical value, the inherent linguistic complexity of Arabic dialects, further compounded by a lack of standardized data, benchmarks, and evaluation guidelines, steers researchers toward safer ground. To bridge this divide, we present Habibi, a suite of specialized and unified text-to-speech models that harnesses existing open-source ASR corpora to support a wide range of high- to low-resource Arabic dialects through linguistically-informed curriculum learning. Our approach outperforms the leading commercial service in generation quality, while maintaining extensibility through effective in-context learning, without requiring text diacritization. We are committed to open-sourcing the model, along with creating the first systematic benchmark for multi-dialect Arabic speech synthesis. Furthermore, by identifying the key challenges in and establishing evaluation standards for the process, we aim to provide a solid groundwork for subsequent research. Resources at https://SWivid.github.io/Habibi/ .]]></description>
<pubDate>Tue, 20 Jan 2026 10:02:11 +0000</pubDate>
</item>
<item>
<title><![CDATA[Insight: Interpretable Semantic Hierarchies in Vision-Language Encoders]]></title>
<link>http://arxiv.org/abs/2601.13798v1</link>
<guid>2601.13798v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.CV, cs.AI, cs.LG
Authors: Kai Wittenmayer, Sukrut Rao, Amin Parchami-Araghi, Bernt Schiele, Jonas Fischer
Institution: 
Published: 2026-01-20
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Language-aligned vision foundation models perform strongly across diverse downstream tasks. Yet, their learned representations remain opaque, making interpreting their decision-making hard. Recent works decompose these representations into human-interpretable concepts, but provide poor spatial grounding and are limited to image classification tasks. In this work, we propose Insight, a language-aligned concept foundation model that provides fine-grained concepts, which are human-interpretable and spatially grounded in the input image. We leverage a hierarchical sparse autoencoder and a foundation model with strong semantic representations to automatically extract concepts at various granularities. Examining local co-occurrence dependencies of concepts allows us to define concept relationships. Through these relations we further improve concept naming and obtain richer explanations. On benchmark data, we show that Insight provides performance on classification and segmentation that is competitive with opaque foundation models while providing fine-grained, high quality concept-based explanations. Code is available at https://github.com/kawi19/Insight.]]></description>
<pubDate>Tue, 20 Jan 2026 09:57:26 +0000</pubDate>
</item>
<item>
<title><![CDATA[PREGEN: Uncovering Latent Thoughts in Composed Video Retrieval]]></title>
<link>http://arxiv.org/abs/2601.13797v1</link>
<guid>2601.13797v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.CV
Authors: Gabriele Serussi, David Vainshtein, Jonathan Kouchly, Dotan Di Castro, Chaim Baskin
Institution: 
Published: 2026-01-20
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Composed Video Retrieval (CoVR) aims to retrieve a video based on a query video and a modifying text. Current CoVR methods fail to fully exploit modern Vision-Language Models (VLMs), either using outdated architectures or requiring computationally expensive fine-tuning and slow caption generation. We introduce PREGEN (PRE GENeration extraction), an efficient and powerful CoVR framework that overcomes these limitations. Our approach uniquely pairs a frozen, pre-trained VLM with a lightweight encoding model, eliminating the need for any VLM fine-tuning. We feed the query video and modifying text into the VLM and extract the hidden state of the final token from each layer. A simple encoder is then trained on these pooled representations, creating a semantically rich and compact embedding for retrieval. PREGEN significantly advances the state of the art, surpassing all prior methods on standard CoVR benchmarks with substantial gains in Recall@1 of +27.23 and +69.59. Our method demonstrates robustness across different VLM backbones and exhibits strong zero-shot generalization to more complex textual modifications, highlighting its effectiveness and semantic capabilities.]]></description>
<pubDate>Tue, 20 Jan 2026 09:57:04 +0000</pubDate>
</item>
<item>
<title><![CDATA[PAtt: A Pattern Attention Network for ETA Prediction Using Historical Speed Profiles]]></title>
<link>http://arxiv.org/abs/2601.13793v1</link>
<guid>2601.13793v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.LG
Authors: ByeoungDo Kim, JunYeop Na, Kyungwook Tak, JunTae Kim, DongHyeon Kim et al.
Institution: 
Published: 2026-01-20
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

In this paper, we propose an ETA model (Estimated Time of Arrival) that leverages an attention mechanism over historical road speed patterns. As autonomous driving and intelligent transportation systems become increasingly prevalent, the need for accurate and reliable ETA estimation has grown, playing a vital role in navigation, mobility planning, and traffic management. However, predicting ETA remains a challenging task due to the dynamic and complex nature of traffic flow. Traditional methods often combine real-time and historical traffic data in simplistic ways, or rely on complex rule-based computations. While recent deep learning models have shown potential, they often require high computational costs and do not effectively capture the spatio-temporal patterns crucial for ETA prediction. ETA prediction inherently involves spatio-temporal causality, and our proposed model addresses this by leveraging attention mechanisms to extract and utilize temporal features accumulated at each spatio-temporal point along a route. This architecture enables efficient and accurate ETA estimation while keeping the model lightweight and scalable. We validate our approach using real-world driving datasets and demonstrate that our approach outperforms existing baselines by effectively integrating road characteristics, real-time traffic conditions, and historical speed patterns in a task-aware manner.]]></description>
<pubDate>Tue, 20 Jan 2026 09:51:35 +0000</pubDate>
</item>
<item>
<title><![CDATA[Principled Latent Diffusion for Graphs via Laplacian Autoencoders]]></title>
<link>http://arxiv.org/abs/2601.13780v1</link>
<guid>2601.13780v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.LG
Authors: Antoine Siraudin, Christopher Morris
Institution: 
Published: 2026-01-20
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Graph diffusion models achieve state-of-the-art performance in graph generation but suffer from quadratic complexity in the number of nodes -- and much of their capacity is wasted modeling the absence of edges in sparse graphs. Inspired by latent diffusion in other modalities, a natural idea is to compress graphs into a low-dimensional latent space and perform diffusion there. However, unlike images or text, graph generation requires nearly lossless reconstruction, as even a single error in decoding an adjacency matrix can render the entire sample invalid. This challenge has remained largely unaddressed. We propose LG-Flow, a latent graph diffusion framework that directly overcomes these obstacles. A permutation-equivariant autoencoder maps each node into a fixed-dimensional embedding from which the full adjacency is provably recoverable, enabling near-lossless reconstruction for both undirected graphs and DAGs. The dimensionality of this latent representation scales linearly with the number of nodes, eliminating the quadratic bottleneck and making it feasible to train larger and more expressive models. In this latent space, we train a Diffusion Transformer with flow matching, enabling efficient and expressive graph generation. Our approach achieves competitive results against state-of-the-art graph diffusion models, while achieving up to $1000\times$ speed-up.]]></description>
<pubDate>Tue, 20 Jan 2026 09:37:53 +0000</pubDate>
</item>
<item>
<title><![CDATA[Orthogonium : A Unified, Efficient Library of Orthogonal and 1-Lipschitz Building Blocks]]></title>
<link>http://arxiv.org/abs/2601.13776v1</link>
<guid>2601.13776v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.LG, stat.ML
Authors: Thibaut Boissin, Franck Mamalet, Valentin Lafargue, Mathieu Serrurier
Institution: 
Published: 2026-01-20
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Orthogonal and 1-Lipschitz neural network layers are essential building blocks in robust deep learning architectures, crucial for certified adversarial robustness, stable generative models, and reliable recurrent networks. Despite significant advancements, existing implementations remain fragmented, limited, and computationally demanding. To address these issues, we introduce Orthogonium , a unified, efficient, and comprehensive PyTorch library providing orthogonal and 1-Lipschitz layers. Orthogonium provides access to standard convolution features-including support for strides, dilation, grouping, and transposed-while maintaining strict mathematical guarantees. Its optimized implementations reduce overhead on large scale benchmarks such as ImageNet. Moreover, rigorous testing within the library has uncovered critical errors in existing implementations, emphasizing the importance of standardized and reliable tools. Orthogonium thus significantly lowers adoption barriers, enabling scalable experimentation and integration across diverse applications requiring orthogonality and robust Lipschitz constraints. Orthogonium is available at https://github.com/deel-ai/orthogonium.]]></description>
<pubDate>Tue, 20 Jan 2026 09:33:14 +0000</pubDate>
</item>
<item>
<title><![CDATA[Look-Ahead-Bench: a Standardized Benchmark of Look-ahead Bias in Point-in-Time LLMs for Finance]]></title>
<link>http://arxiv.org/abs/2601.13770v1</link>
<guid>2601.13770v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.AI, cs.CL, cs.LG
Authors: Mostapha Benhenda
Institution: 
Published: 2026-01-20
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

We introduce Look-Ahead-Bench, a standardized benchmark measuring look-ahead bias in Point-in-Time (PiT) Large Language Models (LLMs) within realistic and practical financial workflows. Unlike most existing approaches that primarily test inner lookahead knowledge via Q\\&A, our benchmark evaluates model behavior in practical scenarios. To distinguish genuine predictive capability from memorization-based performance, we analyze performance decay across temporally distinct market regimes, incorporating several quantitative baselines to establish performance thresholds. We evaluate prominent open-source LLMs -- Llama 3.1 (8B and 70B) and DeepSeek 3.2 -- against a family of Point-in-Time LLMs (Pitinf-Small, Pitinf-Medium, and frontier-level model Pitinf-Large) from PiT-Inference. Results reveal significant lookahead bias in standard LLMs, as measured with alpha decay, unlike Pitinf models, which demonstrate improved generalization and reasoning abilities as they scale in size. This work establishes a foundation for the standardized evaluation of temporal bias in financial LLMs and provides a practical framework for identifying models suitable for real-world deployment. Code is available on GitHub: https://github.com/benstaf/lookaheadbench]]></description>
<pubDate>Tue, 20 Jan 2026 09:23:51 +0000</pubDate>
</item>
<item>
<title><![CDATA[vLinear: A Powerful Linear Model for Multivariate Time Series Forecasting]]></title>
<link>http://arxiv.org/abs/2601.13768v1</link>
<guid>2601.13768v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.LG, cs.AI
Authors: Wenzhen Yue, Ruohao Guo, Ji Shi, Zihan Hao, Shiyu Hu et al.
Institution: 
Published: 2026-01-20
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

In this paper, we present \textbf{vLinear}, an effective yet efficient \textbf{linear}-based multivariate time series forecaster featuring two components: the \textbf{v}ecTrans module and the WFMLoss objective. Many state-of-the-art forecasters rely on self-attention or its variants to capture multivariate correlations, typically incurring $\mathcal{O}(N^2)$ computational complexity with respect to the number of variates $N$. To address this, we propose vecTrans, a lightweight module that utilizes a learnable vector to model multivariate correlations, reducing the complexity to $\mathcal{O}(N)$. Notably, vecTrans can be seamlessly integrated into Transformer-based forecasters, delivering up to 5$\times$ inference speedups and consistent performance gains. Furthermore, we introduce WFMLoss (Weighted Flow Matching Loss) as the objective. In contrast to typical \textbf{velocity-oriented} flow matching objectives, we demonstrate that a \textbf{final-series-oriented} formulation yields significantly superior forecasting accuracy. WFMLoss also incorporates path- and horizon-weighted strategies to focus learning on more reliable paths and horizons. Empirically, vLinear achieves state-of-the-art performance across 22 benchmarks and 124 forecasting settings. Moreover, WFMLoss serves as an effective plug-and-play objective, consistently improving existing forecasters. The code is available at https://anonymous.4open.science/r/vLinear.]]></description>
<pubDate>Tue, 20 Jan 2026 09:23:10 +0000</pubDate>
</item>
<item>
<title><![CDATA[DARC: Decoupled Asymmetric Reasoning Curriculum for LLM Evolution]]></title>
<link>http://arxiv.org/abs/2601.13761v1</link>
<guid>2601.13761v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.AI, cs.CL
Authors: Shengda Fan, Xuyan Ye, Yankai Lin
Institution: 
Published: 2026-01-20
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Self-play with large language models has emerged as a promising paradigm for achieving self-improving artificial intelligence. However, existing self-play frameworks often suffer from optimization instability, due to (i) non-stationary objectives induced by solver-dependent reward feedback for the Questioner, and (ii) bootstrapping errors from self-generated pseudo-labels used to supervise the Solver. To mitigate these challenges, we introduce DARC (Decoupled Asymmetric Reasoning Curriculum), a two-stage framework that stabilizes the self-evolution process. First, we train the Questioner to synthesize difficulty-calibrated questions, conditioned on explicit difficulty levels and external corpora. Second, we train the Solver with an asymmetric self-distillation mechanism, where a document-augmented teacher generates high-quality pseudo-labels to supervise the student Solver that lacks document access. Empirical results demonstrate that DARC is model-agnostic, yielding an average improvement of 10.9 points across nine reasoning benchmarks and three backbone models. Moreover, DARC consistently outperforms all baselines and approaches the performance of fully supervised models without relying on human annotations.The code is available at https://github.com/RUCBM/DARC.]]></description>
<pubDate>Tue, 20 Jan 2026 09:12:27 +0000</pubDate>
</item>
<item>
<title><![CDATA[Finding RELIEF: Shaping Reasoning Behavior without Reasoning Supervision via Belief Engineering]]></title>
<link>http://arxiv.org/abs/2601.13752v1</link>
<guid>2601.13752v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.AI, cs.CL
Authors: Chak Tou Leong, Dingwei Chen, Heming Xia, Qingyu Yin, Sunbowen Lee et al.
Institution: 
Published: 2026-01-20
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Large reasoning models (LRMs) have achieved remarkable success in complex problem-solving, yet they often suffer from computational redundancy or reasoning unfaithfulness. Current methods for shaping LRM behavior typically rely on reinforcement learning or fine-tuning with gold-standard reasoning traces, a paradigm that is both computationally expensive and difficult to scale. In this paper, we reveal that LRMs possess latent \textit{reasoning beliefs} that internally track their own reasoning traits, which can be captured through simple logit probing. Building upon this insight, we propose Reasoning Belief Engineering (RELIEF), a simple yet effective framework that shapes LRM behavior by aligning the model's self-concept with a target belief blueprint. Crucially, RELIEF completely bypasses the need for reasoning-trace supervision. It internalizes desired traits by fine-tuning on synthesized, self-reflective question-answering pairs that affirm the target belief. Extensive experiments on efficiency and faithfulness tasks demonstrate that RELIEF matches or outperforms behavior-supervised and preference-based baselines while requiring lower training costs. Further analysis validates that shifting a model's reasoning belief effectively shapes its actual behavior.]]></description>
<pubDate>Tue, 20 Jan 2026 09:07:01 +0000</pubDate>
</item>
<item>
<title><![CDATA[HiT: History-Injection Transformers for Onboard Continuous Flood Change Detection]]></title>
<link>http://arxiv.org/abs/2601.13751v1</link>
<guid>2601.13751v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.CV, cs.LG
Authors: Daniel Kyselica, Jonáš Herec, Oliver Kutis, Rado Pitoňák
Institution: 
Published: 2026-01-20
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Natural disaster monitoring through continuous satellite observation requires processing multi-temporal data under strict operational constraints. This paper addresses flood detection, a critical application for hazard management, by developing an onboard change detection system that operates within the memory and computational limits of small satellites. We propose History Injection mechanism for Transformer models (HiT), that maintains historical context from previous observations while reducing data storage by over 99\% of original image size. Moreover, testing on the STTORM-CD flood dataset confirms that the HiT mechanism within the Prithvi-tiny foundation model maintains detection accuracy compared to the bitemporal baseline. The proposed HiT-Prithvi model achieved 43 FPS on Jetson Orin Nano, a representative onboard hardware used in nanosats. This work establishes a practical framework for satellite-based continuous monitoring of natural disasters, supporting real-time hazard assessment without dependency on ground-based processing infrastructure. Architecture as well as model checkpoints is available at https://github.com/zaitra/HiT-change-detection]]></description>
<pubDate>Tue, 20 Jan 2026 09:05:43 +0000</pubDate>
</item>
<item>
<title><![CDATA[Pro-AI Bias in Large Language Models]]></title>
<link>http://arxiv.org/abs/2601.13749v1</link>
<guid>2601.13749v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.CL, cs.AI, cs.CY, cs.LG
Authors: Benaya Trabelsi, Jonathan Shaki, Sarit Kraus
Institution: 
Published: 2026-01-20
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Large language models (LLMs) are increasingly employed for decision-support across multiple domains. We investigate whether these models display a systematic preferential bias in favor of artificial intelligence (AI) itself. Across three complementary experiments, we find consistent evidence of pro-AI bias. First, we show that LLMs disproportionately recommend AI-related options in response to diverse advice-seeking queries, with proprietary models doing so almost deterministically. Second, we demonstrate that models systematically overestimate salaries for AI-related jobs relative to closely matched non-AI jobs, with proprietary models overestimating AI salaries more by 10 percentage points. Finally, probing internal representations of open-weight models reveals that ``Artificial Intelligence'' exhibits the highest similarity to generic prompts for academic fields under positive, negative, and neutral framings alike, indicating valence-invariant representational centrality. These patterns suggest that LLM-generated advice and valuation can systematically skew choices and perceptions in high-stakes decisions.]]></description>
<pubDate>Tue, 20 Jan 2026 09:03:57 +0000</pubDate>
</item>
<item>
<title><![CDATA[EEG-Titans: Long-Horizon Seizure Forecasting via Dual-Branch Attention and Neural Memory]]></title>
<link>http://arxiv.org/abs/2601.13748v1</link>
<guid>2601.13748v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.LG, cs.HC
Authors: Tien-Dat Pham, Xuan-The Tran
Institution: 
Published: 2026-01-20
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Accurate epileptic seizure prediction from electroencephalography (EEG) remains challenging because pre-ictal dynamics may span long time horizons while clinically relevant signatures can be subtle and transient. Many deep learning models face a persistent trade-off between capturing local spatiotemporal patterns and maintaining informative long-range context when operating on ultralong sequences. We propose EEG-Titans, a dualbranch architecture that incorporates a modern neural memory mechanism for long-context modeling. The model combines sliding-window attention to capture short-term anomalies with a recurrent memory pathway that summarizes slower, progressive trends over time. On the CHB-MIT scalp EEG dataset, evaluated under a chronological holdout protocol, EEG-Titans achieves 99.46% average segment-level sensitivity across 18 subjects. We further analyze safety-first operating points on artifact-prone recordings and show that a hierarchical context strategy extending the receptive field for high-noise subjects can markedly reduce false alarms (down to 0.00 FPR/h in an extreme outlier) without sacrificing sensitivity. These results indicate that memory-augmented long-context modeling can provide robust seizure forecasting under clinically constrained evaluation]]></description>
<pubDate>Tue, 20 Jan 2026 09:03:49 +0000</pubDate>
</item>
<item>
<title><![CDATA[Variational Dual-path Attention Network for CSI-Based Gesture Recognition]]></title>
<link>http://arxiv.org/abs/2601.13745v1</link>
<guid>2601.13745v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.NI, cs.LG
Authors: N. Zhang
Institution: 
Published: 2026-01-20
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Wi-Fi gesture recognition based on Channel State Information (CSI) is challenged by high-dimensional noise and resource constraints on edge devices. Prevailing end-to-end models tightly couple feature extraction with classification, overlooking the inherent time-frequency sparsity of CSI and leading to redundancy and poor generalization. To address this, this paper proposes a lightweight feature preprocessing module--the Variational Dual-path Attention Network (VDAN). It performs structured feature refinement through frequency-domain filtering and temporal detection. Variational inference is introduced to model the uncertainty in attention weights, thereby enhancing robustness to noise. The design principles of the module are explained from the perspectives of the information bottleneck and regularization. Experiments on a public dataset demonstrate that the learned attention weights align with the physical sparse characteristics of CSI, verifying its interpretability. This work provides an efficient and explainable front-end processing solution for resource-constrained wireless sensing systems.]]></description>
<pubDate>Tue, 20 Jan 2026 09:02:02 +0000</pubDate>
</item>
<item>
<title><![CDATA[Dimension-First Evaluation of Speech-to-Speech Models with Structured Acoustic Cues]]></title>
<link>http://arxiv.org/abs/2601.13742v1</link>
<guid>2601.13742v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.CL
Authors: Arjun Chandra, Kevin Miller, Venkatesh Ravichandran, Constantinos Papayiannis, Venkatesh Saligrama
Institution: 
Published: 2026-01-20
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Large Language Model (LLM) judges exhibit strong reasoning capabilities but are limited to textual content. This leaves current automatic Speech-to-Speech (S2S) evaluation methods reliant on opaque and expensive Audio Language Models (ALMs). In this work, we propose TRACE (Textual Reasoning over Audio Cues for Evaluation), a novel framework that enables LLM judges to reason over audio cues to achieve cost-efficient and human-aligned S2S evaluation. To demonstrate the strength of the framework, we first introduce a Human Chain-of-Thought (HCoT) annotation protocol to improve the diagnostic capability of existing judge benchmarks by separating evaluation into explicit dimensions: content (C), voice quality (VQ), and paralinguistics (P). Using this data, TRACE constructs a textual blueprint of inexpensive audio signals and prompts an LLM to render dimension-wise judgments, fusing them into an overall rating via a deterministic policy. TRACE achieves higher agreement with human raters than ALMs and transcript-only LLM judges while being significantly more cost-effective. We will release the HCoT annotations and the TRACE framework to enable scalable and human-aligned S2S evaluation.]]></description>
<pubDate>Tue, 20 Jan 2026 08:57:02 +0000</pubDate>
</item>
<item>
<title><![CDATA[Reasoning or Fluency? Dissecting Probabilistic Confidence in Best-of-N Selection]]></title>
<link>http://arxiv.org/abs/2601.13735v1</link>
<guid>2601.13735v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.AI
Authors: Hojin Kim, Jaehyung Kim
Institution: 
Published: 2026-01-20
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Probabilistic confidence metrics are increasingly adopted as proxies for reasoning quality in Best-of-N selection, under the assumption that higher confidence reflects higher reasoning fidelity. In this work, we challenge this assumption by investigating whether these metrics truly capture inter-step causal dependencies necessary for valid reasoning. We introduce three classes of inter-step causality perturbations that systematically disrupt dependencies between reasoning steps while preserving local fluency. Surprisingly, across diverse model families and reasoning benchmarks, we find that selection accuracy degrades only marginally under these disruptions. Even severe interventions, such as applying hard attention masks that directly prevent the model from attending to prior reasoning steps, do not substantially reduce selection performance. These findings provide strong evidence that current probabilistic metrics are largely insensitive to logical structure, and primarily capture surface-level fluency or in-distribution priors instead. Motivated by this gap, we propose a contrastive causality metric that explicitly isolates inter-step causal dependencies, and demonstrate that it yields more faithful output selection than existing probability-based approaches.]]></description>
<pubDate>Tue, 20 Jan 2026 08:46:33 +0000</pubDate>
</item>
<item>
<title><![CDATA[Towards robust long-context understanding of large language model via active recap learning]]></title>
<link>http://arxiv.org/abs/2601.13734v1</link>
<guid>2601.13734v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.CL, cs.AI
Authors: Chenyu Hui
Institution: 
Published: 2026-01-20
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

In this paper, we propose active recap learning (ARL), a framework for enhancing large language model (LLM) in understanding long contexts. ARL enables models to revisit and summarize earlier content through targeted sequence construction during contined pretraining and retrospective summarization at inference. First, we identify key tokens in prepared long context based on loss gaps between long and short forward contexts and find most revant preceding paragraphs, then summarize them using an LLM. Second, ARL equips models with the ability to autonomously generate and utilize these retrospective summaries during inference, thereby establishing a recursive memory mechanism across paragraphs. Experimental results show substantial gains, with ARL achieving a 26.8% improvement on RULER and a 9.44% improvement on LongBench. Overall, ARL offers a simple yet effective continued pretraining-based approach to strengthen long-context understanding, advancing scalable memory augmentation in LLM]]></description>
<pubDate>Tue, 20 Jan 2026 08:42:04 +0000</pubDate>
</item>
<item>
<title><![CDATA[Breaking the Data Barrier in Learning Symbolic Computation: A Case Study on Variable Ordering Suggestion for Cylindrical Algebraic Decomposition]]></title>
<link>http://arxiv.org/abs/2601.13731v1</link>
<guid>2601.13731v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.SC, cs.LG
Authors: Rui-Juan Jing, Yuegang Zhao, Changbo Chen
Institution: 
Published: 2026-01-20
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Symbolic computation, powered by modern computer algebra systems, has important applications in mathematical reasoning through exact deep computations. The efficiency of symbolic computation is largely constrained by such deep computations in high dimension. This creates a fundamental barrier on labelled data acquisition if leveraging supervised deep learning to accelerate symbolic computation. Cylindrical algebraic decomposition (CAD) is a pillar symbolic computation method for reasoning with first-order logic formulas over reals with many applications in formal verification and automatic theorem proving. Variable orderings have a huge impact on its efficiency. Impeded by the difficulty to acquire abundant labelled data, existing learning-based approaches are only competitive with the best expert-based heuristics. In this work, we address this problem by designing a series of intimately connected tasks for which a large amount of annotated data can be easily obtained. We pre-train a Transformer model with these data and then fine-tune it on the datasets for CAD ordering. Experiments on publicly available CAD ordering datasets show that on average the orderings predicted by the new model are significantly better than those suggested by the best heuristic methods.]]></description>
<pubDate>Tue, 20 Jan 2026 08:40:35 +0000</pubDate>
</item>
<item>
<title><![CDATA[On Temperature-Constrained Non-Deterministic Machine Translation: Potential and Evaluation]]></title>
<link>http://arxiv.org/abs/2601.13729v1</link>
<guid>2601.13729v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.CL
Authors: Weichuan Wang, Mingyang Liu, Linqi Song, Chen Ma
Institution: 
Published: 2026-01-20
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

In recent years, the non-deterministic properties of language models have garnered considerable attention and have shown a significant influence on real-world applications. However, such properties remain under-explored in machine translation (MT), a complex, non-deterministic NLP task. In this study, we systematically evaluate modern MT systems and identify temperature-constrained Non-Deterministic MT (ND-MT) as a distinct phenomenon. Additionally, we demonstrate that ND-MT exhibits significant potential in addressing the multi-modality issue that has long challenged MT research and provides higher-quality candidates than Deterministic MT (D-MT) under temperature constraints. However, ND-MT introduces new challenges in evaluating system performance. Specifically, the evaluation framework designed for D-MT fails to yield consistent evaluation results when applied to ND-MT. We further investigate this emerging challenge by evaluating five state-of-the-art ND-MT systems across three open datasets using both lexical-based and semantic-based metrics at varying sampling sizes. The results reveal a Buckets effect across these systems: the lowest-quality candidate generated by ND-MT consistently determines the overall system ranking across different sampling sizes for all reasonable metrics. Furthermore, we propose the ExpectoSample strategy to automatically assess the reliability of evaluation metrics for selecting robust ND-MT.]]></description>
<pubDate>Tue, 20 Jan 2026 08:39:10 +0000</pubDate>
</item>
<item>
<title><![CDATA[Facial Spatiotemporal Graphs: Leveraging the 3D Facial Surface for Remote Physiological Measurement]]></title>
<link>http://arxiv.org/abs/2601.13724v1</link>
<guid>2601.13724v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.CV
Authors: Sam Cantrill, David Ahmedt-Aristizabal, Lars Petersson, Hanna Suominen, Mohammad Ali Armin
Institution: 
Published: 2026-01-20
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Facial remote photoplethysmography (rPPG) methods estimate physiological signals by modeling subtle color changes on the 3D facial surface over time. However, existing methods fail to explicitly align their receptive fields with the 3D facial surface-the spatial support of the rPPG signal. To address this, we propose the Facial Spatiotemporal Graph (STGraph), a novel representation that encodes facial color and structure using 3D facial mesh sequences-enabling surface-aligned spatiotemporal processing. We introduce MeshPhys, a lightweight spatiotemporal graph convolutional network that operates on the STGraph to estimate physiological signals. Across four benchmark datasets, MeshPhys achieves state-of-the-art or competitive performance in both intra- and cross-dataset settings. Ablation studies show that constraining the model's receptive field to the facial surface acts as a strong structural prior, and that surface-aligned, 3D-aware node features are critical for robustly encoding facial surface color. Together, the STGraph and MeshPhys constitute a novel, principled modeling paradigm for facial rPPG, enabling robust, interpretable, and generalizable estimation. Code is available at https://samcantrill.github.io/facial-stgraph-rppg/ .]]></description>
<pubDate>Tue, 20 Jan 2026 08:29:44 +0000</pubDate>
</item>
<item>
<title><![CDATA[OP-Bench: Benchmarking Over-Personalization for Memory-Augmented Personalized Conversational Agents]]></title>
<link>http://arxiv.org/abs/2601.13722v1</link>
<guid>2601.13722v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.CL, cs.AI
Authors: Yulin Hu, Zimo Long, Jiahe Guo, Xingyu Sui, Xing Fu et al.
Institution: 
Published: 2026-01-20
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Memory-augmented conversational agents enable personalized interactions using long-term user memory and have gained substantial traction. However, existing benchmarks primarily focus on whether agents can recall and apply user information, while overlooking whether such personalization is used appropriately. In fact, agents may overuse personal information, producing responses that feel forced, intrusive, or socially inappropriate to users. We refer to this issue as \emph{over-personalization}. In this work, we formalize over-personalization into three types: Irrelevance, Repetition, and Sycophancy, and introduce \textbf{OP-Bench} a benchmark of 1,700 verified instances constructed from long-horizon dialogue histories. Using \textbf{OP-Bench}, we evaluate multiple large language models and memory-augmentation methods, and find that over-personalization is widespread when memory is introduced. Further analysis reveals that agents tend to retrieve and over-attend to user memories even when unnecessary. To address this issue, we propose \textbf{Self-ReCheck}, a lightweight, model-agnostic memory filtering mechanism that mitigates over-personalization while preserving personalization performance. Our work takes an initial step toward more controllable and appropriate personalization in memory-augmented dialogue systems.]]></description>
<pubDate>Tue, 20 Jan 2026 08:27:13 +0000</pubDate>
</item>
<item>
<title><![CDATA[Hierarchical Long Video Understanding with Audiovisual Entity Cohesion and Agentic Search]]></title>
<link>http://arxiv.org/abs/2601.13719v1</link>
<guid>2601.13719v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.CV, cs.AI, cs.IR
Authors: Xinlei Yin, Xiulian Peng, Xiao Li, Zhiwei Xiong, Yan Lu
Institution: 
Published: 2026-01-20
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Long video understanding presents significant challenges for vision-language models due to extremely long context windows. Existing solutions relying on naive chunking strategies with retrieval-augmented generation, typically suffer from information fragmentation and a loss of global coherence. We present HAVEN, a unified framework for long-video understanding that enables coherent and comprehensive reasoning by integrating audiovisual entity cohesion and hierarchical video indexing with agentic search. First, we preserve semantic consistency by integrating entity-level representations across visual and auditory streams, while organizing content into a structured hierarchy spanning global summary, scene, segment, and entity levels. Then we employ an agentic search mechanism to enable dynamic retrieval and reasoning across these layers, facilitating coherent narrative reconstruction and fine-grained entity tracking. Extensive experiments demonstrate that our method achieves good temporal coherence, entity consistency, and retrieval efficiency, establishing a new state-of-the-art with an overall accuracy of 84.1% on LVBench. Notably, it achieves outstanding performance in the challenging reasoning category, reaching 80.1%. These results highlight the effectiveness of structured, multimodal reasoning for comprehensive and context-consistent understanding of long-form videos.]]></description>
<pubDate>Tue, 20 Jan 2026 08:23:29 +0000</pubDate>
</item>
<item>
<title><![CDATA[Simulated Ignorance Fails: A Systematic Study of LLM Behaviors on Forecasting Problems Before Model Knowledge Cutoff]]></title>
<link>http://arxiv.org/abs/2601.13717v1</link>
<guid>2601.13717v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.CL, cs.AI
Authors: Zehan Li, Yuxuan Wang, Ali El Lahib, Ying-Jieh Xia, Xinyu Pi
Institution: 
Published: 2026-01-20
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Evaluating LLM forecasting capabilities is constrained by a fundamental tension: prospective evaluation offers methodological rigor but prohibitive latency, while retrospective forecasting (RF) -- evaluating on already-resolved events -- faces rapidly shrinking clean evaluation data as SOTA models possess increasingly recent knowledge cutoffs. Simulated Ignorance (SI), prompting models to suppress pre-cutoff knowledge, has emerged as a potential solution. We provide the first systematic test of whether SI can approximate True Ignorance (TI). Across 477 competition-level questions and 9 models, we find that SI fails systematically: (1) cutoff instructions leave a 52% performance gap between SI and TI; (2) chain-of-thought reasoning fails to suppress prior knowledge, even when reasoning traces contain no explicit post-cutoff references; (3) reasoning-optimized models exhibit worse SI fidelity despite superior reasoning trace quality. These findings demonstrate that prompts cannot reliably "rewind" model knowledge. We conclude that RF on pre-cutoff events is methodologically flawed; we recommend against using SI-based retrospective setups to benchmark forecasting capabilities.]]></description>
<pubDate>Tue, 20 Jan 2026 08:21:55 +0000</pubDate>
</item>
<item>
<title><![CDATA[MVGD-Net: A Novel Motion-aware Video Glass Surface Detection Network]]></title>
<link>http://arxiv.org/abs/2601.13715v1</link>
<guid>2601.13715v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.CV
Authors: Yiwei Lu, Hao Huang, Tao Yan
Institution: 
Published: 2026-01-20
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Glass surface ubiquitous in both daily life and professional environments presents a potential threat to vision-based systems, such as robot and drone navigation. To solve this challenge, most recent studies have shown significant interest in Video Glass Surface Detection (VGSD). We observe that objects in the reflection (or transmission) layer appear farther from the glass surfaces. Consequently, in video motion scenarios, the notable reflected (or transmitted) objects on the glass surface move slower than objects in non-glass regions within the same spatial plane, and this motion inconsistency can effectively reveal the presence of glass surfaces. Based on this observation, we propose a novel network, named MVGD-Net, for detecting glass surfaces in videos by leveraging motion inconsistency cues. Our MVGD-Net features three novel modules: the Cross-scale Multimodal Fusion Module (CMFM) that integrates extracted spatial features and estimated optical flow maps, the History Guided Attention Module (HGAM) and Temporal Cross Attention Module (TCAM), both of which further enhances temporal features. A Temporal-Spatial Decoder (TSD) is also introduced to fuse the spatial and temporal features for generating the glass region mask. Furthermore, for learning our network, we also propose a large-scale dataset, which comprises 312 diverse glass scenarios with a total of 19,268 frames. Extensive experiments demonstrate that our MVGD-Net outperforms relevant state-of-the-art methods.]]></description>
<pubDate>Tue, 20 Jan 2026 08:19:17 +0000</pubDate>
</item>
<item>
<title><![CDATA[SWE-Tester: Training Open-Source LLMs for Issue Reproduction in Real-World Repositories]]></title>
<link>http://arxiv.org/abs/2601.13713v1</link>
<guid>2601.13713v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.SE, cs.LG
Authors: Aditya Bharat Soni, Rajat Ghosh, Vaishnavi Bhargava, Valerie Chen, Debojyoti Dutta
Institution: 
Published: 2026-01-20
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Software testing is crucial for ensuring the correctness and reliability of software systems. Automated generation of issue reproduction tests from natural language issue descriptions enhances developer productivity by simplifying root cause analysis, promotes test-driven development -- "test first, write code later", and can be used for improving the effectiveness of automated issue resolution systems like coding agents. Existing methods proposed for this task predominantly rely on closed-source LLMs, with limited exploration of open models. To address this, we propose SWE-Tester -- a novel pipeline for training open-source LLMs to generate issue reproduction tests. First, we curate a high-quality training dataset of 41K instances from 2.6K open-source GitHub repositories and use it to train LLMs of varying sizes and families. The fine-tuned models achieve absolute improvements of up to 10\% in success rate and 21\% in change coverage on SWT-Bench Verified. Further analysis shows consistent improvements with increased inference-time compute, more data, and larger models. These results highlight the effectiveness of our framework for advancing open-source LLMs in this domain.]]></description>
<pubDate>Tue, 20 Jan 2026 08:10:56 +0000</pubDate>
</item>
<item>
<title><![CDATA[GerAV: Towards New Heights in German Authorship Verification using Fine-Tuned LLMs on a New Benchmark]]></title>
<link>http://arxiv.org/abs/2601.13711v1</link>
<guid>2601.13711v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.CL
Authors: Lotta Kiefer, Christoph Leiter, Sotaro Takeshita, Elena Schmidt, Steffen Eger
Institution: 
Published: 2026-01-20
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Authorship verification (AV) is the task of determining whether two texts were written by the same author and has been studied extensively, predominantly for English data. In contrast, large-scale benchmarks and systematic evaluations for other languages remain scarce. We address this gap by introducing GerAV, a comprehensive benchmark for German AV comprising over 600k labeled text pairs. GerAV is built from Twitter and Reddit data, with the Reddit part further divided into in-domain and cross-domain message-based subsets, as well as a profile-based subset. This design enables controlled analysis of the effects of data source, topical domain, and text length. Using the provided training splits, we conduct a systematic evaluation of strong baselines and state-of-the-art models and find that our best approach, a fine-tuned large language model, outperforms recent baselines by up to 0.09 absolute F1 score and surpasses GPT-5 in a zero-shot setting by 0.08. We further observe a trade-off between specialization and generalization: models trained on specific data types perform best under matching conditions but generalize less well across data regimes, a limitation that can be mitigated by combining training sources. Overall, GerAV provides a challenging and versatile benchmark for advancing research on German and cross-domain AV.]]></description>
<pubDate>Tue, 20 Jan 2026 08:08:18 +0000</pubDate>
</item>
<item>
<title><![CDATA[Who Should Have Surgery? A Comparative Study of GenAI vs Supervised ML for CRS Surgical Outcome Prediction]]></title>
<link>http://arxiv.org/abs/2601.13710v1</link>
<guid>2601.13710v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.LG, cs.AI, cs.CL
Authors: Sayeed Shafayet Chowdhury, Snehasis Mukhopadhyay, Shiaofen Fang, Vijay R. Ramakrishnan
Institution: 
Published: 2026-01-20
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Artificial intelligence has reshaped medical imaging, yet the use of AI on clinical data for prospective decision support remains limited. We study pre-operative prediction of clinically meaningful improvement in chronic rhinosinusitis (CRS), defining success as a more than 8.9-point reduction in SNOT-22 at 6 months (MCID). In a prospectively collected cohort where all patients underwent surgery, we ask whether models using only pre-operative clinical data could have identified those who would have poor outcomes, i.e. those who should have avoided surgery. We benchmark supervised ML (logistic regression, tree ensembles, and an in-house MLP) against generative AI (ChatGPT, Claude, Gemini, Perplexity), giving each the same structured inputs and constraining outputs to binary recommendations with confidence. Our best ML model (MLP) achieves 85 % accuracy with superior calibration and decision-curve net benefit. GenAI models underperform on discrimination and calibration across zero-shot setting. Notably, GenAI justifications align with clinician heuristics and the MLP's feature importance, repeatedly highlighting baseline SNOT-22, CT/endoscopy severity, polyp phenotype, and physchology/pain comorbidities. We provide a reproducible tabular-to-GenAI evaluation protocol and subgroup analyses. Findings support an ML-first, GenAI- augmented workflow: deploy calibrated ML for primary triage of surgical candidacy, with GenAI as an explainer to enhance transparency and shared decision-making.]]></description>
<pubDate>Tue, 20 Jan 2026 08:07:58 +0000</pubDate>
</item>
<item>
<title><![CDATA[Hidden in Plain Text: Measuring LLM Deception Quality Against Human Baselines Using Social Deduction Games]]></title>
<link>http://arxiv.org/abs/2601.13709v1</link>
<guid>2601.13709v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.AI, cs.CL, cs.CY, cs.HC, cs.SI
Authors: Christopher Kao, Vanshika Vats, James Davis
Institution: 
Published: 2026-01-20
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Large Language Model (LLM) agents are increasingly used in many applications, raising concerns about their safety. While previous work has shown that LLMs can deceive in controlled tasks, less is known about their ability to deceive using natural language in social contexts. In this paper, we study deception in the Social Deduction Game (SDG) Mafia, where success is dependent on deceiving others through conversation. Unlike previous SDG studies, we use an asynchronous multi-agent framework which better simulates realistic social contexts. We simulate 35 Mafia games with GPT-4o LLM agents. We then create a Mafia Detector using GPT-4-Turbo to analyze game transcripts without player role information to predict the mafia players. We use prediction accuracy as a surrogate marker for deception quality. We compare this prediction accuracy to that of 28 human games and a random baseline. Results show that the Mafia Detector's mafia prediction accuracy is lower on LLM games than on human games. The result is consistent regardless of the game days and the number of mafias detected. This indicates that LLMs blend in better and thus deceive more effectively. We also release a dataset of LLM Mafia transcripts to support future research. Our findings underscore both the sophistication and risks of LLM deception in social contexts.]]></description>
<pubDate>Tue, 20 Jan 2026 08:07:21 +0000</pubDate>
</item>
<item>
<title><![CDATA[Generative Adversarial Networks for Resource State Generation]]></title>
<link>http://arxiv.org/abs/2601.13708v1</link>
<guid>2601.13708v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.LG
Authors: Shahbaz Shaik, Sourav Chatterjee, Sayantan Pramanik, Indranil Chakrabarty
Institution: 
Published: 2026-01-20
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

We introduce a physics-informed Generative Adversarial Network framework that recasts quantum resource-state generation as an inverse-design task. By embedding task-specific utility functions into training, the model learns to generate valid two-qubit states optimized for teleportation and entanglement broadcasting. Comparing decomposition-based and direct-generation architectures reveals that structural enforcement of Hermiticity, trace-one, and positivity yields higher fidelity and training stability than loss-only approaches. The framework reproduces theoretical resource boundaries for Werner-like and Bell-diagonal states with fidelities exceeding ~98%, establishing adversarial learning as a lightweight yet effective method for constraint-driven quantum-state discovery. This approach provides a scalable foundation for automated design of tailored quantum resources for information-processing applications, exemplified with teleportation and broadcasting of entanglement, and it opens up the possibility of using such states in efficient quantum network design.]]></description>
<pubDate>Tue, 20 Jan 2026 08:04:57 +0000</pubDate>
</item>
<item>
<title><![CDATA[Attention-space Contrastive Guidance for Efficient Hallucination Mitigation in LVLMs]]></title>
<link>http://arxiv.org/abs/2601.13707v1</link>
<guid>2601.13707v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.CV, cs.AI, cs.LG
Authors: Yujin Jo, Sangyoon Bae, Taesup Kim
Institution: 
Published: 2026-01-20
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Hallucinations in large vision-language models (LVLMs) often arise when language priors dominate over visual evidence, causing object misidentification and visually inconsistent descriptions. We address this issue by framing hallucination mitigation as contrastive guidance, steering generation toward visually grounded and semantically faithful text. This approach regulates the model's internal behavior by reducing over-dependence on language priors and contrasting visually grounded with language-only representations. We propose Attention-space Contrastive Guidance (ACG), a single-pass mechanism that operates within self-attention layers to construct both vision-language and language-only attention paths in a single forward computation. This integration enables computationally efficient guidance directly embedded in the model's representation contextualization. To correct approximation bias introduced by the single-pass formulation, we further apply an orthogonalized correction that removes components aligned with the language-only path, selectively amplifying visual contributions. Experiments on the CHAIR and POPE benchmarks show that ACG achieves state-of-the-art faithfulness and caption quality while significantly reducing computational cost. Our method establishes a principled and efficient alternative, reducing latency by up to 2x compared to prior contrastive decoding methods that require multiple forward passes.]]></description>
<pubDate>Tue, 20 Jan 2026 08:04:18 +0000</pubDate>
</item>
<item>
<title><![CDATA[ParkingTwin: Training-Free Streaming 3D Reconstruction for Parking-Lot Digital Twins]]></title>
<link>http://arxiv.org/abs/2601.13706v1</link>
<guid>2601.13706v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.CV
Authors: Xinhao Liu, Yu Wang, Xiansheng Guo, Gordon Owusu Boateng, Yu Cao et al.
Institution: 
Published: 2026-01-20
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

High-fidelity parking-lot digital twins provide essential priors for path planning, collision checking, and perception validation in Automated Valet Parking (AVP). Yet robot-oriented reconstruction faces a trilemma: sparse forward-facing views cause weak parallax and ill-posed geometry; dynamic occlusions and extreme lighting hinder stable texture fusion; and neural rendering typically needs expensive offline optimization, violating edge-side streaming constraints. We propose ParkingTwin, a training-free, lightweight system for online streaming 3D reconstruction. First, OSM-prior-driven geometric construction uses OpenStreetMap semantic topology to directly generate a metric-consistent TSDF, replacing blind geometric search with deterministic mapping and avoiding costly optimization. Second, geometry-aware dynamic filtering employs a quad-modal constraint field (normal/height/depth consistency) to reject moving vehicles and transient occlusions in real time. Third, illumination-robust fusion in CIELAB decouples luminance and chromaticity via adaptive L-channel weighting and depth-gradient suppression, reducing seams under abrupt lighting changes. ParkingTwin runs at 30+ FPS on an entry-level GTX 1660. On a 68,000 m^2 real-world dataset, it achieves SSIM 0.87 (+16.0%), delivers about 15x end-to-end speedup, and reduces GPU memory by 83.3% compared with state-of-the-art 3D Gaussian Splatting (3DGS) that typically requires high-end GPUs (RTX 4090D). The system outputs explicit triangle meshes compatible with Unity/Unreal digital-twin pipelines. Project page: https://mihoutao-liu.github.io/ParkingTwin/]]></description>
<pubDate>Tue, 20 Jan 2026 08:03:58 +0000</pubDate>
</item>
<item>
<title><![CDATA[Reasoning or Pattern Matching? Probing Large Vision-Language Models with Visual Puzzles]]></title>
<link>http://arxiv.org/abs/2601.13705v1</link>
<guid>2601.13705v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.CV
Authors: Maria Lymperaiou, Vasileios Karampinis, Giorgos Filandrianos, Angelos Vlachos, Chrysoula Zerva et al.
Institution: Max Planck
Published: 2026-01-20
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Puzzles have long served as compact and revealing probes of human cognition, isolating abstraction, rule discovery, and systematic reasoning with minimal reliance on prior knowledge. Leveraging these properties, visual puzzles have recently emerged as a powerful diagnostic tool for evaluating the reasoning abilities of Large Vision-Language Models (LVLMs), offering controlled, verifiable alternatives to open-ended multimodal benchmarks. This survey provides a unified perspective of visual puzzle reasoning in LVLMs. We frame visual puzzles through a common abstraction and organize existing benchmarks by the reasoning mechanisms they target (inductive, analogical, algorithmic, deductive, and geometric/spatial), thereby linking puzzle design to the cognitive operations required for solving. Synthesizing empirical evidence across these categories, we identify consistent limitations in current models, including brittle generalization, tight entanglement between perception and reasoning, and a persistent gap between fluent explanations and faithful execution. By framing visual puzzles as diagnostic instruments rather than task formats, this survey elaborates on the state of LVLM reasoning and outlines key directions for future benchmarks and reasoning-aware multimodal systems.]]></description>
<pubDate>Tue, 20 Jan 2026 08:02:04 +0000</pubDate>
</item>
<item>
<title><![CDATA[Performance and Complexity Trade-off Optimization of Speech Models During Training]]></title>
<link>http://arxiv.org/abs/2601.13704v1</link>
<guid>2601.13704v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.SD, cs.AI, cs.LG
Authors: Esteban Gómez, Tom Bäckström
Institution: 
Published: 2026-01-20
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

In speech machine learning, neural network models are typically designed by choosing an architecture with fixed layer sizes and structure. These models are then trained to maximize performance on metrics aligned with the task's objective. While the overall architecture is usually guided by prior knowledge of the task, the sizes of individual layers are often chosen heuristically. However, this approach does not guarantee an optimal trade-off between performance and computational complexity; consequently, post hoc methods such as weight quantization or model pruning are typically employed to reduce computational cost. This occurs because stochastic gradient descent (SGD) methods can only optimize differentiable functions, while factors influencing computational complexity, such as layer sizes and floating-point operations per second (FLOP/s), are non-differentiable and require modifying the model structure during training. We propose a reparameterization technique based on feature noise injection that enables joint optimization of performance and computational complexity during training using SGD-based methods. Unlike traditional pruning methods, our approach allows the model size to be dynamically optimized for a target performance-complexity trade-off, without relying on heuristic criteria to select which weights or structures to remove. We demonstrate the effectiveness of our method through three case studies, including a synthetic example and two practical real-world applications: voice activity detection and audio anti-spoofing. The code related to our work is publicly available to encourage further research.]]></description>
<pubDate>Tue, 20 Jan 2026 08:00:05 +0000</pubDate>
</item>
<item>
<title><![CDATA[Does Privacy Always Harm Fairness? Data-Dependent Trade-offs via Chernoff Information Neural Estimation]]></title>
<link>http://arxiv.org/abs/2601.13698v1</link>
<guid>2601.13698v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.LG, cs.AI, cs.IT, stat.ML
Authors: Arjun Nichani, Hsiang Hsu,  Chun-Fu,  Chen, Haewon Jeong
Institution: 
Published: 2026-01-20
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Fairness and privacy are two vital pillars of trustworthy machine learning. Despite extensive research on these individual topics, the relationship between fairness and privacy has received significantly less attention. In this paper, we utilize the information-theoretic measure Chernoff Information to highlight the data-dependent nature of the relationship among the triad of fairness, privacy, and accuracy. We first define Noisy Chernoff Difference, a tool that allows us to analyze the relationship among the triad simultaneously. We then show that for synthetic data, this value behaves in 3 distinct ways (depending on the distribution of the data). We highlight the data distributions involved in these cases and explore their fairness and privacy implications. Additionally, we show that Noisy Chernoff Difference acts as a proxy for the steepness of the fairness-accuracy curves. Finally, we propose a method for estimating Chernoff Information on data from unknown distributions and utilize this framework to examine the triad dynamic on real datasets. This work builds towards a unified understanding of the fairness-privacy-accuracy relationship and highlights its data-dependent nature.]]></description>
<pubDate>Tue, 20 Jan 2026 07:51:48 +0000</pubDate>
</item>
<item>
<title><![CDATA[Uncertainty-Aware Gradient Signal-to-Noise Data Selection for Instruction Tuning]]></title>
<link>http://arxiv.org/abs/2601.13697v1</link>
<guid>2601.13697v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.CL, cs.AI, cs.LG
Authors: Zhihang Yuan, Chengyu Yue, Long Huang, Litu Ou, Lei Shi
Institution: 
Published: 2026-01-20
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Instruction tuning is a standard paradigm for adapting large language models (LLMs), but modern instruction datasets are large, noisy, and redundant, making full-data fine-tuning costly and often unnecessary. Existing data selection methods either build expensive gradient datastores or assign static scores from a weak proxy, largely ignoring evolving uncertainty, and thus missing a key source of LLM interpretability. We propose GRADFILTERING, an objective-agnostic, uncertainty-aware data selection framework that utilizes a small GPT-2 proxy with a LoRA ensemble and aggregates per-example gradients into a Gradient Signal-to-Noise Ratio (G-SNR) utility. Our method matches or surpasses random subsets and strong baselines in most LLM-as-a-judge evaluations as well as in human assessment. Moreover, GRADFILTERING-selected subsets converge faster than competitive filters under the same compute budget, reflecting the benefit of uncertainty-aware scoring.]]></description>
<pubDate>Tue, 20 Jan 2026 07:51:32 +0000</pubDate>
</item>
<item>
<title><![CDATA[OptiSQL: Executable SQL Generation from Optical TokensOptiSQL: Executable SQL Generation from Optical Tokens]]></title>
<link>http://arxiv.org/abs/2601.13695v1</link>
<guid>2601.13695v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.CL
Authors: Sifan Li, Hongkai Chen, Yujun Cai, Liyang Chen, Qingwen Ye et al.
Institution: 
Published: 2026-01-20
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Executable SQL generation is typically studied in text-to-SQL settings, where tables are provided as fully linearized textual schemas and contents. While effective, this formulation assumes access to structured text and incurs substantial token overhead, which is misaligned with many real-world scenarios where tables appear as visual artifacts in documents or webpages. We investigate whether compact optical representations can serve as an efficient interface for executable semantic parsing. We present OptiSQL, a vision-driven framework that generates executable SQL directly from table images and natural language questions using compact optical tokens. OptiSQL leverages an OCR-oriented visual encoder to compress table structure and content into a small set of optical tokens and fine-tunes a pretrained decoder for SQL generation while freezing the encoder to isolate representation sufficiency. Experiments on a visualized version of Spider 2.0-Snow show that OptiSQL retains strong execution accuracy while reducing table input tokens by an order of magnitude. Robustness analyses further demonstrate that optical tokens preserve essential structural information under visual perturbations.]]></description>
<pubDate>Tue, 20 Jan 2026 07:49:29 +0000</pubDate>
</item>
<item>
<title><![CDATA[End-to-End Reverse Screening Identifies Protein Targets of Small Molecules Using HelixFold3]]></title>
<link>http://arxiv.org/abs/2601.13693v1</link>
<guid>2601.13693v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.AI
Authors: Shengjie Xu, Xianbin Ye, Mengran Zhu, Xiaonan Zhang, Shanzhuo Zhang et al.
Institution: 
Published: 2026-01-20
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Identifying protein targets for small molecules, or reverse screening, is essential for understanding drug action, guiding compound repurposing, predicting off-target effects, and elucidating the molecular mechanisms of bioactive compounds. Despite its critical role, reverse screening remains challenging because accurately capturing interactions between a small molecule and structurally diverse proteins is inherently complex, and conventional step-wise workflows often propagate errors across decoupled steps such as target structure modeling, pocket identification, docking, and scoring. Here, we present an end-to-end reverse screening strategy leveraging HelixFold3, a high-accuracy biomolecular structure prediction model akin to AlphaFold3, which simultaneously models the folding of proteins from a protein library and the docking of small-molecule ligands within a unified framework. We validate this approach on a diverse and representative set of approximately one hundred small molecules. Compared with conventional reverse docking, our method improves screening accuracy and demonstrates enhanced structural fidelity, binding-site precision, and target prioritization. By systematically linking small molecules to their protein targets, this framework establishes a scalable and straightforward platform for dissecting molecular mechanisms, exploring off-target interactions, and supporting rational drug discovery.]]></description>
<pubDate>Tue, 20 Jan 2026 07:45:53 +0000</pubDate>
</item>
<item>
<title><![CDATA[Dr. Assistant: Enhancing Clinical Diagnostic Inquiry via Structured Diagnostic Reasoning Data and Reinforcement Learning]]></title>
<link>http://arxiv.org/abs/2601.13690v1</link>
<guid>2601.13690v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.CL
Authors: Yue Guo, Fanfu Wang, Jianwei Lv, Xincheng Shi, Yuchen Li et al.
Institution: 
Published: 2026-01-20
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Clinical Decision Support Systems (CDSSs) provide reasoning and inquiry guidance for physicians, yet they face notable challenges, including high maintenance costs and low generalization capability. Recently, Large Language Models (LLMs) have been widely adopted in healthcare due to their extensive knowledge reserves, retrieval, and communication capabilities. While LLMs show promise and excel at medical benchmarks, their diagnostic reasoning and inquiry skills are constrained. To mitigate this issue, we propose (1) Clinical Diagnostic Reasoning Data (CDRD) structure to capture abstract clinical reasoning logic, and a pipeline for its construction, and (2) the Dr. Assistant, a clinical diagnostic model equipped with clinical reasoning and inquiry skills. Its training involves a two-stage process: SFT, followed by RL with a tailored reward function. We also introduce a benchmark to evaluate both diagnostic reasoning and inquiry. Our experiments demonstrate that the Dr. Assistant outperforms open-source models and achieves competitive performance to closed-source models, providing an effective solution for clinical diagnostic inquiry guidance.]]></description>
<pubDate>Tue, 20 Jan 2026 07:43:57 +0000</pubDate>
</item>
<item>
<title><![CDATA[Understanding Mental States to Guide Social Influence in Multi-Person Group Dialogue]]></title>
<link>http://arxiv.org/abs/2601.13687v1</link>
<guid>2601.13687v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.AI
Authors: Zhichao Liang, Satoshi Nakamura
Institution: 
Published: 2026-01-20
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Existing dynamic Theory of Mind (ToM) benchmarks mostly place language models in a passive role: the model reads a sequence of connected scenarios and reports what people believe, feel, intend, and do as these states change. In real social interaction, ToM is also used for action: a speaker plans what to say in order to shift another person's mental-state trajectory toward a goal. We introduce SocialMindChange, a benchmark that moves from tracking minds to changing minds in social interaction. Each instance defines a social context with 4 characters and five connected scenes. The model plays one character and generates dialogue across the five scenes to reach the target while remaining consistent with the evolving states of all participants. SocialMindChange also includes selected higher-order states. Using a structured four-step framework, we construct 1,200 social contexts, covering 6000 scenarios and over 90,000 questions, each validated for realism and quality. Evaluations on ten state-of-the-art LLMs show that their average performance is 54.2% below human performance. This gap suggests that current LLMs still struggle to maintain and change mental-state representations across long, linked interactions.]]></description>
<pubDate>Tue, 20 Jan 2026 07:41:26 +0000</pubDate>
</item>
<item>
<title><![CDATA[HeteroCache: A Dynamic Retrieval Approach to Heterogeneous KV Cache Compression for Long-Context LLM Inference]]></title>
<link>http://arxiv.org/abs/2601.13684v1</link>
<guid>2601.13684v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.CL, cs.AI
Authors: Zhiyuan Shi, Qibo Qiu, Feng Xue, Zhonglin Jiang, Li Yu et al.
Institution: 
Published: 2026-01-20
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

The linear memory growth of the KV cache poses a significant bottleneck for LLM inference in long-context tasks. Existing static compression methods often fail to preserve globally important information, principally because they overlook the attention drift phenomenon where token significance evolves dynamically. Although recent dynamic retrieval approaches attempt to address this issue, they typically suffer from coarse-grained caching strategies and incur high I/O overhead due to frequent data transfers. To overcome these limitations, we propose HeteroCache, a training-free dynamic compression framework. Our method is built on two key insights: attention heads exhibit diverse temporal heterogeneity, and there is significant spatial redundancy among heads within the same layer. Guided by these insights, HeteroCache categorizes heads based on stability and redundancy. Consequently, we apply a fine-grained weighting strategy that allocates larger cache budgets to heads with rapidly shifting attention to capture context changes, thereby addressing the inefficiency of coarse-grained strategies. Furthermore, we employ a hierarchical storage mechanism in which a subset of representative heads monitors attention shift, and trigger an asynchronous, on-demand retrieval of contexts from the CPU, effectively hiding I/O latency. Finally, experiments demonstrate that HeteroCache achieves state-of-the-art performance on multiple long-context benchmarks and accelerates decoding by up to $3\times$ compared to the original model in the 224K context. Our code will be open-source.]]></description>
<pubDate>Tue, 20 Jan 2026 07:35:06 +0000</pubDate>
</item>
<item>
<title><![CDATA[Dynamic Differential Linear Attention: Enhancing Linear Diffusion Transformer for High-Quality Image Generation]]></title>
<link>http://arxiv.org/abs/2601.13683v1</link>
<guid>2601.13683v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.CV
Authors: Boyuan Cao, Xingbo Yao, Chenhui Wang, Jiaxin Ye, Yujie Wei et al.
Institution: 
Published: 2026-01-20
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Diffusion transformers (DiTs) have emerged as a powerful architecture for high-fidelity image generation, yet the quadratic cost of self-attention poses a major scalability bottleneck. To address this, linear attention mechanisms have been adopted to reduce computational cost; unfortunately, the resulting linear diffusion transformers (LiTs) models often come at the expense of generative performance, frequently producing over-smoothed attention weights that limit expressiveness. In this work, we introduce Dynamic Differential Linear Attention (DyDiLA), a novel linear attention formulation that enhances the effectiveness of LiTs by mitigating the oversmoothing issue and improving generation quality. Specifically, the novelty of DyDiLA lies in three key designs: (i) dynamic projection module, which facilitates the decoupling of token representations by learning with dynamically assigned knowledge; (ii) dynamic measure kernel, which provides a better similarity measurement to capture fine-grained semantic distinctions between tokens by dynamically assigning kernel functions for token processing; and (iii) token differential operator, which enables more robust query-to-key retrieval by calculating the differences between the tokens and their corresponding information redundancy produced by dynamic measure kernel. To capitalize on DyDiLA, we introduce a refined LiT, termed DyDi-LiT, that systematically incorporates our advancements. Extensive experiments show that DyDi-LiT consistently outperforms current state-of-the-art (SOTA) models across multiple metrics, underscoring its strong practical potential.]]></description>
<pubDate>Tue, 20 Jan 2026 07:33:16 +0000</pubDate>
</item>
<item>
<title><![CDATA[Autoregressive deep learning for real-time simulation of soft tissue dynamics during virtual neurosurgery]]></title>
<link>http://arxiv.org/abs/2601.13676v1</link>
<guid>2601.13676v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.LG
Authors: Fabian Greifeneder, Wolfgang Fenz, Benedikt Alkin, Johannes Brandstetter, Michael Giretzlehner et al.
Institution: 
Published: 2026-01-20
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Accurate simulation of brain deformation is a key component for developing realistic, interactive neurosurgical simulators, as complex nonlinear deformations must be captured to ensure realistic tool-tissue interactions. However, traditional numerical solvers often fall short in meeting real-time performance requirements. To overcome this, we introduce a deep learning-based surrogate model that efficiently simulates transient brain deformation caused by continuous interactions between surgical instruments and the virtual brain geometry. Building on Universal Physics Transformers, our approach operates directly on large-scale mesh data and is trained on an extensive dataset generated from nonlinear finite element simulations, covering a broad spectrum of temporal instrument-tissue interaction scenarios. To reduce the accumulation of errors in autoregressive inference, we propose a stochastic teacher forcing strategy applied during model training. Specifically, training consists of short stochastic rollouts in which the proportion of ground truth inputs is gradually decreased in favor of model-generated predictions. Our results show that the proposed surrogate model achieves accurate and efficient predictions across a range of transient brain deformation scenarios, scaling to meshes with up to 150,000 nodes. The introduced stochastic teacher forcing technique substantially improves long-term rollout stability, reducing the maximum prediction error from 6.7 mm to 3.5 mm. We further integrate the trained surrogate model into an interactive neurosurgical simulation environment, achieving runtimes below 10 ms per simulation step on consumer-grade inference hardware. Our proposed deep learning framework enables rapid, smooth and accurate biomechanical simulations of dynamic brain tissue deformation, laying the foundation for realistic surgical training environments.]]></description>
<pubDate>Tue, 20 Jan 2026 07:25:32 +0000</pubDate>
</item>
<item>
<title><![CDATA[The Orchestration of Multi-Agent Systems: Architectures, Protocols, and Enterprise Adoption]]></title>
<link>http://arxiv.org/abs/2601.13671v1</link>
<guid>2601.13671v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.MA, cs.AI
Authors: Apoorva Adimulam, Rajesh Gupta, Sumit Kumar
Institution: MIT
Published: 2026-01-20
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Orchestrated multi-agent systems represent the next stage in the evolution of artificial intelligence, where autonomous agents collaborate through structured coordination and communication to achieve complex, shared objectives. This paper consolidates and formalizes the technical composition of such systems, presenting a unified architectural framework that integrates planning, policy enforcement, state management, and quality operations into a coherent orchestration layer. Another primary contribution of this work is the in-depth technical delineation of two complementary communication protocols - the Model Context Protocol, which standardizes how agents access external tools and contextual data, and the Agent2Agent protocol, which governs peer coordination, negotiation, and delegation. Together, these protocols establish an interoperable communication substrate that enables scalable, auditable, and policy-compliant reasoning across distributed agent collectives. Beyond protocol design, the paper details how orchestration logic, governance frameworks, and observability mechanisms collectively sustain system coherence, transparency, and accountability. By synthesizing these elements into a cohesive technical blueprint, this paper provides comprehensive treatments of orchestrated multi-agent systems - bridging conceptual architectures with implementation-ready design principles for enterprise-scale AI ecosystems.]]></description>
<pubDate>Tue, 20 Jan 2026 07:13:53 +0000</pubDate>
</item>
<item>
<title><![CDATA[CommunityBench: Benchmarking Community-Level Alignment across Diverse Groups and Tasks]]></title>
<link>http://arxiv.org/abs/2601.13669v1</link>
<guid>2601.13669v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.CL
Authors: Jiayu Lin, Zhongyu Wei
Institution: 
Published: 2026-01-20
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Large language models (LLMs) alignment ensures model behaviors reflect human value. Existing alignment strategies primarily follow two paths: one assumes a universal value set for a unified goal (i.e., one-size-fits-all), while the other treats every individual as unique to customize models (i.e., individual-level). However, assuming a monolithic value space marginalizes minority norms, while tailoring individual models is prohibitively expensive. Recognizing that human society is organized into social clusters with high intra-group value alignment, we propose community-level alignment as a "middle ground". Practically, we introduce CommunityBench, the first large-scale benchmark for community-level alignment evaluation, featuring four tasks grounded in Common Identity and Common Bond theory. With CommunityBench, we conduct a comprehensive evaluation of various foundation models on CommunityBench, revealing that current LLMs exhibit limited capacity to model community-specific preferences. Furthermore, we investigate the potential of community-level alignment in facilitating individual modeling, providing a promising direction for scalable and pluralistic alignment.]]></description>
<pubDate>Tue, 20 Jan 2026 07:10:50 +0000</pubDate>
</item>
<item>
<title><![CDATA[Transformer based Multi-task Fusion Network for Food Spoilage Detection and Shelf life Forecasting]]></title>
<link>http://arxiv.org/abs/2601.13665v1</link>
<guid>2601.13665v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.CV
Authors: Mounika Kanulla, Rajasree Dadigi, Sailaja Thota, Vivek Yelleti
Institution: 
Published: 2026-01-20
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Food wastage is one of the critical challenges in the agricultural supply chain, and accurate and effective spoilage detection can help to reduce it. Further, it is highly important to forecast the spoilage information. This aids the longevity of the supply chain management in the agriculture field. This motivated us to propose fusion based architectures by combining CNN with LSTM and DeiT transformer for the following multi-tasks simultaneously: (i) vegetable classification, (ii) food spoilage detection, and (iii) shelf life forecasting. We developed a dataset by capturing images of vegetables from their fresh state until they were completely spoiled. From the experimental analysis it is concluded that the proposed fusion architectures CNN+CNN-LSTM and CNN+DeiT Transformer outperformed several deep learning models such as CNN, VGG16, ResNet50, Capsule Networks, and DeiT Transformers. Overall, CNN + DeiT Transformer yielded F1-score of 0.98 and 0.61 in vegetable classification and spoilage detection respectively and mean squared error (MSE) and symmetric mean absolute percentage error (SMAPE) of 3.58, and 41.66% respectively in spoilage forecasting. Further, the reliability of the fusion models was validated on noisy images and integrated with LIME to visualize the model decisions.]]></description>
<pubDate>Tue, 20 Jan 2026 07:07:21 +0000</pubDate>
</item>
<item>
<title><![CDATA[VIAFormer: Voxel-Image Alignment Transformer for High-Fidelity Voxel Refinement]]></title>
<link>http://arxiv.org/abs/2601.13664v1</link>
<guid>2601.13664v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.CV
Authors: Tiancheng Fang, Bowen Pan, Lingxi Chen, Jiangjing Lyu, Chengfei Lyu et al.
Institution: 
Published: 2026-01-20
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

We propose VIAFormer, a Voxel-Image Alignment Transformer model designed for Multi-view Conditioned Voxel Refinement--the task of repairing incomplete noisy voxels using calibrated multi-view images as guidance. Its effectiveness stems from a synergistic design: an Image Index that provides explicit 3D spatial grounding for 2D image tokens, a Correctional Flow objective that learns a direct voxel-refinement trajectory, and a Hybrid Stream Transformer that enables robust cross-modal fusion. Experiments show that VIAFormer establishes a new state of the art in correcting both severe synthetic corruptions and realistic artifacts on the voxel shape obtained from powerful Vision Foundation Models. Beyond benchmarking, we demonstrate VIAFormer as a practical and reliable bridge in real-world 3D creation pipelines, paving the way for voxel-based methods to thrive in large-model, big-data wave.]]></description>
<pubDate>Tue, 20 Jan 2026 07:03:35 +0000</pubDate>
</item>
<item>
<title><![CDATA[Reinforcement Learning for Opportunistic Routing in Software-Defined LEO-Terrestrial Systems]]></title>
<link>http://arxiv.org/abs/2601.13662v1</link>
<guid>2601.13662v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.NI, cs.LG
Authors: Sivaram Krishnan, Zhouyou Gu, Jihong Park, Sung-Min Oh, Jinho Choi
Institution: 
Published: 2026-01-20
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

The proliferation of large-scale low Earth orbit (LEO) satellite constellations is driving the need for intelligent routing strategies that can effectively deliver data to terrestrial networks under rapidly time-varying topologies and intermittent gateway visibility. Leveraging the global control capabilities of a geostationary (GEO)-resident software-defined networking (SDN) controller, we introduce opportunistic routing, which aims to minimize delivery delay by forwarding packets to any currently available ground gateways rather than fixed destinations. This makes it a promising approach for achieving low-latency and robust data delivery in highly dynamic LEO networks. Specifically, we formulate a constrained stochastic optimization problem and employ a residual reinforcement learning framework to optimize opportunistic routing for reducing transmission delay. Simulation results over multiple days of orbital data demonstrate that our method achieves significant improvements in queue length reduction compared to classical backpressure and other well-known queueing algorithms.]]></description>
<pubDate>Tue, 20 Jan 2026 07:01:14 +0000</pubDate>
</item>
<item>
<title><![CDATA[Temporal-Spatial Decouple before Act: Disentangled Representation Learning for Multimodal Sentiment Analysis]]></title>
<link>http://arxiv.org/abs/2601.13659v1</link>
<guid>2601.13659v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.CL, cs.AI, cs.MM
Authors: Chunlei Meng, Ziyang Zhou, Lucas He, Xiaojing Du, Chun Ouyang et al.
Institution: 
Published: 2026-01-20
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Multimodal Sentiment Analysis integrates Linguistic, Visual, and Acoustic. Mainstream approaches based on modality-invariant and modality-specific factorization or on complex fusion still rely on spatiotemporal mixed modeling. This ignores spatiotemporal heterogeneity, leading to spatiotemporal information asymmetry and thus limited performance. Hence, we propose TSDA, Temporal-Spatial Decouple before Act, which explicitly decouples each modality into temporal dynamics and spatial structural context before any interaction. For every modality, a temporal encoder and a spatial encoder project signals into separate temporal and spatial body. Factor-Consistent Cross-Modal Alignment then aligns temporal features only with their temporal counterparts across modalities, and spatial features only with their spatial counterparts. Factor specific supervision and decorrelation regularization reduce cross factor leakage while preserving complementarity. A Gated Recouple module subsequently recouples the aligned streams for task. Extensive experiments show that TSDA outperforms baselines. Ablation analysis studies confirm the necessity and interpretability of the design.]]></description>
<pubDate>Tue, 20 Jan 2026 06:50:40 +0000</pubDate>
</item>
<item>
<title><![CDATA[Beyond Known Facts: Generating Unseen Temporal Knowledge to Address Data Contamination in LLM Evaluation]]></title>
<link>http://arxiv.org/abs/2601.13658v1</link>
<guid>2601.13658v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.CL
Authors: Arthur Amalvy, Hen-Hsen Huang
Institution: 
Published: 2026-01-20
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

The automatic extraction of information is important for populating large web knowledge bases such as Wikidata. The temporal version of that task, temporal knowledge graph extraction (TKGE), involves extracting temporally grounded facts from text, represented as semantic quadruples (subject, relation, object, timestamp). Many recent systems take advantage of large language models (LLMs), which are becoming a new cornerstone of the web due to their performance on many tasks across the natural language processing (NLP) field. Despite the importance of TKGE, existing datasets for training and evaluation remain scarce, and contamination of evaluation data is an unaddressed issue, potentially inflating LLMs' perceived performance due to overlaps between training and evaluation sets. To mitigate these challenges, we propose a novel synthetic evaluation dataset constructed from predicted future, previously unseen temporal facts, thereby eliminating contamination and enabling robust and unbiased benchmarking. Our dataset creation involves a two-step approach: (1) Temporal Knowledge Graph Forecasting (TKGF) generates plausible future quadruples, which are subsequently filtered to adhere to the original knowledge base schema; (2) LLMs perform quadruple-to-text generation, creating semantically aligned textual descriptions. We benchmark Extract, Define and Canonicalize (EDC), a state-of-the-art LLM-based extraction framework, demonstrating that LLM performance decreases when evaluated on our dataset compared to a dataset of known facts. We publicly release our dataset consisting of 4.2K future quadruples and corresponding textual descriptions, along with the generation methodology, enabling continuous creation of unlimited future temporal datasets to serve as long-term, contamination-free benchmarks for TKGE.]]></description>
<pubDate>Tue, 20 Jan 2026 06:48:42 +0000</pubDate>
</item>
<item>
<title><![CDATA[Communication-Free Collective Navigation for a Swarm of UAVs via LiDAR-Based Deep Reinforcement Learning]]></title>
<link>http://arxiv.org/abs/2601.13657v1</link>
<guid>2601.13657v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.RO, cs.AI, cs.LG, cs.MA
Authors: Myong-Yol Choi, Hankyoul Ko, Hanse Cho, Changseung Kim, Seunghwan Kim et al.
Institution: 
Published: 2026-01-20
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

This paper presents a deep reinforcement learning (DRL) based controller for collective navigation of unmanned aerial vehicle (UAV) swarms in communication-denied environments, enabling robust operation in complex, obstacle-rich environments. Inspired by biological swarms where informed individuals guide groups without explicit communication, we employ an implicit leader-follower framework. In this paradigm, only the leader possesses goal information, while follower UAVs learn robust policies using only onboard LiDAR sensing, without requiring any inter-agent communication or leader identification. Our system utilizes LiDAR point clustering and an extended Kalman filter for stable neighbor tracking, providing reliable perception independent of external positioning systems. The core of our approach is a DRL controller, trained in GPU-accelerated Nvidia Isaac Sim, that enables followers to learn complex emergent behaviors - balancing flocking and obstacle avoidance - using only local perception. This allows the swarm to implicitly follow the leader while robustly addressing perceptual challenges such as occlusion and limited field-of-view. The robustness and sim-to-real transfer of our approach are confirmed through extensive simulations and challenging real-world experiments with a swarm of five UAVs, which successfully demonstrated collective navigation across diverse indoor and outdoor environments without any communication or external localization.]]></description>
<pubDate>Tue, 20 Jan 2026 06:46:09 +0000</pubDate>
</item>
<item>
<title><![CDATA[Why Does the LLM Stop Computing: An Empirical Study of User-Reported Failures in Open-Source LLMs]]></title>
<link>http://arxiv.org/abs/2601.13655v1</link>
<guid>2601.13655v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.SE, cs.AI, cs.DC
Authors: Guangba Yu, Zirui Wang, Yujie Huang, Renyi Zhong, Yuedong Zhong et al.
Institution: 
Published: 2026-01-20
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

The democratization of open-source Large Language Models (LLMs) allows users to fine-tune and deploy models on local infrastructure but exposes them to a First Mile deployment landscape. Unlike black-box API consumption, the reliability of user-managed orchestration remains a critical blind spot. To bridge this gap, we conduct the first large-scale empirical study of 705 real-world failures from the open-source DeepSeek, Llama, and Qwen ecosystems.
  Our analysis reveals a paradigm shift: white-box orchestration relocates the reliability bottleneck from model algorithmic defects to the systemic fragility of the deployment stack. We identify three key phenomena: (1) Diagnostic Divergence: runtime crashes distinctively signal infrastructure friction, whereas incorrect functionality serves as a signature for internal tokenizer defects. (2) Systemic Homogeneity: Root causes converge across divergent series, confirming reliability barriers are inherent to the shared ecosystem rather than specific architectures. (3) Lifecycle Escalation: Barriers escalate from intrinsic configuration struggles during fine-tuning to compounded environmental incompatibilities during inference. Supported by our publicly available dataset, these insights provide actionable guidance for enhancing the reliability of the LLM landscape.]]></description>
<pubDate>Tue, 20 Jan 2026 06:42:56 +0000</pubDate>
</item>
<item>
<title><![CDATA[TimeART: Towards Agentic Time Series Reasoning via Tool-Augmentation]]></title>
<link>http://arxiv.org/abs/2601.13653v1</link>
<guid>2601.13653v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.LG
Authors: Xingjian Wu, Junkai Lu, Zhengyu Li, Xiangfei Qiu, Jilin Hu et al.
Institution: 
Published: 2026-01-20
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Time series data widely exist in real-world cyber-physical systems. Though analyzing and interpreting them contributes to significant values, e.g, disaster prediction and financial risk control, current workflows mainly rely on human data scientists, which requires significant labor costs and lacks automation. To tackle this, we introduce TimeART, a framework fusing the analytical capability of strong out-of-the-box tools and the reasoning capability of Large Language Models (LLMs), which serves as a fully agentic data scientist for Time Series Question Answering (TSQA). To teach the LLM-based Time Series Reasoning Models (TSRMs) strategic tool-use, we also collect a 100k expert trajectory corpus called TimeToolBench. To enhance TSRMs' generalization capability, we then devise a four-stage training strategy, which boosts TSRMs through learning from their own early experiences and self-reflections. Experimentally, we train an 8B TSRM on TimeToolBench and equip it with the TimeART framework, and it achieves consistent state-of-the-art performance on multiple TSQA tasks, which pioneers a novel approach towards agentic time series reasoning.]]></description>
<pubDate>Tue, 20 Jan 2026 06:39:10 +0000</pubDate>
</item>
<item>
<title><![CDATA[Face-Voice Association with Inductive Bias for Maximum Class Separation]]></title>
<link>http://arxiv.org/abs/2601.13651v1</link>
<guid>2601.13651v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.CV
Authors: Marta Moscati, Oleksandr Kats, Mubashir Noman, Muhammad Zaigham Zaheer, Yufang Hou et al.
Institution: 
Published: 2026-01-20
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Face-voice association is widely studied in multimodal learning and is approached representing faces and voices with embeddings that are close for a same person and well separated from those of others. Previous work achieved this with loss functions. Recent advancements in classification have shown that the discriminative ability of embeddings can be strengthened by imposing maximum class separation as inductive bias. This technique has never been used in the domain of face-voice association, and this work aims at filling this gap. More specifically, we develop a method for face-voice association that imposes maximum class separation among multimodal representations of different speakers as an inductive bias. Through quantitative experiments we demonstrate the effectiveness of our approach, showing that it achieves SOTA performance on two task formulation of face-voice association. Furthermore, we carry out an ablation study to show that imposing inductive bias is most effective when combined with losses for inter-class orthogonality. To the best of our knowledge, this work is the first that applies and demonstrates the effectiveness of maximum class separation as an inductive bias in multimodal learning; it hence paves the way to establish a new paradigm.]]></description>
<pubDate>Tue, 20 Jan 2026 06:38:10 +0000</pubDate>
</item>
<item>
<title><![CDATA[Fairness or Fluency? An Investigation into Language Bias of Pairwise LLM-as-a-Judge]]></title>
<link>http://arxiv.org/abs/2601.13649v1</link>
<guid>2601.13649v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.CL, cs.AI
Authors: Xiaolin Zhou, Zheng Luo, Yicheng Gao, Qixuan Chen, Xiyang Hu et al.
Institution: 
Published: 2026-01-20
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Recent advances in Large Language Models (LLMs) have incentivized the development of LLM-as-a-judge, an application of LLMs where they are used as judges to decide the quality of a certain piece of text given a certain context. However, previous studies have demonstrated that LLM-as-a-judge can be biased towards different aspects of the judged texts, which often do not align with human preference. One of the identified biases is language bias, which indicates that the decision of LLM-as-a-judge can differ based on the language of the judged texts. In this paper, we study two types of language bias in pairwise LLM-as-a-judge: (1) performance disparity between languages when the judge is prompted to compare options from the same language, and (2) bias towards options written in major languages when the judge is prompted to compare options of two different languages. We find that for same-language judging, there exist significant performance disparities across language families, with European languages consistently outperforming African languages, and this bias is more pronounced in culturally-related subjects. For inter-language judging, we observe that most models favor English answers, and that this preference is influenced more by answer language than question language. Finally, we investigate whether language bias is in fact caused by low-perplexity bias, a previously identified bias of LLM-as-a-judge, and we find that while perplexity is slightly correlated with language bias, language bias cannot be fully explained by perplexity only.]]></description>
<pubDate>Tue, 20 Jan 2026 06:33:33 +0000</pubDate>
</item>
<item>
<title><![CDATA[Fusion Segment Transformer: Bi-Directional Attention Guided Fusion Network for AI-Generated Music Detection]]></title>
<link>http://arxiv.org/abs/2601.13647v1</link>
<guid>2601.13647v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.SD, cs.AI
Authors: Yumin Kim, Seonghyeon Go
Institution: 
Published: 2026-01-20
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

With the rise of generative AI technology, anyone can now easily create and deploy AI-generated music, which has heightened the need for technical solutions to address copyright and ownership issues. While existing works mainly focused on short-audio, the challenge of full-audio detection, which requires modeling long-term structure and context, remains insufficiently explored. To address this, we propose an improved version of the Segment Transformer, termed the Fusion Segment Transformer. As in our previous work, we extract content embeddings from short music segments using diverse feature extractors. Furthermore, we enhance the architecture for full-audio AI-generated music detection by introducing a Gated Fusion Layer that effectively integrates content and structural information, enabling the capture of long-term context. Experiments on the SONICS and AIME datasets show that our approach outperforms the previous model and recent baselines, achieving state-of-the-art results in AI-generated music detection.]]></description>
<pubDate>Tue, 20 Jan 2026 06:31:05 +0000</pubDate>
</item>
</channel>
</rss>