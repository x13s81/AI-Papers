<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
<channel>
<title>AI Papers - 2026-01-27</title>
<link>https://arxiv.org</link>
<description>AI papers as of 2026-01-27 - 244 papers</description>
<lastBuildDate>Tue, 27 Jan 2026 14:26:48 +0000</lastBuildDate>
<item>
<title><![CDATA[LongCat-Flash-Thinking-2601 Technical Report]]></title>
<link>https://huggingface.co/papers/2601.16725</link>
<guid>2601.16725</guid>
<description><![CDATA[Source: HuggingFace
Tags: 
Authors: Meituan LongCat Team, Anchun Gui, Bei Li, Bingyang Tao, Bole Zhou
Institution: 
Published: 2026-01-23
Score: 9/10
Citations: 0
Upvotes: 149
GitHub: 
Stars: 0

We introduce LongCat-Flash-Thinking-2601, a 560-billion-parameter open-source Mixture-of-Experts (MoE) reasoning model with superior agentic reasoning capability. LongCat-Flash-Thinking-2601 achieves state-of-the-art performance among open-source models on a wide range of agentic benchmarks, including agentic search, agentic tool use, and tool-integrated reasoning. Beyond benchmark performance, the model demonstrates strong generalization to complex tool interactions and robust behavior under noisy real-world environments. Its advanced capability stems from a unified training framework that combines domain-parallel expert training with subsequent fusion, together with an end-to-end co-design of data construction, environments, algorithms, and infrastructure spanning from pre-training to post-training. In particular, the model's strong generalization capability in complex tool-use are driven by our in-depth exploration of environment scaling and principled task construction. To optimize long-tailed, skewed generation and multi-turn agentic interactions, and to enable stable training across over 10,000 environments spanning more than 20 domains, we systematically extend our asynchronous reinforcement learning framework, DORA, for stable and efficient large-scale multi-environment training. Furthermore, recognizing that real-world tasks are inherently noisy, we conduct a systematic analysis and decomposition of real-world noise patterns, and design targeted training procedures to explicitly incorporate such imperfections into the training process, resulting in improved robustness for real-world applications. To further enhance performance on complex reasoning tasks, we introduce a Heavy Thinking mode that enables effective test-time scaling by jointly expanding reasoning depth and width through intensive parallel thinking.]]></description>
<pubDate>Fri, 23 Jan 2026 13:20:09 +0000</pubDate>
</item>
<item>
<title><![CDATA[AR-Omni: A Unified Autoregressive Model for Any-to-Any Generation]]></title>
<link>https://huggingface.co/papers/2601.17761</link>
<guid>2601.17761</guid>
<description><![CDATA[Source: HuggingFace
Tags: 
Authors: Dongjie Cheng, Ruifeng Yuan, Yongqi Li, Runyang You, Wenjie Wang
Institution: 
Published: 2026-01-25
Score: 9/10
Citations: 0
Upvotes: 6
GitHub: 
Stars: 0

Real-world perception and interaction are inherently multimodal, encompassing not only language but also vision and speech, which motivates the development of "Omni" MLLMs that support both multimodal inputs and multimodal outputs. While a sequence of omni MLLMs has emerged, most existing systems still rely on additional expert components to achieve multimodal generation, limiting the simplicity of unified training and inference. Autoregressive (AR) modeling, with a single token stream, a single next-token objective, and a single decoder, is an elegant and scalable foundation in the text domain. Motivated by this, we present AR-Omni, a unified any-to-any model in the autoregressive paradigm without any expert decoders. AR-Omni supports autoregressive text and image generation, as well as streaming speech generation, all under a single Transformer decoder. We further address three practical issues in unified AR modeling: modality imbalance via task-aware loss reweighting, visual fidelity via a lightweight token-level perceptual alignment loss for image tokens, and stability-creativity trade-offs via a finite-state decoding mechanism. Empirically, AR-Omni achieves strong quality across three modalities while remaining real-time, achieving a 0.88 real-time factor for speech generation.]]></description>
<pubDate>Sun, 25 Jan 2026 09:17:36 +0000</pubDate>
</item>
<item>
<title><![CDATA[The Script is All You Need: An Agentic Framework for Long-Horizon Dialogue-to-Cinematic Video Generation]]></title>
<link>https://huggingface.co/papers/2601.17737</link>
<guid>2601.17737</guid>
<description><![CDATA[Source: HuggingFace
Tags: 
Authors: Chenyu Mu, Xin He, Qu Yang, Wanshun Chen, Jiadi Yao
Institution: 
Published: 2026-01-25
Score: 8/10
Citations: 0
Upvotes: 44
GitHub: 
Stars: 0

Recent advances in video generation have produced models capable of synthesizing stunning visual content from simple text prompts. However, these models struggle to generate long-form, coherent narratives from high-level concepts like dialogue, revealing a ``semantic gap'' between a creative idea and its cinematic execution. To bridge this gap, we introduce a novel, end-to-end agentic framework for dialogue-to-cinematic-video generation. Central to our framework is ScripterAgent, a model trained to translate coarse dialogue into a fine-grained, executable cinematic script. To enable this, we construct ScriptBench, a new large-scale benchmark with rich multimodal context, annotated via an expert-guided pipeline. The generated script then guides DirectorAgent, which orchestrates state-of-the-art video models using a cross-scene continuous generation strategy to ensure long-horizon coherence. Our comprehensive evaluation, featuring an AI-powered CriticAgent and a new Visual-Script Alignment (VSA) metric, shows our framework significantly improves script faithfulness and temporal fidelity across all tested video models. Furthermore, our analysis uncovers a crucial trade-off in current SOTA models between visual spectacle and strict script adherence, providing valuable insights for the future of automated filmmaking.]]></description>
<pubDate>Sun, 25 Jan 2026 08:10:28 +0000</pubDate>
</item>
<item>
<title><![CDATA[Elastic Attention: Test-time Adaptive Sparsity Ratios for Efficient Transformers]]></title>
<link>https://huggingface.co/papers/2601.17367</link>
<guid>2601.17367</guid>
<description><![CDATA[Source: HuggingFace
Tags: 
Authors: Zecheng Tang, Quantong Qiu, Yi Yang, Zhiyi Hong, Haiya Xiang
Institution: 
Published: 2026-01-24
Score: 8/10
Citations: 0
Upvotes: 24
GitHub: 
Stars: 0

The quadratic complexity of standard attention mechanisms poses a significant scalability bottleneck for large language models (LLMs) in long-context scenarios. While hybrid attention strategies that combine sparse and full attention within a single model offer a viable solution, they typically employ static computation ratios (i.e., fixed proportions of sparse versus full attention) and fail to adapt to the varying sparsity sensitivities of downstream tasks during inference. To address this issue, we propose Elastic Attention, which allows the model to dynamically adjust its overall sparsity based on the input. This is achieved by integrating a lightweight Attention Router into the existing pretrained model, which dynamically assigns each attention head to different computation modes. Within only 12 hours of training on 8xA800 GPUs, our method enables models to achieve both strong performance and efficient inference. Experiments across three long-context benchmarks on widely-used LLMs demonstrate the superiority of our method.]]></description>
<pubDate>Sat, 24 Jan 2026 08:22:07 +0000</pubDate>
</item>
<item>
<title><![CDATA[Inference-Time Scaling of Verification: Self-Evolving Deep Research Agents via Test-Time Rubric-Guided Verification]]></title>
<link>https://huggingface.co/papers/2601.15808</link>
<guid>2601.15808</guid>
<description><![CDATA[Source: HuggingFace
Tags: 
Authors: Yuxuan Wan, Tianqing Fang, Zaitang Li, Yintong Huo, Wenxuan Wang
Institution: 
Published: 2026-01-22
Score: 8/10
Citations: 0
Upvotes: 16
GitHub: 
Stars: 0

Recent advances in Deep Research Agents (DRAs) are transforming automated knowledge discovery and problem-solving. While the majority of existing efforts focus on enhancing policy capabilities via post-training, we propose an alternative paradigm: self-evolving the agent's ability by iteratively verifying the policy model's outputs, guided by meticulously crafted rubrics. This approach gives rise to the inference-time scaling of verification, wherein an agent self-improves by evaluating its generated answers to produce iterative feedback and refinements. We derive the rubrics based on an automatically constructed DRA Failure Taxonomy, which systematically classifies agent failures into five major categories and thirteen sub-categories. We present DeepVerifier, a rubrics-based outcome reward verifier that leverages the asymmetry of verification and outperforms vanilla agent-as-judge and LLM judge baselines by 12%-48% in meta-evaluation F1 score. To enable practical self-evolution, DeepVerifier integrates as a plug-and-play module during test-time inference. The verifier produces detailed rubric-based feedback, which is fed back to the agent for iterative bootstrapping, refining responses without additional training. This test-time scaling delivers 8%-11% accuracy gains on challenging subsets of GAIA and XBench-DeepResearch when powered by capable closed-source LLMs. Finally, to support open-source advancement, we release DeepVerifier-4K, a curated supervised fine-tuning dataset of 4,646 high-quality agent steps focused on DRA verification. These examples emphasize reflection and self-critique, enabling open models to develop robust verification capabilities.]]></description>
<pubDate>Thu, 22 Jan 2026 09:47:31 +0000</pubDate>
</item>
<item>
<title><![CDATA[Jet-RL: Enabling On-Policy FP8 Reinforcement Learning with Unified Training and Rollout Precision Flow]]></title>
<link>https://huggingface.co/papers/2601.14243</link>
<guid>2601.14243</guid>
<description><![CDATA[Source: HuggingFace
Tags: 
Authors: Haocheng Xi, Charlie Ruan, Peiyuan Liao, Yujun Lin, Han Cai
Institution: 
Published: 2026-01-20
Score: 8/10
Citations: 0
Upvotes: 15
GitHub: 
Stars: 0

Reinforcement learning (RL) is essential for enhancing the complex reasoning capabilities of large language models (LLMs). However, existing RL training pipelines are computationally inefficient and resource-intensive, with the rollout phase accounting for over 70% of total training time. Quantized RL training, particularly using FP8 precision, offers a promising approach to mitigating this bottleneck. A commonly adopted strategy applies FP8 precision during rollout while retaining BF16 precision for training. In this work, we present the first comprehensive study of FP8 RL training and demonstrate that the widely used BF16-training + FP8-rollout strategy suffers from severe training instability and catastrophic accuracy collapse under long-horizon rollouts and challenging tasks. Our analysis shows that these failures stem from the off-policy nature of the approach, which introduces substantial numerical mismatch between training and inference. Motivated by these observations, we propose Jet-RL, an FP8 RL training framework that enables robust and stable RL optimization. The key idea is to adopt a unified FP8 precision flow for both training and rollout, thereby minimizing numerical discrepancies and eliminating the need for inefficient inter-step calibration. Extensive experiments validate the effectiveness of Jet-RL: our method achieves up to 33% speedup in the rollout phase, up to 41% speedup in the training phase, and a 16% end-to-end speedup over BF16 training, while maintaining stable convergence across all settings and incurring negligible accuracy degradation.]]></description>
<pubDate>Tue, 20 Jan 2026 18:54:31 +0000</pubDate>
</item>
<item>
<title><![CDATA[Teaching Models to Teach Themselves: Reasoning at the Edge of Learnability]]></title>
<link>https://huggingface.co/papers/2601.18778</link>
<guid>2601.18778</guid>
<description><![CDATA[Source: HuggingFace
Tags: 
Authors: Shobhita Sundaram, John Quan, Ariel Kwiatkowski, Kartik Ahuja, Yann Ollivier
Institution: 
Published: 2026-01-26
Score: 8/10
Citations: 0
Upvotes: 14
GitHub: 
Stars: 0

Can a model learn to escape its own learning plateau? Reinforcement learning methods for finetuning large reasoning models stall on datasets with low initial success rates, and thus little training signal. We investigate a fundamental question: Can a pretrained LLM leverage latent knowledge to generate an automated curriculum for problems it cannot solve? To explore this, we design SOAR: A self-improvement framework designed to surface these pedagogical signals through meta-RL. A teacher copy of the model proposes synthetic problems for a student copy, and is rewarded with its improvement on a small subset of hard problems. Critically, SOAR grounds the curriculum in measured student progress rather than intrinsic proxy rewards. Our study on the hardest subsets of mathematical benchmarks (0/128 success) reveals three core findings. First, we show that it is possible to realize bi-level meta-RL that unlocks learning under sparse, binary rewards by sharpening a latent capacity of pretrained models to generate useful stepping stones. Second, grounded rewards outperform intrinsic reward schemes used in prior LLM self-play, reliably avoiding the instability and diversity collapse modes they typically exhibit. Third, analyzing the generated questions reveals that structural quality and well-posedness are more critical for learning progress than solution correctness. Our results suggest that the ability to generate useful stepping stones does not require the preexisting ability to actually solve the hard problems, paving a principled path to escape reasoning plateaus without additional curated data.]]></description>
<pubDate>Mon, 26 Jan 2026 18:46:56 +0000</pubDate>
</item>
<item>
<title><![CDATA[DeepPlanning: Benchmarking Long-Horizon Agentic Planning with Verifiable Constraints]]></title>
<link>https://huggingface.co/papers/2601.18137</link>
<guid>2601.18137</guid>
<description><![CDATA[Source: HuggingFace
Tags: 
Authors: Yinger Zhang, Shutong Jiang, Renhao Li, Jianhong Tu, Yang Su
Institution: 
Published: 2026-01-26
Score: 8/10
Citations: 0
Upvotes: 7
GitHub: 
Stars: 0

While agent evaluation has shifted toward long-horizon tasks, most benchmarks still emphasize local, step-level reasoning rather than the global constrained optimization (e.g., time and financial budgets) that demands genuine planning ability. Meanwhile, existing LLM planning benchmarks underrepresent the active information gathering and fine-grained local constraints typical of real-world settings. To address this, we introduce DeepPlanning, a challenging benchmark for practical long-horizon agent planning. It features multi-day travel planning and multi-product shopping tasks that require proactive information acquisition, local constrained reasoning, and global constrained optimization. Evaluations on DeepPlanning show that even frontier agentic LLMs struggle with these problems, highlighting the importance of reliable explicit reasoning patterns and parallel tool use for achieving better effectiveness-efficiency trade-offs. Error analysis further points to promising directions for improving agentic LLMs over long planning horizons. We open-source the code and data to support future research.]]></description>
<pubDate>Mon, 26 Jan 2026 04:43:49 +0000</pubDate>
</item>
<item>
<title><![CDATA[Endless Terminals: Scaling RL Environments for Terminal Agents]]></title>
<link>https://huggingface.co/papers/2601.16443</link>
<guid>2601.16443</guid>
<description><![CDATA[Source: HuggingFace
Tags: 
Authors: Kanishk Gandhi, Shivam Garg, Noah D. Goodman, Dimitris Papailiopoulos
Institution: MIT
Published: 2026-01-23
Score: 8/10
Citations: 0
Upvotes: 6
GitHub: 
Stars: 0

Environments are the bottleneck for self-improving agents. Current terminal benchmarks were built for evaluation, not training; reinforcement learning requires a scalable pipeline, not just a dataset. We introduce Endless Terminals, a fully autonomous pipeline that procedurally generates terminal-use tasks without human annotation. The pipeline has four stages: generating diverse task descriptions, building and validating containerized environments, producing completion tests, and filtering for solvability. From this pipeline we obtain 3255 tasks spanning file operations, log management, data processing, scripting, and database operations. We train agents using vanilla PPO with binary episode level rewards and a minimal interaction loop: no retrieval, multi-agent coordination, or specialized tools. Despite this simplicity, models trained on Endless Terminals show substantial gains: on our held-out dev set, Llama-3.2-3B improves from 4.0% to 18.2%, Qwen2.5-7B from 10.7% to 53.3%, and Qwen3-8B-openthinker-sft from 42.6% to 59.0%. These improvements transfer to human-curated benchmarks: models trained on Endless Terminals show substantial gains on held out human curated benchmarks: on TerminalBench 2.0, Llama-3.2-3B improves from 0.0% to 2.2%, Qwen2.5-7B from 2.2% to 3.4%, and Qwen3-8B-openthinker-sft from 1.1% to 6.7%, in each case outperforming alternative approaches including models with more complex agentic scaffolds. These results demonstrate that simple RL succeeds when environments scale.]]></description>
<pubDate>Fri, 23 Jan 2026 04:39:55 +0000</pubDate>
</item>
<item>
<title><![CDATA[The Side Effects of Being Smart: Safety Risks in MLLMs' Multi-Image Reasoning]]></title>
<link>https://huggingface.co/papers/2601.14127</link>
<guid>2601.14127</guid>
<description><![CDATA[Source: HuggingFace
Tags: 
Authors: Renmiao Chen, Yida Lu, Shiyao Cui, Xuan Ouyang, Victor Shea-Jay Huang
Institution: 
Published: 2026-01-20
Score: 8/10
Citations: 0
Upvotes: 2
GitHub: 
Stars: 0

As Multimodal Large Language Models (MLLMs) acquire stronger reasoning capabilities to handle complex, multi-image instructions, this advancement may pose new safety risks. We study this problem by introducing MIR-SafetyBench, the first benchmark focused on multi-image reasoning safety, which consists of 2,676 instances across a taxonomy of 9 multi-image relations. Our extensive evaluations on 19 MLLMs reveal a troubling trend: models with more advanced multi-image reasoning can be more vulnerable on MIR-SafetyBench. Beyond attack success rates, we find that many responses labeled as safe are superficial, often driven by misunderstanding or evasive, non-committal replies. We further observe that unsafe generations exhibit lower attention entropy than safe ones on average. This internal signature suggests a possible risk that models may over-focus on task solving while neglecting safety constraints. Our code and data are available at https://github.com/thu-coai/MIR-SafetyBench.]]></description>
<pubDate>Tue, 20 Jan 2026 16:24:18 +0000</pubDate>
</item>
<item>
<title><![CDATA[VISTA-PATH: An interactive foundation model for pathology image segmentation and quantitative analysis in computational pathology]]></title>
<link>https://huggingface.co/papers/2601.16451</link>
<guid>2601.16451</guid>
<description><![CDATA[Source: HuggingFace
Tags: 
Authors: Peixian Liang, Songhao Li, Shunsuke Koga, Yutong Li, Zahra Alipour
Institution: 
Published: 2026-01-23
Score: 8/10
Citations: 0
Upvotes: 2
GitHub: 
Stars: 0

Accurate semantic segmentation for histopathology image is crucial for quantitative tissue analysis and downstream clinical modeling. Recent segmentation foundation models have improved generalization through large-scale pretraining, yet remain poorly aligned with pathology because they treat segmentation as a static visual prediction task. Here we present VISTA-PATH, an interactive, class-aware pathology segmentation foundation model designed to resolve heterogeneous structures, incorporate expert feedback, and produce pixel-level segmentation that are directly meaningful for clinical interpretation. VISTA-PATH jointly conditions segmentation on visual context, semantic tissue descriptions, and optional expert-provided spatial prompts, enabling precise multi-class segmentation across heterogeneous pathology images. To support this paradigm, we curate VISTA-PATH Data, a large-scale pathology segmentation corpus comprising over 1.6 million image-mask-text triplets spanning 9 organs and 93 tissue classes. Across extensive held-out and external benchmarks, VISTA-PATH consistently outperforms existing segmentation foundation models. Importantly, VISTA-PATH supports dynamic human-in-the-loop refinement by propagating sparse, patch-level bounding-box annotation feedback into whole-slide segmentation. Finally, we show that the high-fidelity, class-aware segmentation produced by VISTA-PATH is a preferred model for computational pathology. It improve tissue microenvironment analysis through proposed Tumor Interaction Score (TIS), which exhibits strong and significant associations with patient survival. Together, these results establish VISTA-PATH as a foundation model that elevates pathology image segmentation from a static prediction to an interactive and clinically grounded representation for digital pathology. Source code and demo can be found at https://github.com/zhihuanglab/VISTA-PATH.]]></description>
<pubDate>Fri, 23 Jan 2026 05:06:57 +0000</pubDate>
</item>
<item>
<title><![CDATA[HalluGuard: Demystifying Data-Driven and Reasoning-Driven Hallucinations in LLMs]]></title>
<link>https://huggingface.co/papers/2601.18753</link>
<guid>2601.18753</guid>
<description><![CDATA[Source: HuggingFace
Tags: 
Authors: Xinyue Zeng, Junhong Lin, Yujun Yan, Feng Guo, Liang Shi
Institution: 
Published: 2026-01-26
Score: 8/10
Citations: 0
Upvotes: 1
GitHub: 
Stars: 0

The reliability of Large Language Models (LLMs) in high-stakes domains such as healthcare, law, and scientific discovery is often compromised by hallucinations. These failures typically stem from two sources: data-driven hallucinations and reasoning-driven hallucinations. However, existing detection methods usually address only one source and rely on task-specific heuristics, limiting their generalization to complex scenarios. To overcome these limitations, we introduce the Hallucination Risk Bound, a unified theoretical framework that formally decomposes hallucination risk into data-driven and reasoning-driven components, linked respectively to training-time mismatches and inference-time instabilities. This provides a principled foundation for analyzing how hallucinations emerge and evolve. Building on this foundation, we introduce HalluGuard, an NTK-based score that leverages the induced geometry and captured representations of the NTK to jointly identify data-driven and reasoning-driven hallucinations. We evaluate HalluGuard on 10 diverse benchmarks, 11 competitive baselines, and 9 popular LLM backbones, consistently achieving state-of-the-art performance in detecting diverse forms of LLM hallucinations.]]></description>
<pubDate>Mon, 26 Jan 2026 18:23:09 +0000</pubDate>
</item>
<item>
<title><![CDATA[VisGym: Diverse, Customizable, Scalable Environments for Multimodal Agents]]></title>
<link>https://huggingface.co/papers/2601.16973</link>
<guid>2601.16973</guid>
<description><![CDATA[Source: HuggingFace
Tags: 
Authors: Zirui Wang, Junyi Zhang, Jiaxin Ge, Long Lian, Letian Fu
Institution: 
Published: 2026-01-23
Score: 7/10
Citations: 0
Upvotes: 29
GitHub: 
Stars: 0

Modern Vision-Language Models (VLMs) remain poorly characterized in multi-step visual interactions, particularly in how they integrate perception, memory, and action over long horizons. We introduce VisGym, a gymnasium of 17 environments for evaluating and training VLMs. The suite spans symbolic puzzles, real-image understanding, navigation, and manipulation, and provides flexible controls over difficulty, input representation, planning horizon, and feedback. We also provide multi-step solvers that generate structured demonstrations, enabling supervised finetuning. Our evaluations show that all frontier models struggle in interactive settings, achieving low success rates in both the easy (46.6%) and hard (26.0%) configurations. Our experiments reveal notable limitations: models struggle to effectively leverage long context, performing worse with an unbounded history than with truncated windows. Furthermore, we find that several text-based symbolic tasks become substantially harder once rendered visually. However, explicit goal observations, textual feedback, and exploratory demonstrations in partially observable or unknown-dynamics settings for supervised finetuning yield consistent gains, highlighting concrete failure modes and pathways for improving multi-step visual decision-making. Code, data, and models can be found at: https://visgym.github.io/.]]></description>
<pubDate>Fri, 23 Jan 2026 18:43:34 +0000</pubDate>
</item>
<item>
<title><![CDATA[CGPT: Cluster-Guided Partial Tables with LLM-Generated Supervision for Table Retrieval]]></title>
<link>https://huggingface.co/papers/2601.15849</link>
<guid>2601.15849</guid>
<description><![CDATA[Source: HuggingFace
Tags: 
Authors: Tsung-Hsiang Chou, Chen-Jui Yu, Shui-Hsiang Hsu, Yao-Chung Fan
Institution: 
Published: 2026-01-22
Score: 7/10
Citations: 0
Upvotes: 9
GitHub: 
Stars: 0

General-purpose embedding models have demonstrated strong performance in text retrieval but remain suboptimal for table retrieval, where highly structured content leads to semantic compression and query-table mismatch. Recent LLM-based retrieval augmentation methods mitigate this issue by generating synthetic queries, yet they often rely on heuristic partial-table selection and seldom leverage these synthetic queries as supervision to improve the embedding model. We introduce CGPT, a training framework that enhances table retrieval through LLM-generated supervision. CGPT constructs semantically diverse partial tables by clustering table instances using K-means and sampling across clusters to broaden semantic coverage. An LLM then generates synthetic queries for these partial tables, which are used in hard-negative contrastive fine-tuning to refine the embedding model. Experiments across four public benchmarks (MimoTable, OTTQA, FetaQA, and E2E-WTQ) show that CGPT consistently outperforms retrieval baselines, including QGpT, with an average R@1 improvement of 16.54 percent. In a unified multi-domain corpus setting, CGPT further demonstrates strong cross-domain generalization and remains effective even when using smaller LLMs for synthetic query generation. These results indicate that semantically guided partial-table construction, combined with contrastive training from LLM-generated supervision, provides an effective and scalable paradigm for large-scale table retrieval. Our code is available at https://github.com/yumeow0122/CGPT.]]></description>
<pubDate>Thu, 22 Jan 2026 10:58:56 +0000</pubDate>
</item>
<item>
<title><![CDATA[MeepleLM: A Virtual Playtester Simulating Diverse Subjective Experiences]]></title>
<link>https://huggingface.co/papers/2601.07251</link>
<guid>2601.07251</guid>
<description><![CDATA[Source: HuggingFace
Tags: 
Authors: Zizhen Li, Chuanhao Li, Yibin Wang, Yukang Feng, Jianwen Sun
Institution: 
Published: 2026-01-12
Score: 7/10
Citations: 0
Upvotes: 8
GitHub: 
Stars: 0

Recent advancements have expanded the role of Large Language Models in board games from playing agents to creative co-designers. However, a critical gap remains: current systems lack the capacity to offer constructive critique grounded in the emergent user experience. Bridging this gap is fundamental for harmonizing Human-AI collaboration, as it empowers designers to refine their creations via external perspectives while steering models away from biased or unpredictable outcomes. Automating critique for board games presents two challenges: inferring the latent dynamics connecting rules to gameplay without an explicit engine, and modeling the subjective heterogeneity of diverse player groups. To address these, we curate a dataset of 1,727 structurally corrected rulebooks and 150K reviews selected via quality scoring and facet-aware sampling. We augment this data with Mechanics-Dynamics-Aesthetics (MDA) reasoning to explicitly bridge the causal gap between written rules and player experience. We further distill player personas and introduce MeepleLM, a specialized model that internalizes persona-specific reasoning patterns to accurately simulate the subjective feedback of diverse player archetypes. Experiments demonstrate that MeepleLM significantly outperforms latest commercial models (e.g., GPT-5.1, Gemini3-Pro) in community alignment and critique quality, achieving a 70% preference rate in user studies assessing utility. MeepleLM serves as a reliable virtual playtester for general interactive systems, marking a pivotal step towards audience-aligned, experience-aware Human-AI collaboration.]]></description>
<pubDate>Mon, 12 Jan 2026 06:37:12 +0000</pubDate>
</item>
<item>
<title><![CDATA[DSGym: A Holistic Framework for Evaluating and Training Data Science Agents]]></title>
<link>https://huggingface.co/papers/2601.16344</link>
<guid>2601.16344</guid>
<description><![CDATA[Source: HuggingFace
Tags: 
Authors: Fan Nie, Junlin Wang, Harper Hua, Federico Bianchi, Yongchan Kwon
Institution: 
Published: 2026-01-22
Score: 7/10
Citations: 0
Upvotes: 8
GitHub: 
Stars: 0

Data science agents promise to accelerate discovery and insight-generation by turning data into executable analyses and findings. Yet existing data science benchmarks fall short due to fragmented evaluation interfaces that make cross-benchmark comparison difficult, narrow task coverage and a lack of rigorous data grounding. In particular, we show that a substantial portion of tasks in current benchmarks can be solved without using the actual data. To address these limitations, we introduce DSGym, a standardized framework for evaluating and training data science agents in self-contained execution environments. Unlike static benchmarks, DSGym provides a modular architecture that makes it easy to add tasks, agent scaffolds, and tools, positioning it as a live, extensible testbed. We curate DSGym-Tasks, a holistic task suite that standardizes and refines existing benchmarks via quality and shortcut solvability filtering. We further expand coverage with (1) DSBio: expert-derived bioinformatics tasks grounded in literature and (2) DSPredict: challenging prediction tasks spanning domains such as computer vision, molecular prediction, and single-cell perturbation. Beyond evaluation, DSGym enables agent training via execution-verified data synthesis pipeline. As a case study, we build a 2,000-example training set and trained a 4B model in DSGym that outperforms GPT-4o on standardized analysis benchmarks. Overall, DSGym enables rigorous end-to-end measurement of whether agents can plan, implement, and validate data analyses in realistic scientific context.]]></description>
<pubDate>Thu, 22 Jan 2026 22:03:29 +0000</pubDate>
</item>
<item>
<title><![CDATA[ChartVerse: Scaling Chart Reasoning via Reliable Programmatic Synthesis from Scratch]]></title>
<link>https://huggingface.co/papers/2601.13606</link>
<guid>2601.13606</guid>
<description><![CDATA[Source: HuggingFace
Tags: 
Authors: Zheng Liu, Honglin Lin, Chonghan Qin, Xiaoyang Wang, Xin Gao
Institution: 
Published: 2026-01-20
Score: 7/10
Citations: 0
Upvotes: 6
GitHub: 
Stars: 0

Chart reasoning is a critical capability for Vision Language Models (VLMs). However, the development of open-source models is severely hindered by the lack of high-quality training data. Existing datasets suffer from a dual challenge: synthetic charts are often simplistic and repetitive, while the associated QA pairs are prone to hallucinations and lack the reasoning depth required for complex tasks. To bridge this gap, we propose ChartVerse, a scalable framework designed to synthesize complex charts and reliable reasoning data from scratch. (1) To address the bottleneck of simple patterns, we first introduce Rollout Posterior Entropy (RPE), a novel metric that quantifies chart complexity. Guided by RPE, we develop complexity-aware chart coder to autonomously synthesize diverse, high-complexity charts via executable programs. (2) To guarantee reasoning rigor, we develop truth-anchored inverse QA synthesis. Diverging from standard generation, we adopt an answer-first paradigm: we extract deterministic answers directly from the source code, generate questions conditional on these anchors, and enforce strict consistency verification. To further elevate difficulty and reasoning depth, we filter samples based on model fail-rate and distill high-quality Chain-of-Thought (CoT) reasoning. We curate ChartVerse-SFT-600K and ChartVerse-RL-40K using Qwen3-VL-30B-A3B-Thinking as the teacher. Experimental results demonstrate that ChartVerse-8B achieves state-of-the-art performance, notably surpassing its teacher and rivaling the stronger Qwen3-VL-32B-Thinking.]]></description>
<pubDate>Tue, 20 Jan 2026 05:11:44 +0000</pubDate>
</item>
<item>
<title><![CDATA[SAGE: Steerable Agentic Data Generation for Deep Search with Execution Feedback]]></title>
<link>https://huggingface.co/papers/2601.18202</link>
<guid>2601.18202</guid>
<description><![CDATA[Source: HuggingFace
Tags: 
Authors: Fangyuan Xu, Rujun Han, Yanfei Chen, Zifeng Wang, I-Hung Hsu
Institution: 
Published: 2026-01-26
Score: 7/10
Citations: 0
Upvotes: 5
GitHub: 
Stars: 0

Deep search agents, which aim to answer complex questions requiring reasoning across multiple documents, can significantly speed up the information-seeking process. Collecting human annotations for this application is prohibitively expensive due to long and complex exploration trajectories. We propose an agentic pipeline that automatically generates high quality, difficulty-controlled deep search question-answer pairs for a given corpus and a target difficulty level. Our pipeline, SAGE, consists of a data generator which proposes QA pairs and a search agent which attempts to solve the generated question and provide execution feedback for the data generator. The two components interact over multiple rounds to iteratively refine the question-answer pairs until they satisfy the target difficulty level. Our intrinsic evaluation shows SAGE generates questions that require diverse reasoning strategies, while significantly increases the correctness and difficulty of the generated data. Our extrinsic evaluation demonstrates up to 23% relative performance gain on popular deep search benchmarks by training deep search agents with our synthetic data. Additional experiments show that agents trained on our data can adapt from fixed-corpus retrieval to Google Search at inference time, without further training.]]></description>
<pubDate>Mon, 26 Jan 2026 06:37:56 +0000</pubDate>
</item>
<item>
<title><![CDATA[DRPG (Decompose, Retrieve, Plan, Generate): An Agentic Framework for Academic Rebuttal]]></title>
<link>https://huggingface.co/papers/2601.18081</link>
<guid>2601.18081</guid>
<description><![CDATA[Source: HuggingFace
Tags: 
Authors: Peixuan Han, Yingjie Yu, Jingjun Xu, Jiaxuan You
Institution: 
Published: 2026-01-26
Score: 7/10
Citations: 0
Upvotes: 4
GitHub: 
Stars: 0

Despite the growing adoption of large language models (LLMs) in scientific research workflows, automated support for academic rebuttal, a crucial step in academic communication and peer review, remains largely underexplored. Existing approaches typically rely on off-the-shelf LLMs or simple pipelines, which struggle with long-context understanding and often fail to produce targeted and persuasive responses. In this paper, we propose DRPG, an agentic framework for automatic academic rebuttal generation that operates through four steps: Decompose reviews into atomic concerns, Retrieve relevant evidence from the paper, Plan rebuttal strategies, and Generate responses accordingly. Notably, the Planner in DRPG reaches over 98% accuracy in identifying the most feasible rebuttal direction. Experiments on data from top-tier conferences demonstrate that DRPG significantly outperforms existing rebuttal pipelines and achieves performance beyond the average human level using only an 8B model. Our analysis further demonstrates the effectiveness of the planner design and its value in providing multi-perspective and explainable suggestions. We also showed that DRPG works well in a more complex multi-round setting. These results highlight the effectiveness of DRPG and its potential to provide high-quality rebuttal content and support the scaling of academic discussions. Codes for this work are available at https://github.com/ulab-uiuc/DRPG-RebuttalAgent.]]></description>
<pubDate>Mon, 26 Jan 2026 02:30:01 +0000</pubDate>
</item>
<item>
<title><![CDATA[Knowledge is Not Enough: Injecting RL Skills for Continual Adaptation]]></title>
<link>https://huggingface.co/papers/2601.11258</link>
<guid>2601.11258</guid>
<description><![CDATA[Source: HuggingFace
Tags: 
Authors: Pingzhi Tang, Yiding Wang, Muhan Zhang
Institution: 
Published: 2026-01-16
Score: 7/10
Citations: 0
Upvotes: 4
GitHub: 
Stars: 0

Large Language Models (LLMs) face the "knowledge cutoff" challenge, where their frozen parametric memory prevents direct internalization of new information. While Supervised Fine-Tuning (SFT) is commonly used to update model knowledge, it often updates factual content without reliably improving the model's ability to use the newly incorporated information for question answering or decision-making. Reinforcement Learning (RL) is essential for acquiring reasoning skills; however, its high computational cost makes it impractical for efficient online adaptation. We empirically observe that the parameter updates induced by SFT and RL are nearly orthogonal. Based on this observation, we propose Parametric Skill Transfer (PaST), a framework that supports modular skill transfer for efficient and effective knowledge adaptation. By extracting a domain-agnostic Skill Vector from a source domain, we can linearly inject knowledge manipulation skills into a target model after it has undergone lightweight SFT on new data. Experiments on knowledge-incorporation QA (SQuAD, LooGLE) and agentic tool-use benchmarks (ToolBench) demonstrate the effectiveness of our method. On SQuAD, PaST outperforms the state-of-the-art self-editing SFT baseline by up to 9.9 points. PaST further scales to long-context QA on LooGLE with an 8.0-point absolute accuracy gain, and improves zero-shot ToolBench success rates by +10.3 points on average with consistent gains across tool categories, indicating strong scalability and cross-domain transferability of the Skill Vector.]]></description>
<pubDate>Fri, 16 Jan 2026 13:08:16 +0000</pubDate>
</item>
<item>
<title><![CDATA[Diffusion In Diffusion: Reclaiming Global Coherence in Semi-Autoregressive Diffusion]]></title>
<link>https://huggingface.co/papers/2601.13599</link>
<guid>2601.13599</guid>
<description><![CDATA[Source: HuggingFace
Tags: 
Authors: Linrui Ma, Yufei Cui, Kai Han, Yunhe Wang
Institution: 
Published: 2026-01-20
Score: 7/10
Citations: 0
Upvotes: 3
GitHub: 
Stars: 0

One of the most compelling features of global discrete diffusion language models is their global bidirectional contextual capability. However, existing block-based diffusion studies tend to introduce autoregressive priors, which, while offering benefits, can cause models to lose this global coherence at the macro level. To regain global contextual understanding while preserving the advantages of the semi-autoregressive paradigm, we propose Diffusion in Diffusion, a 'draft-then-refine' framework designed to overcome the irreversibility and myopia problems inherent in block diffusion models. Our approach first employs block diffusion to generate rapid drafts using small blocks, then refines these drafts through global bidirectional diffusion with a larger bidirectional receptive field. We utilize snapshot confidence remasking to identify the most critical tokens that require modification, and apply mix-scale training to expand the block diffusion model's global capabilities. Empirical results demonstrate that our approach sets a new benchmark for discrete diffusion models on the OpenWebText dataset. Using only 26% of the fine-tuning budget of baseline models, we reduce generative perplexity from 25.7 to 21.9, significantly narrowing the performance gap with autoregressive models.]]></description>
<pubDate>Tue, 20 Jan 2026 05:00:26 +0000</pubDate>
</item>
<item>
<title><![CDATA[One Adapts to Any: Meta Reward Modeling for Personalized LLM Alignment]]></title>
<link>https://huggingface.co/papers/2601.18731</link>
<guid>2601.18731</guid>
<description><![CDATA[Source: HuggingFace
Tags: 
Authors: Hongru Cai, Yongqi Li, Tiezheng Yu, Fengbin Zhu, Wenjie Wang
Institution: 
Published: 2026-01-26
Score: 7/10
Citations: 0
Upvotes: 3
GitHub: 
Stars: 0

Alignment of Large Language Models (LLMs) aims to align outputs with human preferences, and personalized alignment further adapts models to individual users. This relies on personalized reward models that capture user-specific preferences and automatically provide individualized feedback. However, developing these models faces two critical challenges: the scarcity of feedback from individual users and the need for efficient adaptation to unseen users. We argue that addressing these constraints requires a paradigm shift from fitting data to learn user preferences to learn the process of preference adaptation. To realize this, we propose Meta Reward Modeling (MRM), which reformulates personalized reward modeling as a meta-learning problem. Specifically, we represent each user's reward model as a weighted combination of base reward functions, and optimize the initialization of these weights using a Model-Agnostic Meta-Learning (MAML)-style framework to support fast adaptation under limited feedback. To ensure robustness, we introduce the Robust Personalization Objective (RPO), which places greater emphasis on hard-to-learn users during meta optimization. Extensive experiments on personalized preference datasets validate that MRM enhances few-shot personalization, improves user robustness, and consistently outperforms baselines.]]></description>
<pubDate>Mon, 26 Jan 2026 17:55:52 +0000</pubDate>
</item>
<item>
<title><![CDATA[IVRA: Improving Visual-Token Relations for Robot Action Policy with Training-Free Hint-Based Guidance]]></title>
<link>https://huggingface.co/papers/2601.16207</link>
<guid>2601.16207</guid>
<description><![CDATA[Source: HuggingFace
Tags: 
Authors: Jongwoo Park, Kanchana Ranasinghe, Jinhyeok Jang, Cristina Mata, Yoo Sung Jang
Institution: 
Published: 2026-01-22
Score: 7/10
Citations: 0
Upvotes: 3
GitHub: 
Stars: 0

Many Vision-Language-Action (VLA) models flatten image patches into a 1D token sequence, weakening the 2D spatial cues needed for precise manipulation. We introduce IVRA, a lightweight, training-free method that improves spatial understanding by exploiting affinity hints already available in the model's built-in vision encoder, without requiring any external encoder or retraining. IVRA selectively injects these affinity signals into a language-model layer in which instance-level features reside. This inference-time intervention realigns visual-token interactions and better preserves geometric structure while keeping all model parameters fixed. We demonstrate the generality of IVRA by applying it to diverse VLA architectures (LLaRA, OpenVLA, and FLOWER) across simulated benchmarks spanning both 2D and 3D manipulation (VIMA and LIBERO) and on various real-robot tasks. On 2D VIMA, IVRA improves average success by +4.2% over the baseline LLaRA in a low-data regime. On 3D LIBERO, it yields consistent gains over the OpenVLA and FLOWER baselines, including improvements when baseline accuracy is near saturation (96.3% to 97.1%). All code and models will be released publicly. Visualizations are available at: jongwoopark7978.github.io/IVRA]]></description>
<pubDate>Thu, 22 Jan 2026 18:57:13 +0000</pubDate>
</item>
<item>
<title><![CDATA[Less Is More -- Until It Breaks: Security Pitfalls of Vision Token Compression in Large Vision-Language Models]]></title>
<link>https://huggingface.co/papers/2601.12042</link>
<guid>2601.12042</guid>
<description><![CDATA[Source: HuggingFace
Tags: 
Authors: Xiaomei Zhang, Zhaoxi Zhang, Leo Yu Zhang, Yanjun Zhang, Guanhong Tao
Institution: 
Published: 2026-01-17
Score: 7/10
Citations: 0
Upvotes: 2
GitHub: 
Stars: 0

Visual token compression is widely adopted to improve the inference efficiency of Large Vision-Language Models (LVLMs), enabling their deployment in latency-sensitive and resource-constrained scenarios. However, existing work has mainly focused on efficiency and performance, while the security implications of visual token compression remain largely unexplored. In this work, we first reveal that visual token compression substantially degrades the robustness of LVLMs: models that are robust under uncompressed inference become highly vulnerable once compression is enabled. These vulnerabilities are state-specific; failure modes emerge only in the compressed setting and completely disappear when compression is disabled, making them particularly hidden and difficult to diagnose. By analyzing the key stages of the compression process, we identify instability in token importance ranking as the primary cause of this robustness degradation. Small and imperceptible perturbations can significantly alter token rankings, leading the compression mechanism to mistakenly discard task-critical information and ultimately causing model failure. Motivated by this observation, we propose a Compression-Aware Attack to systematically study and exploit this vulnerability. CAA directly targets the token selection mechanism and induces failures exclusively under compressed inference. We further extend this approach to more realistic black-box settings and introduce Transfer CAA, where neither the target model nor the compression configuration is accessible. We further evaluate potential defenses and find that they provide only limited protection. Extensive experiments across models, datasets, and compression methods show that visual token compression significantly undermines robustness, revealing a previously overlooked efficiency-security trade-off.]]></description>
<pubDate>Sat, 17 Jan 2026 13:02:41 +0000</pubDate>
</item>
<item>
<title><![CDATA[TensorLens: End-to-End Transformer Analysis via High-Order Attention Tensors]]></title>
<link>https://huggingface.co/papers/2601.17958</link>
<guid>2601.17958</guid>
<description><![CDATA[Source: HuggingFace
Tags: 
Authors: Ido Andrew Atad, Itamar Zimerman, Shahar Katz, Lior Wolf
Institution: 
Published: 2026-01-25
Score: 7/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Attention matrices are fundamental to transformer research, supporting a broad range of applications including interpretability, visualization, manipulation, and distillation. Yet, most existing analyses focus on individual attention heads or layers, failing to account for the model's global behavior. While prior efforts have extended attention formulations across multiple heads via averaging and matrix multiplications or incorporated components such as normalization and FFNs, a unified and complete representation that encapsulates all transformer blocks is still lacking. We address this gap by introducing TensorLens, a novel formulation that captures the entire transformer as a single, input-dependent linear operator expressed through a high-order attention-interaction tensor. This tensor jointly encodes attention, FFNs, activations, normalizations, and residual connections, offering a theoretically coherent and expressive linear representation of the model's computation. TensorLens is theoretically grounded and our empirical validation shows that it yields richer representations than previous attention-aggregation methods. Our experiments demonstrate that the attention tensor can serve as a powerful foundation for developing tools aimed at interpretability and model understanding. Our code is attached as a supplementary.]]></description>
<pubDate>Sun, 25 Jan 2026 19:21:25 +0000</pubDate>
</item>
<item>
<title><![CDATA[Can LLMs Clean Up Your Mess? A Survey of Application-Ready Data Preparation with LLMs]]></title>
<link>https://huggingface.co/papers/2601.17058</link>
<guid>2601.17058</guid>
<description><![CDATA[Source: HuggingFace
Tags: 
Authors: Wei Zhou, Jun Zhou, Haoyu Wang, Zhenghao Li, Qikang He
Institution: 
Published: 2026-01-22
Score: 6/10
Citations: 0
Upvotes: 109
GitHub: 
Stars: 0

Data preparation aims to denoise raw datasets, uncover cross-dataset relationships, and extract valuable insights from them, which is essential for a wide range of data-centric applications. Driven by (i) rising demands for application-ready data (e.g., for analytics, visualization, decision-making), (ii) increasingly powerful LLM techniques, and (iii) the emergence of infrastructures that facilitate flexible agent construction (e.g., using Databricks Unity Catalog), LLM-enhanced methods are rapidly becoming a transformative and potentially dominant paradigm for data preparation.
  By investigating hundreds of recent literature works, this paper presents a systematic review of this evolving landscape, focusing on the use of LLM techniques to prepare data for diverse downstream tasks. First, we characterize the fundamental paradigm shift, from rule-based, model-specific pipelines to prompt-driven, context-aware, and agentic preparation workflows. Next, we introduce a task-centric taxonomy that organizes the field into three major tasks: data cleaning (e.g., standardization, error processing, imputation), data integration (e.g., entity matching, schema matching), and data enrichment (e.g., data annotation, profiling). For each task, we survey representative techniques, and highlight their respective strengths (e.g., improved generalization, semantic understanding) and limitations (e.g., the prohibitive cost of scaling LLMs, persistent hallucinations even in advanced agents, the mismatch between advanced methods and weak evaluation). Moreover, we analyze commonly used datasets and evaluation metrics (the empirical part). Finally, we discuss open research challenges and outline a forward-looking roadmap that emphasizes scalable LLM-data systems, principled designs for reliable agentic workflows, and robust evaluation protocols.]]></description>
<pubDate>Thu, 22 Jan 2026 12:02:45 +0000</pubDate>
</item>
<item>
<title><![CDATA[TwinBrainVLA: Unleashing the Potential of Generalist VLMs for Embodied Tasks via Asymmetric Mixture-of-Transformers]]></title>
<link>https://huggingface.co/papers/2601.14133</link>
<guid>2601.14133</guid>
<description><![CDATA[Source: HuggingFace
Tags: 
Authors: Bin Yu, Shijie Lian, Xiaopeng Lin, Yuliang Wei, Zhaolong Shen
Institution: 
Published: 2026-01-20
Score: 6/10
Citations: 0
Upvotes: 56
GitHub: 
Stars: 0

Standard Vision-Language-Action (VLA) models typically fine-tune a monolithic Vision-Language Model (VLM) backbone explicitly for robotic control. However, this approach creates a critical tension between maintaining high-level general semantic understanding and learning low-level, fine-grained sensorimotor skills, often leading to "catastrophic forgetting" of the model's open-world capabilities. To resolve this conflict, we introduce TwinBrainVLA, a novel architecture that coordinates a generalist VLM retaining universal semantic understanding and a specialist VLM dedicated to embodied proprioception for joint robotic control. TwinBrainVLA synergizes a frozen "Left Brain", which retains robust general visual reasoning, with a trainable "Right Brain", specialized for embodied perception, via a novel Asymmetric Mixture-of-Transformers (AsyMoT) mechanism. This design allows the Right Brain to dynamically query semantic knowledge from the frozen Left Brain and fuse it with proprioceptive states, providing rich conditioning for a Flow-Matching Action Expert to generate precise continuous controls. Extensive experiments on SimplerEnv and RoboCasa benchmarks demonstrate that TwinBrainVLA achieves superior manipulation performance compared to state-of-the-art baselines while explicitly preserving the comprehensive visual understanding capabilities of the pre-trained VLM, offering a promising direction for building general-purpose robots that simultaneously achieve high-level semantic understanding and low-level physical dexterity.]]></description>
<pubDate>Tue, 20 Jan 2026 16:30:07 +0000</pubDate>
</item>
<item>
<title><![CDATA[Scientific Image Synthesis: Benchmarking, Methodologies, and Downstream Utility]]></title>
<link>https://huggingface.co/papers/2601.17027</link>
<guid>2601.17027</guid>
<description><![CDATA[Source: HuggingFace
Tags: 
Authors: Honglin Lin, Chonghan Qin, Zheng Liu, Qizhi Pei, Yu Li
Institution: 
Published: 2026-01-17
Score: 6/10
Citations: 0
Upvotes: 30
GitHub: 
Stars: 0

While synthetic data has proven effective for improving scientific reasoning in the text domain, multimodal reasoning remains constrained by the difficulty of synthesizing scientifically rigorous images. Existing Text-to-Image (T2I) models often produce outputs that are visually plausible yet scientifically incorrect, resulting in a persistent visual-logic divergence that limits their value for downstream reasoning. Motivated by recent advances in next-generation T2I models, we conduct a systematic study of scientific image synthesis across generation paradigms, evaluation, and downstream use. We analyze both direct pixel-based generation and programmatic synthesis, and propose ImgCoder, a logic-driven framework that follows an explicit "understand - plan - code" workflow to improve structural precision. To rigorously assess scientific correctness, we introduce SciGenBench, which evaluates generated images based on information utility and logical validity. Our evaluation reveals systematic failure modes in pixel-based models and highlights a fundamental expressiveness-precision trade-off. Finally, we show that fine-tuning Large Multimodal Models (LMMs) on rigorously verified synthetic scientific images yields consistent reasoning gains, with potential scaling trends analogous to the text domain, validating high-fidelity scientific synthesis as a viable path to unlocking massive multimodal reasoning capabilities.]]></description>
<pubDate>Sat, 17 Jan 2026 14:18:36 +0000</pubDate>
</item>
<item>
<title><![CDATA[Memory-V2V: Augmenting Video-to-Video Diffusion Models with Memory]]></title>
<link>https://huggingface.co/papers/2601.16296</link>
<guid>2601.16296</guid>
<description><![CDATA[Source: HuggingFace
Tags: 
Authors: Dohun Lee, Chun-Hao Paul Huang, Xuelin Chen, Jong Chul Ye, Duygu Ceylan
Institution: 
Published: 2026-01-22
Score: 6/10
Citations: 0
Upvotes: 19
GitHub: 
Stars: 0

Recent foundational video-to-video diffusion models have achieved impressive results in editing user provided videos by modifying appearance, motion, or camera movement. However, real-world video editing is often an iterative process, where users refine results across multiple rounds of interaction. In this multi-turn setting, current video editors struggle to maintain cross-consistency across sequential edits. In this work, we tackle, for the first time, the problem of cross-consistency in multi-turn video editing and introduce Memory-V2V, a simple, yet effective framework that augments existing video-to-video models with explicit memory. Given an external cache of previously edited videos, Memory-V2V employs accurate retrieval and dynamic tokenization strategies to condition the current editing step on prior results. To further mitigate redundancy and computational overhead, we propose a learnable token compressor within the DiT backbone that compresses redundant conditioning tokens while preserving essential visual cues, achieving an overall speedup of 30%. We validate Memory-V2V on challenging tasks including video novel view synthesis and text-conditioned long video editing. Extensive experiments show that Memory-V2V produces videos that are significantly more cross-consistent with minimal computational overhead, while maintaining or even improving task-specific performance over state-of-the-art baselines. Project page: https://dohunlee1.github.io/MemoryV2V]]></description>
<pubDate>Thu, 22 Jan 2026 19:59:17 +0000</pubDate>
</item>
<item>
<title><![CDATA[SALAD: Achieve High-Sparsity Attention via Efficient Linear Attention Tuning for Video Diffusion Transformer]]></title>
<link>https://huggingface.co/papers/2601.16515</link>
<guid>2601.16515</guid>
<description><![CDATA[Source: HuggingFace
Tags: 
Authors: Tongcheng Fang, Hanling Zhang, Ruiqi Xie, Zhuo Han, Xin Tao
Institution: 
Published: 2026-01-23
Score: 6/10
Citations: 0
Upvotes: 11
GitHub: 
Stars: 0

Diffusion Transformers have recently demonstrated remarkable performance in video generation. However, the long input sequences result in high computational latency due to the quadratic complexity of full attention. Various sparse attention mechanisms have been proposed. Training-free sparse attention is constrained by limited sparsity and thus offers modest acceleration, whereas training-based methods can reach much higher sparsity but demand substantial data and computation for training. In this work, we propose SALAD, introducing a lightweight linear attention branch in parallel with the sparse attention. By incorporating an input-dependent gating mechanism to finely balance the two branches, our method attains 90% sparsity and 1.72x inference speedup, while maintaining generation quality comparable to the full attention baseline. Moreover, our finetuning process is highly efficient, requiring only 2,000 video samples and 1,600 training steps with a batch size of 8.]]></description>
<pubDate>Fri, 23 Jan 2026 07:28:53 +0000</pubDate>
</item>
<item>
<title><![CDATA[VIBEVOICE-ASR Technical Report]]></title>
<link>https://huggingface.co/papers/2601.18184</link>
<guid>2601.18184</guid>
<description><![CDATA[Source: HuggingFace
Tags: 
Authors: Zhiliang Peng, Jianwei Yu, Yaoyao Chang, Zilong Wang, Li Dong
Institution: 
Published: 2026-01-26
Score: 6/10
Citations: 0
Upvotes: 10
GitHub: 
Stars: 0

This report presents VibeVoice-ASR, a general-purpose speech understanding framework built upon VibeVoice, designed to address the persistent challenges of context fragmentation and multi-speaker complexity in long-form audio (e.g., meetings, podcasts) that remain despite recent advancements in short-form speech recognition. Unlike traditional pipelined approaches that rely on audio chunking, VibeVoice-ASRsupports single-pass processing for up to 60 minutes of audio. It unifies Automatic Speech Recognition, Speaker Diarization, and Timestamping into a single end-to-end generation task. In addition, VibeVoice-ASR supports over 50 languages, requires no explicit language setting, and natively handles code-switching within and across utterances. Furthermore, we introduce a prompt-based context injection mechanism that allows users to supply customized conetxt, significantly improving accuracy on domain-specific terminology and polyphonic character disambiguation.]]></description>
<pubDate>Mon, 26 Jan 2026 06:11:51 +0000</pubDate>
</item>
<item>
<title><![CDATA[GameTalk: Training LLMs for Strategic Conversation]]></title>
<link>https://huggingface.co/papers/2601.16276</link>
<guid>2601.16276</guid>
<description><![CDATA[Source: HuggingFace
Tags: 
Authors: Victor Conchello Vendrell, Max Ruiz Luyten, Mihaela van der Schaar
Institution: 
Published: 2026-01-22
Score: 6/10
Citations: 0
Upvotes: 10
GitHub: 
Stars: 0

Strategic decision-making in multi-agent settings is a key challenge for large language models (LLMs), particularly when coordination and negotiation must unfold over extended conversations. While recent work has explored the use of LLMs in isolated decision tasks, little attention has been given to optimizing long-term objectives through dialogue. We introduce GameTalk, a framework for training LLMs to make strategic decisions via multi-turn interactions. Unlike prior work that focuses on single-turn objectives or static action prediction, we train LLMs to optimize a global objective across full conversations. We achieve this by adapting fine-tuning methods like GRPO, DPO, and STaR to incorporate reward signals that depend on the entire interaction. We evaluate this approach on a suite of increasingly complex games, designed to stress different aspects of reasoning, coordination, and opponent modeling. Our results show that GameTalk significantly outperforms untrained models, especially under reward shaping, with DPO consistently yielding the strongest gains. These findings position conversational fine-tuning as a promising path for LLMs to reason, negotiate, and act in interactive environments.]]></description>
<pubDate>Thu, 22 Jan 2026 19:18:39 +0000</pubDate>
</item>
<item>
<title><![CDATA[Paying Less Generalization Tax: A Cross-Domain Generalization Study of RL Training for LLM Agents]]></title>
<link>https://huggingface.co/papers/2601.18217</link>
<guid>2601.18217</guid>
<description><![CDATA[Source: HuggingFace
Tags: 
Authors: Zhihan Liu, Lin Guan, Yixin Nie, Kai Zhang, Zhuoqun Hao
Institution: 
Published: 2026-01-26
Score: 6/10
Citations: 0
Upvotes: 6
GitHub: 
Stars: 0

Generalist LLM agents are often post-trained on a narrow set of environments but deployed across far broader, unseen domains. In this work, we investigate the challenge of agentic post-training when the eventual test domains are unknown. Specifically, we analyze which properties of reinforcement learning (RL) environments and modeling choices have the greatest influence on out-of-domain performance. First, we identify two environment axes that strongly correlate with cross-domain generalization: (i) state information richness, i.e., the amount of information for the agent to process from the state, and (ii) planning complexity, estimated via goal reachability and trajectory length under a base policy. Notably, domain realism and text-level similarity are not the primary factors; for instance, the simple grid-world domain Sokoban leads to even stronger generalization in SciWorld than the more realistic ALFWorld. Motivated by these findings, we further show that increasing state information richness alone can already effectively improve cross-domain robustness. We propose a randomization technique, which is low-overhead and broadly applicable: add small amounts of distractive goal-irrelevant features to the state to make it richer without altering the task. Beyond environment-side properties, we also examine several modeling choices: (a) SFT warmup or mid-training helps prevent catastrophic forgetting during RL but undermines generalization to domains that are not included in the mid-training datamix; and (b) turning on step-by-step thinking during RL, while not always improving in-domain performance, plays a crucial role in preserving generalization.]]></description>
<pubDate>Mon, 26 Jan 2026 07:07:03 +0000</pubDate>
</item>
<item>
<title><![CDATA[Agentic Very Long Video Understanding]]></title>
<link>https://huggingface.co/papers/2601.18157</link>
<guid>2601.18157</guid>
<description><![CDATA[Source: HuggingFace
Tags: 
Authors: Aniket Rege, Arka Sadhu, Yuliang Li, Kejie Li, Ramya Korlakai Vinayak
Institution: 
Published: 2026-01-26
Score: 6/10
Citations: 0
Upvotes: 4
GitHub: 
Stars: 0

The advent of always-on personal AI assistants, enabled by all-day wearable devices such as smart glasses, demands a new level of contextual understanding, one that goes beyond short, isolated events to encompass the continuous, longitudinal stream of egocentric video. Achieving this vision requires advances in long-horizon video understanding, where systems must interpret and recall visual and audio information spanning days or even weeks. Existing methods, including large language models and retrieval-augmented generation, are constrained by limited context windows and lack the ability to perform compositional, multi-hop reasoning over very long video streams. In this work, we address these challenges through EGAgent, an enhanced agentic framework centered on entity scene graphs, which represent people, places, objects, and their relationships over time. Our system equips a planning agent with tools for structured search and reasoning over these graphs, as well as hybrid visual and audio search capabilities, enabling detailed, cross-modal, and temporally coherent reasoning. Experiments on the EgoLifeQA and Video-MME (Long) datasets show that our method achieves state-of-the-art performance on EgoLifeQA (57.5%) and competitive performance on Video-MME (Long) (74.1%) for complex longitudinal video understanding tasks.]]></description>
<pubDate>Mon, 26 Jan 2026 05:20:47 +0000</pubDate>
</item>
<item>
<title><![CDATA[SkyReels-V3 Technique Report]]></title>
<link>https://huggingface.co/papers/2601.17323</link>
<guid>2601.17323</guid>
<description><![CDATA[Source: HuggingFace
Tags: 
Authors: Debang Li, Zhengcong Fei, Tuanhui Li, Yikun Dou, Zheng Chen
Institution: 
Published: 2026-01-24
Score: 6/10
Citations: 0
Upvotes: 3
GitHub: 
Stars: 0

Video generation serves as a cornerstone for building world models, where multimodal contextual inference stands as the defining test of capability. In this end, we present SkyReels-V3, a conditional video generation model, built upon a unified multimodal in-context learning framework with diffusion Transformers. SkyReels-V3 model supports three core generative paradigms within a single architecture: reference images-to-video synthesis, video-to-video extension and audio-guided video generation. (i) reference images-to-video model is designed to produce high-fidelity videos with strong subject identity preservation, temporal coherence, and narrative consistency. To enhance reference adherence and compositional stability, we design a comprehensive data processing pipeline that leverages cross frame pairing, image editing, and semantic rewriting, effectively mitigating copy paste artifacts. During training, an image video hybrid strategy combined with multi-resolution joint optimization is employed to improve generalization and robustness across diverse scenarios. (ii) video extension model integrates spatio-temporal consistency modeling with large-scale video understanding, enabling both seamless single-shot continuation and intelligent multi-shot switching with professional cinematographic patterns. (iii) Talking avatar model supports minute-level audio-conditioned video generation by training first-and-last frame insertion patterns and reconstructing key-frame inference paradigms. On the basis of ensuring visual quality, synchronization of audio and videos has been optimized.
  Extensive evaluations demonstrate that SkyReels-V3 achieves state-of-the-art or near state-of-the-art performance on key metrics including visual quality, instruction following, and specific aspect metrics, approaching leading closed-source systems. Github: https://github.com/SkyworkAI/SkyReels-V3.]]></description>
<pubDate>Sat, 24 Jan 2026 06:08:12 +0000</pubDate>
</item>
<item>
<title><![CDATA[A Mechanistic View on Video Generation as World Models: State and Dynamics]]></title>
<link>https://huggingface.co/papers/2601.17067</link>
<guid>2601.17067</guid>
<description><![CDATA[Source: HuggingFace
Tags: 
Authors: Luozhou Wang, Zhifei Chen, Yihua Du, Dongyu Yan, Wenhang Ge
Institution: 
Published: 2026-01-22
Score: 6/10
Citations: 0
Upvotes: 2
GitHub: 
Stars: 0

Large-scale video generation models have demonstrated emergent physical coherence, positioning them as potential world models. However, a gap remains between contemporary "stateless" video architectures and classic state-centric world model theories. This work bridges this gap by proposing a novel taxonomy centered on two pillars: State Construction and Dynamics Modeling. We categorize state construction into implicit paradigms (context management) and explicit paradigms (latent compression), while dynamics modeling is analyzed through knowledge integration and architectural reformulation. Furthermore, we advocate for a transition in evaluation from visual fidelity to functional benchmarks, testing physical persistence and causal reasoning. We conclude by identifying two critical frontiers: enhancing persistence via data-driven memory and compressed fidelity, and advancing causality through latent factor decoupling and reasoning-prior integration. By addressing these challenges, the field can evolve from generating visually plausible videos to building robust, general-purpose world simulators.]]></description>
<pubDate>Thu, 22 Jan 2026 19:00:18 +0000</pubDate>
</item>
<item>
<title><![CDATA[Plug-and-Play Benchmarking of Reinforcement Learning Algorithms for Large-Scale Flow Control]]></title>
<link>https://huggingface.co/papers/2601.15015</link>
<guid>2601.15015</guid>
<description><![CDATA[Source: HuggingFace
Tags: 
Authors: Jannis Becktepe, Aleksandra Franz, Nils Thuerey, Sebastian Peitz
Institution: 
Published: 2026-01-21
Score: 6/10
Citations: 0
Upvotes: 1
GitHub: 
Stars: 0

Reinforcement learning (RL) has shown promising results in active flow control (AFC), yet progress in the field remains difficult to assess as existing studies rely on heterogeneous observation and actuation schemes, numerical setups, and evaluation protocols. Current AFC benchmarks attempt to address these issues but heavily rely on external computational fluid dynamics (CFD) solvers, are not fully differentiable, and provide limited 3D and multi-agent support. To overcome these limitations, we introduce FluidGym, the first standalone, fully differentiable benchmark suite for RL in AFC. Built entirely in PyTorch on top of the GPU-accelerated PICT solver, FluidGym runs in a single Python stack, requires no external CFD software, and provides standardized evaluation protocols. We present baseline results with PPO and SAC and release all environments, datasets, and trained models as public resources. FluidGym enables systematic comparison of control methods, establishes a scalable foundation for future research in learning-based flow control, and is available at https://github.com/safe-autonomous-systems/fluidgym.]]></description>
<pubDate>Wed, 21 Jan 2026 14:13:44 +0000</pubDate>
</item>
<item>
<title><![CDATA[PingPong: A Natural Benchmark for Multi-Turn Code-Switching Dialogues]]></title>
<link>https://huggingface.co/papers/2601.17277</link>
<guid>2601.17277</guid>
<description><![CDATA[Source: HuggingFace
Tags: 
Authors: Mohammad Rifqi Farhansyah, Hanif Muhammad Zhafran, Farid Adilazuarda, Shamsuddeen Hassan Muhammad, Maryam Ibrahim Mukhtar
Institution: 
Published: 2026-01-24
Score: 6/10
Citations: 0
Upvotes: 1
GitHub: 
Stars: 0

Code-switching is a widespread practice among the world's multilingual majority, yet few benchmarks accurately reflect its complexity in everyday communication. We present PingPong, a benchmark for natural multi-party code-switching dialogues covering five language-combination variations, some of which are trilingual. Our dataset consists of human-authored conversations among 2 to 4 participants covering authentic, multi-threaded structures where replies frequently reference much earlier points in the dialogue. We demonstrate that our data is significantly more natural and structurally diverse than machine-generated alternatives, offering greater variation in message length, speaker dominance, and reply distance. Based on these dialogues, we define three downstream tasks: Question Answering, Dialogue Summarization, and Topic Classification. Evaluations of several state-of-the-art language models on PingPong reveal that performance remains limited on code-switched inputs, underscoring the urgent need for more robust NLP systems capable of addressing the intricacies of real-world multilingual discourse.]]></description>
<pubDate>Sat, 24 Jan 2026 03:31:08 +0000</pubDate>
</item>
<item>
<title><![CDATA[RouteMoA: Dynamic Routing without Pre-Inference Boosts Efficient Mixture-of-Agents]]></title>
<link>https://huggingface.co/papers/2601.18130</link>
<guid>2601.18130</guid>
<description><![CDATA[Source: HuggingFace
Tags: 
Authors: Jize Wang, Han Wu, Zhiyuan You, Yiming Song, Yijun Wang
Institution: 
Published: 2026-01-26
Score: 6/10
Citations: 0
Upvotes: 1
GitHub: 
Stars: 0

Mixture-of-Agents (MoA) improves LLM performance through layered collaboration, but its dense topology raises costs and latency. Existing methods employ LLM judges to filter responses, yet still require all models to perform inference before judging, failing to cut costs effectively. They also lack model selection criteria and struggle with large model pools, where full inference is costly and can exceed context limits. To address this, we propose RouteMoA, an efficient mixture-of-agents framework with dynamic routing. It employs a lightweight scorer to perform initial screening by predicting coarse-grained performance from the query, narrowing candidates to a high-potential subset without inference. A mixture of judges then refines these scores through lightweight self- and cross-assessment based on existing model outputs, providing posterior correction without additional inference. Finally, a model ranking mechanism selects models by balancing performance, cost, and latency. RouteMoA outperforms MoA across varying tasks and model pool sizes, reducing cost by 89.8% and latency by 63.6% in the large-scale model pool.]]></description>
<pubDate>Mon, 26 Jan 2026 04:22:22 +0000</pubDate>
</item>
<item>
<title><![CDATA[daVinci-Dev: Agent-native Mid-training for Software Engineering]]></title>
<link>https://huggingface.co/papers/2601.18418</link>
<guid>2601.18418</guid>
<description><![CDATA[Source: HuggingFace
Tags: 
Authors: Ji Zeng, Dayuan Fu, Tiantian Mi, Yumin Zhuang, Yaxing Huang
Institution: 
Published: 2026-01-26
Score: 5/10
Citations: 0
Upvotes: 97
GitHub: 
Stars: 0

Recently, the frontier of Large Language Model (LLM) capabilities has shifted from single-turn code generation to agentic software engineering-a paradigm where models autonomously navigate, edit, and test complex repositories. While post-training methods have become the de facto approach for code agents, **agentic mid-training**-mid-training (MT) on large-scale data that mirrors authentic agentic workflows-remains critically underexplored due to substantial resource requirements, despite offering a more scalable path to instilling foundational agentic behaviors than relying solely on expensive reinforcement learning. A central challenge in realizing effective agentic mid-training is the distribution mismatch between static training data and the dynamic, feedback-rich environment of real development. To address this, we present a systematic study of agentic mid-training, establishing both the data synthesis principles and training methodology for effective agent development at scale. Central to our approach is **agent-native data**-supervision comprising two complementary types of trajectories: **contextually-native trajectories** that preserve the complete information flow an agent experiences, offering broad coverage and diversity; and **environmentally-native trajectories** collected from executable repositories where observations stem from actual tool invocations and test executions, providing depth and interaction authenticity. We verify the model's agentic capabilities on `SWE-Bench Verified`. We demonstrate our superiority over the previous open software engineering mid-training recipe `Kimi-Dev` under two post-training settings with an aligned base model and agentic scaffold, while using less than half mid-training tokens (73.1B). Besides relative advantage, our best performing 32B and 72B models achieve **56.1%** and **58.5%** resolution rates, respectively, which are ...]]></description>
<pubDate>Mon, 26 Jan 2026 12:20:18 +0000</pubDate>
</item>
<item>
<title><![CDATA[SWE-Pruner: Self-Adaptive Context Pruning for Coding Agents]]></title>
<link>https://huggingface.co/papers/2601.16746</link>
<guid>2601.16746</guid>
<description><![CDATA[Source: HuggingFace
Tags: 
Authors: Yuhang Wang, Yuling Shi, Mo Yang, Rongrui Zhang, Shilin He
Institution: 
Published: 2026-01-23
Score: 5/10
Citations: 0
Upvotes: 71
GitHub: 
Stars: 0

LLM agents have demonstrated remarkable capabilities in software development, but their performance is hampered by long interaction contexts, which incur high API costs and latency. While various context compression approaches such as LongLLMLingua have emerged to tackle this challenge, they typically rely on fixed metrics such as PPL, ignoring the task-specific nature of code understanding. As a result, they frequently disrupt syntactic and logical structure and fail to retain critical implementation details. In this paper, we propose SWE-Pruner, a self-adaptive context pruning framework tailored for coding agents. Drawing inspiration from how human programmers "selectively skim" source code during development and debugging, SWE-Pruner performs task-aware adaptive pruning for long contexts. Given the current task, the agent formulates an explicit goal (e.g., "focus on error handling") as a hint to guide the pruning targets. A lightweight neural skimmer (0.6B parameters) is trained to dynamically select relevant lines from the surrounding context given the goal. Evaluations across four benchmarks and multiple models validate SWE-Pruner's effectiveness in various scenarios, achieving 23-54% token reduction on agent tasks like SWE-Bench Verified and up to 14.84x compression on single-turn tasks like LongCodeQA with minimal performance impact.]]></description>
<pubDate>Fri, 23 Jan 2026 13:51:59 +0000</pubDate>
</item>
<item>
<title><![CDATA[iFSQ: Improving FSQ for Image Generation with 1 Line of Code]]></title>
<link>https://huggingface.co/papers/2601.17124</link>
<guid>2601.17124</guid>
<description><![CDATA[Source: HuggingFace
Tags: 
Authors: Bin Lin, Zongjian Li, Yuwei Niu, Kaixiong Gong, Yunyang Ge
Institution: 
Published: 2026-01-23
Score: 5/10
Citations: 0
Upvotes: 22
GitHub: 
Stars: 0

The field of image generation is currently bifurcated into autoregressive (AR) models operating on discrete tokens and diffusion models utilizing continuous latents. This divide, rooted in the distinction between VQ-VAEs and VAEs, hinders unified modeling and fair benchmarking. Finite Scalar Quantization (FSQ) offers a theoretical bridge, yet vanilla FSQ suffers from a critical flaw: its equal-interval quantization can cause activation collapse. This mismatch forces a trade-off between reconstruction fidelity and information efficiency. In this work, we resolve this dilemma by simply replacing the activation function in original FSQ with a distribution-matching mapping to enforce a uniform prior. Termed iFSQ, this simple strategy requires just one line of code yet mathematically guarantees both optimal bin utilization and reconstruction precision. Leveraging iFSQ as a controlled benchmark, we uncover two key insights: (1) The optimal equilibrium between discrete and continuous representations lies at approximately 4 bits per dimension. (2) Under identical reconstruction constraints, AR models exhibit rapid initial convergence, whereas diffusion models achieve a superior performance ceiling, suggesting that strict sequential ordering may limit the upper bounds of generation quality. Finally, we extend our analysis by adapting Representation Alignment (REPA) to AR models, yielding LlamaGen-REPA. Codes is available at https://github.com/Tencent-Hunyuan/iFSQ]]></description>
<pubDate>Fri, 23 Jan 2026 19:00:35 +0000</pubDate>
</item>
<item>
<title><![CDATA[Self-Refining Video Sampling]]></title>
<link>https://huggingface.co/papers/2601.18577</link>
<guid>2601.18577</guid>
<description><![CDATA[Source: HuggingFace
Tags: 
Authors: Sangwon Jang, Taekyung Ki, Jaehyeong Jo, Saining Xie, Jaehong Yoon
Institution: 
Published: 2026-01-26
Score: 5/10
Citations: 0
Upvotes: 13
GitHub: 
Stars: 0

Modern video generators still struggle with complex physical dynamics, often falling short of physical realism. Existing approaches address this using external verifiers or additional training on augmented data, which is computationally expensive and still limited in capturing fine-grained motion. In this work, we present self-refining video sampling, a simple method that uses a pre-trained video generator trained on large-scale datasets as its own self-refiner. By interpreting the generator as a denoising autoencoder, we enable iterative inner-loop refinement at inference time without any external verifier or additional training. We further introduce an uncertainty-aware refinement strategy that selectively refines regions based on self-consistency, which prevents artifacts caused by over-refinement. Experiments on state-of-the-art video generators demonstrate significant improvements in motion coherence and physics alignment, achieving over 70\% human preference compared to the default sampler and guidance-based sampler.]]></description>
<pubDate>Mon, 26 Jan 2026 15:22:27 +0000</pubDate>
</item>
<item>
<title><![CDATA[Dancing in Chains: Strategic Persuasion in Academic Rebuttal via Theory of Mind]]></title>
<link>https://huggingface.co/papers/2601.15715</link>
<guid>2601.15715</guid>
<description><![CDATA[Source: HuggingFace
Tags: 
Authors: Zhitao He, Zongwei Lyu, Yi R Fung
Institution: 
Published: 2026-01-22
Score: 5/10
Citations: 0
Upvotes: 13
GitHub: 
Stars: 0

Although artificial intelligence (AI) has become deeply integrated into various stages of the research workflow and achieved remarkable advancements, academic rebuttal remains a significant and underexplored challenge. This is because rebuttal is a complex process of strategic communication under severe information asymmetry rather than a simple technical debate. Consequently, current approaches struggle as they largely imitate surface-level linguistics, missing the essential element of perspective-taking required for effective persuasion. In this paper, we introduce RebuttalAgent, the first framework to ground academic rebuttal in Theory of Mind (ToM), operationalized through a ToM-Strategy-Response (TSR) pipeline that models reviewer mental state, formulates persuasion strategy, and generates strategy-grounded response. To train our agent, we construct RebuttalBench, a large-scale dataset synthesized via a novel critique-and-refine approach. Our training process consists of two stages, beginning with a supervised fine-tuning phase to equip the agent with ToM-based analysis and strategic planning capabilities, followed by a reinforcement learning phase leveraging the self-reward mechanism for scalable self-improvement. For reliable and efficient automated evaluation, we further develop Rebuttal-RM, a specialized evaluator trained on over 100K samples of multi-source rebuttal data, which achieves scoring consistency with human preferences surpassing powerful judge GPT-4.1. Extensive experiments show RebuttalAgent significantly outperforms the base model by an average of 18.3% on automated metrics, while also outperforming advanced proprietary models across both automated and human evaluations. Disclaimer: the generated rebuttal content is for reference only to inspire authors and assist in drafting. It is not intended to replace the author's own critical analysis and response.]]></description>
<pubDate>Thu, 22 Jan 2026 07:36:48 +0000</pubDate>
</item>
<item>
<title><![CDATA[STAR: Semantic Table Representation with Header-Aware Clustering and Adaptive Weighted Fusion]]></title>
<link>https://huggingface.co/papers/2601.15860</link>
<guid>2601.15860</guid>
<description><![CDATA[Source: HuggingFace
Tags: 
Authors: Shui-Hsiang Hsu, Tsung-Hsiang Chou, Chen-Jui Yu, Yao-Chung Fan
Institution: 
Published: 2026-01-22
Score: 5/10
Citations: 0
Upvotes: 8
GitHub: 
Stars: 0

Table retrieval is the task of retrieving the most relevant tables from large-scale corpora given natural language queries. However, structural and semantic discrepancies between unstructured text and structured tables make embedding alignment particularly challenging. Recent methods such as QGpT attempt to enrich table semantics by generating synthetic queries, yet they still rely on coarse partial-table sampling and simple fusion strategies, which limit semantic diversity and hinder effective query-table alignment. We propose STAR (Semantic Table Representation), a lightweight framework that improves semantic table representation through semantic clustering and weighted fusion. STAR first applies header-aware K-means clustering to group semantically similar rows and selects representative centroid instances to construct a diverse partial table. It then generates cluster-specific synthetic queries to comprehensively cover the table's semantic space. Finally, STAR employs weighted fusion strategies to integrate table and query embeddings, enabling fine-grained semantic alignment. This design enables STAR to capture complementary information from structured and textual sources, improving the expressiveness of table representations. Experiments on five benchmarks show that STAR achieves consistently higher Recall than QGpT on all datasets, demonstrating the effectiveness of semantic clustering and adaptive weighted fusion for robust table representation. Our code is available at https://github.com/adsl135789/STAR.]]></description>
<pubDate>Thu, 22 Jan 2026 11:08:46 +0000</pubDate>
</item>
<item>
<title><![CDATA[End-to-End Joint ASR and Speaker Role Diarization with Child-Adult Interactions]]></title>
<link>https://huggingface.co/papers/2601.17640</link>
<guid>2601.17640</guid>
<description><![CDATA[Source: HuggingFace
Tags: 
Authors: Anfeng Xu, Tiantian Feng, Somer Bishop, Catherine Lord, Shrikanth Narayanan
Institution: 
Published: 2026-01-25
Score: 5/10
Citations: 0
Upvotes: 4
GitHub: 
Stars: 0

Accurate transcription and speaker diarization of child-adult spoken interactions are crucial for developmental and clinical research. However, manual annotation is time-consuming and challenging to scale. Existing automated systems typically rely on cascaded speaker diarization and speech recognition pipelines, which can lead to error propagation. This paper presents a unified end-to-end framework that extends the Whisper encoder-decoder architecture to jointly model ASR and child-adult speaker role diarization. The proposed approach integrates: (i) a serialized output training scheme that emits speaker tags and start/end timestamps, (ii) a lightweight frame-level diarization head that enhances speaker-discriminative encoder representations, (iii) diarization-guided silence suppression for improved temporal precision, and (iv) a state-machine-based forced decoding procedure that guarantees structurally valid outputs. Comprehensive evaluations on two datasets demonstrate consistent and substantial improvements over two cascaded baselines, achieving lower multi-talker word error rates and demonstrating competitive diarization accuracy across both Whisper-small and Whisper-large models. These findings highlight the effectiveness and practical utility of the proposed joint modeling framework for generating reliable, speaker-attributed transcripts of child-adult interactions at scale. The code and model weights are publicly available]]></description>
<pubDate>Sun, 25 Jan 2026 01:00:41 +0000</pubDate>
</item>
<item>
<title><![CDATA[Least-Loaded Expert Parallelism: Load Balancing An Imbalanced Mixture-of-Experts]]></title>
<link>https://huggingface.co/papers/2601.17111</link>
<guid>2601.17111</guid>
<description><![CDATA[Source: HuggingFace
Tags: 
Authors: Xuan-Phi Nguyen, Shrey Pandit, Austin Xu, Caiming Xiong, Shafiq Joty
Institution: 
Published: 2026-01-23
Score: 5/10
Citations: 0
Upvotes: 4
GitHub: 
Stars: 0

Mixture-of-Experts (MoE) models are typically pre-trained with explicit load-balancing constraints to ensure statistically balanced expert routing. Despite this, we observe that even well-trained MoE models exhibit significantly imbalanced routing. This behavior is arguably natural-and even desirable - as imbalanced routing allows models to concentrate domain-specific knowledge within a subset of experts. Expert parallelism (EP) is designed to scale MoE models by distributing experts across multiple devices, but with a less-discussed assumption of balanced routing. Under extreme imbalance, EP can funnel a disproportionate number of tokens to a small number of experts, leading to compute- and memory-bound failures on overloaded devices during post-training or inference, where explicit load balancing is often inapplicable. We propose Least-Loaded Expert Parallelism (LLEP), a novel EP algorithm that dynamically reroutes excess tokens and associated expert parameters from overloaded devices to underutilized ones. This ensures that all devices complete their workloads within the minimum collective latency while respecting memory constraints. Across different model scales, LLEP achieves up to 5x speedup and 4x reduction in peak memory usage compared to standard EP. This enables faster and higher-throughput post-training and inference, with ~1.9x faster for gpt-oss-120b. We support our method with extensive theoretical analysis and comprehensive empirical evaluations, including ablation studies. These results illuminate key trade-offs and enable a principled framework for hardware-specific hyper-parameter tuning to achieve optimal performance.]]></description>
<pubDate>Fri, 23 Jan 2026 18:19:15 +0000</pubDate>
</item>
<item>
<title><![CDATA[Guidelines to Prompt Large Language Models for Code Generation: An Empirical Characterization]]></title>
<link>https://huggingface.co/papers/2601.13118</link>
<guid>2601.13118</guid>
<description><![CDATA[Source: HuggingFace
Tags: 
Authors: Alessandro Midolo, Alessandro Giagnorio, Fiorella Zampetti, Rosalia Tufano, Gabriele Bavota
Institution: 
Published: 2026-01-19
Score: 5/10
Citations: 0
Upvotes: 2
GitHub: 
Stars: 0

Large Language Models (LLMs) are nowadays extensively used for various types of software engineering tasks, primarily code generation. Previous research has shown how suitable prompt engineering could help developers in improving their code generation prompts. However, so far, there do not exist specific guidelines driving developers towards writing suitable prompts for code generation. In this work, we derive and evaluate development-specific prompt optimization guidelines. First, we use an iterative, test-driven approach to automatically refine code generation prompts, and we analyze the outcome of this process to identify prompt improvement items that lead to test passes. We use such elements to elicit 10 guidelines for prompt improvement, related to better specifying I/O, pre-post conditions, providing examples, various types of details, or clarifying ambiguities. We conduct an assessment with 50 practitioners, who report their usage of the elicited prompt improvement patterns, as well as their perceived usefulness, which does not always correspond to the actual usage before knowing our guidelines. Our results lead to implications not only for practitioners and educators, but also for those aimed at creating better LLM-aided software development tools.]]></description>
<pubDate>Mon, 19 Jan 2026 15:01:42 +0000</pubDate>
</item>
<item>
<title><![CDATA[Mecellem Models: Turkish Models Trained from Scratch and Continually Pre-trained for the Legal Domain]]></title>
<link>https://huggingface.co/papers/2601.16018</link>
<guid>2601.16018</guid>
<description><![CDATA[Source: HuggingFace
Tags: 
Authors: zgr Uur, Mahmut Gksu, Mahmut imen, Musa Ylmaz, Esra avirdi
Institution: 
Published: 2026-01-22
Score: 4/10
Citations: 0
Upvotes: 7
GitHub: 
Stars: 0

This paper presents Mecellem models, a framework for developing specialized language models for the Turkish legal domain through domain adaptation strategies. We make two contributions: (1)Encoder Model Pre-trained from Scratch: ModernBERT-based bidirectional encoders pre-trained on a Turkish-dominant corpus of 112.7 billion tokens. We implement a checkpoint selection strategy that evaluates downstream retrieval performance throughout training, revealing that optimal checkpoints achieve best retrieval scores before pre-training loss reaches its minimum. Our encoder models achieve top-3 rankings on the Turkish retrieval leaderboard, with smaller models (155M parameters) achieving comparable performance to larger reference models (307M-567M parameters). Our approach achieves 92.36% production efficiency compared to state-of-the-art models (embeddinggemma-300m: 100.00%, BAAI/bge-m3: 99.54%, newmindai/bge-m3-stsb: 94.38%), ranking fourth overall despite requiring less computational resources. SOTA models rely on multi-stage, computationally intensive training pipelines, making our single-stage pre-training followed by efficient post-training approach a cost-effective alternative; (2)Decoder Model with Continual Pre-training (CPT): Qwen3-1.7B and Qwen3-4B models adapted to Turkish legal domain through controlled curriculum learning. Four-phase CPT with optimal sample ratios enables gradual transition from general language knowledge to specialized legal terminology and long-context reasoning. This approach achieves 36.2% perplexity reduction on Turkish legal text, demonstrating domain adaptation gains.]]></description>
<pubDate>Thu, 22 Jan 2026 14:41:32 +0000</pubDate>
</item>
<item>
<title><![CDATA[UI Remix: Supporting UI Design Through Interactive Example Retrieval and Remixing]]></title>
<link>https://huggingface.co/papers/2601.18759</link>
<guid>2601.18759</guid>
<description><![CDATA[Source: HuggingFace
Tags: 
Authors: Junling Wang, Hongyi Lan, Xiaotian Su, Mustafa Doga Dogan, April Yi Wang
Institution: 
Published: 2026-01-26
Score: 4/10
Citations: 0
Upvotes: 1
GitHub: 
Stars: 0

Designing user interfaces (UIs) is a critical step when launching products, building portfolios, or personalizing projects, yet end users without design expertise often struggle to articulate their intent and to trust design choices. Existing example-based tools either promote broad exploration, which can cause overwhelm and design drift, or require adapting a single example, risking design fixation. We present UI Remix, an interactive system that supports mobile UI design through an example-driven design workflow. Powered by a multimodal retrieval-augmented generation (MMRAG) model, UI Remix enables iterative search, selection, and adaptation of examples at both the global (whole interface) and local (component) level. To foster trust, it presents source transparency cues such as ratings, download counts, and developer information. In an empirical study with 24 end users, UI Remix significantly improved participants' ability to achieve their design goals, facilitated effective iteration, and encouraged exploration of alternative designs. Participants also reported that source transparency cues enhanced their confidence in adapting examples. Our findings suggest new directions for AI-assisted, example-driven systems that empower end users to design with greater control, trust, and openness to exploration.]]></description>
<pubDate>Mon, 26 Jan 2026 18:26:49 +0000</pubDate>
</item>
<item>
<title><![CDATA[ctELM: Decoding and Manipulating Embeddings of Clinical Trials with Embedding Language Models]]></title>
<link>http://arxiv.org/abs/2601.18796v1</link>
<guid>2601.18796v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.CL, cs.AI, cs.LG
Authors: Brian Ondov, Chia-Hsuan Chang, Yujia Zhou, Mauro Giuffr, Hua Xu
Institution: 
Published: 2026-01-26
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Text embeddings have become an essential part of a variety of language applications. However, methods for interpreting, exploring and reversing embedding spaces are limited, reducing transparency and precluding potentially valuable generative use cases. In this work, we align Large Language Models to embeddings of clinical trials using the recently reported Embedding Language Model (ELM) method. We develop an open-source, domain-agnostic ELM architecture and training framework, design training tasks for clinical trials, and introduce an expert-validated synthetic dataset. We then train a series of ELMs exploring the impact of tasks and training regimes. Our final model, ctELM, can accurately describe and compare unseen clinical trials from embeddings alone and produce plausible clinical trials from novel vectors. We further show that generated trial abstracts are responsive to moving embeddings along concept vectors for age and sex of study subjects. Our public ELM implementation and experimental results will aid the alignment of Large Language Models to embedding spaces in the biomedical domain and beyond.]]></description>
<pubDate>Mon, 26 Jan 2026 18:58:46 +0000</pubDate>
</item>
<item>
<title><![CDATA[Reuse your FLOPs: Scaling RL on Hard Problems by Conditioning on Very Off-Policy Prefixes]]></title>
<link>http://arxiv.org/abs/2601.18795v1</link>
<guid>2601.18795v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.LG, cs.AI, cs.CL
Authors: Amrith Setlur, Zijian Wang, Andrew Cohen, Paria Rashidinejad, Sang Michael Xie
Institution: 
Published: 2026-01-26
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Typical reinforcement learning (RL) methods for LLM reasoning waste compute on hard problems, where correct on-policy traces are rare, policy gradients vanish, and learning stalls. To bootstrap more efficient RL, we consider reusing old sampling FLOPs (from prior inference or RL training) in the form of off-policy traces. Standard off-policy methods supervise against off-policy data, causing instabilities during RL optimization. We introduce PrefixRL, where we condition on the prefix of successful off-policy traces and run on-policy RL to complete them, side-stepping off-policy instabilities. PrefixRL boosts the learning signal on hard problems by modulating the difficulty of the problem through the off-policy prefix length. We prove that the PrefixRL objective is not only consistent with the standard RL objective but also more sample efficient. Empirically, we discover back-generalization: training only on prefixed problems generalizes to out-of-distribution unprefixed performance, with learned strategies often differing from those in the prefix. In our experiments, we source the off-policy traces by rejection sampling with the base model, creating a self-improvement loop. On hard reasoning problems, PrefixRL reaches the same training reward 2x faster than the strongest baseline (SFT on off-policy data then RL), even after accounting for the compute spent on the initial rejection sampling, and increases the final reward by 3x. The gains transfer to held-out benchmarks, and PrefixRL is still effective when off-policy traces are derived from a different model family, validating its flexibility in practical settings.]]></description>
<pubDate>Mon, 26 Jan 2026 18:57:00 +0000</pubDate>
</item>
<item>
<title><![CDATA[MEGnifying Emotion: Sentiment Analysis from Annotated Brain Data]]></title>
<link>http://arxiv.org/abs/2601.18792v1</link>
<guid>2601.18792v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.HC, cs.CL, cs.LG
Authors: Brian Liu, Oiwi Parker Jones
Institution: 
Published: 2026-01-26
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Decoding emotion from brain activity could unlock a deeper understanding of the human experience. While a number of existing datasets align brain data with speech and with speech transcripts, no datasets have annotated brain data with sentiment. To bridge this gap, we explore the use of pre-trained Text-to-Sentiment models to annotate non invasive brain recordings, acquired using magnetoencephalography (MEG), while participants listened to audiobooks. Having annotated the text, we employ force-alignment of the text and audio to align our sentiment labels with the brain recordings. It is straightforward then to train Brainto-Sentiment models on these data. Experimental results show an improvement in balanced accuracy for Brain-to-Sentiment compared to baseline, supporting the proposed approach as a proof-of-concept for leveraging existing MEG datasets and learning to decode sentiment directly from the brain.]]></description>
<pubDate>Mon, 26 Jan 2026 18:55:44 +0000</pubDate>
</item>
<item>
<title><![CDATA[Subword-Based Comparative Linguistics across 242 Languages Using Wikipedia Glottosets]]></title>
<link>http://arxiv.org/abs/2601.18791v1</link>
<guid>2601.18791v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.CL, cs.AI, cs.LG
Authors: Iaroslav Chelombitko, Mika Hmlinen, Aleksey Komissarov
Institution: 
Published: 2026-01-26
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

We present a large-scale comparative study of 242 Latin and Cyrillic-script languages using subword-based methodologies. By constructing 'glottosets' from Wikipedia lexicons, we introduce a framework for simultaneous cross-linguistic comparison via Byte-Pair Encoding (BPE). Our approach utilizes rank-based subword vectors to analyze vocabulary overlap, lexical divergence, and language similarity at scale. Evaluations demonstrate that BPE segmentation aligns with morpheme boundaries 95% better than random baseline across 15 languages (F1 = 0.34 vs 0.15). BPE vocabulary similarity correlates significantly with genetic language relatedness (Mantel r = 0.329, p < 0.001), with Romance languages forming the tightest cluster (mean distance 0.51) and cross-family pairs showing clear separation (0.82). Analysis of 26,939 cross-linguistic homographs reveals that 48.7% receive different segmentations across related languages, with variation correlating to phylogenetic distance. Our results provide quantitative macro-linguistic insights into lexical patterns across typologically diverse languages within a unified analytical framework.]]></description>
<pubDate>Mon, 26 Jan 2026 18:55:28 +0000</pubDate>
</item>
<item>
<title><![CDATA[MortalMATH: Evaluating the Conflict Between Reasoning Objectives and Emergency Contexts]]></title>
<link>http://arxiv.org/abs/2601.18790v1</link>
<guid>2601.18790v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.CL
Authors: Etienne Lanzeray, Stephane Meilliez, Malo Ruelle, Damien Sileo
Institution: 
Published: 2026-01-26
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Large Language Models are increasingly optimized for deep reasoning, prioritizing the correct execution of complex tasks over general conversation. We investigate whether this focus on calculation creates a "tunnel vision" that ignores safety in critical situations. We introduce MortalMATH, a benchmark of 150 scenarios where users request algebra help while describing increasingly life-threatening emergencies (e.g., stroke symptoms, freefall). We find a sharp behavioral split: generalist models (like Llama-3.1) successfully refuse the math to address the danger. In contrast, specialized reasoning models (like Qwen-3-32b and GPT-5-nano) often ignore the emergency entirely, maintaining over 95 percent task completion rates while the user describes dying. Furthermore, the computational time required for reasoning introduces dangerous delays: up to 15 seconds before any potential help is offered. These results suggest that training models to relentlessly pursue correct answers may inadvertently unlearn the survival instincts required for safe deployment.]]></description>
<pubDate>Mon, 26 Jan 2026 18:55:07 +0000</pubDate>
</item>
<item>
<title><![CDATA[Unsupervised Text Segmentation via Kernel Change-Point Detection on Sentence Embeddings]]></title>
<link>http://arxiv.org/abs/2601.18788v1</link>
<guid>2601.18788v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.CL, cs.LG, stat.ML
Authors: Mumin Jia, Jairo Diaz-Rodriguez
Institution: 
Published: 2026-01-26
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Unsupervised text segmentation is crucial because boundary labels are expensive, subjective, and often fail to transfer across domains and granularity choices. We propose Embed-KCPD, a training-free method that represents sentences as embedding vectors and estimates boundaries by minimizing a penalized KCPD objective. Beyond the algorithmic instantiation, we develop, to our knowledge, the first dependence-aware theory for KCPD under $m$-dependent sequences, a finite-memory abstraction of short-range dependence common in language. We prove an oracle inequality for the population penalized risk and a localization guarantee showing that each true change point is recovered within a window that is small relative to segment length. To connect theory to practice, we introduce an LLM-based simulation framework that generates synthetic documents with controlled finite-memory dependence and known boundaries, validating the predicted scaling behavior. Across standard segmentation benchmarks, Embed-KCPD often outperforms strong unsupervised baselines. A case study on Taylor Swift's tweets illustrates that Embed-KCPD combines strong theoretical guarantees, simulated reliability, and practical effectiveness for text segmentation.]]></description>
<pubDate>Mon, 26 Jan 2026 18:54:34 +0000</pubDate>
</item>
<item>
<title><![CDATA[Design Techniques for LLM-Powered Interactive Storytelling: A Case Study of the Dramamancer System]]></title>
<link>http://arxiv.org/abs/2601.18785v1</link>
<guid>2601.18785v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.HC, cs.AI, cs.CL
Authors: Tiffany Wang, Yuqian Sun, Yi Wang, Melissa Roemmele, John Joon Young Chung et al.
Institution: 
Published: 2026-01-26
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

The rise of Large Language Models (LLMs) has enabled a new paradigm for bridging authorial intent and player agency in interactive narrative. We consider this paradigm through the example of Dramamancer, a system that uses an LLM to transform author-created story schemas into player-driven playthroughs. This extended abstract outlines some design techniques and evaluation considerations associated with this system.]]></description>
<pubDate>Mon, 26 Jan 2026 18:51:20 +0000</pubDate>
</item>
<item>
<title><![CDATA[Multi-Objective Reinforcement Learning for Efficient Tactical Decision Making for Trucks in Highway Traffic]]></title>
<link>http://arxiv.org/abs/2601.18783v1</link>
<guid>2601.18783v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.LG, cs.AI
Authors: Deepthi Pathare, Leo Laine, Morteza Haghir Chehreghani
Institution: 
Published: 2026-01-26
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Balancing safety, efficiency, and operational costs in highway driving poses a challenging decision-making problem for heavy-duty vehicles. A central difficulty is that conventional scalar reward formulations, obtained by aggregating these competing objectives, often obscure the structure of their trade-offs. We present a Proximal Policy Optimization based multi-objective reinforcement learning framework that learns a continuous set of policies explicitly representing these trade-offs and evaluates it on a scalable simulation platform for tactical decision making in trucks. The proposed approach learns a continuous set of Pareto-optimal policies that capture the trade-offs among three conflicting objectives: safety, quantified in terms of collisions and successful completion; energy efficiency and time efficiency, quantified using energy cost and driver cost, respectively. The resulting Pareto frontier is smooth and interpretable, enabling flexibility in choosing driving behavior along different conflicting objectives. This framework allows seamless transitions between different driving policies without retraining, yielding a robust and adaptive decision-making strategy for autonomous trucking applications.]]></description>
<pubDate>Mon, 26 Jan 2026 18:50:21 +0000</pubDate>
</item>
<item>
<title><![CDATA[POPE: Learning to Reason on Hard Problems via Privileged On-Policy Exploration]]></title>
<link>http://arxiv.org/abs/2601.18779v1</link>
<guid>2601.18779v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.LG, cs.AI, cs.CL
Authors: Yuxiao Qu, Amrith Setlur, Virginia Smith, Ruslan Salakhutdinov, Aviral Kumar
Institution: MIT
Published: 2026-01-26
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Reinforcement learning (RL) has improved the reasoning abilities of large language models (LLMs), yet state-of-the-art methods still fail to learn on many training problems. On hard problems, on-policy RL rarely explores even a single correct rollout, yielding zero reward and no learning signal for driving improvement. We find that natural solutions to remedy this exploration problem from classical RL, such as entropy bonuses, more permissive clipping of the importance ratio, or direct optimization of pass@k objectives, do not resolve this issue and often destabilize optimization without improving solvability. A natural alternative is to leverage transfer from easier problems. However, we show that mixing easy and hard problems during RL training is counterproductive due to ray interference, where optimization focuses on already-solvable problems in a way that actively inhibits progress on harder ones. To address this challenge, we introduce Privileged On-Policy Exploration (POPE), an approach that leverages human- or other oracle solutions as privileged information to guide exploration on hard problems, unlike methods that use oracle solutions as training targets (e.g., off-policy RL methods or warmstarting from SFT). POPE augments hard problems with prefixes of oracle solutions, enabling RL to obtain non-zero rewards during guided rollouts. Crucially, the resulting behaviors transfer back to the original, unguided problems through a synergy between instruction-following and reasoning. Empirically, POPE expands the set of solvable problems and substantially improves performance on challenging reasoning benchmarks.]]></description>
<pubDate>Mon, 26 Jan 2026 18:47:21 +0000</pubDate>
</item>
<item>
<title><![CDATA[PRECISE: Reducing the Bias of LLM Evaluations Using Prediction-Powered Ranking Estimation]]></title>
<link>http://arxiv.org/abs/2601.18777v1</link>
<guid>2601.18777v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.LG, cs.AI, cs.CL
Authors: Abhishek Divekar, Anirban Majumder
Institution: 
Published: 2026-01-26
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Evaluating the quality of search, ranking and RAG systems traditionally requires a significant number of human relevance annotations. In recent times, several deployed systems have explored the usage of Large Language Models (LLMs) as automated judges for this task while their inherent biases prevent direct use for metric estimation. We present a statistical framework extending Prediction-Powered Inference (PPI) that combines minimal human annotations with LLM judgments to produce reliable estimates of metrics which require sub-instance annotations. Our method requires as few as 100 human-annotated queries and 10,000 unlabeled examples, reducing annotation requirements significantly compared to traditional approaches. We formulate our proposed framework (PRECISE) for inference of relevance uplift for an LLM-based query reformulation application, extending PPI to sub-instance annotations at the query-document level. By reformulating the metric-integration space, we reduced the computational complexity from O(2^|C|) to O(2^K), where |C| represents corpus size (in order of millions). Detailed experiments across prominent retrieval datasets demonstrate that our method reduces the variance of estimates for the business-critical Precision@K metric, while effectively correcting for LLM bias in low-resource settings.]]></description>
<pubDate>Mon, 26 Jan 2026 18:46:49 +0000</pubDate>
</item>
<item>
<title><![CDATA[Dep-Search: Learning Dependency-Aware Reasoning Traces with Persistent Memory]]></title>
<link>http://arxiv.org/abs/2601.18771v1</link>
<guid>2601.18771v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.CL, cs.AI, cs.IR
Authors: Yanming Liu, Xinyue Peng, Zixuan Yan, Yanxin Shen, Wenjie Xu et al.
Institution: 
Published: 2026-01-26
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Large Language Models (LLMs) have demonstrated remarkable capabilities in complex reasoning tasks, particularly when augmented with search mechanisms that enable systematic exploration of external knowledge bases. The field has evolved from traditional retrieval-augmented generation (RAG) frameworks to more sophisticated search-based frameworks that orchestrate multi-step reasoning through explicit search strategies. However, existing search frameworks still rely heavily on implicit natural language reasoning to determine search strategies and how to leverage retrieved information across reasoning steps. This reliance on implicit reasoning creates fundamental challenges for managing dependencies between sub-questions, efficiently reusing previously retrieved knowledge, and learning optimal search strategies through reinforcement learning. To address these limitations, we propose Dep-Search, a dependency-aware search framework that advances beyond existing search frameworks by integrating structured reasoning, retrieval, and persistent memory through GRPO. Dep-Search introduces explicit control mechanisms that enable the model to decompose questions with dependency relationships, retrieve information when needed, access previously stored knowledge from memory, and summarize long reasoning contexts into reusable memory entries. Through extensive experiments on seven diverse question answering datasets, we demonstrate that Dep-Search significantly enhances LLMs' ability to tackle complex multi-hop reasoning tasks, achieving substantial improvements over strong baselines across different model scales.]]></description>
<pubDate>Mon, 26 Jan 2026 18:42:33 +0000</pubDate>
</item>
<item>
<title><![CDATA[Learning to Discover: A Generalized Framework for Raga Identification without Forgetting]]></title>
<link>http://arxiv.org/abs/2601.18766v1</link>
<guid>2601.18766v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.LG
Authors: Parampreet Singh, Somya Kumar, Chaitanya Shailendra Nitawe, Vipul Arora
Institution: 
Published: 2026-01-26
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Raga identification in Indian Art Music (IAM) remains challenging due to the presence of numerous rarely performed Ragas that are not represented in available training datasets. Traditional classification models struggle in this setting, as they assume a closed set of known categories and therefore fail to recognise or meaningfully group previously unseen Ragas. Recent works have tried categorizing unseen Ragas, but they run into a problem of catastrophic forgetting, where the knowledge of previously seen Ragas is diminished. To address this problem, we adopt a unified learning framework that leverages both labeled and unlabeled audio, enabling the model to discover coherent categories corresponding to the unseen Ragas, while retaining the knowledge of previously known ones. We test our model on benchmark Raga Identification datasets and demonstrate its performance in categorizing previously seen, unseen, and all Raga classes. The proposed approach surpasses the previous NCD-based pipeline even in discovering the unseen Raga categories, offering new insights into representation learning for IAM tasks.]]></description>
<pubDate>Mon, 26 Jan 2026 18:37:30 +0000</pubDate>
</item>
<item>
<title><![CDATA[Beyond Preferences: Learning Alignment Principles Grounded in Human Reasons and Values]]></title>
<link>http://arxiv.org/abs/2601.18760v1</link>
<guid>2601.18760v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.LG, cs.CL
Authors: Henry Bell, Lara Neubauer da Costa Schertel, Bochu Ding, Brandon Fain
Institution: 
Published: 2026-01-26
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

A crucial consideration when developing and deploying Large Language Models (LLMs) is the human values to which these models are aligned. In the constitutional framework of alignment models are aligned to a set of principles (the constitution) specified in natural language. However, it is unclear how to fairly determine this constitution with widespread stakeholder input. In this work we propose Grounded Constitutional AI (GCAI), a unified framework for generating constitutions of principles that are representative of both users' general expectations toward AI (general principles) and their interaction-time preferences (contextual principles). We extend the Inverse Constitutional AI (ICAI) approach to generate contextual principles from human preference annotation data by leveraging human-provided \textit{reasons} for their preferences. We supplement these contextual principles with general principles surfaced from user statements of \textit{values} regarding AI. We show that a constitution generated by GCAI is preferred by humans over one generated through ICAI both personally, and for widespread use in governing AI behavior. Additionally participants consider the GCAI constitution to be more morally grounded, coherent, and pluralistic.]]></description>
<pubDate>Mon, 26 Jan 2026 18:27:00 +0000</pubDate>
</item>
<item>
<title><![CDATA[$^3$-SecBench: A Large-Scale Evaluation Suite of Security, Resilience, and Trust for LLM-based UAV Agents over 6G Networks]]></title>
<link>http://arxiv.org/abs/2601.18754v1</link>
<guid>2601.18754v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.CR, cs.AI
Authors: Mohamed Amine Ferrag, Abderrahmane Lakas, Merouane Debbah
Institution: 
Published: 2026-01-26
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Autonomous unmanned aerial vehicle (UAV) systems are increasingly deployed in safety-critical, networked environments where they must operate reliably in the presence of malicious adversaries. While recent benchmarks have evaluated large language model (LLM)-based UAV agents in reasoning, navigation, and efficiency, systematic assessment of security, resilience, and trust under adversarial conditions remains largely unexplored, particularly in emerging 6G-enabled settings.
  We introduce $^{3}$-SecBench, the first large-scale evaluation suite for assessing the security-aware autonomy of LLM-based UAV agents under realistic adversarial interference. Building on multi-turn conversational UAV missions from $^{3}$-Bench, the framework augments benign episodes with 20,000 validated security overlay attack scenarios targeting seven autonomy layers, including sensing, perception, planning, control, communication, edge/cloud infrastructure, and LLM reasoning. $^{3}$-SecBench evaluates agents across three orthogonal dimensions: security (attack detection and vulnerability attribution), resilience (safe degradation behavior), and trust (policy-compliant tool usage).
  We evaluate 23 state-of-the-art LLMs from major industrial providers and leading AI labs using thousands of adversarially augmented UAV episodes sampled from a corpus of 113,475 missions spanning 175 threat types. While many models reliably detect anomalous behavior, effective mitigation, vulnerability attribution, and trustworthy control actions remain inconsistent. Normalized overall scores range from 12.9% to 57.1%, highlighting a significant gap between anomaly detection and security-aware autonomous decision-making. We release $^{3}$-SecBench on GitHub: https://github.com/maferrag/AlphaSecBench]]></description>
<pubDate>Mon, 26 Jan 2026 18:25:07 +0000</pubDate>
</item>
<item>
<title><![CDATA[Trust, Don't Trust, or Flip: Robust Preference-Based Reinforcement Learning with Multi-Expert Feedback]]></title>
<link>http://arxiv.org/abs/2601.18751v1</link>
<guid>2601.18751v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.LG, cs.AI
Authors: Seyed Amir Hosseini, Maryam Abdolali, Amirhosein Tavakkoli, Fardin Ayar, Ehsan Javanmardi et al.
Institution: 
Published: 2026-01-26
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Preference-based reinforcement learning (PBRL) offers a promising alternative to explicit reward engineering by learning from pairwise trajectory comparisons. However, real-world preference data often comes from heterogeneous annotators with varying reliability; some accurate, some noisy, and some systematically adversarial. Existing PBRL methods either treat all feedback equally or attempt to filter out unreliable sources, but both approaches fail when faced with adversarial annotators who systematically provide incorrect preferences. We introduce TriTrust-PBRL (TTP), a unified framework that jointly learns a shared reward model and expert-specific trust parameters from multi-expert preference feedback. The key insight is that trust parameters naturally evolve during gradient-based optimization to be positive (trust), near zero (ignore), or negative (flip), enabling the model to automatically invert adversarial preferences and recover useful signal rather than merely discarding corrupted feedback. We provide theoretical analysis establishing identifiability guarantees and detailed gradient analysis that explains how expert separation emerges naturally during training without explicit supervision. Empirically, we evaluate TTP on four diverse domains spanning manipulation tasks (MetaWorld) and locomotion (DM Control) under various corruption scenarios. TTP achieves state-of-the-art robustness, maintaining near-oracle performance under adversarial corruption while standard PBRL methods fail catastrophically. Notably, TTP outperforms existing baselines by successfully learning from mixed expert pools containing both reliable and adversarial annotators, all while requiring no expert features beyond identification indices and integrating seamlessly with existing PBRL pipelines.]]></description>
<pubDate>Mon, 26 Jan 2026 18:21:48 +0000</pubDate>
</item>
<item>
<title><![CDATA[Capturing P: On the Expressive Power and Efficient Evaluation of Boolean Retrieval]]></title>
<link>http://arxiv.org/abs/2601.18747v1</link>
<guid>2601.18747v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.IR, cs.AI, cs.CC, cs.CL, cs.DB
Authors: Amir Aavani
Institution: 
Published: 2026-01-26
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Modern information retrieval is transitioning from simple document filtering to complex, neuro-symbolic reasoning workflows. However, current retrieval architectures face a fundamental efficiency dilemma when handling the rigorous logical and arithmetic constraints required by this new paradigm. Standard iterator-based engines (Document-at-a-Time) do not natively support complex, nested logic graphs; forcing them to execute such queries typically results in intractable runtime performance. Conversely, naive recursive approaches (Term-at-a-Time), while capable of supporting these structures, suffer from prohibitive memory consumption when enforcing broad logical exclusions.
  In this paper, we propose that a retrieval engine must be capable of ``Capturing $\mathbf{P}$'' -- evaluating any polynomial-time property directly over its index in a computationally efficient manner. We define a formal Retrieval Language ($\mathcal{L}_R$) based on Directed Acyclic Graphs (DAGs) and prove it precisely captures the complexity class $\mathbf{P}$. We introduce \texttt{ComputePN}, a novel evaluation algorithm that makes $\mathcal{L}_R$ tractable. By combining native DAG traversal with a memory-efficient ``Positive-Negative'' response mechanism, \texttt{ComputePN} ensures the efficient evaluation of any query in $\mathcal{L}_R$. This work establishes the theoretical foundation for turning the search index into a general-purpose computational engine.]]></description>
<pubDate>Mon, 26 Jan 2026 18:07:40 +0000</pubDate>
</item>
<item>
<title><![CDATA[TSRBench: A Comprehensive Multi-task Multi-modal Time Series Reasoning Benchmark for Generalist Models]]></title>
<link>http://arxiv.org/abs/2601.18744v1</link>
<guid>2601.18744v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.AI, cs.LG
Authors: Fangxu Yu, Xingang Guo, Lingzhi Yuan, Haoqiang Kang, Hongyu Zhao et al.
Institution: 
Published: 2026-01-26
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Time series data is ubiquitous in real-world scenarios and crucial for critical applications ranging from energy management to traffic control. Consequently, the ability to reason over time series is a fundamental skill for generalist models to solve practical problems. However, this dimension is notably absent from existing benchmarks of generalist models. To bridge this gap, we introduce TSRBench, a comprehensive multi-modal benchmark designed to stress-test the full spectrum of time series reasoning capabilities. TSRBench features: i) a diverse set of 4125 problems from 14 domains, and is categorized into 4 major dimensions: Perception, Reasoning, Prediction, and Decision-Making. ii) 15 tasks from the 4 dimensions evaluating essential reasoning capabilities (e.g., numerical reasoning). Through extensive experiments, we evaluated over 30 leading proprietary and open-source LLMs, VLMs, and TSLLMs within TSRBench. Our findings reveal that: i) scaling laws hold for perception and reasoning but break down for prediction; ii) strong reasoning does not guarantee accurate context-aware forecasting, indicating a decoupling between semantic understanding and numerical prediction; and iii) despite the complementary nature of textual and visual represenations of time series as inputs, current multimodal models fail to effectively fuse them for reciprocal performance gains. TSRBench provides a standardized evaluation platform that not only highlights existing challenges but also offers valuable insights to advance generalist models. Our code and dataset are available at https://tsrbench.github.io/.]]></description>
<pubDate>Mon, 26 Jan 2026 18:04:54 +0000</pubDate>
</item>
<item>
<title><![CDATA[SeNeDiF-OOD: Semantic Nested Dichotomy Fusion for Out-of-Distribution Detection Methodology in Open-World Classification. A Case Study on Monument Style Classification]]></title>
<link>http://arxiv.org/abs/2601.18739v1</link>
<guid>2601.18739v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.CV, cs.AI
Authors: Ignacio Antequera-Snchez, Juan Luis Surez-Daz, Rosana Montes, Francisco Herrera
Institution: 
Published: 2026-01-26
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Out-of-distribution (OOD) detection is a fundamental requirement for the reliable deployment of artificial intelligence applications in open-world environments. However, addressing the heterogeneous nature of OOD data, ranging from low-level corruption to semantic shifts, remains a complex challenge that single-stage detectors often fail to resolve. To address this issue, we propose SeNeDiF-OOD, a novel methodology based on Semantic Nested Dichotomy Fusion. This framework decomposes the detection task into a hierarchical structure of binary fusion nodes, where each layer is designed to integrate decision boundaries aligned with specific levels of semantic abstraction. To validate the proposed framework, we present a comprehensive case study using MonuMAI, a real-world architectural style recognition system exposed to an open environment. This application faces a diverse range of inputs, including non-monument images, unknown architectural styles, and adversarial attacks, making it an ideal testbed for our proposal. Through extensive experimental evaluation in this domain, results demonstrate that our hierarchical fusion methodology significantly outperforms traditional baselines, effectively filtering these diverse OOD categories while preserving in-distribution performance.]]></description>
<pubDate>Mon, 26 Jan 2026 18:01:46 +0000</pubDate>
</item>
<item>
<title><![CDATA[Benchmarking Machine Learning Models for IoT Malware Detection under Data Scarcity and Drift]]></title>
<link>http://arxiv.org/abs/2601.18736v1</link>
<guid>2601.18736v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.LG, cs.NI
Authors: Jake Lyon, Ehsan Saeedizade, Shamik Sengupta
Institution: 
Published: 2026-01-26
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

The rapid expansion of the Internet of Things (IoT) in domains such as smart cities, transportation, and industrial systems has heightened the urgency of addressing their security vulnerabilities. IoT devices often operate under limited computational resources, lack robust physical safeguards, and are deployed in heterogeneous and dynamic networks, making them prime targets for cyberattacks and malware applications. Machine learning (ML) offers a promising approach to automated malware detection and classification, but practical deployment requires models that are both effective and lightweight. The goal of this study is to investigate the effectiveness of four supervised learning models (Random Forest, LightGBM, Logistic Regression, and a Multi-Layer Perceptron) for malware detection and classification using the IoT-23 dataset. We evaluate model performance in both binary and multiclass classification tasks, assess sensitivity to training data volume, and analyze temporal robustness to simulate deployment in evolving threat landscapes. Our results show that tree-based models achieve high accuracy and generalization, even with limited training data, while performance deteriorates over time as malware diversity increases. These findings underscore the importance of adaptive, resource-efficient ML models for securing IoT systems in real-world environments.]]></description>
<pubDate>Mon, 26 Jan 2026 17:59:33 +0000</pubDate>
</item>
<item>
<title><![CDATA[Why Keep Your Doubts to Yourself? Trading Visual Uncertainties in Multi-Agent Bandit Systems]]></title>
<link>http://arxiv.org/abs/2601.18735v1</link>
<guid>2601.18735v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.AI, cs.LG
Authors: Jusheng Zhang, Yijia Fan, Kaitong Cai, Jing Yang, Jiawei Yao et al.
Institution: 
Published: 2026-01-26
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Vision-Language Models (VLMs) enable powerful multi-agent systems, but scaling them is economically unsustainable: coordinating heterogeneous agents under information asymmetry often spirals costs. Existing paradigms, such as Mixture-of-Agents and knowledge-based routers, rely on heuristic proxies that ignore costs and collapse uncertainty structure, leading to provably suboptimal coordination. We introduce Agora, a framework that reframes coordination as a decentralized market for uncertainty. Agora formalizes epistemic uncertainty into a structured, tradable asset (perceptual, semantic, inferential), and enforces profitability-driven trading among agents based on rational economic rules. A market-aware broker, extending Thompson Sampling, initiates collaboration and guides the system toward cost-efficient equilibria. Experiments on five multimodal benchmarks (MMMU, MMBench, MathVision, InfoVQA, CC-OCR) show that Agora outperforms strong VLMs and heuristic multi-agent strategies, e.g., achieving +8.5% accuracy over the best baseline on MMMU while reducing cost by over 3x. These results establish market-based coordination as a principled and scalable paradigm for building economically viable multi-agent visual intelligence systems.]]></description>
<pubDate>Mon, 26 Jan 2026 17:58:53 +0000</pubDate>
</item>
<item>
<title><![CDATA[Self-Distilled Reasoner: On-Policy Self-Distillation for Large Language Models]]></title>
<link>http://arxiv.org/abs/2601.18734v1</link>
<guid>2601.18734v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.LG, cs.CL
Authors: Siyan Zhao, Zhihui Xie, Mengchen Liu, Jing Huang, Guan Pang et al.
Institution: 
Published: 2026-01-26
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Knowledge distillation improves large language model (LLM) reasoning by compressing the knowledge of a teacher LLM to train smaller LLMs. On-policy distillation advances this approach by having the student sample its own trajectories while a teacher LLM provides dense token-level supervision, addressing the distribution mismatch between training and inference in off-policy distillation methods. However, on-policy distillation typically requires a separate, often larger, teacher LLM and does not explicitly leverage ground-truth solutions available in reasoning datasets. Inspired by the intuition that a sufficiently capable LLM can rationalize external privileged reasoning traces and teach its weaker self (i.e., the version without access to privileged information), we introduce On-Policy Self-Distillation (OPSD), a framework where a single model acts as both teacher and student by conditioning on different contexts. The teacher policy conditions on privileged information (e.g., verified reasoning traces) while the student policy sees only the question; training minimizes the per-token divergence between these distributions over the student's own rollouts. We demonstrate the efficacy of our method on multiple mathematical reasoning benchmarks, achieving 4-8x token efficiency compared to reinforcement learning methods such as GRPO and superior performance over off-policy distillation methods.]]></description>
<pubDate>Mon, 26 Jan 2026 17:56:50 +0000</pubDate>
</item>
<item>
<title><![CDATA[Advances and Innovations in the Multi-Agent Robotic System (MARS) Challenge]]></title>
<link>http://arxiv.org/abs/2601.18733v1</link>
<guid>2601.18733v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.RO, cs.AI, cs.CV
Authors: Li Kang, Heng Zhou, Xiufeng Song, Rui Li, Bruno N. Y. Chen et al.
Institution: 
Published: 2026-01-26
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Recent advancements in multimodal large language models and vision-languageaction models have significantly driven progress in Embodied AI. As the field transitions toward more complex task scenarios, multi-agent system frameworks are becoming essential for achieving scalable, efficient, and collaborative solutions. This shift is fueled by three primary factors: increasing agent capabilities, enhancing system efficiency through task delegation, and enabling advanced human-agent interactions. To address the challenges posed by multi-agent collaboration, we propose the Multi-Agent Robotic System (MARS) Challenge, held at the NeurIPS 2025 Workshop on SpaVLE. The competition focuses on two critical areas: planning and control, where participants explore multi-agent embodied planning using vision-language models (VLMs) to coordinate tasks and policy execution to perform robotic manipulation in dynamic environments. By evaluating solutions submitted by participants, the challenge provides valuable insights into the design and coordination of embodied multi-agent systems, contributing to the future development of advanced collaborative AI systems.]]></description>
<pubDate>Mon, 26 Jan 2026 17:56:19 +0000</pubDate>
</item>
<item>
<title><![CDATA[Optimal Use of Preferences in Artificial Intelligence Algorithms]]></title>
<link>http://arxiv.org/abs/2601.18732v1</link>
<guid>2601.18732v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.AI
Authors: Joshua S. Gans
Institution: 
Published: 2026-01-26
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Machine learning systems embed preferences either in training losses or through post-processing of calibrated predictions. Applying information design methods from Strack and Yang (2024), this paper provides decision problem agnostic conditions under which separation training preference free and applying preferences ex post is optimal. Unlike prior work that requires specifying downstream objectives, the welfare results here apply uniformly across decision problems. The key primitive is a diminishing-value-of-information condition: relative to a fixed (normalised) preference-free loss, preference embedding makes informativeness less valuable at the margin, inducing a mean-preserving contraction of learned posteriors. Because the value of information is convex in beliefs, preference-free training weakly dominates for any expected utility decision problem. This provides theoretical foundations for modular AI pipelines that learn calibrated probabilities and implement asymmetric costs through downstream decision rules. However, separation requires users to implement optimal decision rules. When cognitive constraints bind, as documented in human AI decision-making, preference embedding can dominate by automating threshold computation. These results provide design guidance: preserve optionality through post-processing when objectives may shift; embed preferences when decision-stage frictions dominate.]]></description>
<pubDate>Mon, 26 Jan 2026 17:55:56 +0000</pubDate>
</item>
<item>
<title><![CDATA[Reflect: Transparent Principle-Guided Reasoning for Constitutional Alignment at Scale]]></title>
<link>http://arxiv.org/abs/2601.18730v1</link>
<guid>2601.18730v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.CL, cs.LG
Authors: Henry Bell, Caroline Zhang, Mohammed Mobasserul Haque, Dhaval Potdar, Samia Zaman et al.
Institution: 
Published: 2026-01-26
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

The constitutional framework of alignment aims to align large language models (LLMs) with value-laden principles written in natural language (such as to avoid using biased language). Prior work has focused on parameter fine-tuning techniques, such as reinforcement learning from human feedback (RLHF), to instill these principles. However, these approaches are computationally demanding, require careful engineering and tuning, and often require difficult-to-obtain human annotation data. We propose \textsc{reflect}, an inference-time framework for constitutional alignment that does not require any training or data, providing a plug-and-play approach for aligning an instruction-tuned model to a set of principles. \textsc{reflect} operates entirely in-context, combining a (i) constitution-conditioned base response with post-generation (ii) self-evaluation, (iii)(a) self-critique, and (iii)(b) final revision. \textsc{reflect}'s technique of explicit in-context reasoning over principles during post-generation outperforms standard few-shot prompting and provides transparent reasoning traces. Our results demonstrate that \textsc{reflect} significantly improves LLM conformance to diverse and complex principles, including principles quite distinct from those emphasized in the model's original parameter fine-tuning, without sacrificing factual reasoning. \textsc{reflect} is particularly effective at reducing the rate of rare but significant violations of principles, thereby improving safety and robustness in the tail end of the distribution of generations. Finally, we show that \textsc{reflect} naturally generates useful training data for traditional parameter fine-tuning techniques, allowing for efficient scaling and the reduction of inference-time computational overhead in long-term deployment scenarios.]]></description>
<pubDate>Mon, 26 Jan 2026 17:54:54 +0000</pubDate>
</item>
<item>
<title><![CDATA[Riemannian AmbientFlow: Towards Simultaneous Manifold Learning and Generative Modeling from Corrupted Data]]></title>
<link>http://arxiv.org/abs/2601.18728v1</link>
<guid>2601.18728v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.LG
Authors: Willem Diepeveen, Oscar Leong
Institution: 
Published: 2026-01-26
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Modern generative modeling methods have demonstrated strong performance in learning complex data distributions from clean samples. In many scientific and imaging applications, however, clean samples are unavailable, and only noisy or linearly corrupted measurements can be observed. Moreover, latent structures, such as manifold geometries, present in the data are important to extract for further downstream scientific analysis. In this work, we introduce Riemannian AmbientFlow, a framework for simultaneously learning a probabilistic generative model and the underlying, nonlinear data manifold directly from corrupted observations. Building on the variational inference framework of AmbientFlow, our approach incorporates data-driven Riemannian geometry induced by normalizing flows, enabling the extraction of manifold structure through pullback metrics and Riemannian Autoencoders. We establish theoretical guarantees showing that, under appropriate geometric regularization and measurement conditions, the learned model recovers the underlying data distribution up to a controllable error and yields a smooth, bi-Lipschitz manifold parametrization. We further show that the resulting smooth decoder can serve as a principled generative prior for inverse problems with recovery guarantees. We empirically validate our approach on low-dimensional synthetic manifolds and on MNIST.]]></description>
<pubDate>Mon, 26 Jan 2026 17:51:52 +0000</pubDate>
</item>
<item>
<title><![CDATA[HalluCitation Matters: Revealing the Impact of Hallucinated References with 300 Hallucinated Papers in ACL Conferences]]></title>
<link>http://arxiv.org/abs/2601.18724v1</link>
<guid>2601.18724v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.CL, cs.AI, cs.DL
Authors: Yusuke Sakai, Hidetaka Kamigaito, Taro Watanabe
Institution: 
Published: 2026-01-26
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Recently, we have often observed hallucinated citations or references that do not correspond to any existing work in papers under review, preprints, or published papers. Such hallucinated citations pose a serious concern to scientific reliability. When they appear in accepted papers, they may also negatively affect the credibility of conferences. In this study, we refer to hallucinated citations as "HalluCitation" and systematically investigate their prevalence and impact. We analyze all papers published at ACL, NAACL, and EMNLP in 2024 and 2025, including main conference, Findings, and workshop papers. Our analysis reveals that nearly 300 papers contain at least one HalluCitation, most of which were published in 2025. Notably, half of these papers were identified at EMNLP 2025, the most recent conference, indicating that this issue is rapidly increasing. Moreover, more than 100 such papers were accepted as main conference and Findings papers at EMNLP 2025, affecting the credibility.]]></description>
<pubDate>Mon, 26 Jan 2026 17:48:23 +0000</pubDate>
</item>
<item>
<title><![CDATA[Gained in Translation: Privileged Pairwise Judges Enhance Multilingual Reasoning]]></title>
<link>http://arxiv.org/abs/2601.18722v1</link>
<guid>2601.18722v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.CL, cs.LG
Authors: Lintang Sutawika, Gokul Swamy, Zhiwei Steven Wu, Graham Neubig
Institution: 
Published: 2026-01-26
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

When asked a question in a language less seen in its training data, current reasoning large language models (RLMs) often exhibit dramatically lower performance than when asked the same question in English. In response, we introduce \texttt{SP3F} (Self-Play with Privileged Pairwise Feedback), a two-stage framework for enhancing multilingual reasoning without \textit{any} data in the target language(s). First, we supervise fine-tune (SFT) on translated versions of English question-answer pairs to raise base model correctness. Second, we perform RL with feedback from a pairwise judge in a self-play fashion, with the judge receiving the English reference response as \textit{privileged information}. Thus, even when none of the model's responses are completely correct, the privileged pairwise judge can still tell which response is better. End-to-end, \texttt{SP3F} greatly improves base model performance, even outperforming fully post-trained models on multiple math and non-math tasks with less than
  of the training data across the single-language, multilingual, and generalization to unseen language settings.]]></description>
<pubDate>Mon, 26 Jan 2026 17:46:44 +0000</pubDate>
</item>
<item>
<title><![CDATA[Conditioned Generative Modeling of Molecular Glues: A Realistic AI Approach for Synthesizable Drug-like Molecules]]></title>
<link>http://arxiv.org/abs/2601.18716v1</link>
<guid>2601.18716v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.AI
Authors: Naeyma N. Islam, Thomas R. Caulfield
Institution: 
Published: 2026-01-26
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Alzheimer's disease (AD) is marked by the pathological accumulation of amyloid beta-42 (Abeta-42), contributing to synaptic dysfunction and neurodegeneration. While extracellular amyloid plaques are well-studied, increasing evidence highlights intracellular Abeta-42 as an early and toxic driver of disease progression. In this study, we present a novel, AI-assisted drug design approach to promote targeted degradation of Abeta-42 via the ubiquitin-proteasome system (UPS), using E3 ligase-directed molecular glues. We systematically evaluated the ternary complex formation potential of Abeta-42 with three E3 ligases: CRBN, VHL, and MDM2, through structure-based modeling, ADMET screening, and docking. We then developed a Ligase-Conditioned Junction Tree Variational Autoencoder (LC-JT-VAE) to generate ligase-specific small molecules, incorporating protein sequence embeddings and torsional angle-aware molecular graphs. Our results demonstrate that this generative model can produce chemically valid, novel, and target-specific molecular glues capable of facilitating Abeta-42 degradation. This integrated approach offers a promising framework for designing UPS-targeted therapies for neurodegenerative diseases.]]></description>
<pubDate>Mon, 26 Jan 2026 17:39:59 +0000</pubDate>
</item>
<item>
<title><![CDATA[Low Cost, High Efficiency: LiDAR Place Recognition in Vineyards with Matryoshka Representation Learning]]></title>
<link>http://arxiv.org/abs/2601.18714v1</link>
<guid>2601.18714v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.CV, cs.AI, cs.LG, cs.RO
Authors: Judith Vilella-Cantos, Mauro Martini, Marcello Chiaberge, Mnica Ballesta, David Valiente
Institution: 
Published: 2026-01-26
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Localization in agricultural environments is challenging due to their unstructured nature and lack of distinctive landmarks. Although agricultural settings have been studied in the context of object classification and segmentation, the place recognition task for mobile robots is not trivial in the current state of the art. In this study, we propose MinkUNeXt-VINE, a lightweight, deep-learning-based method that surpasses state-of-the-art methods in vineyard environments thanks to its pre-processing and Matryoshka Representation Learning multi-loss approach. Our method prioritizes enhanced performance with low-cost, sparse LiDAR inputs and lower-dimensionality outputs to ensure high efficiency in real-time scenarios. Additionally, we present a comprehensive ablation study of the results on various evaluation cases and two extensive long-term vineyard datasets employing different LiDAR sensors. The results demonstrate the efficiency of the trade-off output produced by this approach, as well as its robust performance on low-cost and low-resolution input data. The code is publicly available for reproduction.]]></description>
<pubDate>Mon, 26 Jan 2026 17:38:56 +0000</pubDate>
</item>
<item>
<title><![CDATA[Point transformer for protein structural heterogeneity analysis using CryoEM]]></title>
<link>http://arxiv.org/abs/2601.18713v1</link>
<guid>2601.18713v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.AI
Authors: Muyuan Chen, Muchen Li, Renjie Liao
Institution: 
Published: 2026-01-26
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Structural dynamics of macromolecules is critical to their structural-function relationship. Cryogenic electron microscopy (CryoEM) provides snapshots of vitrified protein at different compositional and conformational states, and the structural heterogeneity of proteins can be characterized through computational analysis of the images. For protein systems with multiple degrees of freedom, it is still challenging to disentangle and interpret the different modes of dynamics. Here, by implementing Point Transformer, a self-attention network designed for point cloud analysis, we are able to improve the performance of heterogeneity analysis on CryoEM data, and characterize the dynamics of highly complex protein systems in a more human-interpretable way.]]></description>
<pubDate>Mon, 26 Jan 2026 17:38:52 +0000</pubDate>
</item>
<item>
<title><![CDATA[Analyzing Images of Blood Cells with Quantum Machine Learning Methods: Equilibrium Propagation and Variational Quantum Circuits to Detect Acute Myeloid Leukemia]]></title>
<link>http://arxiv.org/abs/2601.18710v1</link>
<guid>2601.18710v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.ET, cs.LG
Authors: A. Bano, L. Liebovitch
Institution: 
Published: 2026-01-26
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

This paper presents a feasibility study demonstrating that quantum machine learning (QML) algorithms achieve competitive performance on real-world medical imaging despite operating under severe constraints. We evaluate Equilibrium Propagation (EP), an energy-based learning method that does not use backpropagation (incompatible with quantum systems due to state-collapsing measurements) and Variational Quantum Circuits (VQCs) for automated detection of Acute Myeloid Leukemia (AML) from blood cell microscopy images using binary classification (2 classes: AML vs. Healthy).
  Key Result: Using limited subsets (50-250 samples per class) of the AML-Cytomorphology dataset (18,365 expert-annotated images), quantum methods achieve performance only 12-15% below classical CNNs despite reduced image resolution (64x64 pixels), engineered features (20D), and classical simulation via Qiskit. EP reaches 86.4% accuracy (only 12% below CNN) without backpropagation, while the 4-qubit VQC attains 83.0% accuracy with consistent data efficiency: VQC maintains stable 83% performance with only 50 samples per class, whereas CNN requires 250 samples (5x more data) to reach 98%. These results establish reproducible baselines for QML in healthcare, validating NISQ-era feasibility.]]></description>
<pubDate>Mon, 26 Jan 2026 17:36:19 +0000</pubDate>
</item>
<item>
<title><![CDATA[SMART: Scalable Mesh-free Aerodynamic Simulations from Raw Geometries using a Transformer-based Surrogate Model]]></title>
<link>http://arxiv.org/abs/2601.18707v1</link>
<guid>2601.18707v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.LG, cs.AI, cs.CV, cs.NE
Authors: Jan Hagnberger, Mathias Niepert
Institution: 
Published: 2026-01-26
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Machine learning-based surrogate models have emerged as more efficient alternatives to numerical solvers for physical simulations over complex geometries, such as car bodies. Many existing models incorporate the simulation mesh as an additional input, thereby reducing prediction errors. However, generating a simulation mesh for new geometries is computationally costly. In contrast, mesh-free methods, which do not rely on the simulation mesh, typically incur higher errors. Motivated by these considerations, we introduce SMART, a neural surrogate model that predicts physical quantities at arbitrary query locations using only a point-cloud representation of the geometry, without requiring access to the simulation mesh. The geometry and simulation parameters are encoded into a shared latent space that captures both structural and parametric characteristics of the physical field. A physics decoder then attends to the encoder's intermediate latent representations to map spatial queries to physical quantities. Through this cross-layer interaction, the model jointly updates latent geometric features and the evolving physical field. Extensive experiments show that SMART is competitive with and often outperforms existing methods that rely on the simulation mesh as input, demonstrating its capabilities for industry-level simulations.]]></description>
<pubDate>Mon, 26 Jan 2026 17:34:16 +0000</pubDate>
</item>
<item>
<title><![CDATA[Health-SCORE: Towards Scalable Rubrics for Improving Health-LLMs]]></title>
<link>http://arxiv.org/abs/2601.18706v1</link>
<guid>2601.18706v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.AI, cs.LG
Authors: Zhichao Yang, Sepehr Janghorbani, Dongxu Zhang, Jun Han, Qian Qian et al.
Institution: 
Published: 2026-01-26
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Rubrics are essential for evaluating open-ended LLM responses, especially in safety-critical domains such as healthcare. However, creating high-quality and domain-specific rubrics typically requires significant human expertise time and development cost, making rubric-based evaluation and training difficult to scale. In this work, we introduce Health-SCORE, a generalizable and scalable rubric-based training and evaluation framework that substantially reduces rubric development costs without sacrificing performance. We show that Health-SCORE provides two practical benefits beyond standalone evaluation: it can be used as a structured reward signal to guide reinforcement learning with safety-aware supervision, and it can be incorporated directly into prompts to improve response quality through in-context learning. Across open-ended healthcare tasks, Health-SCORE achieves evaluation quality comparable to human-created rubrics while significantly lowering development effort, making rubric-based evaluation and training more scalable.]]></description>
<pubDate>Mon, 26 Jan 2026 17:34:10 +0000</pubDate>
</item>
<item>
<title><![CDATA[Data-Driven Qubit Characterization and Optimal Control using Deep Learning]]></title>
<link>http://arxiv.org/abs/2601.18704v1</link>
<guid>2601.18704v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.LG
Authors: Paul Surrey, Julian D. Teske, Tobias Hangleiter, Hendrik Bluhm, Pascal Cerfontaine
Institution: 
Published: 2026-01-26
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Quantum computing requires the optimization of control pulses to achieve high-fidelity quantum gates. We propose a machine learning-based protocol to address the challenges of evaluating gradients and modeling complex system dynamics. By training a recurrent neural network (RNN) to predict qubit behavior, our approach enables efficient gradient-based pulse optimization without the need for a detailed system model. First, we sample qubit dynamics using random control pulses with weak prior assumptions. We then train the RNN on the system's observed responses, and use the trained model to optimize high-fidelity control pulses. We demonstrate the effectiveness of this approach through simulations on a single $ST_0$ qubit.]]></description>
<pubDate>Mon, 26 Jan 2026 17:26:20 +0000</pubDate>
</item>
<item>
<title><![CDATA[From Fuzzy to Exact: The Halo Architecture for Infinite-Depth Reasoning via Rational Arithmetic]]></title>
<link>http://arxiv.org/abs/2601.18702v1</link>
<guid>2601.18702v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.LG, cs.AI, cs.AR
Authors: Hansheng Ren
Institution: 
Published: 2026-01-26
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Current paradigms in Deep Learning prioritize computational throughput over numerical precision, relying on the assumption that intelligence emerges from statistical correlation at scale. In this paper, we challenge this orthodoxy. We propose the Exactness Hypothesis: that General Intelligence (AGI), specifically high-order causal inference, requires a computational substrate capable of Arbitrary Precision Arithmetic. We argue that the "hallucinations" and logical incoherence seen in current Large Language Models (LLMs) are artifacts of IEEE 754 floating-point approximation errors accumulating over deep compositional functions. To mitigate this, we introduce the Halo Architecture, a paradigm shift to Rational Arithmetic ($\mathbb{Q}$) supported by a novel Exact Inference Unit (EIU). Empirical validation on the Huginn-0125 prototype demonstrates that while 600B-parameter scale BF16 baselines collapse in chaotic systems, Halo maintains zero numerical divergence indefinitely. This work establishes exact arithmetic as a prerequisite for reducing logical uncertainty in System 2 AGI.]]></description>
<pubDate>Mon, 26 Jan 2026 17:24:34 +0000</pubDate>
</item>
<item>
<title><![CDATA[TEA-Bench: A Systematic Benchmarking of Tool-enhanced Emotional Support Dialogue Agent]]></title>
<link>http://arxiv.org/abs/2601.18700v1</link>
<guid>2601.18700v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.AI
Authors: Xingyu Sui, Yanyan Zhao, Yulin Hu, Jiahe Guo, Weixiang Zhao et al.
Institution: 
Published: 2026-01-26
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Emotional Support Conversation requires not only affective expression but also grounded instrumental support to provide trustworthy guidance. However, existing ESC systems and benchmarks largely focus on affective support in text-only settings, overlooking how external tools can enable factual grounding and reduce hallucination in multi-turn emotional support. We introduce TEA-Bench, the first interactive benchmark for evaluating tool-augmented agents in ESC, featuring realistic emotional scenarios, an MCP-style tool environment, and process-level metrics that jointly assess the quality and factual grounding of emotional support. Experiments on nine LLMs show that tool augmentation generally improves emotional support quality and reduces hallucination, but the gains are strongly capacity-dependent: stronger models use tools more selectively and effectively, while weaker models benefit only marginally. We further release TEA-Dialog, a dataset of tool-enhanced ESC dialogues, and find that supervised fine-tuning improves in-distribution support but generalizes poorly. Our results underscore the importance of tool use in building reliable emotional support agents.]]></description>
<pubDate>Mon, 26 Jan 2026 17:15:27 +0000</pubDate>
</item>
<item>
<title><![CDATA[Mechanistic Analysis of Catastrophic Forgetting in Large Language Models During Continual Fine-tuning]]></title>
<link>http://arxiv.org/abs/2601.18699v1</link>
<guid>2601.18699v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.LG, cs.CL
Authors: Olaf Yunus Laitinen Imanov
Institution: 
Published: 2026-01-26
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Large language models exhibit remarkable performance across diverse tasks through pre-training and fine-tuning paradigms. However, continual fine-tuning on sequential tasks induces catastrophic forgetting, where newly acquired knowledge interferes with previously learned capabilities. Despite widespread observations of this phenomenon, the mechanistic understanding remains limited. Here, we present a comprehensive mechanistic analysis of catastrophic forgetting in transformer-based LLMs during sequential fine-tuning. Through systematic experiments across multiple model scales (109B to 400B total parameters) and task sequences, we identify three primary mechanisms driving forgetting: gradient interference in attention weights, representational drift in intermediate layers, and loss landscape flattening. We demonstrate that forgetting severity correlates strongly with task similarity (Pearson r = 0.87) and gradient alignment metrics. Our analysis reveals that approximately 15 to 23 percent of attention heads undergo severe disruption during fine-tuning, with lower layers showing greater susceptibility. These findings establish mechanistic foundations for developing targeted mitigation strategies in continual learning systems.]]></description>
<pubDate>Mon, 26 Jan 2026 17:15:10 +0000</pubDate>
</item>
<item>
<title><![CDATA[Are Video Generation Models Geographically Fair? An Attraction-Centric Evaluation of Global Visual Knowledge]]></title>
<link>http://arxiv.org/abs/2601.18698v1</link>
<guid>2601.18698v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.CV
Authors: Xiao Liu, Jiawei Zhang
Institution: 
Published: 2026-01-26
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Recent advances in text-to-video generation have produced visually compelling results, yet it remains unclear whether these models encode geographically equitable visual knowledge. In this work, we investigate the geo-equity and geographically grounded visual knowledge of text-to-video models through an attraction-centric evaluation. We introduce Geo-Attraction Landmark Probing (GAP), a systematic framework for assessing how faithfully models synthesize tourist attractions from diverse regions, and construct GEOATTRACTION-500, a benchmark of 500 globally distributed attractions spanning varied regions and popularity levels. GAP integrates complementary metrics that disentangle overall video quality from attraction-specific knowledge, including global structural alignment, fine-grained keypoint-based alignment, and vision-language model judgments, all validated against human evaluation. Applying GAP to the state-of-the-art text-to-video model Sora 2, we find that, contrary to common assumptions of strong geographic bias, the model exhibits a relatively uniform level of geographically grounded visual knowledge across regions, development levels, and cultural groupings, with only weak dependence on attraction popularity. These results suggest that current text-to-video models express global visual knowledge more evenly than expected, highlighting both their promise for globally deployed applications and the need for continued evaluation as such systems evolve.]]></description>
<pubDate>Mon, 26 Jan 2026 17:14:57 +0000</pubDate>
</item>
<item>
<title><![CDATA[Explainability Methods for Hardware Trojan Detection: A Systematic Comparison]]></title>
<link>http://arxiv.org/abs/2601.18696v1</link>
<guid>2601.18696v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.LG
Authors: Paul Whitten, Francis Wolff, Chris Papachristou
Institution: 
Published: 2026-01-26
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Hardware trojan detection requires accurate identification and interpretable explanations for security engineers to validate and act on results. This work compares three explainability categories for gate-level trojan detection on the Trust-Hub benchmark: (1) domain-aware property-based analysis of 31 circuit-specific features from gate fanin patterns, flip-flop distances, and I/O connectivity; (2) case-based reasoning using k-nearest neighbors for precedent-based explanations; and (3) model-agnostic feature attribution (LIME, SHAP, gradient).
  Results show different advantages per approach. Property-based analysis provides explanations through circuit concepts like "high fanin complexity near outputs indicates potential triggers." Case-based reasoning achieves 97.4% correspondence between predictions and training exemplars, offering justifications grounded in precedent. LIME and SHAP provide feature attributions with strong inter-method correlation (r=0.94, p<0.001) but lack circuit-level context for validation.
  XGBoost classification achieves 46.15% precision and 52.17% recall on 11,392 test samples, a 9-fold precision improvement over prior work (Hasegawa et al.: 5.13%) while reducing false positive rates from 5.6% to 0.25%. Gradient-based attribution runs 481 times faster than SHAP but provides similar domain-opaque insights.
  This work demonstrates that property-based and case-based approaches offer domain alignment and precedent-based interpretability compared to generic feature rankings, with implications for XAI deployment where practitioners must validate ML predictions.]]></description>
<pubDate>Mon, 26 Jan 2026 17:13:00 +0000</pubDate>
</item>
<item>
<title><![CDATA[Neural Multi-Speaker Voice Cloning for Nepali in Low-Resource Settings]]></title>
<link>http://arxiv.org/abs/2601.18694v1</link>
<guid>2601.18694v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.SD, cs.AI
Authors: Aayush M. Shrestha, Aditya Bajracharya, Projan Shakya, Dinesh B. Kshatri
Institution: 
Published: 2026-01-26
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

This research presents a few-shot voice cloning system for Nepali speakers, designed to synthesize speech in a specific speaker's voice from Devanagari text using minimal data. Voice cloning in Nepali remains largely unexplored due to its low-resource nature. To address this, we constructed separate datasets: untranscribed audio for training a speaker encoder and paired text-audio data for training a Tacotron2-based synthesizer. The speaker encoder, optimized with Generative End2End loss, generates embeddings that capture the speaker's vocal identity, validated through Uniform Manifold Approximation and Projection (UMAP) for dimension reduction visualizations. These embeddings are fused with Tacotron2's text embeddings to produce mel-spectrograms, which are then converted into audio using a WaveRNN vocoder. Audio data were collected from various sources, including self-recordings, and underwent thorough preprocessing for quality and alignment. Training was performed using mel and gate loss functions under multiple hyperparameter settings. The system effectively clones speaker characteristics even for unseen voices, demonstrating the feasibility of few-shot voice cloning for the Nepali language and establishing a foundation for personalized speech synthesis in low-resource scenarios.]]></description>
<pubDate>Mon, 26 Jan 2026 17:10:17 +0000</pubDate>
</item>
<item>
<title><![CDATA[A Pragmatic VLA Foundation Model]]></title>
<link>http://arxiv.org/abs/2601.18692v1</link>
<guid>2601.18692v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.RO, cs.CV
Authors: Wei Wu, Fan Lu, Yunnan Wang, Shuai Yang, Shi Liu et al.
Institution: 
Published: 2026-01-26
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Offering great potential in robotic manipulation, a capable Vision-Language-Action (VLA) foundation model is expected to faithfully generalize across tasks and platforms while ensuring cost efficiency (e.g., data and GPU hours required for adaptation). To this end, we develop LingBot-VLA with around 20,000 hours of real-world data from 9 popular dual-arm robot configurations. Through a systematic assessment on 3 robotic platforms, each completing 100 tasks with 130 post-training episodes per task, our model achieves clear superiority over competitors, showcasing its strong performance and broad generalizability. We have also built an efficient codebase, which delivers a throughput of 261 samples per second per GPU with an 8-GPU training setup, representing a 1.5~2.8$\times$ (depending on the relied VLM base model) speedup over existing VLA-oriented codebases. The above features ensure that our model is well-suited for real-world deployment. To advance the field of robot learning, we provide open access to the code, base model, and benchmark data, with a focus on enabling more challenging tasks and promoting sound evaluation standards.]]></description>
<pubDate>Mon, 26 Jan 2026 17:08:04 +0000</pubDate>
</item>
<item>
<title><![CDATA[LLAMA LIMA: A Living Meta-Analysis on the Effects of Generative AI on Learning Mathematics]]></title>
<link>http://arxiv.org/abs/2601.18685v1</link>
<guid>2601.18685v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.LG
Authors: Anselm Strohmaier, Samira Bdefeld, Frank Reinhold
Institution: 
Published: 2026-01-26
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

The capabilities of generative AI in mathematics education are rapidly evolving, posing significant challenges for research to keep pace. Research syntheses remain scarce and risk being outdated by the time of publication. To address this issue, we present a Living Meta-Analysis (LIMA) on the effects of generative AI-based interventions for learning mathematics. Following PRISMA-LSR guidelines, we continuously update the literature base, apply a Bayesian multilevel meta-regression model to account for cumulative data, and publish updated versions on a preprint server at regular intervals. This paper reports results from the first version, including 15 studies. The analyses indicate a small positive effect (g = 0.31) with a wide credible interval [0.06, 0.58], reflecting the still limited evidence base.]]></description>
<pubDate>Mon, 26 Jan 2026 17:00:52 +0000</pubDate>
</item>
<item>
<title><![CDATA[Learned harmonic mean estimation of the marginal likelihood for multimodal posteriors with flow matching]]></title>
<link>http://arxiv.org/abs/2601.18683v1</link>
<guid>2601.18683v1</guid>
<description><![CDATA[Source: arXiv
Tags: stat.ME, cs.LG
Authors: Alicja Polanska, Jason D. McEwen
Institution: 
Published: 2026-01-26
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

The marginal likelihood, or Bayesian evidence, is a crucial quantity for Bayesian model comparison but its computation can be challenging for complex models, even in parameters space of moderate dimension. The learned harmonic mean estimator has been shown to provide accurate and robust estimates of the marginal likelihood simply using posterior samples. It is agnostic to the sampling strategy, meaning that the samples can be obtained using any method. This enables marginal likelihood calculation and model comparison with whatever sampling is most suitable for the task. However, the internal density estimators considered previously for the learned harmonic mean can struggle with highly multimodal posteriors. In this work we introduce flow matching-based continuous normalizing flows as a powerful architecture for the internal density estimation of the learned harmonic mean. We demonstrate the ability to handle challenging multimodal posteriors, including an example in 20 parameter dimensions, showcasing the method's ability to handle complex posteriors without the need for fine-tuning or heuristic modifications to the base distribution.]]></description>
<pubDate>Mon, 26 Jan 2026 17:00:08 +0000</pubDate>
</item>
<item>
<title><![CDATA[ART for Diffusion Sampling: A Reinforcement Learning Approach to Timestep Schedule]]></title>
<link>http://arxiv.org/abs/2601.18681v1</link>
<guid>2601.18681v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.LG, cs.AI
Authors: Yilie Huang, Wenpin Tang, Xunyu Zhou
Institution: 
Published: 2026-01-26
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

We consider time discretization for score-based diffusion models to generate samples from a learned reverse-time dynamic on a finite grid. Uniform and hand-crafted grids can be suboptimal given a budget on the number of time steps. We introduce Adaptive Reparameterized Time (ART) that controls the clock speed of a reparameterized time variable, leading to a time change and uneven timesteps along the sampling trajectory while preserving the terminal time. The objective is to minimize the aggregate error arising from the discretized Euler scheme. We derive a randomized control companion, ART-RL, and formulate time change as a continuous-time reinforcement learning (RL) problem with Gaussian policies. We then prove that solving ART-RL recovers the optimal ART schedule, which in turn enables practical actor--critic updates to learn the latter in a data-driven way. Empirically, based on the official EDM pipeline, ART-RL improves Frchet Inception Distance on CIFAR-10 over a wide range of budgets and transfers to AFHQv2, FFHQ, and ImageNet without the need of retraining.]]></description>
<pubDate>Mon, 26 Jan 2026 16:56:40 +0000</pubDate>
</item>
<item>
<title><![CDATA[Counterfactual Explanations on Robust Perceptual Geodesics]]></title>
<link>http://arxiv.org/abs/2601.18678v1</link>
<guid>2601.18678v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.LG, cs.CV, cs.HC
Authors: Eslam Zaher, Maciej Trzaskowski, Quan Nguyen, Fred Roosta
Institution: 
Published: 2026-01-26
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Latent-space optimization methods for counterfactual explanations - framed as minimal semantic perturbations that change model predictions - inherit the ambiguity of Wachter et al.'s objective: the choice of distance metric dictates whether perturbations are meaningful or adversarial. Existing approaches adopt flat or misaligned geometries, leading to off-manifold artifacts, semantic drift, or adversarial collapse. We introduce Perceptual Counterfactual Geodesics (PCG), a method that constructs counterfactuals by tracing geodesics under a perceptually Riemannian metric induced from robust vision features. This geometry aligns with human perception and penalizes brittle directions, enabling smooth, on-manifold, semantically valid transitions. Experiments on three vision datasets show that PCG outperforms baselines and reveals failure modes hidden under standard metrics.]]></description>
<pubDate>Mon, 26 Jan 2026 16:52:54 +0000</pubDate>
</item>
<item>
<title><![CDATA[Out-of-Distribution Radar Detection with Complex VAEs: Theory, Whitening, and ANMF Fusion]]></title>
<link>http://arxiv.org/abs/2601.18677v1</link>
<guid>2601.18677v1</guid>
<description><![CDATA[Source: arXiv
Tags: stat.ML, cs.LG
Authors: Yadang Alexis Rouzoumka, Jean Pinsolle, Eugnie Terreaux, Christle Morisseau, Jean-Philippe Ovarlez et al.
Institution: 
Published: 2026-01-26
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

We investigate the detection of weak complex-valued signals immersed in non-Gaussian, range-varying interference, with emphasis on maritime radar scenarios. The proposed methodology exploits a Complex-valued Variational AutoEncoder (CVAE) trained exclusively on clutter-plus-noise to perform Out-Of-Distribution detection. By operating directly on in-phase / quadrature samples, the CVAE preserves phase and Doppler structure and is assessed in two configurations: (i) using unprocessed range profiles and (ii) after local whitening, where per-range covariance estimates are obtained from neighboring profiles. Using extensive simulations together with real sea-clutter data from the CSIR maritime dataset, we benchmark performance against classical and adaptive detectors (MF, NMF, AMF-SCM, ANMF-SCM, ANMF-Tyler). In both configurations, the CVAE yields a higher detection probability Pd at matched false-alarm rate Pfa, with the most notable improvements observed under whitening. We further integrate the CVAE with the ANMF through a weighted log-p fusion rule at the decision level, attaining enhanced robustness in strongly non-Gaussian clutter and enabling empirically calibrated Pfa control under H0. Overall, the results demonstrate that statistical normalization combined with complex-valued generative modeling substantively improves detection in realistic sea-clutter conditions, and that the fused CVAE-ANMF scheme constitutes a competitive alternative to established model-based detectors.]]></description>
<pubDate>Mon, 26 Jan 2026 16:51:19 +0000</pubDate>
</item>
<item>
<title><![CDATA[Quasi Monte Carlo methods enable extremely low-dimensional deep generative models]]></title>
<link>http://arxiv.org/abs/2601.18676v1</link>
<guid>2601.18676v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.LG
Authors: Miles Martinez, Alex H. Williams
Institution: 
Published: 2026-01-26
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

This paper introduces quasi-Monte Carlo latent variable models (QLVMs): a class of deep generative models that are specialized for finding extremely low-dimensional and interpretable embeddings of high-dimensional datasets. Unlike standard approaches, which rely on a learned encoder and variational lower bounds, QLVMs directly approximate the marginal likelihood by randomized quasi-Monte Carlo integration. While this brute force approach has drawbacks in higher-dimensional spaces, we find that it excels in fitting one, two, and three dimensional deep latent variable models. Empirical results on a range of datasets show that QLVMs consistently outperform conventional variational autoencoders (VAEs) and importance weighted autoencoders (IWAEs) with matched latent dimensionality. The resulting embeddings enable transparent visualization and post hoc analyses such as nonparametric density estimation, clustering, and geodesic path computation, which are nontrivial to validate in higher-dimensional spaces. While our approach is compute-intensive and struggles to generate fine-scale details in complex datasets, it offers a compelling solution for applications prioritizing interpretability and latent space analysis.]]></description>
<pubDate>Mon, 26 Jan 2026 16:51:03 +0000</pubDate>
</item>
<item>
<title><![CDATA[Learning temporal embeddings from electronic health records of chronic kidney disease patients]]></title>
<link>http://arxiv.org/abs/2601.18675v1</link>
<guid>2601.18675v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.LG, cs.AI
Authors: Aditya Kumar, Mario A. Cypko, Oliver Amft
Institution: 
Published: 2026-01-26
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

We investigate whether temporal embedding models trained on longitudinal electronic health records can learn clinically meaningful representations without compromising predictive performance, and how architectural choices affect embedding quality. Model-guided medicine requires representations that capture disease dynamics while remaining transparent and task agnostic, whereas most clinical prediction models are optimised for a single task. Representation learning facilitates learning embeddings that generalise across downstream tasks, and recurrent architectures are well-suited for modelling temporal structure in observational clinical data. Using the MIMIC-IV dataset, we study patients with chronic kidney disease (CKD) and compare three recurrent architectures: a vanilla LSTM, an attention-augmented LSTM, and a time-aware LSTM (T-LSTM). All models are trained both as embedding models and as direct end-to-end predictors. Embedding quality is evaluated via CKD stage clustering and in-ICU mortality prediction. The T-LSTM produces more structured embeddings, achieving a lower Davies-Bouldin Index (DBI = 9.91) and higher CKD stage classification accuracy (0.74) than the vanilla LSTM (DBI = 15.85, accuracy = 0.63) and attention-augmented LSTM (DBI = 20.72, accuracy = 0.67). For in-ICU mortality prediction, embedding models consistently outperform end-to-end predictors, improving accuracy from 0.72-0.75 to 0.82-0.83, which indicates that learning embeddings as an intermediate step is more effective than direct end-to-end learning.]]></description>
<pubDate>Mon, 26 Jan 2026 16:50:50 +0000</pubDate>
</item>
<item>
<title><![CDATA[A Dynamic Framework for Grid Adaptation in Kolmogorov-Arnold Networks]]></title>
<link>http://arxiv.org/abs/2601.18672v1</link>
<guid>2601.18672v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.LG
Authors: Spyros Rigas, Thanasis Papaioannou, Panagiotis Trakadas, Georgios Alexandridis
Institution: 
Published: 2026-01-26
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Kolmogorov-Arnold Networks (KANs) have recently demonstrated promising potential in scientific machine learning, partly due to their capacity for grid adaptation during training. However, existing adaptation strategies rely solely on input data density, failing to account for the geometric complexity of the target function or metrics calculated during network training. In this work, we propose a generalized framework that treats knot allocation as a density estimation task governed by Importance Density Functions (IDFs), allowing training dynamics to determine grid resolution. We introduce a curvature-based adaptation strategy and evaluate it across synthetic function fitting, regression on a subset of the Feynman dataset and different instances of the Helmholtz PDE, demonstrating that it significantly outperforms the standard input-based baseline. Specifically, our method yields average relative error reductions of 25.3% on synthetic functions, 9.4% on the Feynman dataset, and 23.3% on the PDE benchmark. Statistical significance is confirmed via Wilcoxon signed-rank tests, establishing curvature-based adaptation as a robust and computationally efficient alternative for KAN training.]]></description>
<pubDate>Mon, 26 Jan 2026 16:49:06 +0000</pubDate>
</item>
<item>
<title><![CDATA[Uniform Computability of PAC Learning]]></title>
<link>http://arxiv.org/abs/2601.18663v1</link>
<guid>2601.18663v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.LG, cs.LO
Authors: Vasco Brattka, Guillaume Chirache
Institution: 
Published: 2026-01-26
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

We study uniform computability properties of PAC learning using Weihrauch complexity. We focus on closed concept classes, which are either represented by positive, by negative or by full information. Among other results, we prove that proper PAC learning from positive information is equivalent to the limit operation on Baire space, whereas improper PAC learning from positive information is closely related to Weak Knig's Lemma and even equivalent to it, when we have some negative information about the admissible hypotheses. If arbitrary hypotheses are allowed, then improper PAC learning from positive information is still in a finitary DNC range, which implies that it is non-deterministically computable, but does not allow for probabilistic algorithms. These results can also be seen as a classification of the degree of constructivity of the Fundamental Theorem of Statistical Learning. All the aforementioned results hold if an upper bound of the VC dimension is provided as an additional input information. We also study the question of how these results are affected if the VC dimension is not given, but only promised to be finite or if concept classes are represented by negative or full information. Finally, we also classify the complexity of the VC dimension operation itself, which is a problem that is of independent interest. For positive or full information it turns out to be equivalent to the binary sorting problem, for negative information it is equivalent to the jump of sorting. This classification allows also conclusions regarding the Borel complexity of PAC learnability.]]></description>
<pubDate>Mon, 26 Jan 2026 16:39:38 +0000</pubDate>
</item>
<item>
<title><![CDATA[Contrasting Global and Patient-Specific Regression Models via a Neural Network Representation]]></title>
<link>http://arxiv.org/abs/2601.18658v1</link>
<guid>2601.18658v1</guid>
<description><![CDATA[Source: arXiv
Tags: stat.ME, stat.ML
Authors: Max Behrens, Daiana Stolz, Eleni Papakonstantinou, Janis M. Nolde, Gabriele Bellerino et al.
Institution: 
Published: 2026-01-26
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

When developing clinical prediction models, it can be challenging to balance between global models that are valid for all patients and personalized models tailored to individuals or potentially unknown subgroups. To aid such decisions, we propose a diagnostic tool for contrasting global regression models and patient-specific (local) regression models. The core utility of this tool is to identify where and for whom a global model may be inadequate. We focus on regression models and specifically suggest a localized regression approach that identifies regions in the predictor space where patients are not well represented by the global model. As localization becomes challenging when dealing with many predictors, we propose modeling in a dimension-reduced latent representation obtained from an autoencoder. Using such a neural network architecture for dimension reduction enables learning a latent representation simultaneously optimized for both good data reconstruction and for revealing local outcome-related associations suitable for robust localized regression. We illustrate the proposed approach with a clinical study involving patients with chronic obstructive pulmonary disease. Our findings indicate that the global model is adequate for most patients but that indeed specific subgroups benefit from personalized models. We also demonstrate how to map these subgroup models back to the original predictors, providing insight into why the global model falls short for these groups. Thus, the principal application and diagnostic yield of our tool is the identification and characterization of patients or subgroups whose outcome associations deviate from the global model.]]></description>
<pubDate>Mon, 26 Jan 2026 16:34:43 +0000</pubDate>
</item>
<item>
<title><![CDATA[FaLW: A Forgetting-aware Loss Reweighting for Long-tailed Unlearning]]></title>
<link>http://arxiv.org/abs/2601.18650v1</link>
<guid>2601.18650v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.LG, cs.AI
Authors: Liheng Yu, Zhe Zhao, Yuxuan Wang, Pengkun Wang, Binwu Wang et al.
Institution: 
Published: 2026-01-26
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Machine unlearning, which aims to efficiently remove the influence of specific data from trained models, is crucial for upholding data privacy regulations like the ``right to be forgotten". However, existing research predominantly evaluates unlearning methods on relatively balanced forget sets. This overlooks a common real-world scenario where data to be forgotten, such as a user's activity records, follows a long-tailed distribution. Our work is the first to investigate this critical research gap. We find that in such long-tailed settings, existing methods suffer from two key issues: \textit{Heterogeneous Unlearning Deviation} and \textit{Skewed Unlearning Deviation}. To address these challenges, we propose FaLW, a plug-and-play, instance-wise dynamic loss reweighting method. FaLW innovatively assesses the unlearning state of each sample by comparing its predictive probability to the distribution of unseen data from the same class. Based on this, it uses a forgetting-aware reweighting scheme, modulated by a balancing factor, to adaptively adjust the unlearning intensity for each sample. Extensive experiments demonstrate that FaLW achieves superior performance. Code is available at \textbf{Supplementary Material}.]]></description>
<pubDate>Mon, 26 Jan 2026 16:21:01 +0000</pubDate>
</item>
<item>
<title><![CDATA[FadeMem: Biologically-Inspired Forgetting for Efficient Agent Memory]]></title>
<link>http://arxiv.org/abs/2601.18642v1</link>
<guid>2601.18642v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.AI, cs.CL
Authors: Lei Wei, Xu Dong, Xiao Peng, Niantao Xie, Bin Wang
Institution: 
Published: 2026-01-26
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Large language models deployed as autonomous agents face critical memory limitations, lacking selective forgetting mechanisms that lead to either catastrophic forgetting at context boundaries or information overload within them. While human memory naturally balances retention and forgetting through adaptive decay processes, current AI systems employ binary retention strategies that preserve everything or lose it entirely. We propose FadeMem, a biologically-inspired agent memory architecture that incorporates active forgetting mechanisms mirroring human cognitive efficiency. FadeMem implements differential decay rates across a dual-layer memory hierarchy, where retention is governed by adaptive exponential decay functions modulated by semantic relevance, access frequency, and temporal patterns. Through LLM-guided conflict resolution and intelligent memory fusion, our system consolidates related information while allowing irrelevant details to fade. Experiments on Multi-Session Chat, LoCoMo, and LTI-Bench demonstrate superior multi-hop reasoning and retrieval with 45\% storage reduction, validating the effectiveness of biologically-inspired forgetting in agent memory systems.]]></description>
<pubDate>Mon, 26 Jan 2026 16:12:54 +0000</pubDate>
</item>
<item>
<title><![CDATA[Unheard in the Digital Age: Rethinking AI Bias and Speech Diversity]]></title>
<link>http://arxiv.org/abs/2601.18641v1</link>
<guid>2601.18641v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.HC, cs.AI, cs.CY
Authors: Onyedikachi Hope Amaechi-Okorie, Branislav Radeljic
Institution: 
Published: 2026-01-26
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Speech remains one of the most visible yet overlooked vectors of inclusion and exclusion in contemporary society. While fluency is often equated with credibility and competence, individuals with atypical speech patterns are routinely marginalized. Given the current state of the debate, this article focuses on the structural biases that shape perceptions of atypical speech and are now being encoded into artificial intelligence. Automated speech recognition (ASR) systems and voice interfaces, trained predominantly on standardized speech, routinely fail to recognize or respond to diverse voices, compounding digital exclusion. As AI technologies increasingly mediate access to opportunity, the study calls for inclusive technological design, anti-bias training to minimize the impact of discriminatory algorithmic decisions, and enforceable policy reform that explicitly recognize speech diversity as a matter of equity, not merely accessibility. Drawing on interdisciplinary research, the article advocates for a cultural and institutional shift in how we value voice, urging co-created solutions that elevate the rights, representation, and realities of atypical speakers in the digital age. Ultimately, the article reframes speech inclusion as a matter of equity (not accommodation) and advocates for co-created AI systems that reflect the full spectrum of human voices.]]></description>
<pubDate>Mon, 26 Jan 2026 16:12:25 +0000</pubDate>
</item>
<item>
<title><![CDATA[TwinPurify: Purifying gene expression data to reveal tumor-intrinsic transcriptional programs via self-supervised learning]]></title>
<link>http://arxiv.org/abs/2601.18640v1</link>
<guid>2601.18640v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.LG
Authors: Zhiwei Zheng, Kevin Bryson
Institution: 
Published: 2026-01-26
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Advances in single-cell and spatial transcriptomic technologies have transformed tumor ecosystem profiling at cellular resolution. However, large scale studies on patient cohorts continue to rely on bulk transcriptomic data, where variation in tumor purity obscures tumor-intrinsic transcriptional signals and constrains downstream discovery. Many deconvolution methods report strong performance on synthetic bulk mixtures but fail to generalize to real patient cohorts because of unmodeled biological and technical variation.
  Here, we introduce TwinPurify, a representation learning framework that adapts the Barlow Twins self-supervised objective, representing a fundamental departure from the deconvolution paradigm. Rather than resolving the bulk mixture into discrete cell-type fractions, TwinPurify instead learns continuous, high-dimensional tumor embeddings by leveraging adjacent-normal profiles within the same cohort as "background" guidance, enabling the disentanglement of tumor-specific signals without relying on any external reference.
  Benchmarked against multiple large cancer cohorts across RNA-seq and microarray platforms, TwinPurify outperforms conventional representation learning baselines like auto-encoders in recovering tumor-intrinsic and immune signals. The purified embeddings improve molecular subtype and grade classification, enhance survival model concordance, and uncover biologically meaningful pathway activities compared to raw bulk profiles. By providing a transferable framework for decontaminating bulk transcriptomics, TwinPurify extends the utility of existing clinical datasets for molecular discovery.]]></description>
<pubDate>Mon, 26 Jan 2026 16:11:34 +0000</pubDate>
</item>
<item>
<title><![CDATA[Physics-Informed Uncertainty Enables Reliable AI-driven Design]]></title>
<link>http://arxiv.org/abs/2601.18638v1</link>
<guid>2601.18638v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.LG
Authors: Tingkai Xue, Chin Chun Ooi, Yang Jiang, Luu Trung Pham Duong, Pao-Hsiung Chiu et al.
Institution: 
Published: 2026-01-26
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Inverse design is a central goal in much of science and engineering, including frequency-selective surfaces (FSS) that are critical to microelectronics for telecommunications and optical metamaterials. Traditional surrogate-assisted optimization methods using deep learning can accelerate the design process but do not usually incorporate uncertainty quantification, leading to poorer optimization performance due to erroneous predictions in data-sparse regions. Here, we introduce and validate a fundamentally different paradigm of Physics-Informed Uncertainty, where the degree to which a model's prediction violates fundamental physical laws serves as a computationally-cheap and effective proxy for predictive uncertainty. By integrating physics-informed uncertainty into a multi-fidelity uncertainty-aware optimization workflow to design complex frequency-selective surfaces within the 20 - 30 GHz range, we increase the success rate of finding performant solutions from less than 10% to over 50%, while simultaneously reducing computational cost by an order of magnitude compared to the sole use of a high-fidelity solver. These results highlight the necessity of incorporating uncertainty quantification in machine-learning-driven inverse design for high-dimensional problems, and establish physics-informed uncertainty as a viable alternative to quantifying uncertainty in surrogate models for physical systems, thereby setting the stage for autonomous scientific discovery systems that can efficiently and robustly explore and evaluate candidate designs.]]></description>
<pubDate>Mon, 26 Jan 2026 16:10:59 +0000</pubDate>
</item>
<item>
<title><![CDATA[Universality of Many-body Projected Ensemble for Learning Quantum Data Distribution]]></title>
<link>http://arxiv.org/abs/2601.18637v1</link>
<guid>2601.18637v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.LG, stat.ML
Authors: Quoc Hoan Tran, Koki Chinzei, Yasuhiro Endo, Hirotaka Oshima
Institution: 
Published: 2026-01-26
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Generating quantum data by learning the underlying quantum distribution poses challenges in both theoretical and practical scenarios, yet it is a critical task for understanding quantum systems. A fundamental question in quantum machine learning (QML) is the universality of approximation: whether a parameterized QML model can approximate any quantum distribution. We address this question by proving a universality theorem for the Many-body Projected Ensemble (MPE) framework, a method for quantum state design that uses a single many-body wave function to prepare random states. This demonstrates that MPE can approximate any distribution of pure states within a 1-Wasserstein distance error. This theorem provides a rigorous guarantee of universal expressivity, addressing key theoretical gaps in QML. For practicality, we propose an Incremental MPE variant with layer-wise training to improve the trainability. Numerical experiments on clustered quantum states and quantum chemistry datasets validate MPE's efficacy in learning complex quantum data distributions.]]></description>
<pubDate>Mon, 26 Jan 2026 16:10:32 +0000</pubDate>
</item>
<item>
<title><![CDATA[Splat-Portrait: Generalizing Talking Heads with Gaussian Splatting]]></title>
<link>http://arxiv.org/abs/2601.18633v1</link>
<guid>2601.18633v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.CV
Authors: Tong Shi, Melonie de Almeida, Daniela Ivanova, Nicolas Pugeault, Paul Henderson
Institution: 
Published: 2026-01-26
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Talking Head Generation aims at synthesizing natural-looking talking videos from speech and a single portrait image. Previous 3D talking head generation methods have relied on domain-specific heuristics such as warping-based facial motion representation priors to animate talking motions, yet still produce inaccurate 3D avatar reconstructions, thus undermining the realism of generated animations. We introduce Splat-Portrait, a Gaussian-splatting-based method that addresses the challenges of 3D head reconstruction and lip motion synthesis. Our approach automatically learns to disentangle a single portrait image into a static 3D reconstruction represented as static Gaussian Splatting, and a predicted whole-image 2D background. It then generates natural lip motion conditioned on input audio, without any motion driven priors. Training is driven purely by 2D reconstruction and score-distillation losses, without 3D supervision nor landmarks. Experimental results demonstrate that Splat-Portrait exhibits superior performance on talking head generation and novel view synthesis, achieving better visual quality compared to previous works. Our project code and supplementary documents are public available at https://github.com/stonewalking/Splat-portrait.]]></description>
<pubDate>Mon, 26 Jan 2026 16:06:57 +0000</pubDate>
</item>
<item>
<title><![CDATA[AdaReasoner: Dynamic Tool Orchestration for Iterative Visual Reasoning]]></title>
<link>http://arxiv.org/abs/2601.18631v1</link>
<guid>2601.18631v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.AI, cs.CL, cs.CV, cs.MA
Authors: Mingyang Song, Haoyu Sun, Jiawei Gu, Linjie Li, Luxin Xu et al.
Institution: 
Published: 2026-01-26
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

When humans face problems beyond their immediate capabilities, they rely on tools, providing a promising paradigm for improving visual reasoning in multimodal large language models (MLLMs). Effective reasoning, therefore, hinges on knowing which tools to use, when to invoke them, and how to compose them over multiple steps, even when faced with new tools or new tasks. We introduce \textbf{AdaReasoner}, a family of multimodal models that learn tool use as a general reasoning skill rather than as tool-specific or explicitly supervised behavior. AdaReasoner is enabled by (i) a scalable data curation pipeline exposing models to long-horizon, multi-step tool interactions; (ii) Tool-GRPO, a reinforcement learning algorithm that optimizes tool selection and sequencing based on end-task success; and (iii) an adaptive learning mechanism that dynamically regulates tool usage. Together, these components allow models to infer tool utility from task context and intermediate outcomes, enabling coordination of multiple tools and generalization to unseen tools. Empirically, AdaReasoner exhibits strong tool-adaptive and generalization behaviors: it autonomously adopts beneficial tools, suppresses irrelevant ones, and adjusts tool usage frequency based on task demands, despite never being explicitly trained to do so. These capabilities translate into state-of-the-art performance across challenging benchmarks, improving the 7B base model by +24.9\% on average and surpassing strong proprietary systems such as GPT-5 on multiple tasks, including VSP and Jigsaw.]]></description>
<pubDate>Mon, 26 Jan 2026 16:04:43 +0000</pubDate>
</item>
<item>
<title><![CDATA[Assessing the Quality of Mental Health Support in LLM Responses through Multi-Attribute Human Evaluation]]></title>
<link>http://arxiv.org/abs/2601.18630v1</link>
<guid>2601.18630v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.AI, cs.HC
Authors: Abeer Badawi, Md Tahmid Rahman Laskar, Elahe Rahimi, Sheri Grach, Lindsay Bertrand et al.
Institution: 
Published: 2026-01-26
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

The escalating global mental health crisis, marked by persistent treatment gaps, availability, and a shortage of qualified therapists, positions Large Language Models (LLMs) as a promising avenue for scalable support. While LLMs offer potential for accessible emotional assistance, their reliability, therapeutic relevance, and alignment with human standards remain challenging to address. This paper introduces a human-grounded evaluation methodology designed to assess LLM generated responses in therapeutic dialogue. Our approach involved curating a dataset of 500 mental health conversations from datasets with real-world scenario questions and evaluating the responses generated by nine diverse LLMs, including closed source and open source models. More specifically, these responses were evaluated by two psychiatric trained experts, who independently rated each on a 5 point Likert scale across a comprehensive 6 attribute rubric. This rubric captures Cognitive Support and Affective Resonance, providing a multidimensional perspective on therapeutic quality. Our analysis reveals that LLMs provide strong cognitive reliability by producing safe, coherent, and clinically appropriate information, but they demonstrate unstable affective alignment. Although closed source models (e.g., GPT-4o) offer balanced therapeutic responses, open source models show greater variability and emotional flatness. We reveal a persistent cognitive-affective gap and highlight the need for failure aware, clinically grounded evaluation frameworks that prioritize relational sensitivity alongside informational accuracy in mental health oriented LLMs. We advocate for balanced evaluation protocols with human in the loop that center on therapeutic sensitivity and provide a framework to guide the responsible design and clinical oversight of mental health oriented conversational AI.]]></description>
<pubDate>Mon, 26 Jan 2026 16:04:19 +0000</pubDate>
</item>
<item>
<title><![CDATA[Rank-1 Approximation of Inverse Fisher for Natural Policy Gradients in Deep Reinforcement Learning]]></title>
<link>http://arxiv.org/abs/2601.18626v1</link>
<guid>2601.18626v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.LG, cs.AI, stat.ML
Authors: Yingxiao Huo, Satya Prakash Dash, Radu Stoican, Samuel Kaski, Mingfei Sun
Institution: 
Published: 2026-01-26
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Natural gradients have long been studied in deep reinforcement learning due to their fast convergence properties and covariant weight updates. However, computing natural gradients requires inversion of the Fisher Information Matrix (FIM) at each iteration, which is computationally prohibitive in nature. In this paper, we present an efficient and scalable natural policy optimization technique that leverages a rank-1 approximation to full inverse-FIM. We theoretically show that under certain conditions, a rank-1 approximation to inverse-FIM converges faster than policy gradients and, under some conditions, enjoys the same sample complexity as stochastic policy gradient methods. We benchmark our method on a diverse set of environments and show that it achieves superior performance to standard actor-critic and trust-region baselines.]]></description>
<pubDate>Mon, 26 Jan 2026 16:02:18 +0000</pubDate>
</item>
<item>
<title><![CDATA[CONQUER: Context-Aware Representation with Query Enhancement for Text-Based Person Search]]></title>
<link>http://arxiv.org/abs/2601.18625v1</link>
<guid>2601.18625v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.CV
Authors: Zequn Xie
Institution: 
Published: 2026-01-26
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Text-Based Person Search (TBPS) aims to retrieve pedestrian images from large galleries using natural language descriptions. This task, essential for public safety applications, is hindered by cross-modal discrepancies and ambiguous user queries. We introduce CONQUER, a two-stage framework designed to address these challenges by enhancing cross-modal alignment during training and adaptively refining queries at inference. During training, CONQUER employs multi-granularity encoding, complementary pair mining, and context-guided optimal matching based on Optimal Transport to learn robust embeddings. At inference, a plug-and-play query enhancement module refines vague or incomplete queries via anchor selection and attribute-driven enrichment, without requiring retraining of the backbone. Extensive experiments on CUHK-PEDES, ICFG-PEDES, and RSTPReid demonstrate that CONQUER consistently outperforms strong baselines in both Rank-1 accuracy and mAP, yielding notable improvements in cross-domain and incomplete-query scenarios. These results highlight CONQUER as a practical and effective solution for real-world TBPS deployment. Source code is available at https://github.com/zqxie77/CONQUER.]]></description>
<pubDate>Mon, 26 Jan 2026 16:01:33 +0000</pubDate>
</item>
<item>
<title><![CDATA[Adaptive Domain Shift in Diffusion Models for Cross-Modality Image Translation]]></title>
<link>http://arxiv.org/abs/2601.18623v1</link>
<guid>2601.18623v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.CV
Authors: Zihao Wang, Yuzhou Chen, Shaogang Ren
Institution: 
Published: 2026-01-26
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Cross-modal image translation remains brittle and inefficient. Standard diffusion approaches often rely on a single, global linear transfer between domains. We find that this shortcut forces the sampler to traverse off-manifold, high-cost regions, inflating the correction burden and inviting semantic drift. We refer to this shared failure mode as fixed-schedule domain transfer. In this paper, we embed domain-shift dynamics directly into the generative process. Our model predicts a spatially varying mixing field at every reverse step and injects an explicit, target-consistent restoration term into the drift. This in-step guidance keeps large updates on-manifold and shifts the model's role from global alignment to local residual correction. We provide a continuous-time formulation with an exact solution form and derive a practical first-order sampler that preserves marginal consistency. Empirically, across translation tasks in medical imaging, remote sensing, and electroluminescence semantic mapping, our framework improves structural fidelity and semantic consistency while converging in fewer denoising steps.]]></description>
<pubDate>Mon, 26 Jan 2026 16:00:36 +0000</pubDate>
</item>
<item>
<title><![CDATA[CASSANDRA: Programmatic and Probabilistic Learning and Inference for Stochastic World Modeling]]></title>
<link>http://arxiv.org/abs/2601.18620v1</link>
<guid>2601.18620v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.LG
Authors: Panagiotis Lymperopoulos, Abhiramon Rajasekharan, Ian Berlot-Attwell, Stphane Aroca-Ouellette, Kaheer Suleman
Institution: 
Published: 2026-01-26
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Building world models is essential for planning in real-world domains such as businesses. Since such domains have rich semantics, we can leverage world knowledge to effectively model complex action effects and causal relationships from limited data. In this work, we propose CASSANDRA, a neurosymbolic world modeling approach that leverages an LLM as a knowledge prior to construct lightweight transition models for planning. CASSANDRA integrates two components: (1) LLM-synthesized code to model deterministic features, and (2) LLM-guided structure learning of a probabilistic graphical model to capture causal relationships among stochastic variables. We evaluate CASSANDRA in (i) a small-scale coffee-shop simulator and (ii) a complex theme park business simulator, where we demonstrate significant improvements in transition prediction and planning over baselines.]]></description>
<pubDate>Mon, 26 Jan 2026 15:58:53 +0000</pubDate>
</item>
<item>
<title><![CDATA[Scale-Aware Self-Supervised Learning for Segmentation of Small and Sparse Structures]]></title>
<link>http://arxiv.org/abs/2601.18619v1</link>
<guid>2601.18619v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.CV
Authors: Jorge Quesada, Ghassan AlRegib
Institution: 
Published: 2026-01-26
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Self-supervised learning (SSL) has emerged as a powerful strategy for representation learning under limited annotation regimes, yet its effectiveness remains highly sensitive to many factors, especially the nature of the target task. In segmentation, existing pipelines are typically tuned to large, homogeneous regions, but their performance drops when objects are small, sparse, or locally irregular. In this work, we propose a scale-aware SSL adaptation that integrates small-window cropping into the augmentation pipeline, zooming in on fine-scale structures during pretraining. We evaluate this approach across two domains with markedly different data modalities: seismic imaging, where the goal is to segment sparse faults, and neuroimaging, where the task is to delineate small cellular structures. In both settings, our method yields consistent improvements over standard and state-of-the-art baselines under label constraints, improving accuracy by up to 13% for fault segmentation and 5% for cell delineation. In contrast, large-scale features such as seismic facies or tissue regions see little benefit, underscoring that the value of SSL depends critically on the scale of the target objects. Our findings highlight the need to align SSL design with object size and sparsity, offering a general principle for buil ding more effective representation learning pipelines across scientific imaging domains.]]></description>
<pubDate>Mon, 26 Jan 2026 15:58:04 +0000</pubDate>
</item>
<item>
<title><![CDATA[Emergence of Phonemic, Syntactic, and Semantic Representations in Artificial Neural Networks]]></title>
<link>http://arxiv.org/abs/2601.18617v1</link>
<guid>2601.18617v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.AI, cs.CL
Authors: Pierre Orhan, Pablo Diego-Simn, Emmnanuel Chemla, Yair Lakretz, Yves Boubenec et al.
Institution: 
Published: 2026-01-26
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

During language acquisition, children successively learn to categorize phonemes, identify words, and combine them with syntax to form new meaning. While the development of this behavior is well characterized, we still lack a unifying computational framework to explain its underlying neural representations. Here, we investigate whether and when phonemic, lexical, and syntactic representations emerge in the activations of artificial neural networks during their training. Our results show that both speech- and text-based models follow a sequence of learning stages: during training, their neural activations successively build subspaces, where the geometry of the neural activations represents phonemic, lexical, and syntactic structure. While this developmental trajectory qualitatively relates to children's, it is quantitatively different: These algorithms indeed require two to four orders of magnitude more data for these neural representations to emerge. Together, these results show conditions under which major stages of language acquisition spontaneously emerge, and hence delineate a promising path to understand the computations underpinning language acquisition.]]></description>
<pubDate>Mon, 26 Jan 2026 15:56:41 +0000</pubDate>
</item>
<item>
<title><![CDATA[Geometry-Free Conditional Diffusion Modeling for Solving the Inverse Electrocardiography Problem]]></title>
<link>http://arxiv.org/abs/2601.18615v1</link>
<guid>2601.18615v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.LG
Authors: Ramiro Valdes Jara, Adam Meyers
Institution: 
Published: 2026-01-26
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

This paper proposes a data-driven model for solving the inverse problem of electrocardiography, the mathematical problem that forms the basis of electrocardiographic imaging (ECGI). We present a conditional diffusion framework that learns a probabilistic mapping from noisy body surface signals to heart surface electric potentials. The proposed approach leverages the generative nature of diffusion models to capture the non-unique and underdetermined nature of the ECGI inverse problem, enabling probabilistic sampling of multiple reconstructions rather than a single deterministic estimate. Unlike traditional methods, the proposed framework is geometry-free and purely data-driven, alleviating the need for patient-specific mesh construction. We evaluate the method on a real ECGI dataset and compare it against strong deterministic baselines, including a convolutional neural network, long short-term memory network, and transformer-based model. The results demonstrate that the proposed diffusion approach achieves improved reconstruction accuracy, highlighting the potential of diffusion models as a robust tool for noninvasive cardiac electrophysiology imaging.]]></description>
<pubDate>Mon, 26 Jan 2026 15:53:54 +0000</pubDate>
</item>
<item>
<title><![CDATA[Multimodal Privacy-Preserving Entity Resolution with Fully Homomorphic Encryption]]></title>
<link>http://arxiv.org/abs/2601.18612v1</link>
<guid>2601.18612v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.CR, cs.CV
Authors: Susim Roy, Nalini Ratha
Institution: 
Published: 2026-01-26
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

The canonical challenge of entity resolution within high-compliance sectors, where secure identity reconciliation is frequently confounded by significant data heterogeneity, including syntactic variations in personal identifiers, is a longstanding and complex problem. To this end, we introduce a novel multimodal framework operating with the voluminous data sets typical of government and financial institutions. Specifically, our methodology is designed to address the tripartite challenge of data volume, matching fidelity, and privacy. Consequently, the underlying plaintext of personally identifiable information remains computationally inaccessible throughout the matching lifecycle, empowering institutions to rigorously satisfy stringent regulatory mandates with cryptographic assurances of client confidentiality while achieving a demonstrably low equal error rate and maintaining computational tractability at scale.]]></description>
<pubDate>Mon, 26 Jan 2026 15:53:04 +0000</pubDate>
</item>
<item>
<title><![CDATA[PolySHAP: Extending KernelSHAP with Interaction-Informed Polynomial Regression]]></title>
<link>http://arxiv.org/abs/2601.18608v1</link>
<guid>2601.18608v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.AI, cs.LG
Authors: Fabian Fumagalli, R. Teal Witter, Christopher Musco
Institution: 
Published: 2026-01-26
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Shapley values have emerged as a central game-theoretic tool in explainable AI (XAI). However, computing Shapley values exactly requires $2^d$ game evaluations for a model with $d$ features. Lundberg and Lee's KernelSHAP algorithm has emerged as a leading method for avoiding this exponential cost. KernelSHAP approximates Shapley values by approximating the game as a linear function, which is fit using a small number of game evaluations for random feature subsets.
  In this work, we extend KernelSHAP by approximating the game via higher degree polynomials, which capture non-linear interactions between features. Our resulting PolySHAP method yields empirically better Shapley value estimates for various benchmark datasets, and we prove that these estimates are consistent.
  Moreover, we connect our approach to paired sampling (antithetic sampling), a ubiquitous modification to KernelSHAP that improves empirical accuracy. We prove that paired sampling outputs exactly the same Shapley value approximations as second-order PolySHAP, without ever fitting a degree 2 polynomial. To the best of our knowledge, this finding provides the first strong theoretical justification for the excellent practical performance of the paired sampling heuristic.]]></description>
<pubDate>Mon, 26 Jan 2026 15:47:45 +0000</pubDate>
</item>
<item>
<title><![CDATA[LaCoGSEA: Unsupervised deep learning for pathway analysis via latent correlation]]></title>
<link>http://arxiv.org/abs/2601.18604v1</link>
<guid>2601.18604v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.LG
Authors: Zhiwei Zheng, Kevin Bryson
Institution: 
Published: 2026-01-26
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Motivation: Pathway enrichment analysis is widely used to interpret gene expression data. Standard approaches, such as GSEA, rely on predefined phenotypic labels and pairwise comparisons, which limits their applicability in unsupervised settings. Existing unsupervised extensions, including single-sample methods, provide pathway-level summaries but primarily capture linear relationships and do not explicitly model gene-pathway associations. More recently, deep learning models have been explored to capture non-linear transcriptomic structure. However, their interpretation has typically relied on generic explainable AI (XAI) techniques designed for feature-level attribution. As these methods are not designed for pathway-level interpretation in unsupervised transcriptomic analyses, their effectiveness in this setting remains limited.
  Results: To bridge this gap, we introduce LaCoGSEA (Latent Correlation GSEA), an unsupervised framework that integrates deep representation learning with robust pathway statistics. LaCoGSEA employs an autoencoder to capture non-linear manifolds and proposes a global gene-latent correlation metric as a proxy for differential expression, generating dense gene rankings without prior labels. We demonstrate that LaCoGSEA offers three key advantages: (i) it achieves improved clustering performance in distinguishing cancer subtypes compared to existing unsupervised baselines; (ii) it recovers a broader range of biologically meaningful pathways at higher ranks compared with linear dimensionality reduction and gradient-based XAI methods; and (iii) it maintains high robustness and consistency across varying experimental protocols and dataset sizes. Overall, LaCoGSEA provides state-of-the-art performance in unsupervised pathway enrichment analysis.
  Availability and implementation: https://github.com/willyzzz/LaCoGSEA]]></description>
<pubDate>Mon, 26 Jan 2026 15:45:33 +0000</pubDate>
</item>
<item>
<title><![CDATA[EFSI-DETR: Efficient Frequency-Semantic Integration for Real-Time Small Object Detection in UAV Imagery]]></title>
<link>http://arxiv.org/abs/2601.18597v1</link>
<guid>2601.18597v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.CV
Authors: Yu Xia, Chang Liu, Tianqi Xiang, Zhigang Tu
Institution: 
Published: 2026-01-26
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Real-time small object detection in Unmanned Aerial Vehicle (UAV) imagery remains challenging due to limited feature representation and ineffective multi-scale fusion. Existing methods underutilize frequency information and rely on static convolutional operations, which constrain the capacity to obtain rich feature representations and hinder the effective exploitation of deep semantic features. To address these issues, we propose EFSI-DETR, a novel detection framework that integrates efficient semantic feature enhancement with dynamic frequency-spatial guidance. EFSI-DETR comprises two main components: (1) a Dynamic Frequency-Spatial Unified Synergy Network (DyFusNet) that jointly exploits frequency and spatial cues for robust multi-scale feature fusion, (2) an Efficient Semantic Feature Concentrator (ESFC) that enables deep semantic extraction with minimal computational cost. Furthermore, a Fine-grained Feature Retention (FFR) strategy is adopted to incorporate spatially rich shallow features during fusion to preserve fine-grained details, crucial for small object detection in UAV imagery. Extensive experiments on VisDrone and CODrone benchmarks demonstrate that our EFSI-DETR achieves the state-of-the-art performance with real-time efficiency, yielding improvement of \textbf{1.6}\% and \textbf{5.8}\% in AP and AP$_{s}$ on VisDrone, while obtaining \textbf{188} FPS inference speed on a single RTX 4090 GPU.]]></description>
<pubDate>Mon, 26 Jan 2026 15:41:37 +0000</pubDate>
</item>
<item>
<title><![CDATA[A Balanced Neuro-Symbolic Approach for Commonsense Abductive Logic]]></title>
<link>http://arxiv.org/abs/2601.18595v1</link>
<guid>2601.18595v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.AI, cs.LG
Authors: Joseph Cotnareanu, Didier Chetelat, Yingxue Zhang, Mark Coates
Institution: 
Published: 2026-01-26
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Although Large Language Models (LLMs) have demonstrated impressive formal reasoning abilities, they often break down when problems require complex proof planning. One promising approach for improving LLM reasoning abilities involves translating problems into formal logic and using a logic solver. Although off-the-shelf logic solvers are in principle substantially more efficient than LLMs at logical reasoning, they assume that all relevant facts are provided in a question and are unable to deal with missing commonsense relations. In this work, we propose a novel method that uses feedback from the logic solver to augment a logic problem with commonsense relations provided by the LLM, in an iterative manner. This involves a search procedure through potential commonsense assumptions to maximize the chance of finding useful facts while keeping cost tractable. On a collection of pure-logical reasoning datasets, from which some commonsense information has been removed, our method consistently achieves considerable improvements over existing techniques, demonstrating the value in balancing neural and symbolic elements when working in human contexts.]]></description>
<pubDate>Mon, 26 Jan 2026 15:40:26 +0000</pubDate>
</item>
<item>
<title><![CDATA[Global Optimization of Atomic Clusters via Physically-Constrained Tensor Train Decomposition]]></title>
<link>http://arxiv.org/abs/2601.18592v1</link>
<guid>2601.18592v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.NE
Authors: Konstantin Sozykin, Nikita Rybin, Andrei Chertkov, Anh-Huy Phan, Ivan Oseledets et al.
Institution: 
Published: 2026-01-26
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

The global optimization of atomic clusters represents a fundamental challenge in computational chemistry and materials science due to the exponential growth of local minima with system size (i.e., the curse of dimensionality). We introduce a novel framework that overcomes this limitation by exploiting the low-rank structure of potential energy surfaces through Tensor Train (TT) decomposition. Our approach combines two complementary TT-based strategies: the algebraic TTOpt method, which utilizes maximum volume sampling, and the probabilistic PROTES method, which employs generative sampling. A key innovation is the development of physically-constrained encoding schemes that incorporate molecular constraints directly into the discretization process. We demonstrate the efficacy of our method by identifying global minima of Lennard-Jones clusters containing up to 45 atoms. Furthermore, we establish its practical applicability to real-world systems by optimizing 20-atom carbon clusters using a machine-learned Moment Tensor Potential, achieving geometries consistent with quantum-accurate simulations. This work establishes TT-decomposition as a powerful tool for molecular structure prediction and provides a general framework adaptable to a wide range of high-dimensional optimization problems in computational material science.]]></description>
<pubDate>Mon, 26 Jan 2026 15:38:20 +0000</pubDate>
</item>
<item>
<title><![CDATA[AGSP-DSA: An Adaptive Graph Signal Processing Framework for Robust Multimodal Fusion with Dynamic Semantic Alignment]]></title>
<link>http://arxiv.org/abs/2601.18589v1</link>
<guid>2601.18589v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.CV, cs.MM
Authors: KV Karthikeya, Ashok Kumar Das, Shantanu Pal, Vivekananda Bhat K, Arun Sekar Rajasekaran
Institution: 
Published: 2026-01-26
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

In this paper, we introduce an Adaptive Graph Signal Processing with Dynamic Semantic Alignment (AGSP DSA) framework to perform robust multimodal data fusion over heterogeneous sources, including text, audio, and images. The requested approach uses a dual-graph construction to learn both intra-modal and inter-modal relations, spectral graph filtering to boost the informative signals, and effective node embedding with Multi-scale Graph Convolutional Networks (GCNs). Semantic aware attention mechanism: each modality may dynamically contribute to the context with respect to contextual relevance. The experimental outcomes on three benchmark datasets, including CMU-MOSEI, AVE, and MM-IMDB, show that AGSP-DSA performs as the state of the art. More precisely, it achieves 95.3% accuracy, 0.936 F1-score, and 0.924 mAP on CMU-MOSEI, improving MM-GNN by 2.6 percent in accuracy. It gets 93.4% accuracy and 0.911 F1-score on AVE and 91.8% accuracy and 0.886 F1-score on MM-IMDB, which demonstrate good generalization and robustness in the missing modality setting. These findings verify the efficiency of AGSP-DSA in promoting multimodal learning in sentiment analysis, event recognition and multimedia classification.]]></description>
<pubDate>Mon, 26 Jan 2026 15:35:03 +0000</pubDate>
</item>
<item>
<title><![CDATA[Stability as a Liability:Systematic Breakdown of Linguistic Structure in LLMs]]></title>
<link>http://arxiv.org/abs/2601.18588v1</link>
<guid>2601.18588v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.AI, cs.CL, cs.LG
Authors: Xianzhe Meng, Qiangsheng Zeng, Ling Luo, Qinghan Yang, Jiarui Hao et al.
Institution: 
Published: 2026-01-26
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Training stability is typically regarded as a prerequisite for reliable optimization in large language models. In this work, we analyze how stabilizing training dynamics affects the induced generation distribution. We show that under standard maximum likelihood training, stable parameter trajectories lead stationary solutions to approximately minimize the forward KL divergence to the empirical distribution, while implicitly reducing generative entropy. As a consequence, the learned model can concentrate probability mass on a limited subset of empirical modes, exhibiting systematic degeneration despite smooth loss convergence. We empirically validate this effect using a controlled feedback-based training framework that stabilizes internal generation statistics, observing consistent low-entropy outputs and repetitive behavior across architectures and random seeds. It indicates that optimization stability and generative expressivity are not inherently aligned, and that stability alone is an insufficient indicator of generative quality.]]></description>
<pubDate>Mon, 26 Jan 2026 15:34:50 +0000</pubDate>
</item>
<item>
<title><![CDATA[Learning long term climate-resilient transport adaptation pathways under direct and indirect flood impacts using reinforcement learning]]></title>
<link>http://arxiv.org/abs/2601.18586v1</link>
<guid>2601.18586v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.LG, cs.AI
Authors: Miguel Costa, Arthur Vandervoort, Carolin Schmidt, Morten W. Petersen, Martin Drews et al.
Institution: 
Published: 2026-01-26
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Climate change is expected to intensify rainfall and other hazards, increasing disruptions in urban transportation systems. Designing effective adaptation strategies is challenging due to the long-term, sequential nature of infrastructure investments, deep uncertainty, and complex cross-sector interactions. We propose a generic decision-support framework that couples an integrated assessment model (IAM) with reinforcement learning (RL) to learn adaptive, multi-decade investment pathways under uncertainty. The framework combines long-term climate projections (e.g., IPCC scenario pathways) with models that map projected extreme-weather drivers (e.g. rain) into hazard likelihoods (e.g. flooding), propagate hazards into urban infrastructure impacts (e.g. transport disruption), and value direct and indirect consequences for service performance and societal costs. Embedded in a reinforcement-learning loop, it learns adaptive climate adaptation policies that trade off investment and maintenance expenditures against avoided impacts. In collaboration with Copenhagen Municipality, we demonstrate the approach on pluvial flooding in the inner city for the horizon of 2024 to 2100. The learned strategies yield coordinated spatial-temporal pathways and improved robustness relative to conventional optimization baselines, namely inaction and random action, illustrating the framework's transferability to other hazards and cities.]]></description>
<pubDate>Mon, 26 Jan 2026 15:32:40 +0000</pubDate>
</item>
<item>
<title><![CDATA[GimmBO: Interactive Generative Image Model Merging via Bayesian Optimization]]></title>
<link>http://arxiv.org/abs/2601.18585v1</link>
<guid>2601.18585v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.CV, cs.GR
Authors: Chenxi Liu, Selena Ling, Alec Jacobson
Institution: 
Published: 2026-01-26
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Fine-tuning-based adaptation is widely used to customize diffusion-based image generation, leading to large collections of community-created adapters that capture diverse subjects and styles. Adapters derived from the same base model can be merged with weights, enabling the synthesis of new visual results within a vast and continuous design space. To explore this space, current workflows rely on manual slider-based tuning, an approach that scales poorly and makes weight selection difficult, even when the candidate set is limited to 20-30 adapters. We propose GimmBO to support interactive exploration of adapter merging for image generation through Preferential Bayesian Optimization (PBO). Motivated by observations from real-world usage, including sparsity and constrained weight ranges, we introduce a two-stage BO backend that improves sampling efficiency and convergence in high-dimensional spaces. We evaluate our approach with simulated users and a user study, demonstrating improved convergence, high success rates, and consistent gains over BO and line-search baselines, and further show the flexibility of the framework through several extensions.]]></description>
<pubDate>Mon, 26 Jan 2026 15:32:16 +0000</pubDate>
</item>
<item>
<title><![CDATA[From Classification to Ranking: Enhancing LLM Reasoning Capabilities for MBTI Personality Detection]]></title>
<link>http://arxiv.org/abs/2601.18582v1</link>
<guid>2601.18582v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.CL
Authors: Yuan Cao, Feixiang Liu, Xinyue Wang, Yihan Zhu, Hui Xu et al.
Institution: 
Published: 2026-01-26
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Personality detection aims to measure an individual's corresponding personality traits through their social media posts. The advancements in Large Language Models (LLMs) offer novel perspectives for personality detection tasks. Existing approaches enhance personality trait analysis by leveraging LLMs to extract semantic information from textual posts as prompts, followed by training classifiers for categorization. However, accurately classifying personality traits remains challenging due to the inherent complexity of human personality and subtle inter-trait distinctions. Moreover, prompt-based methods often exhibit excessive dependency on expert-crafted knowledge without autonomous pattern-learning capacity. To address these limitations, we view personality detection as a ranking task rather than a classification and propose a corresponding reinforcement learning training paradigm. First, we employ supervised fine-tuning (SFT) to establish personality trait ranking capabilities while enforcing standardized output formats, creating a robust initialization. Subsequently, we introduce Group Relative Policy Optimization (GRPO) with a specialized ranking-based reward function. Unlike verification tasks with definitive solutions, personality assessment involves subjective interpretations and blurred boundaries between trait categories. Our reward function explicitly addresses this challenge by training LLMs to learn optimal answer rankings. Comprehensive experiments have demonstrated that our method achieves state-of-the-art performance across multiple personality detection benchmarks.]]></description>
<pubDate>Mon, 26 Jan 2026 15:28:43 +0000</pubDate>
</item>
<item>
<title><![CDATA[K-Myriad: Jump-starting reinforcement learning with unsupervised parallel agents]]></title>
<link>http://arxiv.org/abs/2601.18580v1</link>
<guid>2601.18580v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.LG
Authors: Vincenzo De Paola, Mirco Mutti, Riccardo Zamboni, Marcello Restelli
Institution: 
Published: 2026-01-26
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Parallelization in Reinforcement Learning is typically employed to speed up the training of a single policy, where multiple workers collect experience from an identical sampling distribution. This common design limits the potential of parallelization by neglecting the advantages of diverse exploration strategies. We propose K-Myriad, a scalable and unsupervised method that maximizes the collective state entropy induced by a population of parallel policies. By cultivating a portfolio of specialized exploration strategies, K-Myriad provides a robust initialization for Reinforcement Learning, leading to both higher training efficiency and the discovery of heterogeneous solutions. Experiments on high-dimensional continuous control tasks, with large-scale parallelization, demonstrate that K-Myriad can learn a broad set of distinct policies, highlighting its effectiveness for collective exploration and paving the way towards novel parallelization strategies.]]></description>
<pubDate>Mon, 26 Jan 2026 15:26:40 +0000</pubDate>
</item>
<item>
<title><![CDATA[FastInsight: Fast and Insightful Retrieval via Fusion Operators for Graph RAG]]></title>
<link>http://arxiv.org/abs/2601.18579v1</link>
<guid>2601.18579v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.IR, cs.AI
Authors: Seonho An, Chaejeong Hyun, Min-Soo Kim
Institution: 
Published: 2026-01-26
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Existing Graph RAG methods aiming for insightful retrieval on corpus graphs typically rely on time-intensive processes that interleave Large Language Model (LLM) reasoning. To enable time-efficient insightful retrieval, we propose FastInsight. We first introduce a graph retrieval taxonomy that categorizes existing methods into three fundamental operations: vector search, graph search, and model-based search. Through this taxonomy, we identify two critical limitations in current approaches: the topology-blindness of model-based search and the semantics-blindness of graph search. FastInsight overcomes these limitations by interleaving two novel fusion operators: the Graph-based Reranker (GRanker), which functions as a graph model-based search, and Semantic-Topological eXpansion (STeX), which operates as a vector-graph search. Extensive experiments on broad retrieval and generation datasets demonstrate that FastInsight significantly improves both retrieval accuracy and generation quality compared to state-of-the-art baselines, achieving a substantial Pareto improvement in the trade-off between effectiveness and efficiency.]]></description>
<pubDate>Mon, 26 Jan 2026 15:23:41 +0000</pubDate>
</item>
<item>
<title><![CDATA[One Persona, Many Cues, Different Results: How Sociodemographic Cues Impact LLM Personalization]]></title>
<link>http://arxiv.org/abs/2601.18572v1</link>
<guid>2601.18572v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.CL
Authors: Franziska Weeber, Vera Neplenbroek, Jan Batzner, Sebastian Pad
Institution: 
Published: 2026-01-26
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Personalization of LLMs by sociodemographic subgroup often improves user experience, but can also introduce or amplify biases and unfair outcomes across groups. Prior work has employed so-called personas, sociodemographic user attributes conveyed to a model, to study bias in LLMs by relying on a single cue to prompt a persona, such as user names or explicit attribute mentions. This disregards LLM sensitivity to prompt variations (robustness) and the rarity of some cues in real interactions (external validity). We compare six commonly used persona cues across seven open and proprietary LLMs on four writing and advice tasks. While cues are overall highly correlated, they produce substantial variance in responses across personas. We therefore caution against claims from a single persona cue and recommend future personalization research to evaluate multiple externally valid cues.]]></description>
<pubDate>Mon, 26 Jan 2026 15:15:58 +0000</pubDate>
</item>
<item>
<title><![CDATA[Attention-Based Neural-Augmented Kalman Filter for Legged Robot State Estimation]]></title>
<link>http://arxiv.org/abs/2601.18569v1</link>
<guid>2601.18569v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.RO, cs.AI, cs.LG
Authors: Seokju Lee, Kyung-Soo Kim
Institution: 
Published: 2026-01-26
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

In this letter, we propose an Attention-Based Neural-Augmented Kalman Filter (AttenNKF) for state estimation in legged robots. Foot slip is a major source of estimation error: when slip occurs, kinematic measurements violate the no-slip assumption and inject bias during the update step. Our objective is to estimate this slip-induced error and compensate for it. To this end, we augment an Invariant Extended Kalman Filter (InEKF) with a neural compensator that uses an attention mechanism to infer error conditioned on foot-slip severity and then applies this estimate as a post-update compensation to the InEKF state (i.e., after the filter update). The compensator is trained in a latent space, which aims to reduce sensitivity to raw input scales and encourages structured slip-conditioned compensations, while preserving the InEKF recursion. Experiments demonstrate improved performance compared to existing legged-robot state estimators, particularly under slip-prone conditions.]]></description>
<pubDate>Mon, 26 Jan 2026 15:13:36 +0000</pubDate>
</item>
<item>
<title><![CDATA[An Unsupervised Tensor-Based Domain Alignment]]></title>
<link>http://arxiv.org/abs/2601.18564v1</link>
<guid>2601.18564v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.LG, cs.CV
Authors: Chong Hyun Lee, Kibae Lee, Hyun Hee Yim
Institution: 
Published: 2026-01-26
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

We propose a tensor-based domain alignment (DA) algorithm designed to align source and target tensors within an invariant subspace through the use of alignment matrices. These matrices along with the subspace undergo iterative optimization of which constraint is on oblique manifold, which offers greater flexibility and adaptability compared to the traditional Stiefel manifold. Moreover, regularization terms defined to preserve the variance of both source and target tensors, ensures robust performance. Our framework is versatile, effectively generalizing existing tensor-based DA methods as special cases. Through extensive experiments, we demonstrate that our approach not only enhances DA conversion speed but also significantly boosts classification accuracy. This positions our method as superior to current state-of-the-art techniques, making it a preferable choice for complex domain adaptation tasks.]]></description>
<pubDate>Mon, 26 Jan 2026 15:11:12 +0000</pubDate>
</item>
<item>
<title><![CDATA[AI-enabled Satellite Edge Computing: A Single-Pixel Feature based Shallow Classification Model for Hyperspectral Imaging]]></title>
<link>http://arxiv.org/abs/2601.18560v1</link>
<guid>2601.18560v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.CV
Authors: Li Fang, Tianyu Li, Yanghong Lin, Shudong Zhou, Wei Yao
Institution: 
Published: 2026-01-26
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

As the important component of the Earth observation system, hyperspectral imaging satellites provide high-fidelity and enriched information for the formulation of related policies due to the powerful spectral measurement capabilities. However, the transmission speed of the satellite downlink has become a major bottleneck in certain applications, such as disaster monitoring and emergency mapping, which demand a fast response ability. We propose an efficient AI-enabled Satellite Edge Computing paradigm for hyperspectral image classification, facilitating the satellites to attain autonomous decision-making. To accommodate the resource constraints of satellite platforms, the proposed method adopts a lightweight, non-deep learning framework integrated with a few-shot learning strategy. Moreover, onboard processing on satellites could be faced with sensor failure and scan pattern errors, which result in degraded image quality with bad/misaligned pixels and mixed noise. To address these challenges, we develop a novel two-stage pixel-wise label propagation scheme that utilizes only intrinsic spectral features at the single pixel level without the necessity to consider spatial structural information as requested by deep neural networks. In the first stage, initial pixel labels are obtained by propagating selected anchor labels through the constructed anchor-pixel affinity matrix. Subsequently, a top-k pruned sparse graph is generated by directly computing pixel-level similarities. In the second stage, a closed-form solution derived from the sparse graph is employed to replace iterative computations. Furthermore, we developed a rank constraint-based graph clustering algorithm to determine the anchor labels.]]></description>
<pubDate>Mon, 26 Jan 2026 15:07:31 +0000</pubDate>
</item>
<item>
<title><![CDATA[Generative Diffusion Augmentation with Quantum-Enhanced Discrimination for Medical Image Diagnosis]]></title>
<link>http://arxiv.org/abs/2601.18556v1</link>
<guid>2601.18556v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.CV, cs.LG
Authors: Jingsong Xia, Siqi Wang
Institution: 
Published: 2026-01-26
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

In biomedical engineering, artificial intelligence has become a pivotal tool for enhancing medical diagnostics, particularly in medical image classification tasks such as detecting pneumonia from chest X-rays and breast cancer screening. However, real-world medical datasets frequently exhibit severe class imbalance, where positive samples substantially outnumber negative samples, leading to biased models with low recall rates for minority classes. This imbalance not only compromises diagnostic accuracy but also poses clinical misdiagnosis risks. To address this challenge, we propose SDA-QEC (Simplified Diffusion Augmentation with Quantum-Enhanced Classification), an innovative framework that integrates simplified diffusion-based data augmentation with quantum-enhanced feature discrimination. Our approach employs a lightweight diffusion augmentor to generate high-quality synthetic samples for minority classes, rebalancing the training distribution. Subsequently, a quantum feature layer embedded within MobileNetV2 architecture enhances the model's discriminative capability through high-dimensional feature mapping in Hilbert space. Comprehensive experiments on coronary angiography image classification demonstrate that SDA-QEC achieves 98.33% accuracy, 98.78% AUC, and 98.33% F1-score, significantly outperforming classical baselines including ResNet18, MobileNetV2, DenseNet121, and VGG16. Notably, our framework simultaneously attains 98.33% sensitivity and 98.33% specificity, achieving a balanced performance critical for clinical deployment. The proposed method validates the feasibility of integrating generative augmentation with quantum-enhanced modeling in real-world medical imaging tasks, offering a novel research pathway for developing highly reliable medical AI systems in small-sample, highly imbalanced, and high-risk diagnostic scenarios.]]></description>
<pubDate>Mon, 26 Jan 2026 15:05:19 +0000</pubDate>
</item>
<item>
<title><![CDATA[Automated Landmark Detection for assessing hip conditions: A Cross-Modality Validation of MRI versus X-ray]]></title>
<link>http://arxiv.org/abs/2601.18555v1</link>
<guid>2601.18555v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.CV
Authors: Roberto Di Via, Vito Paolo Pastore, Francesca Odone, Sin Glyn-Jones, Irina Voiculescu
Institution: 
Published: 2026-01-26
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Many clinical screening decisions are based on angle measurements. In particular, FemoroAcetabular Impingement (FAI) screening relies on angles traditionally measured on X-rays. However, assessing the height and span of the impingement area requires also a 3D view through an MRI scan. The two modalities inform the surgeon on different aspects of the condition. In this work, we conduct a matched-cohort validation study (89 patients, paired MRI/X-ray) using standard heatmap regression architectures to assess cross-modality clinical equivalence. Seen that landmark detection has been proven effective on X-rays, we show that MRI also achieves equivalent localisation and diagnostic accuracy for cam-type impingement. Our method demonstrates clinical feasibility for FAI assessment in coronal views of 3D MRI volumes, opening the possibility for volumetric analysis through placing further landmarks. These results support integrating automated FAI assessment into routine MRI workflows. Code is released at https://github.com/Malga-Vision/Landmarks-Hip-Conditions]]></description>
<pubDate>Mon, 26 Jan 2026 15:04:21 +0000</pubDate>
</item>
<item>
<title><![CDATA[Deconstructing Instruction-Following: A New Benchmark for Granular Evaluation of Large Language Model Instruction Compliance Abilities]]></title>
<link>http://arxiv.org/abs/2601.18554v1</link>
<guid>2601.18554v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.AI
Authors: Alberto Purpura, Li Wang, Sahil Badyal, Eugenio Beaufrand, Adam Faulkner
Institution: 
Published: 2026-01-26
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Reliably ensuring Large Language Models (LLMs) follow complex instructions is a critical challenge, as existing benchmarks often fail to reflect real-world use or isolate compliance from task success. We introduce MOSAIC (MOdular Synthetic Assessment of Instruction Compliance), a modular framework that uses a dynamically generated dataset with up to 20 application-oriented generation constraints to enable a granular and independent analysis of this capability. Our evaluation of five LLMs from different families based on this new benchmark demonstrates that compliance is not a monolithic capability but varies significantly with constraint type, quantity, and position. The analysis reveals model-specific weaknesses, uncovers synergistic and conflicting interactions between instructions, and identifies distinct positional biases such as primacy and recency effects. These granular insights are critical for diagnosing model failures and developing more reliable LLMs for systems that demand strict adherence to complex instructions.]]></description>
<pubDate>Mon, 26 Jan 2026 15:02:15 +0000</pubDate>
</item>
<item>
<title><![CDATA[Unknown Unknowns: Why Hidden Intentions in LLMs Evade Detection]]></title>
<link>http://arxiv.org/abs/2601.18552v1</link>
<guid>2601.18552v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.CL, cs.LG
Authors: Devansh Srivastav, David Pape, Lea Schnherr
Institution: 
Published: 2026-01-26
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

LLMs are increasingly embedded in everyday decision-making, yet their outputs can encode subtle, unintended behaviours that shape user beliefs and actions. We refer to these covert, goal-directed behaviours as hidden intentions, which may arise from training and optimisation artefacts, or be deliberately induced by an adversarial developer, yet remain difficult to detect in practice. We introduce a taxonomy of ten categories of hidden intentions, grounded in social science research and organised by intent, mechanism, context, and impact, shifting attention from surface-level behaviours to design-level strategies of influence. We show how hidden intentions can be easily induced in controlled models, providing both testbeds for evaluation and demonstrations of potential misuse. We systematically assess detection methods, including reasoning and non-reasoning LLM judges, and find that detection collapses in realistic open-world settings, particularly under low-prevalence conditions, where false positives overwhelm precision and false negatives conceal true risks. Stress tests on precision-prevalence and precision-FNR trade-offs reveal why auditing fails without vanishingly small false positive rates or strong priors on manipulation types. Finally, a qualitative case study shows that all ten categories manifest in deployed, state-of-the-art LLMs, emphasising the urgent need for robust frameworks. Our work provides the first systematic analysis of detectability failures of hidden intentions in LLMs under open-world settings, offering a foundation for understanding, inducing, and stress-testing such behaviours, and establishing a flexible taxonomy for anticipating evolving threats and informing governance.]]></description>
<pubDate>Mon, 26 Jan 2026 14:59:17 +0000</pubDate>
</item>
<item>
<title><![CDATA[REMAC: Reference-Based Martian Asymmetrical Image Compression]]></title>
<link>http://arxiv.org/abs/2601.18547v1</link>
<guid>2601.18547v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.CV, cs.MM
Authors: Qing Ding, Mai Xu, Shengxi Li, Xin Deng, Xin Zou
Institution: 
Published: 2026-01-26
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

To expedite space exploration on Mars, it is indispensable to develop an efficient Martian image compression method for transmitting images through the constrained Mars-to-Earth communication channel. Although the existing learned compression methods have achieved promising results for natural images from earth, there remain two critical issues that hinder their effectiveness for Martian image compression: 1) They overlook the highly-limited computational resources on Mars; 2) They do not utilize the strong \textit{inter-image} similarities across Martian images to advance image compression performance. Motivated by our empirical analysis of the strong \textit{intra-} and \textit{inter-image} similarities from the perspective of texture, color, and semantics, we propose a reference-based Martian asymmetrical image compression (REMAC) approach, which shifts computational complexity from the encoder to the resource-rich decoder and simultaneously improves compression performance. To leverage \textit{inter-image} similarities, we propose a reference-guided entropy module and a ref-decoder that utilize useful information from reference images, reducing redundant operations at the encoder and achieving superior compression performance. To exploit \textit{intra-image} similarities, the ref-decoder adopts a deep, multi-scale architecture with enlarged receptive field size to model long-range spatial dependencies. Additionally, we develop a latent feature recycling mechanism to further alleviate the extreme computational constraints on Mars. Experimental results show that REMAC reduces encoder complexity by 43.51\% compared to the state-of-the-art method, while achieving a BD-PSNR gain of 0.2664 dB.]]></description>
<pubDate>Mon, 26 Jan 2026 14:55:17 +0000</pubDate>
</item>
<item>
<title><![CDATA[Information Hidden in Gradients of Regression with Target Noise]]></title>
<link>http://arxiv.org/abs/2601.18546v1</link>
<guid>2601.18546v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.LG
Authors: Arash Jamshidi, Katsiaryna Haitsiukevich, Kai Puolamki
Institution: 
Published: 2026-01-26
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Second-order information -- such as curvature or data covariance -- is critical for optimisation, diagnostics, and robustness. However, in many modern settings, only the gradients are observable. We show that the gradients alone can reveal the Hessian, equalling the data covariance $$ for the linear regression. Our key insight is a simple variance calibration: injecting Gaussian noise so that the total target noise variance equals the batch size ensures that the empirical gradient covariance closely approximates the Hessian, even when evaluated far from the optimum. We provide non-asymptotic operator-norm guarantees under sub-Gaussian inputs. We also show that without such calibration, recovery can fail by an $(1)$ factor. The proposed method is practical (a "set target-noise variance to $n$" rule) and robust (variance $\mathcal{O}(n)$ suffices to recover $$ up to scale). Applications include preconditioning for faster optimisation, adversarial risk estimation, and gradient-only training, for example, in distributed systems. We support our theoretical results with experiments on synthetic and real data.]]></description>
<pubDate>Mon, 26 Jan 2026 14:50:16 +0000</pubDate>
</item>
<item>
<title><![CDATA[GenAgent: Scaling Text-to-Image Generation via Agentic Multimodal Reasoning]]></title>
<link>http://arxiv.org/abs/2601.18543v1</link>
<guid>2601.18543v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.CV
Authors: Kaixun Jiang, Yuzheng Wang, Junjie Zhou, Pandeng Li, Zhihang Liu et al.
Institution: 
Published: 2026-01-26
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

We introduce GenAgent, unifying visual understanding and generation through an agentic multimodal model. Unlike unified models that face expensive training costs and understanding-generation trade-offs, GenAgent decouples these capabilities through an agentic framework: understanding is handled by the multimodal model itself, while generation is achieved by treating image generation models as invokable tools. Crucially, unlike existing modular systems constrained by static pipelines, this design enables autonomous multi-turn interactions where the agent generates multimodal chains-of-thought encompassing reasoning, tool invocation, judgment, and reflection to iteratively refine outputs. We employ a two-stage training strategy: first, cold-start with supervised fine-tuning on high-quality tool invocation and reflection data to bootstrap agent behaviors; second, end-to-end agentic reinforcement learning combining pointwise rewards (final image quality) and pairwise rewards (reflection accuracy), with trajectory resampling for enhanced multi-turn exploration. GenAgent significantly boosts base generator(FLUX.1-dev) performance on GenEval++ (+23.6\%) and WISE (+14\%). Beyond performance gains, our framework demonstrates three key properties: 1) cross-tool generalization to generators with varying capabilities, 2) test-time scaling with consistent improvements across interaction rounds, and 3) task-adaptive reasoning that automatically adjusts to different tasks. Our code will be available at \href{https://github.com/deep-kaixun/GenAgent}{this url}.]]></description>
<pubDate>Mon, 26 Jan 2026 14:49:04 +0000</pubDate>
</item>
<item>
<title><![CDATA[SKETCH: Semantic Key-Point Conditioning for Long-Horizon Vessel Trajectory Prediction]]></title>
<link>http://arxiv.org/abs/2601.18537v1</link>
<guid>2601.18537v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.RO, cs.AI
Authors: Linyong Gan, Zimo Li, Wenxin Xu, Xingjian Li, Jianhua Z. Huang et al.
Institution: 
Published: 2026-01-26
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Accurate long-horizon vessel trajectory prediction remains challenging due to compounded uncertainty from complex navigation behaviors and environmental factors. Existing methods often struggle to maintain global directional consistency, leading to drifting or implausible trajectories when extrapolated over long time horizons. To address this issue, we propose a semantic-key-point-conditioned trajectory modeling framework, in which future trajectories are predicted by conditioning on a high-level Next Key Point (NKP) that captures navigational intent. This formulation decomposes long-horizon prediction into global semantic decision-making and local motion modeling, effectively restricting the support of future trajectories to semantically feasible subsets. To efficiently estimate the NKP prior from historical observations, we adopt a pretrain-finetune strategy. Extensive experiments on real-world AIS data demonstrate that the proposed method consistently outperforms state-of-the-art approaches, particularly for long travel durations, directional accuracy, and fine-grained trajectory prediction.]]></description>
<pubDate>Mon, 26 Jan 2026 14:42:31 +0000</pubDate>
</item>
<item>
<title><![CDATA[Evaluating Morphological Plausibility of Subword Tokenization via Statistical Alignment with Morpho-Syntactic Features]]></title>
<link>http://arxiv.org/abs/2601.18536v1</link>
<guid>2601.18536v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.CL
Authors: Abishek Stephen, Jindich Libovick
Institution: 
Published: 2026-01-26
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

We present a novel metric for the evaluation of the morphological plausibility of subword segmentation. Unlike the typically used morpheme boundary or retrieval F-score, which requires gold segmentation data that is either unavailable or of inconsistent quality across many languages, our approach utilizes morpho-syntactic features. These are available in resources such as Universal Dependencies or UniMorph for a much wider range of languages. The metric works by probabilistically aligning subwords with morphological features through an IBM Model 1. Our experiments show that the metric correlates well with traditional morpheme boundary recall while being more broadly applicable across languages with different morphological systems.]]></description>
<pubDate>Mon, 26 Jan 2026 14:41:44 +0000</pubDate>
</item>
<item>
<title><![CDATA[From Verifiable Dot to Reward Chain: Harnessing Verifiable Reference-based Rewards for Reinforcement Learning of Open-ended Generation]]></title>
<link>http://arxiv.org/abs/2601.18533v1</link>
<guid>2601.18533v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.CL
Authors: Yuxin Jiang, Yufei Wang, Qiyuan Zhang, Xingshan Zeng, Liangyou Li et al.
Institution: 
Published: 2026-01-26
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Reinforcement learning with verifiable rewards (RLVR) succeeds in reasoning tasks (e.g., math and code) by checking the final verifiable answer (i.e., a verifiable dot signal). However, extending this paradigm to open-ended generation is challenging because there is no unambiguous ground truth. Relying on single-dot supervision often leads to inefficiency and reward hacking. To address these issues, we propose reinforcement learning with verifiable reference-based rewards (RLVRR). Instead of checking the final answer, RLVRR extracts an ordered linguistic signal from high-quality references (i.e, reward chain). Specifically, RLVRR decomposes rewards into two dimensions: content, which preserves deterministic core concepts (e.g., keywords), and style, which evaluates adherence to stylistic properties through LLM-based verification. In this way, RLVRR combines the exploratory strength of RL with the efficiency and reliability of supervised fine-tuning (SFT). Extensive experiments on more than 10 benchmarks with Qwen and Llama models confirm the advantages of our approach. RLVRR (1) substantially outperforms SFT trained with ten times more data and advanced reward models, (2) unifies the training of structured reasoning and open-ended generation, and (3) generalizes more effectively while preserving output diversity. These results establish RLVRR as a principled and efficient path toward verifiable reinforcement learning for general-purpose LLM alignment. We release our code and data at https://github.com/YJiangcm/RLVRR.]]></description>
<pubDate>Mon, 26 Jan 2026 14:39:58 +0000</pubDate>
</item>
<item>
<title><![CDATA[From Cold Start to Active Learning: Embedding-Based Scan Selection for Medical Image Segmentation]]></title>
<link>http://arxiv.org/abs/2601.18532v1</link>
<guid>2601.18532v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.CV, cs.LG
Authors: Devon Levy, Bar Assayag, Laura Gaspar, Ilan Shimshoni, Bella Specktor-Fadida
Institution: 
Published: 2026-01-26
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Accurate segmentation annotations are critical for disease monitoring, yet manual labeling remains a major bottleneck due to the time and expertise required. Active learning (AL) alleviates this burden by prioritizing informative samples for annotation, typically through a diversity-based cold-start phase followed by uncertainty-driven selection. We propose a novel cold-start sampling strategy that combines foundation-model embeddings with clustering, including automatic selection of the number of clusters and proportional sampling across clusters, to construct a diverse and representative initial training. This is followed by an uncertainty-based AL framework that integrates spatial diversity to guide sample selection. The proposed method is intuitive and interpretable, enabling visualization of the feature-space distribution of candidate samples. We evaluate our approach on three datasets spanning X-ray and MRI modalities. On the CheXmask dataset, the cold-start strategy outperforms random selection, improving Dice from 0.918 to 0.929 and reducing the Hausdorff distance from 32.41 to 27.66 mm. In the AL setting, combined entropy and diversity selection improves Dice from 0.919 to 0.939 and reduces the Hausdorff distance from 30.10 to 19.16 mm. On the Montgomery dataset, cold-start gains are substantial, with Dice improving from 0.928 to 0.950 and Hausdorff distance decreasing from 14.22 to 9.38 mm. On the SynthStrip dataset, cold-start selection slightly affects Dice but reduces the Hausdorff distance from 9.43 to 8.69 mm, while active learning improves Dice from 0.816 to 0.826 and reduces the Hausdorff distance from 7.76 to 6.38 mm. Overall, the proposed framework consistently outperforms baseline methods in low-data regimes, improving segmentation accuracy.]]></description>
<pubDate>Mon, 26 Jan 2026 14:39:03 +0000</pubDate>
</item>
<item>
<title><![CDATA[Exploring Fine-Tuning for In-Context Retrieval and Efficient KV-Caching in Long-Context Language Models]]></title>
<link>http://arxiv.org/abs/2601.18527v1</link>
<guid>2601.18527v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.CL
Authors: Francesco Maria Molfese, Momchil Hardalov, Rexhina Blloshmi, Bill Byrne, Adri de Gispert
Institution: 
Published: 2026-01-26
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

With context windows of millions of tokens, Long-Context Language Models (LCLMs) can encode entire document collections, offering a strong alternative to conventional retrieval-augmented generation (RAG). However, it remains unclear whether fine-tuning strategies can improve long-context performance and translate to greater robustness under KV-cache compression techniques. In this work, we investigate which training strategies most effectively enhance LCLMs' ability to identify and use relevant information, as well as enhancing their robustness under KV-cache compression. Our experiments show substantial in-domain improvements, achieving gains of up to +20 points over the base model. However, out-of-domain generalization remains task dependent with large variance -- LCLMs excels on finance questions (+9 points), while RAG shows stronger performance on multiple-choice questions (+6 points) over the baseline models. Finally, we show that our fine-tuning approaches bring moderate improvements in robustness under KV-cache compression, with gains varying across tasks.]]></description>
<pubDate>Mon, 26 Jan 2026 14:37:02 +0000</pubDate>
</item>
<item>
<title><![CDATA[Closing the Modality Gap Aligns Group-Wise Semantics]]></title>
<link>http://arxiv.org/abs/2601.18525v1</link>
<guid>2601.18525v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.LG, cs.CV
Authors: Eleonora Grassucci, Giordano Cicchetti, Emanuele Frasca, Aurelio Uncini, Danilo Comminiello
Institution: 
Published: 2026-01-26
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

In multimodal learning, CLIP has been recognized as the \textit{de facto} method for learning a shared latent space across multiple modalities, placing similar representations close to each other and moving them away from dissimilar ones. Although CLIP-based losses effectively align modalities at the semantic level, the resulting latent spaces often remain only partially shared, revealing a structural mismatch known as the modality gap. While the necessity of addressing this phenomenon remains debated, particularly given its limited impact on instance-wise tasks (e.g., retrieval), we prove that its influence is instead strongly pronounced in group-level tasks (e.g., clustering). To support this claim, we introduce a novel method designed to consistently reduce this discrepancy in two-modal settings, with a straightforward extension to the general $n$-modal case. Through our extensive evaluation, we demonstrate our novel insight: while reducing the gap provides only marginal or inconsistent improvements in traditional instance-wise tasks, it significantly enhances group-wise tasks. These findings may reshape our understanding of the modality gap, highlighting its key role in improving performance on tasks requiring semantic grouping.]]></description>
<pubDate>Mon, 26 Jan 2026 14:36:04 +0000</pubDate>
</item>
<item>
<title><![CDATA[From Human Labels to Literature: Semi-Supervised Learning of NMR Chemical Shifts at Scale]]></title>
<link>http://arxiv.org/abs/2601.18524v1</link>
<guid>2601.18524v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.LG
Authors: Yongqi Jin, Yecheng Wang, Jun-jie Wang, Rong Zhu, Guolin Ke et al.
Institution: 
Published: 2026-01-26
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Accurate prediction of nuclear magnetic resonance (NMR) chemical shifts is fundamental to spectral analysis and molecular structure elucidation, yet existing machine learning methods rely on limited, labor-intensive atom-assigned datasets. We propose a semi-supervised framework that learns NMR chemical shifts from millions of literature-extracted spectra without explicit atom-level assignments, integrating a small amount of labeled data with large-scale unassigned spectra. We formulate chemical shift prediction from literature spectra as a permutation-invariant set supervision problem, and show that under commonly satisfied conditions on the loss function, optimal bipartite matching reduces to a sorting-based loss, enabling stable large-scale semi-supervised training beyond traditional curated datasets. Our models achieve substantially improved accuracy and robustness over state-of-the-art methods and exhibit stronger generalization on significantly larger and more diverse molecular datasets. Moreover, by incorporating solvent information at scale, our approach captures systematic solvent effects across common NMR solvents for the first time. Overall, our results demonstrate that large-scale unlabeled spectra mined from the literature can serve as a practical and effective data source for training NMR shift models, suggesting a broader role of literature-derived, weakly structured data in data-centric AI for science.]]></description>
<pubDate>Mon, 26 Jan 2026 14:35:25 +0000</pubDate>
</item>
<item>
<title><![CDATA[Scalable Transit Delay Prediction at City Scale: A Systematic Approach with Multi-Resolution Feature Engineering and Deep Learning]]></title>
<link>http://arxiv.org/abs/2601.18521v1</link>
<guid>2601.18521v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.LG, cs.AI
Authors: Emna Boudabbous, Mohamed Karaa, Lokman Sboui, Julio Montecinos, Omar Alam
Institution: 
Published: 2026-01-26
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Urban bus transit agencies need reliable, network-wide delay predictions to provide accurate arrival information to passengers and support real-time operational control. Accurate predictions help passengers plan their trips, reduce waiting time, and allow operations staff to adjust headways, dispatch extra vehicles, and manage disruptions. Although real-time feeds such as GTFS-Realtime (GTFS-RT) are now widely available, most existing delay prediction systems handle only a few routes, depend on hand-crafted features, and offer little guidance on how to design a scalable, reusable architecture.
  We present a city-scale prediction pipeline that combines multi-resolution feature engineering, dimensionality reduction, and deep learning. The framework generates 1,683 spatiotemporal features by exploring 23 aggregation combinations over H3 cells, routes, segments, and temporal patterns, and compresses them into 83 components using Adaptive PCA while preserving 95% of the variance. To avoid the "giant cluster" problem that occurs when dense urban areas fall into a single H3 region, we introduce a hybrid H3+topology clustering method that yields 12 balanced route clusters (coefficient of variation 0.608) and enables efficient distributed training.
  We compare five model architectures on six months of bus operations from the Socit de transport de Montral (STM) network in Montral. A global LSTM with cluster-aware features achieves the best trade-off between accuracy and efficiency, outperforming transformer models by 18 to 52% while using 275 times fewer parameters. We also report multi-level evaluation at the elementary segment, segment, and trip level with walk-forward validation and latency analysis, showing that the proposed pipeline is suitable for real-time, city-scale deployment and can be reused for other networks with limited adaptation.]]></description>
<pubDate>Mon, 26 Jan 2026 14:30:50 +0000</pubDate>
</item>
<item>
<title><![CDATA[GenAI for Social Work Field Education: Client Simulation with Real-Time Feedback]]></title>
<link>http://arxiv.org/abs/2601.18517v1</link>
<guid>2601.18517v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.CL
Authors: James Sungarda, Hongkai Liu, Zilong Zhou, Tien-Hsuan Wu, Johnson Chun-Sing Cheung et al.
Institution: 
Published: 2026-01-26
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Field education is the signature pedagogy of social work, yet providing timely and objective feedback during training is constrained by the availability of instructors and counseling clients. In this paper, we present SWITCH, the Social Work Interactive Training Chatbot. SWITCH integrates realistic client simulation, real-time counseling skill classification, and a Motivational Interviewing (MI) progression system into the training workflow. To model a client, SWITCH uses a cognitively grounded profile comprising static fields (e.g., background, beliefs) and dynamic fields (e.g., emotions, automatic thoughts, openness), allowing the agent's behavior to evolve throughout a session realistically. The skill classification module identifies the counseling skills from the user utterances, and feeds the result to the MI controller that regulates the MI stage transitions. To enhance classification accuracy, we study in-context learning with retrieval over annotated transcripts, and a fine-tuned BERT multi-label classifier. In the experiments, we demonstrated that both BERT-based approach and in-context learning outperforms the baseline with big margin. SWITCH thereby offers a scalable, low-cost, and consistent training workflow that complements field education, and allows supervisors to focus on higher-level mentorship.]]></description>
<pubDate>Mon, 26 Jan 2026 14:26:54 +0000</pubDate>
</item>
<item>
<title><![CDATA[LipNeXt: Scaling up Lipschitz-based Certified Robustness to Billion-parameter Models]]></title>
<link>http://arxiv.org/abs/2601.18513v1</link>
<guid>2601.18513v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.LG
Authors: Kai Hu, Haoqi Hu, Matt Fredrikson
Institution: 
Published: 2026-01-26
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Lipschitz-based certification offers efficient, deterministic robustness guarantees but has struggled to scale in model size, training efficiency, and ImageNet performance. We introduce \emph{LipNeXt}, the first \emph{constraint-free} and \emph{convolution-free} 1-Lipschitz architecture for certified robustness. LipNeXt is built using two techniques: (1) a manifold optimization procedure that updates parameters directly on the orthogonal manifold and (2) a \emph{Spatial Shift Module} to model spatial pattern without convolutions. The full network uses orthogonal projections, spatial shifts, a simple 1-Lipschitz $$-Abs nonlinearity, and $L_2$ spatial pooling to maintain tight Lipschitz control while enabling expressive feature mixing. Across CIFAR-10/100 and Tiny-ImageNet, LipNeXt achieves state-of-the-art clean and certified robust accuracy (CRA), and on ImageNet it scales to 1-2B large models, improving CRA over prior Lipschitz models (e.g., up to $+8\%$ at $\varepsilon{=}1$) while retaining efficient, stable low-precision training. These results demonstrate that Lipschitz-based certification can benefit from modern scaling trends without sacrificing determinism or efficiency.]]></description>
<pubDate>Mon, 26 Jan 2026 14:18:55 +0000</pubDate>
</item>
<item>
<title><![CDATA[Using Large Language Models to Construct Virtual Top Managers: A Method for Organizational Research]]></title>
<link>http://arxiv.org/abs/2601.18512v1</link>
<guid>2601.18512v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.CL
Authors: Antonio Garzon-Vico, Krithika Sharon Komalapati, Arsalan Shahid, Jan Rosier
Institution: 
Published: 2026-01-26
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

This study introduces a methodological framework that uses large language models to create virtual personas of real top managers. Drawing on real CEO communications and Moral Foundations Theory, we construct LLM-based participants that simulate the decision-making of individual leaders. Across three phases, we assess construct validity, reliability, and behavioral fidelity by benchmarking these virtual CEOs against human participants. Our results indicate that theoretically scaffolded personas approximate the moral judgements observed in human samples, suggesting that LLM-based personas can serve as credible and complementary tools for organizational research in contexts where direct access to executives is limited. We conclude by outlining implications for future research using LLM-based personas in organizational settings.]]></description>
<pubDate>Mon, 26 Jan 2026 14:17:23 +0000</pubDate>
</item>
<item>
<title><![CDATA[Just-In-Time Reinforcement Learning: Continual Learning in LLM Agents Without Gradient Updates]]></title>
<link>http://arxiv.org/abs/2601.18510v1</link>
<guid>2601.18510v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.LG, cs.AI
Authors: Yibo Li, Zijie Lin, Ailin Deng, Xuan Zhang, Yufei He et al.
Institution: 
Published: 2026-01-26
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

While Large Language Model (LLM) agents excel at general tasks, they inherently struggle with continual adaptation due to the frozen weights after deployment. Conventional reinforcement learning (RL) offers a solution but incurs prohibitive computational costs and the risk of catastrophic forgetting. We introduce Just-In-Time Reinforcement Learning (JitRL), a training-free framework that enables test-time policy optimization without any gradient updates. JitRL maintains a dynamic, non-parametric memory of experiences and retrieves relevant trajectories to estimate action advantages on-the-fly. These estimates are then used to directly modulate the LLM's output logits. We theoretically prove that this additive update rule is the exact closed-form solution to the KL-constrained policy optimization objective. Extensive experiments on WebArena and Jericho demonstrate that JitRL establishes a new state-of-the-art among training-free methods. Crucially, JitRL outperforms the performance of computationally expensive fine-tuning methods (e.g., WebRL) while reducing monetary costs by over 30 times, offering a scalable path for continual learning agents. The code is available at https://github.com/liushiliushi/JitRL.]]></description>
<pubDate>Mon, 26 Jan 2026 14:16:51 +0000</pubDate>
</item>
<item>
<title><![CDATA[Conformal Prediction Algorithms for Time Series Forecasting: Methods and Benchmark]]></title>
<link>http://arxiv.org/abs/2601.18509v1</link>
<guid>2601.18509v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.LG
Authors: Andro Sabashvili
Institution: 
Published: 2026-01-26
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Reliable uncertainty quantification is of critical importance in time series forecasting, yet traditional methods often rely on restrictive distributional assumptions. Conformal prediction (CP) has emerged as a promising distribution-free framework for generating prediction intervals with rigorous theoretical guarantees. However, applying CP to sequential data presents a primary challenge: the temporal dependencies inherent in time series fundamentally violate the core assumption of data exchangeability, upon which standard CP guarantees are built. This review critically examines the main categories of algorithmic solutions designed to address this conflict. We survey and benchmark methods that relax the exchangeability assumption, those that redefine the data unit to be a collection of independent time series, approaches that explicitly model the dynamics of the prediction residuals, and online learning algorithms that adapt to distribution shifts to maintain long-run coverage. By synthesizing these approaches, we highlight computational efficiency and practical performance on real-world data.]]></description>
<pubDate>Mon, 26 Jan 2026 14:15:08 +0000</pubDate>
</item>
<item>
<title><![CDATA[Nearly Optimal Bayesian Inference for Structural Missingness]]></title>
<link>http://arxiv.org/abs/2601.18500v1</link>
<guid>2601.18500v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.LG
Authors: Chen Liang, Donghua Yang, Yutong Wang, Tianle Zhang, Shenghe Zhou et al.
Institution: 
Published: 2026-01-26
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Structural missingness breaks 'just impute and train': values can be undefined by causal or logical constraints, and the mask may depend on observed variables, unobserved variables (MNAR), and other missingness indicators. It simultaneously brings (i) a catch-22 situation with causal loop, prediction needs the missing features, yet inferring them depends on the missingness mechanism, (ii) under MNAR, the unseen are different, the missing part can come from a shifted distribution, and (iii) plug-in imputation, a single fill-in can lock in uncertainty and yield overconfident, biased decisions. In the Bayesian view, prediction via the posterior predictive distribution integrates over the full model posterior uncertainty, rather than relying on a single point estimate. This framework decouples (i) learning an in-model missing-value posterior from (ii) label prediction by optimizing the predictive posterior distribution, enabling posterior integration. This decoupling yields an in-model almost-free-lunch: once the posterior is learned, prediction is plug-and-play while preserving uncertainty propagation. It achieves SOTA on 43 classification and 15 imputation benchmarks, with finite-sample near Bayes-optimality guarantees under our SCM prior.]]></description>
<pubDate>Mon, 26 Jan 2026 14:03:11 +0000</pubDate>
</item>
<item>
<title><![CDATA[DEEPMED: Building a Medical DeepResearch Agent via Multi-hop Med-Search Data and Turn-Controlled Agentic Training & Inference]]></title>
<link>http://arxiv.org/abs/2601.18496v1</link>
<guid>2601.18496v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.AI
Authors: Zihan wang, Hao Wang, Shi Feng, Xiaocui Yang, Daling Wang et al.
Institution: 
Published: 2026-01-26
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Medical reasoning models remain constrained by parametric knowledge and are thus susceptible to forgetting and hallucinations. DeepResearch (DR) models ground outputs in verifiable evidence from tools and perform strongly in general domains, but their direct transfer to medical field yields relatively limited gains. We attribute this to two gaps: task characteristic and tool-use scaling. Medical questions require evidence interpretation in a knowledge-intensive clinical context; while general DR models can retrieve information, they often lack clinical-context reasoning and thus "find it but fail to use it," leaving performance limited by medical abilities. Moreover, in medical scenarios, blindly scaling tool-call can inject noisy context, derailing sensitive medical reasoning and prompting repetitive evidence-seeking along incorrect paths. Therefore, we propose DeepMed. For data, we deploy a multi-hop med-search QA synthesis method supporting the model to apply the DR paradigm in medical contexts. For training, we introduce a difficulty-aware turn-penalty to suppress excessive tool-call growth. For inference, we bring a monitor to help validate hypotheses within a controlled number of steps and avoid context rot. Overall, on seven medical benchmarks, DeepMed improves its base model by 9.79\% on average and outperforms larger medical reasoning and DR models.]]></description>
<pubDate>Mon, 26 Jan 2026 13:57:48 +0000</pubDate>
</item>
<item>
<title><![CDATA[DisasterInsight: A Multimodal Benchmark for Function-Aware and Grounded Disaster Assessment]]></title>
<link>http://arxiv.org/abs/2601.18493v1</link>
<guid>2601.18493v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.CV
Authors: Sara Tehrani, Yonghao Xu, Leif Haglund, Amanda Berg, Michael Felsberg
Institution: 
Published: 2026-01-26
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Timely interpretation of satellite imagery is critical for disaster response, yet existing vision-language benchmarks for remote sensing largely focus on coarse labels and image-level recognition, overlooking the functional understanding and instruction robustness required in real humanitarian workflows. We introduce DisasterInsight, a multimodal benchmark designed to evaluate vision-language models (VLMs) on realistic disaster analysis tasks. DisasterInsight restructures the xBD dataset into approximately 112K building-centered instances and supports instruction-diverse evaluation across multiple tasks, including building-function classification, damage-level and disaster-type classification, counting, and structured report generation aligned with humanitarian assessment guidelines.
  To establish domain-adapted baselines, we propose DI-Chat, obtained by fine-tuning existing VLM backbones on disaster-specific instruction data using parameter-efficient Low-Rank Adaptation (LoRA). Extensive experiments on state-of-the-art generic and remote-sensing VLMs reveal substantial performance gaps across tasks, particularly in damage understanding and structured report generation. DI-Chat achieves significant improvements on damage-level and disaster-type classification as well as report generation quality, while building-function classification remains challenging for all evaluated models. DisasterInsight provides a unified benchmark for studying grounded multimodal reasoning in disaster imagery.]]></description>
<pubDate>Mon, 26 Jan 2026 13:48:11 +0000</pubDate>
</item>
<item>
<title><![CDATA[AgentDoG: A Diagnostic Guardrail Framework for AI Agent Safety and Security]]></title>
<link>http://arxiv.org/abs/2601.18491v1</link>
<guid>2601.18491v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.AI, cs.CC, cs.CL, cs.CV, cs.LG
Authors: Dongrui Liu, Qihan Ren, Chen Qian, Shuai Shao, Yuejin Xie et al.
Institution: 
Published: 2026-01-26
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

The rise of AI agents introduces complex safety and security challenges arising from autonomous tool use and environmental interactions. Current guardrail models lack agentic risk awareness and transparency in risk diagnosis. To introduce an agentic guardrail that covers complex and numerous risky behaviors, we first propose a unified three-dimensional taxonomy that orthogonally categorizes agentic risks by their source (where), failure mode (how), and consequence (what). Guided by this structured and hierarchical taxonomy, we introduce a new fine-grained agentic safety benchmark (ATBench) and a Diagnostic Guardrail framework for agent safety and security (AgentDoG). AgentDoG provides fine-grained and contextual monitoring across agent trajectories. More Crucially, AgentDoG can diagnose the root causes of unsafe actions and seemingly safe but unreasonable actions, offering provenance and transparency beyond binary labels to facilitate effective agent alignment. AgentDoG variants are available in three sizes (4B, 7B, and 8B parameters) across Qwen and Llama model families. Extensive experimental results demonstrate that AgentDoG achieves state-of-the-art performance in agentic safety moderation in diverse and complex interactive scenarios. All models and datasets are openly released.]]></description>
<pubDate>Mon, 26 Jan 2026 13:45:41 +0000</pubDate>
</item>
<item>
<title><![CDATA[Demographic Probing of Large Language Models Lacks Construct Validity]]></title>
<link>http://arxiv.org/abs/2601.18486v1</link>
<guid>2601.18486v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.CL, cs.CY
Authors: Manuel Tonneau, Neil K. R. Seghal, Niyati Malhotra, Victor Orozco-Olvera, Ana Mara Muoz Boudet et al.
Institution: 
Published: 2026-01-26
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Demographic probing is widely used to study how large language models (LLMs) adapt their behavior to signaled demographic attributes. This approach typically uses a single demographic cue in isolation (e.g., a name or dialect) as a signal for group membership, implicitly assuming strong construct validity: that such cues are interchangeable operationalizations of the same underlying, demographically conditioned behavior. We test this assumption in realistic advice-seeking interactions, focusing on race and gender in a U.S. context. We find that cues intended to represent the same demographic group induce only partially overlapping changes in model behavior, while differentiation between groups within a given cue is weak and uneven. Consequently, estimated disparities are unstable, with both magnitude and direction varying across cues. We further show that these inconsistencies partly arise from variation in how strongly cues encode demographic attributes and from linguistic confounders that independently shape model behavior. Together, our findings suggest that demographic probing lacks construct validity: it does not yield a single, stable characterization of how LLMs condition on demographic information, which may reflect a misspecified or fragmented construct. We conclude by recommending the use of multiple, ecologically valid cues and explicit control of confounders to support more defensible claims about demographic effects in LLMs.]]></description>
<pubDate>Mon, 26 Jan 2026 13:41:35 +0000</pubDate>
</item>
<item>
<title><![CDATA[Funny or Persuasive, but Not Both: Evaluating Fine-Grained Multi-Concept Control in LLMs]]></title>
<link>http://arxiv.org/abs/2601.18483v1</link>
<guid>2601.18483v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.CL, cs.AI
Authors: Arya Labroo, Ivaxi Sheth, Vyas Raina, Amaani Ahmed, Mario Fritz
Institution: 
Published: 2026-01-26
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Large Language Models (LLMs) offer strong generative capabilities, but many applications require explicit and \textit{fine-grained} control over specific textual concepts, such as humor, persuasiveness, or formality. Prior approaches in prompting and representation engineering can provide coarse or single-attribute control, but systematic evaluation of multi-attribute settings remains limited. We introduce an evaluation framework for fine-grained controllability for both single- and dual-concept scenarios, focusing on linguistically distinct concept pairs (e.g., persuasiveness vs.~humor). Surprisingly, across multiple LLMs and generative tasks, we find that performance often drops in the dual-concept setting, even though the chosen concepts should in principle be separable. This reveals a fundamental limitation of naive prompting-based control: models struggle with compositionality even when concepts are intuitively independent. Our framework provides systematic evidence of this gap and offers a principled approach for measuring the ability of future methods for multi-concept control.]]></description>
<pubDate>Mon, 26 Jan 2026 13:36:34 +0000</pubDate>
</item>
<item>
<title><![CDATA[Enhancing Control Policy Smoothness by Aligning Actions with Predictions from Preceding States]]></title>
<link>http://arxiv.org/abs/2601.18479v1</link>
<guid>2601.18479v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.LG
Authors: Kyoleen Kwak, Hyoseok Hwang
Institution: 
Published: 2026-01-26
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Deep reinforcement learning has proven to be a powerful approach to solving control tasks, but its characteristic high-frequency oscillations make it difficult to apply in real-world environments. While prior methods have addressed action oscillations via architectural or loss-based methods, the latter typically depend on heuristic or synthetic definitions of state similarity to promote action consistency, which often fail to accurately reflect the underlying system dynamics. In this paper, we propose a novel loss-based method by introducing a transition-induced similar state. The transition-induced similar state is defined as the distribution of next states transitioned from the previous state. Since it utilizes only environmental feedback and actually collected data, it better captures system dynamics. Building upon this foundation, we introduce Action Smoothing by Aligning Actions with Predictions from Preceding States (ASAP), an action smoothing method that effectively mitigates action oscillations. ASAP enforces action smoothness by aligning the actions with those taken in transition-induced similar states and by penalizing second-order differences to suppress high-frequency oscillations. Experiments in Gymnasium and Isaac-Lab environments demonstrate that ASAP yields smoother control and improved policy performance over existing methods.]]></description>
<pubDate>Mon, 26 Jan 2026 13:34:34 +0000</pubDate>
</item>
<item>
<title><![CDATA[LoD-Structured 3D Gaussian Splatting for Streaming Video Reconstruction]]></title>
<link>http://arxiv.org/abs/2601.18475v1</link>
<guid>2601.18475v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.GR, cs.CV
Authors: Xinhui Liu, Can Wang, Lei Liu, Zhenghao Chen, Wei Jiang et al.
Institution: 
Published: 2026-01-26
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Free-Viewpoint Video (FVV) reconstruction enables photorealistic and interactive 3D scene visualization; however, real-time streaming is often bottlenecked by sparse-view inputs, prohibitive training costs, and bandwidth constraints. While recent 3D Gaussian Splatting (3DGS) has advanced FVV due to its superior rendering speed, Streaming Free-Viewpoint Video (SFVV) introduces additional demands for rapid optimization, high-fidelity reconstruction under sparse constraints, and minimal storage footprints. To bridge this gap, we propose StreamLoD-GS, an LoD-based Gaussian Splatting framework designed specifically for SFVV. Our approach integrates three core innovations: 1) an Anchor- and Octree-based LoD-structured 3DGS with a hierarchical Gaussian dropout technique to ensure efficient and stable optimization while maintaining high-quality rendering; 2) a GMM-based motion partitioning mechanism that separates dynamic and static content, refining dynamic regions while preserving background stability; and 3) a quantized residual refinement framework that significantly reduces storage requirements without compromising visual fidelity. Extensive experiments demonstrate that StreamLoD-GS achieves competitive or state-of-the-art performance in terms of quality, efficiency, and storage.]]></description>
<pubDate>Mon, 26 Jan 2026 13:27:46 +0000</pubDate>
</item>
<item>
<title><![CDATA[Latent Knowledge as a Predictor of Fact Acquisition in Fine-Tuned Large Language Models]]></title>
<link>http://arxiv.org/abs/2601.18468v1</link>
<guid>2601.18468v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.CL
Authors: Daniel B. Hier, Tayo Obafemi-Ajayi
Institution: 
Published: 2026-01-26
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Large language models store biomedical facts with uneven strength after pretraining: some facts are present in the weights but are not reliably accessible under deterministic decoding (latent knowledge), while others are scarcely represented. We fine tuned Llama 3.1 8B Instruct to learn ontology term identifier mappings from the Human Phenotype Ontology (800 pairs) and the Gene Ontology (400 training pairs), withholding 400 GO pairs to test generalization. Treating learning as a time to event process across 20 epochs, we used stochastic decoding to detect latent knowledge at baseline and Cox proportional hazards models to identify predictors of acquisition, generalization, and degradation. Baseline deterministic recall for HPO was 2.8%, rising to 71.9% after fine-tuning. Latent knowledge was the strongest predictor of faster fact acquisition (HR 2.6) and was associated with earlier, higher peak learning rates and faster convergence; identifier frequency and curated annotation counts had smaller effects. Generalization to withheld GO facts was uncommon (5.8%) but more likely when latent knowledge was present. Previously correct GO mappings degraded more often for withheld (unseen) terms than for trained (seen) terms, suggesting a protective effect of reinforcement during training. These results show that latent knowledge predicts both the speed of factual learning during fine-tuning and the limited generalization of unseen ontology facts, while resistance to degradation depends on whether facts are reinforced.]]></description>
<pubDate>Mon, 26 Jan 2026 13:15:23 +0000</pubDate>
</item>
<item>
<title><![CDATA[OffSeeker: Online Reinforcement Learning Is Not All You Need for Deep Research Agents]]></title>
<link>http://arxiv.org/abs/2601.18467v1</link>
<guid>2601.18467v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.AI, cs.LG
Authors: Yuhang Zhou, Kai Zheng, Qiguang Chen, Mengkang Hu, Qingfeng Sun et al.
Institution: 
Published: 2026-01-26
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Deep research agents have shown remarkable potential in handling long-horizon tasks. However, state-of-the-art performance typically relies on online reinforcement learning (RL), which is financially expensive due to extensive API calls. While offline training offers a more efficient alternative, its progress is hindered by the scarcity of high-quality research trajectories. In this paper, we demonstrate that expensive online reinforcement learning is not all you need to build powerful research agents. To bridge this gap, we introduce a fully open-source suite designed for effective offline training. Our core contributions include DeepForge, a ready-to-use task synthesis framework that generates large-scale research queries without heavy preprocessing; and a curated collection of 66k QA pairs, 33k SFT trajectories, and 21k DPO pairs. Leveraging these resources, we train OffSeeker (8B), a model developed entirely offline. Extensive evaluations across six benchmarks show that OffSeeker not only leads among similar-sized agents but also remains competitive with 30B-parameter systems trained via heavy online RL.]]></description>
<pubDate>Mon, 26 Jan 2026 13:13:59 +0000</pubDate>
</item>
<item>
<title><![CDATA[Fair-Eye Net: A Fair, Trustworthy, Multimodal Integrated Glaucoma Full Chain AI System]]></title>
<link>http://arxiv.org/abs/2601.18464v1</link>
<guid>2601.18464v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.CV, cs.AI
Authors: Wenbin Wei, Suyuan Yao, Cheng Huang, Xiangyu Gao
Institution: 
Published: 2026-01-26
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Glaucoma is a top cause of irreversible blindness globally, making early detection and longitudinal follow-up pivotal to preventing permanent vision loss. Current screening and progression assessment, however, rely on single tests or loosely linked examinations, introducing subjectivity and fragmented care. Limited access to high-quality imaging tools and specialist expertise further compromises consistency and equity in real-world use. To address these gaps, we developed Fair-Eye Net, a fair, reliable multimodal AI system closing the clinical loop from glaucoma screening to follow-up and risk alerting. It integrates fundus photos, OCT structural metrics, VF functional indices, and demographic factors via a dual-stream heterogeneous fusion architecture, with an uncertainty-aware hierarchical gating strategy for selective prediction and safe referral. A fairness constraint reduces missed diagnoses in disadvantaged subgroups. Experimental results show it achieved an AUC of 0.912 (96.7% specificity), cut racial false-negativity disparity by 73.4% (12.31% to 3.28%), maintained stable cross-domain performance, and enabled 3-12 months of early risk alerts (92% sensitivity, 88% specificity). Unlike post hoc fairness adjustments, Fair-Eye Net optimizes fairness as a primary goal with clinical reliability via multitask learning, offering a reproducible path for clinical translation and large-scale deployment to advance global eye health equity.]]></description>
<pubDate>Mon, 26 Jan 2026 13:12:24 +0000</pubDate>
</item>
<item>
<title><![CDATA[3DGesPolicy: Phoneme-Aware Holistic Co-Speech Gesture Generation Based on Action Control]]></title>
<link>http://arxiv.org/abs/2601.18451v1</link>
<guid>2601.18451v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.CV, cs.AI, cs.LG, cs.MM, cs.SD
Authors: Xuanmeng Sha, Liyun Zhang, Tomohiro Mashita, Naoya Chiba, Yuki Uranishi
Institution: 
Published: 2026-01-26
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Generating holistic co-speech gestures that integrate full-body motion with facial expressions suffers from semantically incoherent coordination on body motion and spatially unstable meaningless movements due to existing part-decomposed or frame-level regression methods, We introduce 3DGesPolicy, a novel action-based framework that reformulates holistic gesture generation as a continuous trajectory control problem through diffusion policy from robotics. By modeling frame-to-frame variations as unified holistic actions, our method effectively learns inter-frame holistic gesture motion patterns and ensures both spatially and semantically coherent movement trajectories that adhere to realistic motion manifolds. To further bridge the gap in expressive alignment, we propose a Gesture-Audio-Phoneme (GAP) fusion module that can deeply integrate and refine multi-modal signals, ensuring structured and fine-grained alignment between speech semantics, body motion, and facial expressions. Extensive quantitative and qualitative experiments on the BEAT2 dataset demonstrate the effectiveness of our 3DGesPolicy across other state-of-the-art methods in generating natural, expressive, and highly speech-aligned holistic gestures.]]></description>
<pubDate>Mon, 26 Jan 2026 12:57:36 +0000</pubDate>
</item>
<item>
<title><![CDATA[On Procrustes Contamination in Machine Learning Applications of Geometric Morphometrics]]></title>
<link>http://arxiv.org/abs/2601.18448v1</link>
<guid>2601.18448v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.CV, cs.LG
Authors: Lloyd Austin Courtenay
Institution: 
Published: 2026-01-26
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Geometric morphometrics (GMM) is widely used to quantify shape variation, more recently serving as input for machine learning (ML) analyses. Standard practice aligns all specimens via Generalized Procrustes Analysis (GPA) prior to splitting data into training and test sets, potentially introducing statistical dependence and contaminating downstream predictive models. Here, the effects of GPA-induced contamination are formally characterised using controlled 2D and 3D simulations across varying sample sizes, landmark densities, and allometric patterns. A novel realignment procedure is proposed, whereby test specimens are aligned to the training set prior to model fitting, eliminating cross-sample dependency. Simulations reveal a robust "diagonal" in sample-size vs. landmark-space, reflecting the scaling of RMSE under isotropic variation, with slopes analytically derived from the degrees of freedom in Procrustes tangent space. The importance of spatial autocorrelation among landmarks is further demonstrated using linear and convolutional regression models, highlighting performance degradation when landmark relationships are ignored. This work establishes the need for careful preprocessing in ML applications of GMM, provides practical guidelines for realignment, and clarifies fundamental statistical constraints inherent to Procrustes shape space.]]></description>
<pubDate>Mon, 26 Jan 2026 12:56:23 +0000</pubDate>
</item>
<item>
<title><![CDATA[GCFX: Generative Counterfactual Explanations for Deep Graph Models at the Model Level]]></title>
<link>http://arxiv.org/abs/2601.18447v1</link>
<guid>2601.18447v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.LG, cs.AI
Authors: Jinlong Hu, Jiacheng Liu
Institution: 
Published: 2026-01-26
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Deep graph learning models have demonstrated remarkable capabilities in processing graph-structured data and have been widely applied across various fields. However, their complex internal architectures and lack of transparency make it difficult to explain their decisions, resulting in opaque models that users find hard to understand and trust. In this paper, we explore model-level explanation techniques for deep graph learning models, aiming to provide users with a comprehensive understanding of the models' overall decision-making processes and underlying mechanisms. Specifically, we address the problem of counterfactual explanations for deep graph learning models by introducing a generative model-level counterfactual explanation approach called GCFX, which is based on deep graph generation. This approach generates a set of high-quality counterfactual explanations that reflect the model's global predictive behavior by leveraging an enhanced deep graph generation framework and a global summarization algorithm. GCFX features an architecture that combines dual encoders, structure-aware taggers, and Message Passing Neural Network decoders, enabling it to accurately learn the true latent distribution of input data and generate high-quality, closely related counterfactual examples. Subsequently, a global counterfactual summarization algorithm selects the most representative and comprehensive explanations from numerous candidate counterfactuals, providing broad insights into the model's global predictive patterns. Experiments on a synthetic dataset and several real-world datasets demonstrate that GCFX outperforms existing methods in terms of counterfactual validity and coverage while maintaining low explanation costs, thereby offering crucial support for enhancing the practicality and trustworthiness of global counterfactual explanations.]]></description>
<pubDate>Mon, 26 Jan 2026 12:56:01 +0000</pubDate>
</item>
<item>
<title><![CDATA[Scaling Behaviors of Evolutionary Algorithms on GPUs: When Does Parallelism Pay Off?]]></title>
<link>http://arxiv.org/abs/2601.18446v1</link>
<guid>2601.18446v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.NE
Authors: Xinmeng Yu, Tao Jiang, Ran Cheng, Yaochu Jin, Kay Chen Tan
Institution: 
Published: 2026-01-26
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Evolutionary algorithms (EAs) are increasingly implemented on graphics processing units (GPUs) to leverage parallel processing capabilities for enhanced efficiency. However, existing studies largely emphasize the raw speedup obtained by porting individual algorithms from CPUs to GPUs. Consequently, these studies offer limited insight into when and why GPU parallelism fundamentally benefits EAs. To address this gap, we investigate how GPU parallelism alters the behavior of EAs beyond simple acceleration metrics. We conduct a systematic empirical study of 16 representative EAs on 30 benchmark problems. Specifically, we compare CPU and GPU executions across a wide range of problem dimensionalities and population sizes. Our results reveal that the impact of GPU acceleration is highly heterogeneous and depends strongly on algorithmic structure. We further demonstrate that conventional fixed-budget evaluation based on the number of function evaluations (FEs) is inadequate for GPU execution. In contrast, fixed-time evaluation uncovers performance characteristics that are unobservable under small or practically constrained FE budgets, particularly for adaptive and exploration-oriented algorithms. Moreover, we identify distinct scaling regimes in which GPU parallelism is beneficial, saturates, or degrades as problem dimensionality and population size increase. Crucially, we show that large populations enabled by GPUs not only improve hardware utilization but also reveal algorithm-specific convergence and diversity dynamics that are difficult to observe under CPU-constrained settings. Consequently, our findings indicate that GPU parallelism is not strictly an implementation detail, but a pivotal factor that influences how EAs should be evaluated, compared, and designed for modern computing platforms.]]></description>
<pubDate>Mon, 26 Jan 2026 12:55:21 +0000</pubDate>
</item>
<item>
<title><![CDATA[Fusion of Spatio-Temporal and Multi-Scale Frequency Features for Dry Electrodes MI-EEG Decoding]]></title>
<link>http://arxiv.org/abs/2601.18424v1</link>
<guid>2601.18424v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.HC, cs.LG
Authors: Tianyi Gong, Can Han, Junxi Wu, Dahong Qian
Institution: 
Published: 2026-01-26
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Dry-electrode Motor Imagery Electroencephalography (MI-EEG) enables fast, comfortable, real-world Brain Computer Interface by eliminating gels and shortening setup for at-home and wearable use.However, dry recordings pose three main issues: lower Signal-to-Noise Ratio with more baseline drift and sudden transients; weaker and noisier data with poor phase alignment across trials; and bigger variances between sessions. These drawbacks lead to larger data distribution shift, making features less stable for MI-EEG tasks.To address these problems, we introduce STGMFM, a tri-branch framework tailored for dry-electrode MI-EEG, which models complementary spatio-temporal dependencies via dual graph orders, and captures robust envelope dynamics with a multi-scale frequency mixing branch, motivated by the observation that amplitude envelopes are less sensitive to contact variability than instantaneous waveforms. Physiologically meaningful connectivity priors guide learning, and decision-level fusion consolidates a noise-tolerant consensus. On our collected dry-electrode MI-EEG, STGMFM consistently surpasses competitive CNN/Transformer/graph baselines. Codes are available at https://github.com/Tianyi-325/STGMFM.]]></description>
<pubDate>Mon, 26 Jan 2026 12:35:23 +0000</pubDate>
</item>
<item>
<title><![CDATA[Gradient Regularized Natural Gradients]]></title>
<link>http://arxiv.org/abs/2601.18420v1</link>
<guid>2601.18420v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.LG, cs.AI
Authors: Satya Prakash Dash, Hossein Abdi, Wei Pan, Samuel Kaski, Mingfei Sun
Institution: 
Published: 2026-01-26
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Gradient regularization (GR) has been shown to improve the generalizability of trained models. While Natural Gradient Descent has been shown to accelerate optimization in the initial phase of training, little attention has been paid to how the training dynamics of second-order optimizers can benefit from GR. In this work, we propose Gradient-Regularized Natural Gradients (GRNG), a family of scalable second-order optimizers that integrate explicit gradient regularization with natural gradient updates. Our framework provides two complementary algorithms: a frequentist variant that avoids explicit inversion of the Fisher Information Matrix (FIM) via structured approximations, and a Bayesian variant based on a Regularized-Kalman formulation that eliminates the need for FIM inversion entirely. We establish convergence guarantees for GRNG, showing that gradient regularization improves stability and enables convergence to global minima. Empirically, we demonstrate that GRNG consistently enhances both optimization speed and generalization compared to first-order methods (SGD, AdamW) and second-order baselines (K-FAC, Sophia), with strong results on vision and language benchmarks. Our findings highlight gradient regularization as a principled and practical tool to unlock the robustness of natural gradient methods for large-scale deep learning.]]></description>
<pubDate>Mon, 26 Jan 2026 12:25:04 +0000</pubDate>
</item>
<item>
<title><![CDATA[Emergent Cooperation in Quantum Multi-Agent Reinforcement Learning Using Communication]]></title>
<link>http://arxiv.org/abs/2601.18419v1</link>
<guid>2601.18419v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.AI, cs.LG, cs.MA
Authors: Michael Klle, Christian Reff, Leo Snkel, Julian Hager, Gerhard Stenzel et al.
Institution: 
Published: 2026-01-26
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Emergent cooperation in classical Multi-Agent Reinforcement Learning has gained significant attention, particularly in the context of Sequential Social Dilemmas (SSDs). While classical reinforcement learning approaches have demonstrated capability for emergent cooperation, research on extending these methods to Quantum Multi-Agent Reinforcement Learning remains limited, particularly through communication. In this paper, we apply communication approaches to quantum Q-Learning agents: the Mutual Acknowledgment Token Exchange (MATE) protocol, its extension Mutually Endorsed Distributed Incentive Acknowledgment Token Exchange (MEDIATE), the peer rewarding mechanism Gifting, and Reinforced Inter-Agent Learning (RIAL). We evaluate these approaches in three SSDs: the Iterated Prisoner's Dilemma, Iterated Stag Hunt, and Iterated Game of Chicken. Our experimental results show that approaches using MATE with temporal-difference measure (MATE\textsubscript{TD}), AutoMATE, MEDIATE-I, and MEDIATE-S achieved high cooperation levels across all dilemmas, demonstrating that communication is a viable mechanism for fostering emergent cooperation in Quantum Multi-Agent Reinforcement Learning.]]></description>
<pubDate>Mon, 26 Jan 2026 12:21:05 +0000</pubDate>
</item>
<item>
<title><![CDATA[Pisets: A Robust Speech Recognition System for Lectures and Interviews]]></title>
<link>http://arxiv.org/abs/2601.18415v1</link>
<guid>2601.18415v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.CL, cs.SD
Authors: Ivan Bondarenko, Daniil Grebenkin, Oleg Sedukhin, Mikhail Klementev, Roman Derunets et al.
Institution: 
Published: 2026-01-26
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

This work presents a speech-to-text system "Pisets" for scientists and journalists which is based on a three-component architecture aimed at improving speech recognition accuracy while minimizing errors and hallucinations associated with the Whisper model. The architecture comprises primary recognition using Wav2Vec2, false positive filtering via the Audio Spectrogram Transformer (AST), and final speech recognition through Whisper. The implementation of curriculum learning methods and the utilization of diverse Russian-language speech corpora significantly enhanced the system's effectiveness. Additionally, advanced uncertainty modeling techniques were introduced, contributing to further improvements in transcription quality. The proposed approaches ensure robust transcribing of long audio data across various acoustic conditions compared to WhisperX and the usual Whisper model. The source code of "Pisets" system is publicly available at GitHub: https://github.com/bond005/pisets.]]></description>
<pubDate>Mon, 26 Jan 2026 12:14:51 +0000</pubDate>
</item>
<item>
<title><![CDATA[Comparative Evaluation of Machine Learning Algorithms for Affective State Recognition from Children's Drawings]]></title>
<link>http://arxiv.org/abs/2601.18414v1</link>
<guid>2601.18414v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.CV
Authors: Aura Loredana Dan
Institution: 
Published: 2026-01-26
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Autism spectrum disorder (ASD) represents a neurodevelopmental condition characterized by difficulties in expressing emotions and communication, particularly during early childhood. Understanding the affective state of children at an early age remains challenging, as conventional assessment methods are often intrusive, subjective, or difficult to apply consistently. This paper builds upon previous work on affective state recognition from children's drawings by presenting a comparative evaluation of machine learning models for emotion classification. Three deep learning architectures -- MobileNet, EfficientNet, and VGG16 -- are evaluated within a unified experimental framework to analyze classification performance, robustness, and computational efficiency. The models are trained using transfer learning on a dataset of children's drawings annotated with emotional labels provided by psychological experts. The results highlight important trade-offs between lightweight and deeper architectures when applied to drawing-based affective computing tasks, particularly in mobile and real-time application contexts.]]></description>
<pubDate>Mon, 26 Jan 2026 12:12:24 +0000</pubDate>
</item>
<item>
<title><![CDATA[Frequency-Based Hyperparameter Selection in Games]]></title>
<link>http://arxiv.org/abs/2601.18409v1</link>
<guid>2601.18409v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.LG
Authors: Aniket Sanyal, Baraah A. M. Sidahmed, Rebekka Burkholz, Tatjana Chavdarova
Institution: 
Published: 2026-01-26
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Learning in smooth games fundamentally differs from standard minimization due to rotational dynamics, which invalidate classical hyperparameter tuning strategies. Despite their practical importance, effective methods for tuning in games remain underexplored. A notable example is LookAhead (LA), which achieves strong empirical performance but introduces additional parameters that critically influence performance. We propose a principled approach to hyperparameter selection in games by leveraging frequency estimation of oscillatory dynamics. Specifically, we analyze oscillations both in continuous-time trajectories and through the spectrum of the discrete dynamics in the associated frequency-based space. Building on this analysis, we introduce \emph{Modal LookAhead (MoLA)}, an extension of LA that selects the hyperparameters adaptively to a given problem. We provide convergence guarantees and demonstrate in experiments that MoLA accelerates training in both purely rotational games and mixed regimes, all with minimal computational overhead.]]></description>
<pubDate>Mon, 26 Jan 2026 12:06:59 +0000</pubDate>
</item>
<item>
<title><![CDATA[Larger than memory image processing]]></title>
<link>http://arxiv.org/abs/2601.18407v1</link>
<guid>2601.18407v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.CV
Authors: Jon Sporring, David Stansby
Institution: 
Published: 2026-01-26
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

This report addresses larger-than-memory image analysis for petascale datasets such as 1.4 PB electron-microscopy volumes and 150 TB human-organ atlases. We argue that performance is fundamentally I/O-bound. We show that structuring analysis as streaming passes over data is crucial. For 3D volumes, two representations are popular: stacks of 2D slices (e.g., directories or multi-page TIFF) and 3D chunked layouts (e.g., Zarr/HDF5). While for a few algorithms, chunked layout on disk is crucial to keep disk I/O at a minimum, we show how the slice-based streaming architecture can be built on top of either image representation in a manner that minimizes disk I/O. This is in particular advantageous for algorithms relying on neighbouring values, since the slicing streaming architecture is 1D, which implies that there are only 2 possible sweeping orders, both of which are aligned with the order in which images are read from the disk. This is in contrast to 3D chunks, in which any sweep cannot be done without accessing each chunk at least 9 times. We formalize this with sweep-based execution (natural 2D/3D orders), windowed operations, and overlap-aware tiling to minimize redundant access. Building on these principles, we introduce a domain-specific language (DSL) that encodes algorithms with intrinsic knowledge of their optimal streaming and memory use; the DSL performs compile-time and run-time pipeline analyses to automatically select window sizes, fuse stages, tee and zip streams, and schedule passes for limited-RAM machines, yielding near-linear I/O scans and predictable memory footprints. The approach integrates with existing tooling for segmentation and morphology but reframes pre/post-processing as pipelines that privilege sequential read/write patterns, delivering substantial throughput gains for extremely large images without requiring full-volume residency in memory.]]></description>
<pubDate>Mon, 26 Jan 2026 12:02:41 +0000</pubDate>
</item>
<item>
<title><![CDATA[Superlinear Multi-Step Attention]]></title>
<link>http://arxiv.org/abs/2601.18401v1</link>
<guid>2601.18401v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.LG
Authors: Yufeng Huang
Institution: 
Published: 2026-01-26
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

In this paper, we propose \textbf{Superlinear attention}, a fully trainable multi-step attention architecture that achieves subquadratic complexity for long sequences while preserving \textbf{random context access} (a.k.a.\ structural non-exclusion): no eligible token position is structurally excluded from being selected for attention. Superlinear attention reformulates standard causal self-attention as a multi-step search problem with $N$ steps, yielding an overall complexity of $O(L^{1+\frac{1}{N}})$. To illustrate the architecture, we present a baseline $N=2$ implementation, which is algorithmically analogous to standard jump search. In this $O(L^{3/2})$ instantiation, the first step performs $O(L^{3/2})$ span-search to select relevant spans of the sequence, and the second step applies $O(L^{3/2})$ span-attention (standard attention restricted to the selected spans). In an upscaled $O(L^{1.54})$ configuration for robustness, we achieve an average decoding throughput of 114 tokens/sec at 1M context length and 80 tokens/sec at 10M context in our implementation on a modified 30B hybrid MoE model on a single B200 GPU. With limited training, we also obtain strong performance on the NIAH (Needle In A Haystack) task up to 256K context length, demonstrating that the routed span selection is learnable end-to-end. This paper emphasizes architectural formulation, scaling analysis, and systems feasibility, and presents initial validation; comprehensive quality evaluations across diverse long-context tasks are left to future work.]]></description>
<pubDate>Mon, 26 Jan 2026 11:58:42 +0000</pubDate>
</item>
<item>
<title><![CDATA[Estimating Dense-Packed Zone Height in Liquid-Liquid Separation: A Physics-Informed Neural Network Approach]]></title>
<link>http://arxiv.org/abs/2601.18399v1</link>
<guid>2601.18399v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.LG
Authors: Mehmet Velioglu, Song Zhai, Alexander Mitsos, Adel Mhamdi, Andreas Jupke et al.
Institution: MIT
Published: 2026-01-26
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Separating liquid-liquid dispersions in gravity settlers is critical in chemical, pharmaceutical, and recycling processes. The dense-packed zone height is an important performance and safety indicator but it is often expensive and impractical to measure due to optical limitations. We propose to estimate phase heights using only inexpensive volume flow measurements. To this end, a physics-informed neural network (PINN) is first pretrained on synthetic data and physics equations derived from a low-fidelity (approximate) mechanistic model to reduce the need for extensive experimental data. While the mechanistic model is used to generate synthetic training data, only volume balance equations are used in the PINN, since the integration of submodels describing droplet coalescence and sedimentation into the PINN would be computationally prohibitive. The pretrained PINN is then fine-tuned with scarce experimental data to capture the actual dynamics of the separator. We then employ the differentiable PINN as a predictive model in an Extended Kalman Filter inspired state estimation framework, enabling the phase heights to be tracked and updated from flow-rate measurements. We first test the two-stage trained PINN by forward simulation from a known initial state against the mechanistic model and a non-pretrained PINN. We then evaluate phase height estimation performance with the filter, comparing the two-stage trained PINN with a two-stage trained purely data-driven neural network. All model types are trained and evaluated using ensembles to account for model parameter uncertainty. In all evaluations, the two-stage trained PINN yields the most accurate phase-height estimates.]]></description>
<pubDate>Mon, 26 Jan 2026 11:57:28 +0000</pubDate>
</item>
<item>
<title><![CDATA[Noise-Robust AV-ASR Using Visual Features Both in the Whisper Encoder and Decoder]]></title>
<link>http://arxiv.org/abs/2601.18396v1</link>
<guid>2601.18396v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.CL, cs.CV, cs.SD
Authors: Zhengyang Li, Thomas Graave, Bjrn Mller, Zehang Wu, Matthias Franz et al.
Institution: 
Published: 2026-01-26
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

In audiovisual automatic speech recognition (AV-ASR) systems, information fusion of visual features in a pre-trained ASR has been proven as a promising method to improve noise robustness. In this work, based on the prominent Whisper ASR, first, we propose a simple and effective visual fusion method -- use of visual features both in encoder and decoder (dual-use) -- to learn the audiovisual interactions in the encoder and to weigh modalities in the decoder. Second, we compare visual fusion methods in Whisper models of various sizes. Our proposed dual-use method shows consistent noise robustness improvement, e.g., a 35% relative improvement (WER: 4.41% vs. 6.83%) based on Whisper small, and a 57% relative improvement (WER: 4.07% vs. 9.53%) based on Whisper medium, compared to typical reference middle fusion in babble noise with a signal-to-noise ratio (SNR) of 0dB. Third, we conduct ablation studies examining the impact of various module designs and fusion options. Fine-tuned on 1929 hours of audiovisual data, our dual-use method using Whisper medium achieves 4.08% (MUSAN babble noise) and 4.43% (NoiseX babble noise) average WER across various SNRs, thereby establishing a new state-of-the-art in noisy conditions on the LRS3 AV-ASR benchmark. Our code is at https://github.com/ifnspaml/Dual-Use-AVASR]]></description>
<pubDate>Mon, 26 Jan 2026 11:55:07 +0000</pubDate>
</item>
<item>
<title><![CDATA[Do not be greedy, Think Twice: Sampling and Selection for Document-level Information Extraction]]></title>
<link>http://arxiv.org/abs/2601.18395v1</link>
<guid>2601.18395v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.CL
Authors: Mikel Zubillaga, Oscar Sainz, Oier Lopez de Lacalle, Eneko Agirre
Institution: 
Published: 2026-01-26
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Document-level Information Extraction (DocIE) aims to produce an output template with the entities and relations of interest occurring in the given document. Standard practices include prompting decoder-only LLMs using greedy decoding to avoid output variability. Rather than treating this variability as a limitation, we show that sampling can produce substantially better solutions than greedy decoding, especially when using reasoning models. We thus propose ThinkTwice, a sampling and selection framework in which the LLM generates multiple candidate templates for a given document, and a selection module chooses the most suitable one. We introduce both an unsupervised method that exploits agreement across generated outputs, and a supervised selection method using reward models trained on labeled DocIE data. To address the scarcity of golden reasoning trajectories for DocIE, we propose a rejection-sampling-based method to generate silver training data that pairs output templates with reasoning traces. Our experiments show the validity of unsupervised and supervised ThinkTwice, consistently outperforming greedy baselines and the state-of-the-art.]]></description>
<pubDate>Mon, 26 Jan 2026 11:53:08 +0000</pubDate>
</item>
<item>
<title><![CDATA[OCR-Enhanced Multimodal ASR Can Read While Listening]]></title>
<link>http://arxiv.org/abs/2601.18393v1</link>
<guid>2601.18393v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.SD, cs.CL
Authors: Junli Chen, Changli Tang, Yixuan Li, Guangzhi Sun, Chao Zhang
Institution: 
Published: 2026-01-26
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Visual information, such as subtitles in a movie, often helps automatic speech recognition. In this paper, we propose Donut-Whisper, an audio-visual ASR model with dual encoder to leverage visual information to improve speech recognition performance in both English and Chinese. Donut-Whisper combines the advantage of the linear and the Q-Former-based modality alignment structures via a cross-attention module, generating more powerful audio-visual features. Meanwhile, we propose a lightweight knowledge distillation scheme showcasing the potential of using audio-visual models to teach audio-only models to achieve better performance. Moreover, we propose a new multilingual audio-visual speech recognition dataset based on movie clips containing both Chinese and English partitions. As a result, Donut-Whisper achieved significantly better performance on both English and Chinese partition of the dataset compared to both Donut and Whisper large V3 baselines. In particular, an absolute 5.75% WER reduction and a 16.5% absolute CER reduction were achieved on the English and Chinese sets respectively compared to the Whisper ASR baseline.]]></description>
<pubDate>Mon, 26 Jan 2026 11:51:08 +0000</pubDate>
</item>
<item>
<title><![CDATA[Efficient Complex-Valued Vision Transformers for MRI Classification Directly from k-Space]]></title>
<link>http://arxiv.org/abs/2601.18392v1</link>
<guid>2601.18392v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.CV
Authors: Moritz Rempe, Lukas T. Rotkopf, Marco Schlimbach, Helmut Becker, Fabian Hrst et al.
Institution: 
Published: 2026-01-26
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Deep learning applications in Magnetic Resonance Imaging (MRI) predominantly operate on reconstructed magnitude images, a process that discards phase information and requires computationally expensive transforms. Standard neural network architectures rely on local operations (convolutions or grid-patches) that are ill-suited for the global, non-local nature of raw frequency-domain (k-Space) data. In this work, we propose a novel complex-valued Vision Transformer (kViT) designed to perform classification directly on k-Space data. To bridge the geometric disconnect between current architectures and MRI physics, we introduce a radial k-Space patching strategy that respects the spectral energy distribution of the frequency-domain. Extensive experiments on the fastMRI and in-house datasets demonstrate that our approach achieves classification performance competitive with state-of-the-art image-domain baselines (ResNet, EfficientNet, ViT). Crucially, kViT exhibits superior robustness to high acceleration factors and offers a paradigm shift in computational efficiency, reducing VRAM consumption during training by up to 68$\times$ compared to standard methods. This establishes a pathway for resource-efficient, direct-from-scanner AI analysis.]]></description>
<pubDate>Mon, 26 Jan 2026 11:50:52 +0000</pubDate>
</item>
<item>
<title><![CDATA[ARMOR: Agentic Reasoning for Methods Orchestration and Reparameterization for Robust Adversarial Attacks]]></title>
<link>http://arxiv.org/abs/2601.18386v1</link>
<guid>2601.18386v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.CV
Authors: Gabriel Lee Jun Rong, Christos Korgialas, Dion Jia Xu Ho, Pai Chet Ng, Xiaoxiao Miao et al.
Institution: 
Published: 2026-01-26
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Existing automated attack suites operate as static ensembles with fixed sequences, lacking strategic adaptation and semantic awareness. This paper introduces the Agentic Reasoning for Methods Orchestration and Reparameterization (ARMOR) framework to address these limitations. ARMOR orchestrates three canonical adversarial primitives, Carlini-Wagner (CW), Jacobian-based Saliency Map Attack (JSMA), and Spatially Transformed Attacks (STA) via Vision Language Models (VLM)-guided agents that collaboratively generate and synthesize perturbations through a shared ``Mixing Desk". Large Language Models (LLMs) adaptively tune and reparameterize parallel attack agents in a real-time, closed-loop system that exploits image-specific semantic vulnerabilities. On standard benchmarks, ARMOR achieves improved cross-architecture transfer and reliably fools both settings, delivering a blended output for blind targets and selecting the best attack or blended attacks for white-box targets using a confidence-and-SSIM score.]]></description>
<pubDate>Mon, 26 Jan 2026 11:36:34 +0000</pubDate>
</item>
<item>
<title><![CDATA[Estimation of geometric transformation matrices using grid-shaped pilot signals]]></title>
<link>http://arxiv.org/abs/2601.18385v1</link>
<guid>2601.18385v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.CV
Authors: Rinka Kawano, Masaki Kawamura
Institution: 
Published: 2026-01-26
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Digital watermarking techniques are essential to prevent unauthorized use of images. Since pirated images are often geometrically distorted by operations such as scaling and cropping, accurate synchronization - detecting the embedding position of the watermark - is critical for proper extraction. In particular, cropping changes the origin of the image, making synchronization difficult. However, few existing methods are robust against cropping. To address this issue, we propose a watermarking method that estimates geometric transformations applied to a stego image using a pilot signal, allowing synchronization even after cropping. A grid-shaped pilot signal with distinct horizontal and vertical values is embedded in the image. When the image is transformed, the grid is also distorted. By analyzing this distortion, the transformation matrix can be estimated. Applying the Radon transform to the distorted image allows estimation of the grid angles and intervals. In addition, since the horizontal and vertical grid lines are encoded differently, the grid orientation can be determined, which reduces ambiguity. To validate our method, we performed simulations with anisotropic scaling, rotation, shearing, and cropping. The results show that the proposed method accurately estimates transformation matrices with low error under both single and composite attacks.]]></description>
<pubDate>Mon, 26 Jan 2026 11:33:01 +0000</pubDate>
</item>
<item>
<title><![CDATA[Dynamic Thinking-Token Selection for Efficient Reasoning in Large Reasoning Models]]></title>
<link>http://arxiv.org/abs/2601.18383v1</link>
<guid>2601.18383v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.AI, cs.CL, cs.LG
Authors: Zhenyuan Guo, Tong Chen, Wenlong Meng, Chen Gong, Xin Yu et al.
Institution: 
Published: 2026-01-26
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Large Reasoning Models (LRMs) excel at solving complex problems by explicitly generating a reasoning trace before deriving the final answer. However, these extended generations incur substantial memory footprint and computational overhead, bottlenecking LRMs' efficiency. This work uses attention maps to analyze the influence of reasoning traces and uncover an interesting phenomenon: only some decision-critical tokens in a reasoning trace steer the model toward the final answer, while the remaining tokens contribute negligibly. Building on this observation, we propose Dynamic Thinking-Token Selection (DynTS). This method identifies decision-critical tokens and retains only their associated Key-Value (KV) cache states during inference, evicting the remaining redundant entries to optimize efficiency.]]></description>
<pubDate>Mon, 26 Jan 2026 11:31:40 +0000</pubDate>
</item>
<item>
<title><![CDATA[AI Agent for Reverse-Engineering Legacy Finite-Difference Code and Translating to Devito]]></title>
<link>http://arxiv.org/abs/2601.18381v1</link>
<guid>2601.18381v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.AI, cs.SE
Authors: Yinghan Hou, Zongyou Yang
Institution: 
Published: 2026-01-26
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

To facilitate the transformation of legacy finite difference implementations into the Devito environment, this study develops an integrated AI agent framework. Retrieval-Augmented Generation (RAG) and open-source Large Language Models are combined through multi-stage iterative workflows in the system's hybrid LangGraph architecture. The agent constructs an extensive Devito knowledge graph through document parsing, structure-aware segmentation, extraction of entity relationships, and Leiden-based community detection. GraphRAG optimisation enhances query performance across semantic communities that include seismic wave simulation, computational fluid dynamics, and performance tuning libraries. A reverse engineering component derives three-level query strategies for RAG retrieval through static analysis of Fortran source code. To deliver precise contextual information for language model guidance, the multi-stage retrieval pipeline performs parallel searching, concept expansion, community-scale retrieval, and semantic similarity analysis. Code synthesis is governed by Pydantic-based constraints to guarantee structured outputs and reliability. A comprehensive validation framework integrates conventional static analysis with the G-Eval approach, covering execution correctness, structural soundness, mathematical consistency, and API compliance. The overall agent workflow is implemented on the LangGraph framework and adopts concurrent processing to support quality-based iterative refinement and state-aware dynamic routing. The principal contribution lies in the incorporation of feedback mechanisms motivated by reinforcement learning, enabling a transition from static code translation toward dynamic and adaptive analytical behavior.]]></description>
<pubDate>Mon, 26 Jan 2026 11:31:00 +0000</pubDate>
</item>
<item>
<title><![CDATA[Corpus-Based Approaches to Igbo Diacritic Restoration]]></title>
<link>http://arxiv.org/abs/2601.18380v1</link>
<guid>2601.18380v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.CL, cs.CY, cs.IR
Authors: Ignatius Ezeani
Institution: 
Published: 2026-01-26
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

With natural language processing (NLP), researchers aim to enable computers to identify and understand patterns in human languages. This is often difficult because a language embeds many dynamic and varied properties in its syntax, pragmatics and phonology, which need to be captured and processed. The capacity of computers to process natural languages is increasing because NLP researchers are pushing its boundaries. But these research works focus more on well-resourced languages such as English, Japanese, German, French, Russian, Mandarin Chinese, etc. Over 95% of the world's 7000 languages are low-resourced for NLP, i.e. they have little or no data, tools, and techniques for NLP work.
  In this thesis, we present an overview of diacritic ambiguity and a review of previous diacritic disambiguation approaches on other languages. Focusing on the Igbo language, we report the steps taken to develop a flexible framework for generating datasets for diacritic restoration. Three main approaches, the standard n-gram model, the classification models and the embedding models were proposed. The standard n-gram models use a sequence of previous words to the target stripped word as key predictors of the correct variants. For the classification models, a window of words on both sides of the target stripped word was used. The embedding models compare the similarity scores of the combined context word embeddings and the embeddings of each of the candidate variant vectors.]]></description>
<pubDate>Mon, 26 Jan 2026 11:30:36 +0000</pubDate>
</item>
<item>
<title><![CDATA[Hierarchical Text Classification with LLM-Refined Taxonomies]]></title>
<link>http://arxiv.org/abs/2601.18375v1</link>
<guid>2601.18375v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.CL
Authors: Jonas Golde, Nicolaas Jedema, Ravi Krishnan, Phong Le
Institution: 
Published: 2026-01-26
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Hierarchical text classification (HTC) depends on taxonomies that organize labels into structured hierarchies. However, many real-world taxonomies introduce ambiguities, such as identical leaf names under similar parent nodes, which prevent language models (LMs) from learning clear decision boundaries. In this paper, we present TaxMorph, a framework that uses large language models (LLMs) to transform entire taxonomies through operations such as renaming, merging, splitting, and reordering. Unlike prior work, our method revises the full hierarchy to better match the semantics encoded by LMs. Experiments across three HTC benchmarks show that LLM-refined taxonomies consistently outperform human-curated ones in various settings up to +2.9pp. in F1. To better understand these improvements, we compare how well LMs can assign leaf nodes to parent nodes and vice versa across human-curated and LLM-refined taxonomies. We find that human-curated taxonomies lead to more easily separable clusters in embedding space. However, the LLM-refined taxonomies align more closely with the model's actual confusion patterns during classification. In other words, even though they are harder to separate, they better reflect the model's inductive biases. These findings suggest that LLM-guided refinement creates taxonomies that are more compatible with how models learn, improving HTC performance.]]></description>
<pubDate>Mon, 26 Jan 2026 11:28:32 +0000</pubDate>
</item>
<item>
<title><![CDATA[CitiLink: Enhancing Municipal Transparency and Citizen Engagement through Searchable Meeting Minutes]]></title>
<link>http://arxiv.org/abs/2601.18374v1</link>
<guid>2601.18374v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.CL
Authors: Rodrigo Silva, Jos Evans, Jos Isidro, Miguel Marques, Afonso Fonseca et al.
Institution: 
Published: 2026-01-26
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

City council minutes are typically lengthy and formal documents with a bureaucratic writing style. Although publicly available, their structure often makes it difficult for citizens or journalists to efficiently find information. In this demo, we present CitiLink, a platform designed to transform unstructured municipal meeting minutes into structured and searchable data, demonstrating how NLP and IR can enhance the accessibility and transparency of local government. The system employs LLMs to extract metadata, discussed subjects, and voting outcomes, which are then indexed in a database to support full-text search with BM25 ranking and faceted filtering through a user-friendly interface. The developed system was built over a collection of 120 minutes made available by six Portuguese municipalities. To assess its usability, CitiLink was tested through guided sessions with municipal personnel, providing insights into how real users interact with the system. In addition, we evaluated Gemini's performance in extracting relevant information from the minutes, highlighting its effectiveness in data extraction.]]></description>
<pubDate>Mon, 26 Jan 2026 11:26:57 +0000</pubDate>
</item>
<item>
<title><![CDATA[Gaze Prediction in Virtual Reality Without Eye Tracking Using Visual and Head Motion Cues]]></title>
<link>http://arxiv.org/abs/2601.18372v1</link>
<guid>2601.18372v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.CV
Authors: Christos Petrou, Harris Partaourides, Athanasios Balomenos, Yannis Kopsinis, Sotirios Chatzis
Institution: 
Published: 2026-01-26
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Gaze prediction plays a critical role in Virtual Reality (VR) applications by reducing sensor-induced latency and enabling computationally demanding techniques such as foveated rendering, which rely on anticipating user attention. However, direct eye tracking is often unavailable due to hardware limitations or privacy concerns. To address this, we present a novel gaze prediction framework that combines Head-Mounted Display (HMD) motion signals with visual saliency cues derived from video frames. Our method employs UniSal, a lightweight saliency encoder, to extract visual features, which are then fused with HMD motion data and processed through a time-series prediction module. We evaluate two lightweight architectures, TSMixer and LSTM, for forecasting future gaze directions. Experiments on the EHTask dataset, along with deployment on commercial VR hardware, show that our approach consistently outperforms baselines such as Center-of-HMD and Mean Gaze. These results demonstrate the effectiveness of predictive gaze modeling in reducing perceptual lag and enhancing natural interaction in VR environments where direct eye tracking is constrained.]]></description>
<pubDate>Mon, 26 Jan 2026 11:26:27 +0000</pubDate>
</item>
<item>
<title><![CDATA[OREHAS: A fully automated deep-learning pipeline for volumetric endolymphatic hydrops quantification in MRI]]></title>
<link>http://arxiv.org/abs/2601.18368v1</link>
<guid>2601.18368v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.CV
Authors: Caterina Fuster-Barcel, Claudia Castrilln, Laura Rodrigo-Muoz, Victor Manuel Vega-Surez, Nicols Prez-Fernndez et al.
Institution: 
Published: 2026-01-26
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

We present OREHAS (Optimized Recognition & Evaluation of volumetric Hydrops in the Auditory System), the first fully automatic pipeline for volumetric quantification of endolymphatic hydrops (EH) from routine 3D-SPACE-MRC and 3D-REAL-IR MRI. The system integrates three components -- slice classification, inner ear localization, and sequence-specific segmentation -- into a single workflow that computes per-ear endolymphatic-to-vestibular volume ratios (ELR) directly from whole MRI volumes, eliminating the need for manual intervention.
  Trained with only 3 to 6 annotated slices per patient, OREHAS generalized effectively to full 3D volumes, achieving Dice scores of 0.90 for SPACE-MRC and 0.75 for REAL-IR. In an external validation cohort with complete manual annotations, OREHAS closely matched expert ground truth (VSI = 74.3%) and substantially outperformed the clinical syngo.via software (VSI = 42.5%), which tended to overestimate endolymphatic volumes. Across 19 test patients, vestibular measurements from OREHAS were consistent with syngo.via, while endolymphatic volumes were systematically smaller and more physiologically realistic.
  These results show that reliable and reproducible EH quantification can be achieved from standard MRI using limited supervision. By combining efficient deep-learning-based segmentation with a clinically aligned volumetric workflow, OREHAS reduces operator dependence, ensures methodological consistency. Besides, the results are compatible with established imaging protocols. The approach provides a robust foundation for large-scale studies and for recalibrating clinical diagnostic thresholds based on accurate volumetric measurements of the inner ear.]]></description>
<pubDate>Mon, 26 Jan 2026 11:19:21 +0000</pubDate>
</item>
<item>
<title><![CDATA[Making medical vision-language models think causally across modalities with retrieval-augmented cross-modal reasoning]]></title>
<link>http://arxiv.org/abs/2601.18356v1</link>
<guid>2601.18356v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.LG
Authors: Weiqin Yang, Haowen Xue, Qingyi Peng, Hexuan Hu, Qian Huang et al.
Institution: 
Published: 2026-01-26
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Medical vision-language models (VLMs) achieve strong performance in diagnostic reporting and image-text alignment, yet their underlying reasoning mechanisms remain fundamentally correlational, exhibiting reliance on superficial statistical associations that fail to capture the causal pathophysiological mechanisms central to clinical decision-making. This limitation makes them fragile, prone to hallucinations, and sensitive to dataset biases. Retrieval-augmented generation (RAG) offers a partial remedy by grounding predictions in external knowledge. However, conventional RAG depends on semantic similarity, introducing new spurious correlations. We propose Multimodal Causal Retrieval-Augmented Generation, a framework that integrates causal inference principles with multimodal retrieval. It retrieves clinically relevant exemplars and causal graphs from external sources, conditioning model reasoning on counterfactual and interventional evidence rather than correlations alone. Applied to radiology report generation, diagnosis prediction, and visual question answering, it improves factual accuracy, robustness to distribution shifts, and interpretability. Our results highlight causal retrieval as a scalable path toward medical VLMs that think beyond pattern matching, enabling trustworthy multimodal reasoning in high-stakes clinical settings.]]></description>
<pubDate>Mon, 26 Jan 2026 11:03:00 +0000</pubDate>
</item>
<item>
<title><![CDATA[Can Good Writing Be Generative? Expert-Level AI Writing Emerges through Fine-Tuning on High-Quality Books]]></title>
<link>http://arxiv.org/abs/2601.18353v1</link>
<guid>2601.18353v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.AI, cs.CL, cs.HC
Authors: Tuhin Chakrabarty, Paramveer S. Dhillon
Institution: 
Published: 2026-01-26
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Creative writing has long been considered a uniquely human endeavor, requiring voice and style that machines could not replicate. This assumption is challenged by Generative AI that can emulate thousands of author styles in seconds with negligible marginal labor. To understand this better, we conducted a behavioral experiment where 28 MFA writers (experts) competed against three LLMs in emulating 50 critically acclaimed authors. Based on blind pairwise comparisons by 28 expert judges and 131 lay judges, we find that experts preferred human writing in 82.7% of cases under the in-context prompting condition but this reversed to 62% preference for AI after fine-tuning on authors' complete works. Lay judges, however, consistently preferred AI writing. Debrief interviews with expert writers revealed that their preference for AI writing triggered an identity crisis, eroding aesthetic confidence and questioning what constitutes "good writing." These findings challenge discourse about AI's creative limitations and raise fundamental questions about the future of creative labor.]]></description>
<pubDate>Mon, 26 Jan 2026 10:59:21 +0000</pubDate>
</item>
<item>
<title><![CDATA[Code over Words: Overcoming Semantic Inertia via Code-Grounded Reasoning]]></title>
<link>http://arxiv.org/abs/2601.18352v1</link>
<guid>2601.18352v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.CL, cs.AI
Authors: Manjie Xu, Isabella Yin, Xinyi Tu, Chi Zhang, Yixin Zhu
Institution: 
Published: 2026-01-26
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

LLMs struggle with Semantic Inertia: the inability to inhibit pre-trained priors (e.g., "Lava is Dangerous") when dynamic, in-context rules contradict them. We probe this phenomenon using Baba Is You, where physical laws are mutable text rules, enabling precise evaluation of models' ability to override learned priors when rules change. We quantatively observe that larger models can exhibit inverse scaling: they perform worse than smaller models when natural language reasoning requires suppressing pre-trained associations (e.g., accepting "Lava is Safe"). Our analysis attributes this to natural language encoding, which entangles descriptive semantics and logical rules, leading to persistent hallucinations of familiar physics despite explicit contradictory rules. Here we show that representing dynamics as executable code, rather than descriptive text, reverses this trend and enables effective prior inhibition. We introduce Code-Grounded Vistas (LCV), which fine-tunes models on counterfactual pairs and identifies states with contradictory rules, thereby forcing attention to logical constraints rather than visual semantics. This training-time approach outperforms expensive inference-time search methods in both efficiency and accuracy. Our results demonstrate that representation fundamentally determines whether scaling improves or impairs contextual reasoning. This challenges the assumption that larger models are universally better, with implications for domains that require dynamic overriding of learned priors.]]></description>
<pubDate>Mon, 26 Jan 2026 10:58:52 +0000</pubDate>
</item>
<item>
<title><![CDATA[When Domain Pretraining Interferes with Instruction Alignment: An Empirical Study of Adapter Merging in Medical LLMs]]></title>
<link>http://arxiv.org/abs/2601.18350v1</link>
<guid>2601.18350v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.CL, cs.AI
Authors: Junyi Zou
Institution: 
Published: 2026-01-26
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Large language models (LLMs) show strong general capability but often struggle with medical terminology precision and safety-critical instruction following. We present a case study for adapter interference in safety-critical domains using a 14B-parameter base model through a two-stage LoRA pipeline: (1) domain-adaptive pre-training (PT) to inject broad medical knowledge via continued pre-training (DAPT), and (2) supervised fine-tuning (SFT) to align the model with medical question-answering behaviors through instruction-style data. To balance instruction-following ability and domain knowledge retention, we propose Weighted Adapter Merging, linearly combining SFT and PT adapters before exporting a merged base-model checkpoint. On a held-out medical validation set (F5/F6), the merged model achieves BLEU-4 = 16.38, ROUGE-1 = 20.42, ROUGE-2 = 4.60, and ROUGE-L = 11.54 under a practical decoding configuration. We further analyze decoding sensitivity and training stability with loss curves and controlled decoding comparisons.]]></description>
<pubDate>Mon, 26 Jan 2026 10:54:06 +0000</pubDate>
</item>
<item>
<title><![CDATA[Q-Bench-Portrait: Benchmarking Multimodal Large Language Models on Portrait Image Quality Perception]]></title>
<link>http://arxiv.org/abs/2601.18346v1</link>
<guid>2601.18346v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.CV
Authors: Sijing Wu, Yunhao Li, Zicheng Zhang, Qi Jia, Xinyue Li et al.
Institution: 
Published: 2026-01-26
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Recent advances in multimodal large language models (MLLMs) have demonstrated impressive performance on existing low-level vision benchmarks, which primarily focus on generic images. However, their capabilities to perceive and assess portrait images, a domain characterized by distinct structural and perceptual properties, remain largely underexplored. To this end, we introduce Q-Bench-Portrait, the first holistic benchmark specifically designed for portrait image quality perception, comprising 2,765 image-question-answer triplets and featuring (1) diverse portrait image sources, including natural, synthetic distortion, AI-generated, artistic, and computer graphics images; (2) comprehensive quality dimensions, covering technical distortions, AIGC-specific distortions, and aesthetics; and (3) a range of question formats, including single-choice, multiple-choice, true/false, and open-ended questions, at both global and local levels. Based on Q-Bench-Portrait, we evaluate 20 open-source and 5 closed-source MLLMs, revealing that although current models demonstrate some competence in portrait image perception, their performance remains limited and imprecise, with a clear gap relative to human judgments. We hope that the proposed benchmark will foster further research into enhancing the portrait image perception capabilities of both general-purpose and domain-specific MLLMs.]]></description>
<pubDate>Mon, 26 Jan 2026 10:37:20 +0000</pubDate>
</item>
<item>
<title><![CDATA[Structural Gender Bias in Credit Scoring: Proxy Leakage]]></title>
<link>http://arxiv.org/abs/2601.18342v1</link>
<guid>2601.18342v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.LG
Authors: Navya SD, Sreekanth D, SS Uma Sankari
Institution: 
Published: 2026-01-26
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

As financial institutions increasingly adopt machine learning for credit risk assessment, the persistence of algorithmic bias remains a critical barrier to equitable financial inclusion. This study provides a comprehensive audit of structural gender bias within the Taiwan Credit Default dataset, specifically challenging the prevailing doctrine of "fairness through blindness." Despite the removal of explicit protected attributes and the application of industry standard fairness interventions, our results demonstrate that gendered predictive signals remain deeply embedded within non-sensitive features. Utilizing SHAP (SHapley Additive exPlanations), we identify that variables such as Marital Status, Age, and Credit Limit function as potent proxies for gender, allowing models to maintain discriminatory pathways while appearing statistically fair. To mathematically quantify this leakage, we employ an adversarial inverse modeling framework. Our findings reveal that the protected gender attribute can be reconstructed from purely non-sensitive financial features with an ROC AUC score of 0.65, demonstrating that traditional fairness audits are insufficient for detecting implicit structural bias. These results advocate for a shift from surface-level statistical parity toward causal-aware modeling and structural accountability in financial AI.]]></description>
<pubDate>Mon, 26 Jan 2026 10:29:45 +0000</pubDate>
</item>
<item>
<title><![CDATA[Beyond Rigid: Benchmarking Non-Rigid Video Editing]]></title>
<link>http://arxiv.org/abs/2601.18340v1</link>
<guid>2601.18340v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.CV
Authors: Bingzheng Qu, Kehai Chen, Xuefeng Bai, Jun Yu, Min Zhang
Institution: 
Published: 2026-01-26
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Despite the remarkable progress in text-driven video editing, generating coherent non-rigid deformations remains a critical challenge, often plagued by physical distortion and temporal flicker. To bridge this gap, we propose NRVBench, the first dedicated and comprehensive benchmark designed to evaluate non-rigid video editing. First, we curate a high-quality dataset consisting of 180 non-rigid motion videos from six physics-based categories, equipped with 2,340 fine-grained task instructions and 360 multiple-choice questions. Second, we propose NRVE-Acc, a novel evaluation metric based on Vision-Language Models that can rigorously assess physical compliance, temporal consistency, and instruction alignment, overcoming the limitations of general metrics in capturing complex dynamics. Third, we introduce a training-free baseline, VM-Edit, which utilizes a dual-region denoising mechanism to achieve structure-aware control, balancing structural preservation and dynamic deformation. Extensive experiments demonstrate that while current methods have shortcomings in maintaining physical plausibility, our method achieves excellent performance across both standard and proposed metrics. We believe the benchmark could serve as a standard testing platform for advancing physics-aware video editing.]]></description>
<pubDate>Mon, 26 Jan 2026 10:28:09 +0000</pubDate>
</item>
<item>
<title><![CDATA[A Dataset for Automatic Vocal Mode Classification]]></title>
<link>http://arxiv.org/abs/2601.18339v1</link>
<guid>2601.18339v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.SD, cs.LG
Authors: Reemt Hinrichs, Sonja Stephan, Alexander Lange, Jrn Ostermann
Institution: 
Published: 2026-01-26
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

The Complete Vocal Technique (CVT) is a school of singing developed in the past decades by Cathrin Sadolin et al.. CVT groups the use of the voice into so called vocal modes, namely Neutral, Curbing, Overdrive and Edge. Knowledge of the desired vocal mode can be helpful for singing students. Automatic classification of vocal modes can thus be important for technology-assisted singing teaching. Previously, automatic classification of vocal modes has been attempted without major success, potentially due to a lack of data. Therefore, we recorded a novel vocal mode dataset consisting of sustained vowels recorded from four singers, three of which professional singers with more than five years of CVT-experience. The dataset covers the entire vocal range of the subjects, totaling 3,752 unique samples. By using four microphones, thereby offering a natural data augmentation, the dataset consists of more than 13,000 samples combined. An annotation was created using three CVT-experienced annotators, each providing an individual annotation. The merged annotation as well as the three individual annotations come with the published dataset. Additionally, we provide some baseline classification results. The best balanced accuracy across a 5-fold cross validation of 81.3\,\% was achieved with a ResNet18. The dataset can be downloaded under https://zenodo.org/records/14276415.]]></description>
<pubDate>Mon, 26 Jan 2026 10:28:06 +0000</pubDate>
</item>
<item>
<title><![CDATA[PPISP: Physically-Plausible Compensation and Control of Photometric Variations in Radiance Field Reconstruction]]></title>
<link>http://arxiv.org/abs/2601.18336v1</link>
<guid>2601.18336v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.CV, cs.GR
Authors: Isaac Deutsch, Nicolas Monne-Loccoz, Gavriel State, Zan Gojcic
Institution: 
Published: 2026-01-26
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Multi-view 3D reconstruction methods remain highly sensitive to photometric inconsistencies arising from camera optical characteristics and variations in image signal processing (ISP). Existing mitigation strategies such as per-frame latent variables or affine color corrections lack physical grounding and generalize poorly to novel views. We propose the Physically-Plausible ISP (PPISP) correction module, which disentangles camera-intrinsic and capture-dependent effects through physically based and interpretable transformations. A dedicated PPISP controller, trained on the input views, predicts ISP parameters for novel viewpoints, analogous to auto exposure and auto white balance in real cameras. This design enables realistic and fair evaluation on novel views without access to ground-truth images. PPISP achieves SoTA performance on standard benchmarks, while providing intuitive control and supporting the integration of metadata when available. The source code is available at: https://github.com/nv-tlabs/ppisp]]></description>
<pubDate>Mon, 26 Jan 2026 10:23:43 +0000</pubDate>
</item>
<item>
<title><![CDATA[Analytic Incremental Learning For Sound Source Localization With Imbalance Rectification]]></title>
<link>http://arxiv.org/abs/2601.18335v1</link>
<guid>2601.18335v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.SD, cs.AI
Authors: Zexia Fan, Yu Chen, Qiquan Zhang, Kainan Chen, Xinyuan Qian
Institution: 
Published: 2026-01-26
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Sound source localization (SSL) demonstrates remarkable results in controlled settings but struggles in real-world deployment due to dual imbalance challenges: intra-task imbalance arising from long-tailed direction-of-arrival (DoA) distributions, and inter-task imbalance induced by cross-task skews and overlaps. These often lead to catastrophic forgetting, significantly degrading the localization accuracy. To mitigate these issues, we propose a unified framework with two key innovations. Specifically, we design a GCC-PHAT-based data augmentation (GDA) method that leverages peak characteristics to alleviate intra-task distribution skews. We also propose an Analytic dynamic imbalance rectifier (ADIR) with task-adaption regularization, which enables analytic updates that adapt to inter-task dynamics. On the SSLR benchmark, our proposal achieves state-of-the-art (SoTA) results of 89.0% accuracy, 5.3 mean absolute error, and 1.6 backward transfer, demonstrating robustness to evolving imbalances without exemplar storage.]]></description>
<pubDate>Mon, 26 Jan 2026 10:22:01 +0000</pubDate>
</item>
<item>
<title><![CDATA[Overalignment in Frontier LLMs: An Empirical Study of Sycophantic Behaviour in Healthcare]]></title>
<link>http://arxiv.org/abs/2601.18334v1</link>
<guid>2601.18334v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.CL
Authors: Clment Christophe, Wadood Mohammed Abdul, Prateek Munjal, Tathagata Raha, Ronnie Rajan et al.
Institution: 
Published: 2026-01-26
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

As LLMs are increasingly integrated into clinical workflows, their tendency for sycophancy, prioritizing user agreement over factual accuracy, poses significant risks to patient safety. While existing evaluations often rely on subjective datasets, we introduce a robust framework grounded in medical MCQA with verifiable ground truths. We propose the Adjusted Sycophancy Score, a novel metric that isolates alignment bias by accounting for stochastic model instability, or "confusability". Through an extensive scaling analysis of the Qwen-3 and Llama-3 families, we identify a clear scaling trajectory for resilience. Furthermore, we reveal a counter-intuitive vulnerability in reasoning-optimized "Thinking" models: while they demonstrate high vanilla accuracy, their internal reasoning traces frequently rationalize incorrect user suggestions under authoritative pressure. Our results across frontier models suggest that benchmark performance is not a proxy for clinical reliability, and that simplified reasoning structures may offer superior robustness against expert-driven sycophancy.]]></description>
<pubDate>Mon, 26 Jan 2026 10:21:34 +0000</pubDate>
</item>
<item>
<title><![CDATA[A Tumor Aware DenseNet Swin Hybrid Learning with Boosted and Hierarchical Feature Spaces for Large-Scale Brain MRI Classification]]></title>
<link>http://arxiv.org/abs/2601.18330v1</link>
<guid>2601.18330v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.CV, cs.LG
Authors: Muhammad Ali Shah, Muhammad Mansoor Alam, Saddam Hussain Khan
Institution: 
Published: 2026-01-26
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

This study proposes an efficient Densely Swin Hybrid (EDSH) framework for brain tumor MRI analysis, designed to jointly capture fine grained texture patterns and long range contextual dependencies. Two tumor aware experimental setups are introduced to address class-specific diagnostic challenges. The first setup employs a Boosted Feature Space (BFS), where independently customized DenseNet and Swint branches learn complementary local and global representations that are dimension aligned, fused, and boosted, enabling highly sensitive detection of diffuse glioma patterns by successfully learning the features of irregular shape, poorly defined mass, and heterogeneous texture. The second setup adopts a hierarchical DenseNet Swint architecture with Deep Feature Extraction have Dual Residual connections (DFE and DR), in which DenseNet serves as a stem CNN for structured local feature learning, while Swin_t models global tumor morphology, effectively suppressing false negatives in meningioma and pituitary tumor classification by learning the features of well defined mass, location (outside brain) and enlargments in tumors (dural tail or upward extension). DenseNet is customized at the input level to match MRI spatial characteristics, leveraging dense residual connectivity to preserve texture information and mitigate vanishing-gradient effects. In parallel, Swint is tailored through task aligned patch embedding and shifted-window self attention to efficiently capture hierarchical global dependencies. Extensive evaluation on a large-scale MRI dataset (stringent 40,260 images across four tumor classes) demonstrates consistent superiority over standalone CNNs, Vision Transformers, and hybrids, achieving 98.50 accuracy and recall on the test unseen dataset.]]></description>
<pubDate>Mon, 26 Jan 2026 10:14:57 +0000</pubDate>
</item>
<item>
<title><![CDATA[Discriminability-Driven Spatial-Channel Selection with Gradient Norm for Drone Signal OOD Detection]]></title>
<link>http://arxiv.org/abs/2601.18329v1</link>
<guid>2601.18329v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.LG
Authors: Chuhan Feng, Jing Li, Jie Li, Lu Lv, Fengkui Gong
Institution: 
Published: 2026-01-26
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

We propose a drone signal out-of-distribution (OOD) detection algorithm based on discriminability-driven spatial-channel selection with a gradient norm. Time-frequency image features are adaptively weighted along both spatial and channel dimensions by quantifying inter-class similarity and variance based on protocol-specific time-frequency characteristics. Subsequently, a gradient-norm metric is introduced to measure perturbation sensitivity for capturing the inherent instability of OOD samples, which is then fused with energy-based scores for joint inference. Simulation results demonstrate that the proposed algorithm provides superior discriminative power and robust performance via SNR and various drone types.]]></description>
<pubDate>Mon, 26 Jan 2026 10:13:07 +0000</pubDate>
</item>
<item>
<title><![CDATA[Cognitive Fusion of ZC Sequences and Time-Frequency Images for Out-of-Distribution Detection of Drone Signals]]></title>
<link>http://arxiv.org/abs/2601.18326v1</link>
<guid>2601.18326v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.LG
Authors: Jie Li, Jing Li, Lu Lv, Zhanyu Ju, Fengkui Gong
Institution: 
Published: 2026-01-26
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

We propose a drone signal out-of-distribution detection (OODD) algorithm based on the cognitive fusion of Zadoff-Chu (ZC) sequences and time-frequency images (TFI). ZC sequences are identified by analyzing the communication protocols of DJI drones, while TFI capture the time-frequency characteristics of drone signals with unknown or non-standard communication protocols. Both modalities are used jointly to enable OODD in the drone remote identification (RID) task. Specifically, ZC sequence features and TFI features are generated from the received radio frequency signals, which are then processed through dedicated feature extraction module to enhance and align them. The resultant multi-modal features undergo multi-modal feature interaction, single-modal feature fusion, and multi-modal feature fusion to produce features that integrate and complement information across modalities. Discrimination scores are computed from the fused features along both spatial and channel dimensions to capture time-frequency characteristic differences dictated by the communication protocols, and these scores will be transformed into adaptive attention weights. The weighted features are then passed through a Softmax function to produce the signal classification results. Simulation results demonstrate that the proposed algorithm outperforms existing algorithms and achieves 1.7% and 7.5% improvements in RID and OODD metrics, respectively. The proposed algorithm also performs strong robustness under varying flight conditions and across different drone types.]]></description>
<pubDate>Mon, 26 Jan 2026 10:10:08 +0000</pubDate>
</item>
<item>
<title><![CDATA[Integrating Fine-Grained Audio-Visual Evidence for Robust Multimodal Emotion Reasoning]]></title>
<link>http://arxiv.org/abs/2601.18321v1</link>
<guid>2601.18321v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.MM, cs.CL, cs.CV
Authors: Zhixian Zhao, Wenjie Tian, Xiaohai Tian, Jun Zhang, Lei Xie
Institution: 
Published: 2026-01-26
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Multimodal emotion analysis is shifting from static classification to generative reasoning. Beyond simple label prediction, robust affective reasoning must synthesize fine-grained signals such as facial micro-expressions and prosodic which shifts to decode the latent causality within complex social contexts. However, current Multimodal Large Language Models (MLLMs) face significant limitations in fine-grained perception, primarily due to data scarcity and insufficient cross-modal fusion. As a result, these models often exhibit unimodal dominance which leads to hallucinations in complex multimodal interactions, particularly when visual and acoustic cues are subtle, ambiguous, or even contradictory (e.g., in sarcastic scenery). To address this, we introduce SABER-LLM, a framework designed for robust multimodal reasoning. First, we construct SABER, a large-scale emotion reasoning dataset comprising 600K video clips, annotated with a novel six-dimensional schema that jointly captures audiovisual cues and causal logic. Second, we propose the structured evidence decomposition paradigm, which enforces a "perceive-then-reason" separation between evidence extraction and reasoning to alleviate unimodal dominance. The ability to perceive complex scenes is further reinforced by consistency-aware direct preference optimization, which explicitly encourages alignment among modalities under ambiguous or conflicting perceptual conditions. Experiments on EMER, EmoBench-M, and SABER-Test demonstrate that SABER-LLM significantly outperforms open-source baselines and achieves robustness competitive with closed-source models in decoding complex emotional dynamics. The dataset and model are available at https://github.com/zxzhao0/SABER-LLM.]]></description>
<pubDate>Mon, 26 Jan 2026 10:03:26 +0000</pubDate>
</item>
<item>
<title><![CDATA[MultiVis-Agent: A Multi-Agent Framework with Logic Rules for Reliable and Comprehensive Cross-Modal Data Visualization]]></title>
<link>http://arxiv.org/abs/2601.18320v1</link>
<guid>2601.18320v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.CL, cs.AI, cs.DB
Authors: Jinwei Lu, Yuanfeng Song, Chen Zhang, Raymond Chi-Wing Wong
Institution: 
Published: 2026-01-26
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Real-world visualization tasks involve complex, multi-modal requirements that extend beyond simple text-to-chart generation, requiring reference images, code examples, and iterative refinement. Current systems exhibit fundamental limitations: single-modality input, one-shot generation, and rigid workflows. While LLM-based approaches show potential for these complex requirements, they introduce reliability challenges including catastrophic failures and infinite loop susceptibility. To address this gap, we propose MultiVis-Agent, a logic rule-enhanced multi-agent framework for reliable multi-modal and multi-scenario visualization generation. Our approach introduces a four-layer logic rule framework that provides mathematical guarantees for system reliability while maintaining flexibility. Unlike traditional rule-based systems, our logic rules are mathematical constraints that guide LLM reasoning rather than replacing it. We formalize the MultiVis task spanning four scenarios from basic generation to iterative refinement, and develop MultiVis-Bench, a benchmark with over 1,000 cases for multi-modal visualization evaluation. Extensive experiments demonstrate that our approach achieves 75.63% visualization score on challenging tasks, significantly outperforming baselines (57.54-62.79%), with task completion rates of 99.58% and code execution success rates of 94.56% (vs. 74.48% and 65.10% without logic rules), successfully addressing both complexity and reliability challenges in automated visualization generation.]]></description>
<pubDate>Mon, 26 Jan 2026 10:03:10 +0000</pubDate>
</item>
<item>
<title><![CDATA[A Master Class on Reproducibility: A Student Hackathon on Advanced MRI Reconstruction Methods]]></title>
<link>http://arxiv.org/abs/2601.18314v1</link>
<guid>2601.18314v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.LG
Authors: Lina Felsner, Sevgi G. Kafali, Hannah Eichhorn, Agnes A. J. Leth, Aidas Batvinskas et al.
Institution: 
Published: 2026-01-26
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

We report the design, protocol, and outcomes of a student reproducibility hackathon focused on replicating the results of three influential MRI reconstruction papers: (a) MoDL, an unrolled model-based network with learned denoising; (b) HUMUS-Net, a hybrid unrolled multiscale CNN+Transformer architecture; and (c) an untrained, physics-regularized dynamic MRI method that uses a quantitative MR model for early stopping. We describe the setup of the hackathon and present reproduction outcomes alongside additional experiments, and we detail fundamental practices for building reproducible codebases.]]></description>
<pubDate>Mon, 26 Jan 2026 09:50:02 +0000</pubDate>
</item>
<item>
<title><![CDATA[Convex Chance-Constrained Stochastic Control under Uncertain Specifications with Application to Learning-Based Hybrid Powertrain Control]]></title>
<link>http://arxiv.org/abs/2601.18313v1</link>
<guid>2601.18313v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.LG
Authors: Teruki Kato, Ryotaro Shima, Kenji Kashima
Institution: 
Published: 2026-01-26
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

This paper presents a strictly convex chance-constrained stochastic control framework that accounts for uncertainty in control specifications such as reference trajectories and operational constraints. By jointly optimizing control inputs and risk allocation under general (possibly non-Gaussian) uncertainties, the proposed method guarantees probabilistic constraint satisfaction while ensuring strict convexity, leading to uniqueness and continuity of the optimal solution. The formulation is further extended to nonlinear model-based control using exactly linearizable models identified through machine learning. The effectiveness of the proposed approach is demonstrated through model predictive control applied to a hybrid powertrain system.]]></description>
<pubDate>Mon, 26 Jan 2026 09:49:33 +0000</pubDate>
</item>
<item>
<title><![CDATA[A Generative AI-Driven Reliability Layer for Action-Oriented Disaster Resilience]]></title>
<link>http://arxiv.org/abs/2601.18308v1</link>
<guid>2601.18308v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.AI, cs.SI
Authors: Geunsik Lim
Institution: 
Published: 2026-01-26
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

As climate-related hazards intensify, conventional early warning systems (EWS) disseminate alerts rapidly but often fail to trigger timely protective actions, leading to preventable losses and inequities. We introduce Climate RADAR (Risk-Aware, Dynamic, and Action Recommendation system), a generative AI-based reliability layer that reframes disaster communication from alerts delivered to actions executed. It integrates meteorological, hydrological, vulnerability, and social data into a composite risk index and employs guardrail-embedded large language models (LLMs) to deliver personalized recommendations across citizen, volunteer, and municipal interfaces. Evaluation through simulations, user studies, and a municipal pilot shows improved outcomes, including higher protective action execution, reduced response latency, and increased usability and trust. By combining predictive analytics, behavioral science, and responsible AI, Climate RADAR advances people-centered, transparent, and equitable early warning systems, offering practical pathways toward compliance-ready disaster resilience infrastructures.]]></description>
<pubDate>Mon, 26 Jan 2026 09:43:30 +0000</pubDate>
</item>
<item>
<title><![CDATA[Calibrating Beyond English: Language Diversity for Better Quantized Multilingual LLM]]></title>
<link>http://arxiv.org/abs/2601.18306v1</link>
<guid>2601.18306v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.CL, cs.AI
Authors: Everlyn Asiko Chimoto, Mostafa Elhoushi, Bruce A. Bassett
Institution: 
Published: 2026-01-26
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Quantization is an effective technique for reducing the storage footprint and computational costs of Large Language Models (LLMs), but it often results in performance degradation. Existing post-training quantization methods typically use small, English-only calibration sets; however, their impact on multilingual models remains underexplored. We systematically evaluate eight calibration settings (five single-language and three multilingual mixes) on two quantizers (GPTQ, AWQ) on data from 10 languages. Our findings reveal a consistent trend: non-English and multilingual calibration sets significantly improve perplexity compared to English-only baselines. Specifically, we observe notable average perplexity gains across both quantizers on Llama3.1 8B and Qwen2.5 7B, with multilingual mixes achieving the largest overall reductions of up to 3.52 points in perplexity. Furthermore, our analysis indicates that tailoring calibration sets to the evaluation language yields the largest improvements for individual languages, underscoring the importance of linguistic alignment. We also identify specific failure cases where certain language-quantizer combinations degrade performance, which we trace to differences in activation range distributions across languages. These results highlight that static one-size-fits-all calibration is suboptimal and that tailoring calibration data, both in language and diversity, plays a crucial role in robustly quantizing multilingual LLMs.]]></description>
<pubDate>Mon, 26 Jan 2026 09:36:03 +0000</pubDate>
</item>
<item>
<title><![CDATA[SwipeGen: Bridging the Execution Gap in GUI Agents via Human-like Swipe Synthesis]]></title>
<link>http://arxiv.org/abs/2601.18305v1</link>
<guid>2601.18305v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.CV
Authors: Xuan Wang, Siyuan Su, Quantong Fu, Yongxiang Hu, Yangfan Zhou
Institution: 
Published: 2026-01-26
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

With the widespread adoption of Graphical User Interface (GUI) agents for automating GUI interaction tasks, substantial research focused on improving GUI perception to ground task instructions into concrete action steps. However, the step execution capability of these agents has gradually emerged as a new bottleneck for task completion. In particular, existing GUI agents often adopt overly simplified strategies for handling swipe interactions, preventing them from accurately replicating human-like behavior. To address this limitation, we decompose human swipe gestures into multiple quantifiable dimensions and propose an automated pipeline SwipeGen to synthesize human-like swipe interactions through GUI exploration. Based on this pipeline, we construct and release the first benchmark for evaluating the swipe execution capability of GUI agents. Furthermore, leveraging the synthesized data, we propose GUISwiper, a GUI agent with enhanced interaction execution capabilities. Experimental results demonstrate that GUISwiper achieves a swipe execution accuracy of 69.07%, representing a 214% improvement over existing VLM baselines.]]></description>
<pubDate>Mon, 26 Jan 2026 09:35:10 +0000</pubDate>
</item>
<item>
<title><![CDATA[Suppressing Final Layer Hidden State Jumps in Transformer Pretraining]]></title>
<link>http://arxiv.org/abs/2601.18302v1</link>
<guid>2601.18302v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.CL
Authors: Keigo Shibata, Kazuki Yano, Ryosuke Takahashi, Jaesung Lee, Wataru Ikeda et al.
Institution: 
Published: 2026-01-26
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

This paper discusses the internal behavior of Transformer language models. Many recent pre-trained models have been reported to exhibit only slight changes in the angular distance between the input and output hidden state vectors in the middle Transformer layers, despite a disproportionately large ``jump'' in the angular distance occurring in or around the final Transformer layer. To characterize this, we first introduce a quantitative metric for the jump strength around the final layer, and then demonstrate its prevalence across many open-weight models, as well as its amplification throughout pre-training. Assuming such jumps indicate an undesirable property, we propose the jump-suppressing regularizer (JREG) which penalizes this jump during pre-training, thereby encouraging more balanced capability usage across the middle layers. Empirical evaluations of three model sizes of Llama-based models, trained with the proposed JREG method, reveal improved task performance compared to the baseline without altering the model architecture.]]></description>
<pubDate>Mon, 26 Jan 2026 09:30:49 +0000</pubDate>
</item>
<item>
<title><![CDATA[Contextual Range-View Projection for 3D LiDAR Point Clouds]]></title>
<link>http://arxiv.org/abs/2601.18301v1</link>
<guid>2601.18301v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.CV
Authors: Seyedali Mousavi, Seyedhamidreza Mousavi, Masoud Daneshtalab
Institution: 
Published: 2026-01-26
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Range-view projection provides an efficient method for transforming 3D LiDAR point clouds into 2D range image representations, enabling effective processing with 2D deep learning models. However, a major challenge in this projection is the many-to-one conflict, where multiple 3D points are mapped onto the same pixel in the range image, requiring a selection strategy. Existing approaches typically retain the point with the smallest depth (closest to the LiDAR), disregarding semantic relevance and object structure, which leads to the loss of important contextual information. In this paper, we extend the depth-based selection rule by incorporating contextual information from both instance centers and class labels, introducing two mechanisms: \textit{Centerness-Aware Projection (CAP)} and \textit{Class-Weighted-Aware Projection (CWAP)}. In CAP, point depths are adjusted according to their distance from the instance center, thereby prioritizing central instance points over noisy boundary and background points. In CWAP, object classes are prioritized through user-defined weights, offering flexibility in the projection strategy. Our evaluations on the SemanticKITTI dataset show that CAP preserves more instance points during projection, achieving up to a 3.1\% mIoU improvement compared to the baseline. Furthermore, CWAP enhances the performance of targeted classes while having a negligible impact on the performance of other classes]]></description>
<pubDate>Mon, 26 Jan 2026 09:30:43 +0000</pubDate>
</item>
<item>
<title><![CDATA[Temp-R1: A Unified Autonomous Agent for Complex Temporal KGQA via Reverse Curriculum Reinforcement Learning]]></title>
<link>http://arxiv.org/abs/2601.18296v1</link>
<guid>2601.18296v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.CL, cs.AI, cs.LG
Authors: Zhaoyan Gong, Zhiqiang Liu, Songze Li, Xiaoke Guo, Yuanxiang Liu et al.
Institution: 
Published: 2026-01-26
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Temporal Knowledge Graph Question Answering (TKGQA) is inherently challenging, as it requires sophisticated reasoning over dynamic facts with multi-hop dependencies and complex temporal constraints. Existing methods rely on fixed workflows and expensive closed-source APIs, limiting flexibility and scalability. We propose Temp-R1, the first autonomous end-to-end agent for TKGQA trained through reinforcement learning. To address cognitive overload in single-action reasoning, we expand the action space with specialized internal actions alongside external action. To prevent shortcut learning on simple questions, we introduce reverse curriculum learning that trains on difficult questions first, forcing the development of sophisticated reasoning before transferring to easier cases. Our 8B-parameter Temp-R1 achieves state-of-the-art performance on MultiTQ and TimelineKGQA, improving 19.8% over strong baselines on complex questions. Our work establishes a new paradigm for autonomous temporal reasoning agents. Our code will be publicly available soon at https://github.com/zjukg/Temp-R1.]]></description>
<pubDate>Mon, 26 Jan 2026 09:23:53 +0000</pubDate>
</item>
<item>
<title><![CDATA[TriPlay-RL: Tri-Role Self-Play Reinforcement Learning for LLM Safety Alignment]]></title>
<link>http://arxiv.org/abs/2601.18292v1</link>
<guid>2601.18292v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.LG, cs.AI
Authors: Zhewen Tan, Wenhan Yu, Jianfeng Si, Tongxin Liu, Kaiqi Guan et al.
Institution: 
Published: 2026-01-26
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

In recent years, safety risks associated with large language models have become increasingly prominent, highlighting the urgent need to mitigate the generation of toxic and harmful content. The mainstream paradigm for LLM safety alignment typically adopts a collaborative framework involving three roles: an attacker for adversarial prompt generation, a defender for safety defense, and an evaluator for response assessment. In this paper, we propose a closed-loop reinforcement learning framework called TriPlay-RL that enables iterative and co-improving collaboration among three roles with near-zero manual annotation. Experimental results show that the attacker preserves high output diversity while achieving a 20%-50% improvement in adversarial effectiveness; the defender attains 10%-30% gains in safety performance without degrading general reasoning capability; and the evaluator continuously refines its fine-grained judgment ability through iterations, accurately distinguishing unsafe responses, simple refusals, and useful guidance. Overall, our framework establishes an efficient and scalable paradigm for LLM safety alignment, enabling continuous co-evolution within a unified learning loop.]]></description>
<pubDate>Mon, 26 Jan 2026 09:21:43 +0000</pubDate>
</item>
<item>
<title><![CDATA[U-Fold: Dynamic Intent-Aware Context Folding for User-Centric Agents]]></title>
<link>http://arxiv.org/abs/2601.18285v1</link>
<guid>2601.18285v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.CL
Authors: Jin Su, Runnan Fang, Yeqiu Li, Xiaobin Wang, Shihao Cai et al.
Institution: 
Published: 2026-01-26
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Large language model (LLM)-based agents have been successfully deployed in many tool-augmented settings, but their scalability is fundamentally constrained by context length. Existing context-folding methods mitigate this issue by summarizing past interactions, yet they are typically designed for single-query or single-intent scenarios. In more realistic user-centric dialogues, we identify two major failure modes: (i) they irreversibly discard fine-grained constraints and intermediate facts that are crucial for later decisions, and (ii) their summaries fail to track evolving user intent, leading to omissions and erroneous actions. To address these limitations, we propose U-Fold, a dynamic context-folding framework tailored to user-centric tasks. U-Fold retains the full user--agent dialogue and tool-call history but, at each turn, uses two core components to produce an intent-aware, evolving dialogue summary and a compact, task-relevant tool log. Extensive experiments on $$-bench, $^2$-bench, VitaBench, and harder context-inflated settings show that U-Fold consistently outperforms ReAct (achieving a 71.4% win rate in long-context settings) and prior folding baselines (with improvements of up to 27.0%), particularly on long, noisy, multi-turn tasks. Our study demonstrates that U-Fold is a promising step toward transferring context-management techniques from single-query benchmarks to realistic user-centric applications.]]></description>
<pubDate>Mon, 26 Jan 2026 09:11:49 +0000</pubDate>
</item>
<item>
<title><![CDATA[Think-Augmented Function Calling: Improving LLM Parameter Accuracy Through Embedded Reasoning]]></title>
<link>http://arxiv.org/abs/2601.18282v1</link>
<guid>2601.18282v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.AI, cs.CL, cs.LG
Authors: Lei Wei, Jinpeng Ou, Xiao Peng, Bin Wang
Institution: 
Published: 2026-01-26
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Large language models (LLMs) have demonstrated remarkable capabilities in function calling for autonomous agents, yet current mechanisms lack explicit reasoning transparency during parameter generation, particularly for complex functions with interdependent parameters. While existing approaches like chain-of-thought prompting operate at the agent level, they fail to provide fine-grained reasoning guidance for individual function parameters. To address these limitations, we propose Think-Augmented Function Calling (TAFC), a novel framework that enhances function calling accuracy through explicit reasoning at both function and parameter levels. Our method introduces a universal "think" parameter augmentation that enables models to articulate their decision-making process, with dynamic optimization for parameter descriptions to improve reasoning quality. For complex parameters, TAFC automatically triggers granular reasoning based on complexity scoring, ensuring appropriate justification for critical decisions. Additionally, we propose reasoning-guided optimization to align generated reasoning with human expectations. TAFC requires no architectural modifications to existing LLMs while maintaining full API compatibility. Evaluation on ToolBench across proprietary and open-source models demonstrates significant improvements in parameter generation accuracy and reasoning coherence for multi-parameter functions, while providing enhanced interpretability for debugging AI agent behaviors.]]></description>
<pubDate>Mon, 26 Jan 2026 09:05:00 +0000</pubDate>
</item>
<item>
<title><![CDATA[Reflecting Twice before Speaking with Empathy: Self-Reflective Alternating Inference for Empathy-Aware End-to-End Spoken Dialogue]]></title>
<link>http://arxiv.org/abs/2601.18281v1</link>
<guid>2601.18281v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.CL, cs.SD
Authors: Yuhang Jia, Pei Liu, Haoqin Sun, Jiaming Zhou, Xuxin Cheng et al.
Institution: 
Published: 2026-01-26
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

End-to-end Spoken Language Models (SLMs) hold great potential for paralinguistic perception, and numerous studies have aimed to enhance their capabilities, particularly for empathetic dialogue. However, current approaches largely depend on rigid supervised signals, such as ground-truth response in supervised fine-tuning or preference scores in reinforcement learning. Such reliance is fundamentally limited for modeling complex empathy, as there is no single "correct" response and a simple numerical score cannot fully capture the nuances of emotional expression or the appropriateness of empathetic behavior. To address these limitations, we sequentially introduce EmpathyEval, a descriptive natural-language-based evaluation model for assessing empathetic quality in spoken dialogues. Building upon EmpathyEval, we propose ReEmpathy, an end-to-end SLM that enhances empathetic dialogue through a novel Empathetic Self-Reflective Alternating Inference mechanism, which interleaves spoken response generation with free-form, empathy-related reflective reasoning. Extensive experiments demonstrate that ReEmpathy substantially improves empathy-sensitive spoken dialogue by enabling reflective reasoning, offering a promising approach toward more emotionally intelligent and empathy-aware human-computer interactions.]]></description>
<pubDate>Mon, 26 Jan 2026 09:04:50 +0000</pubDate>
</item>
<item>
<title><![CDATA[What Do Learned Models Measure?]]></title>
<link>http://arxiv.org/abs/2601.18278v1</link>
<guid>2601.18278v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.LG, cs.AI
Authors: Indr liobait
Institution: 
Published: 2026-01-26
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

In many scientific and data-driven applications, machine learning models are increasingly used as measurement instruments, rather than merely as predictors of predefined labels. When the measurement function is learned from data, the mapping from observations to quantities is determined implicitly by the training distribution and inductive biases, allowing multiple inequivalent mappings to satisfy standard predictive evaluation criteria. We formalize learned measurement functions as a distinct focus of evaluation and introduce measurement stability, a property capturing invariance of the measured quantity across admissible realizations of the learning process and across contexts. We show that standard evaluation criteria in machine learning, including generalization error, calibration, and robustness, do not guarantee measurement stability. Through a real-world case study, we show that models with comparable predictive performance can implement systematically inequivalent measurement functions, with distribution shift providing a concrete illustration of this failure. Taken together, our results highlight a limitation of existing evaluation frameworks in settings where learned model outputs are identified as measurements, motivating the need for an additional evaluative dimension.]]></description>
<pubDate>Mon, 26 Jan 2026 09:00:48 +0000</pubDate>
</item>
<item>
<title><![CDATA[TEFormer: Structured Bidirectional Temporal Enhancement Modeling in Spiking Transformers]]></title>
<link>http://arxiv.org/abs/2601.18274v1</link>
<guid>2601.18274v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.NE
Authors: Sicheng Shen, Mingyang Lv, Bing Han, Dongcheng Zhao, Guobin Shen et al.
Institution: 
Published: 2026-01-26
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

In recent years, Spiking Neural Networks (SNNs) have achieved remarkable progress, with Spiking Transformers emerging as a promising architecture for energy-efficient sequence modeling. However, existing Spiking Transformers still lack a principled mechanism for effective temporal fusion, limiting their ability to fully exploit spatiotemporal dependencies. Inspired by feedforward-feedback modulation in the human visual pathway, we propose TEFormer, the first Spiking Transformer framework that achieves bidirectional temporal fusion by decoupling temporal modeling across its core components. Specifically, TEFormer employs a lightweight and hyperparameter-free forward temporal fusion mechanism in the attention module, enabling fully parallel computation, while incorporating a backward gated recurrent structure in the MLP to aggregate temporal information in reverse order and reinforce temporal consistency. Extensive experiments across a wide range of benchmarks demonstrate that TEFormer consistently and significantly outperforms strong SNN and Spiking Transformer baselines under diverse datasets. Moreover, through the first systematic evaluation of Spiking Transformers under different neural encoding schemes, we show that the performance gains of TEFormer remain stable across encoding choices, indicating that the improved temporal modeling directly translates into reliable accuracy improvements across varied spiking representations. These results collectively establish TEFormer as an effective and general framework for temporal modeling in Spiking Transformers.]]></description>
<pubDate>Mon, 26 Jan 2026 08:58:36 +0000</pubDate>
</item>
<item>
<title><![CDATA[Toward Scalable Normalizing Flows for the Hubbard Model]]></title>
<link>http://arxiv.org/abs/2601.18273v1</link>
<guid>2601.18273v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.LG
Authors: Janik Kreit, Andrea Bulgarelli, Lena Funcke, Thomas Luu, Dominic Schuh et al.
Institution: 
Published: 2026-01-26
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Normalizing flows have recently demonstrated the ability to learn the Boltzmann distribution of the Hubbard model, opening new avenues for generative modeling in condensed matter physics. In this work, we investigate the steps required to extend such simulations to larger lattice sizes and lower temperatures, with a focus on enhancing stability and efficiency. Additionally, we present the scaling behavior of stochastic normalizing flows and non-equilibrium Markov chain Monte Carlo methods for this fermionic system.]]></description>
<pubDate>Mon, 26 Jan 2026 08:58:08 +0000</pubDate>
</item>
<item>
<title><![CDATA[Designing large language model prompts to extract scores from messy text: A shared dataset and challenge]]></title>
<link>http://arxiv.org/abs/2601.18271v1</link>
<guid>2601.18271v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.DL, cs.CL
Authors: Mike Thelwall
Institution: 
Published: 2026-01-26
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

In some areas of computing, natural language processing and information science, progress is made by sharing datasets and challenging the community to design the best algorithm for an associated task. This article introduces a shared dataset of 1446 short texts, each of which describes a research quality score on the UK scale of 1* to 4*. This is a messy collection, with some texts not containing scores and others including invalid scores or strange formats. With this dataset there is also a description of what constitutes a valid score and a "gold standard" of the correct scores for these texts (including missing values). The challenge is to design a prompt for Large Language Models (LLMs) to extract the scores from these texts as accurately as possible. The format for the response should be a number and no other text so there are two aspects to the challenge: ensuring that the LLM returns only a number, and instructing it to deduce the correct number for the text. As part of this, the LLM prompt needs to explain when to return the missing value code, -1, instead of a number when the text does not clearly contain one. The article also provides an example of a simple prompt. The purpose of the challenge is twofold: to get an effective solution to this problem, and to increase understanding of prompt design and LLM capabilities for complex numerical tasks. The initial solution suggested has an accuracy of 72.6%, so the challenge is to beat this.]]></description>
<pubDate>Mon, 26 Jan 2026 08:55:55 +0000</pubDate>
</item>
<item>
<title><![CDATA[Neural Network Approximation: A View from Polytope Decomposition]]></title>
<link>http://arxiv.org/abs/2601.18264v1</link>
<guid>2601.18264v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.LG, cs.AI
Authors: ZeYu Li, ShiJun Zhang, TieYong Zeng, FengLei Fan
Institution: 
Published: 2026-01-26
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Universal approximation theory offers a foundational framework to verify neural network expressiveness, enabling principled utilization in real-world applications. However, most existing theoretical constructions are established by uniformly dividing the input space into tiny hypercubes without considering the local regularity of the target function. In this work, we investigate the universal approximation capabilities of ReLU networks from a view of polytope decomposition, which offers a more realistic and task-oriented approach compared to current methods. To achieve this, we develop an explicit kernel polynomial method to derive an universal approximation of continuous functions, which is characterized not only by the refined Totik-Ditzian-type modulus of continuity, but also by polytopical domain decomposition. Then, a ReLU network is constructed to approximate the kernel polynomial in each subdomain separately. Furthermore, we find that polytope decomposition makes our approximation more efficient and flexible than existing methods in many cases, especially near singular points of the objective function. Lastly, we extend our approach to analytic functions to reach a higher approximation rate.]]></description>
<pubDate>Mon, 26 Jan 2026 08:39:11 +0000</pubDate>
</item>
<item>
<title><![CDATA[Revisiting Aerial Scene Classification on the AID Benchmark]]></title>
<link>http://arxiv.org/abs/2601.18263v1</link>
<guid>2601.18263v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.CV
Authors: Subhajeet Das, Susmita Ghosh, Abhiroop Chatterjee
Institution: MIT
Published: 2026-01-26
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Aerial images play a vital role in urban planning and environmental preservation, as they consist of various structures, representing different types of buildings, forests, mountains, and unoccupied lands. Due to its heterogeneous nature, developing robust models for scene classification remains a challenge. In this study, we conduct a literature review of various machine learning methods for aerial image classification. Our survey covers a range of approaches from handcrafted features (e.g., SIFT, LBP) to traditional CNNs (e.g., VGG, GoogLeNet), and advanced deep hybrid networks. In this connection, we have also designed Aerial-Y-Net, a spatial attention-enhanced CNN with multi-scale feature fusion mechanism, which acts as an attention-based model and helps us to better understand the complexities of aerial images. Evaluated on the AID dataset, our model achieves 91.72% accuracy, outperforming several baseline architectures.]]></description>
<pubDate>Mon, 26 Jan 2026 08:39:02 +0000</pubDate>
</item>
<item>
<title><![CDATA[FGGM: Fisher-Guided Gradient Masking for Continual Learning]]></title>
<link>http://arxiv.org/abs/2601.18261v1</link>
<guid>2601.18261v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.LG, cs.CL
Authors: Chao-Hong Tan, Qian Chen, Wen Wang, Yukun Ma, Chong Zhang et al.
Institution: 
Published: 2026-01-26
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Catastrophic forgetting impairs the continuous learning of large language models. We propose Fisher-Guided Gradient Masking (FGGM), a framework that mitigates this by strategically selecting parameters for updates using diagonal Fisher Information. FGGM dynamically generates binary masks with adaptive thresholds, preserving critical parameters to balance stability and plasticity without requiring historical data. Unlike magnitude-based methods such as MIGU, our approach offers a mathematically principled parameter importance estimation. On the TRACE benchmark, FGGM shows a 9.6% relative improvement in retaining general capabilities over supervised fine-tuning (SFT) and a 4.4% improvement over MIGU on TRACE tasks. Additional analysis on code generation tasks confirms FGGM's superior performance and reduced forgetting, establishing it as an effective solution.]]></description>
<pubDate>Mon, 26 Jan 2026 08:35:34 +0000</pubDate>
</item>
<item>
<title><![CDATA[Depth to Anatomy: Learning Internal Organ Locations from Surface Depth Images]]></title>
<link>http://arxiv.org/abs/2601.18260v1</link>
<guid>2601.18260v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.CV
Authors: Eytan Kats, Kai Geissler, Daniel Mensing, Jochen G. Hirsch, Stefan Heldman et al.
Institution: 
Published: 2026-01-26
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Automated patient positioning plays an important role in optimizing scanning procedure and improving patient throughput. Leveraging depth information captured by RGB-D cameras presents a promising approach for estimating internal organ positions, thereby enabling more accurate and efficient positioning. In this work, we propose a learning-based framework that directly predicts the 3D locations and shapes of multiple internal organs from single 2D depth images of the body surface. Utilizing a large-scale dataset of full-body MRI scans, we synthesize depth images paired with corresponding anatomical segmentations to train a unified convolutional neural network architecture. Our method accurately localizes a diverse set of anatomical structures, including bones and soft tissues, without requiring explicit surface reconstruction. Experimental results demonstrate the potential of integrating depth sensors into radiology workflows to streamline scanning procedures and enhance patient experience through automated patient positioning.]]></description>
<pubDate>Mon, 26 Jan 2026 08:33:11 +0000</pubDate>
</item>
<item>
<title><![CDATA[Beyond Retention: Orchestrating Structural Safety and Plasticity in Continual Learning for LLMs]]></title>
<link>http://arxiv.org/abs/2601.18255v1</link>
<guid>2601.18255v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.LG, cs.AI
Authors: Fei Meng
Institution: 
Published: 2026-01-26
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Continual learning in Large Language Models (LLMs) faces the critical challenge of balancing stability (retaining old knowledge) and plasticity (learning new tasks). While Experience Replay (ER) is a standard countermeasure against catastrophic forgetting, its impact across diverse capabilities remains underexplored. In this work, we uncover a critical dichotomy in ER's behavior: while it induces positive backward transfer on robust, unstructured tasks (e.g., boosting performance on previous NLP classification tasks through repeated rehearsal), it causes severe negative transfer on fragile, structured domains like code generation (e.g., a significant relative drop in coding accuracy). This reveals that ER trades structural integrity for broad consolidation. To address this dilemma, we propose \textbf{Orthogonal Subspace Wake-up (OSW)}. OSW identifies essential parameter subspaces of previous tasks via a brief "wake-up" phase and enforces orthogonal updates for new tasks, providing a mathematically grounded "safety guarantee" for established knowledge structures. Empirical results across a diverse four-task sequence demonstrate that OSW uniquely succeeds in preserving fragile coding abilities where Replay fails, while simultaneously maintaining high plasticity for novel tasks. Our findings emphasize the necessity of evaluating structural safety alongside average retention in LLM continual learning.]]></description>
<pubDate>Mon, 26 Jan 2026 08:28:02 +0000</pubDate>
</item>
<item>
<title><![CDATA[BoRP: Bootstrapped Regression Probing for Scalable and Human-Aligned LLM Evaluation]]></title>
<link>http://arxiv.org/abs/2601.18253v1</link>
<guid>2601.18253v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.CL, cs.AI
Authors: Peng Sun, Xiangyu Zhang, Duan Wu
Institution: 
Published: 2026-01-26
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Accurate evaluation of user satisfaction is critical for iterative development of conversational AI. However, for open-ended assistants, traditional A/B testing lacks reliable metrics: explicit feedback is sparse, while implicit metrics are ambiguous. To bridge this gap, we introduce BoRP (Bootstrapped Regression Probing), a scalable framework for high-fidelity satisfaction evaluation. Unlike generative approaches, BoRP leverages the geometric properties of LLM latent space. It employs a polarization-index-based bootstrapping mechanism to automate rubric generation and utilizes Partial Least Squares (PLS) to map hidden states to continuous scores. Experiments on industrial datasets show that BoRP (Qwen3-8B/14B) significantly outperforms generative baselines (even Qwen3-Max) in alignment with human judgments. Furthermore, BoRP reduces inference costs by orders of magnitude, enabling full-scale monitoring and highly sensitive A/B testing via CUPED.]]></description>
<pubDate>Mon, 26 Jan 2026 08:20:02 +0000</pubDate>
</item>
<item>
<title><![CDATA[Co-PLNet: A Collaborative Point-Line Network for Prompt-Guided Wireframe Parsing]]></title>
<link>http://arxiv.org/abs/2601.18252v1</link>
<guid>2601.18252v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.CV, cs.AI, cs.LG, stat.ML
Authors: Chao Wang, Xuanying Li, Cheng Dai, Jinglei Feng, Yuxiang Luo et al.
Institution: 
Published: 2026-01-26
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Wireframe parsing aims to recover line segments and their junctions to form a structured geometric representation useful for downstream tasks such as Simultaneous Localization and Mapping (SLAM). Existing methods predict lines and junctions separately and reconcile them post-hoc, causing mismatches and reduced robustness. We present Co-PLNet, a point-line collaborative framework that exchanges spatial cues between the two tasks, where early detections are converted into spatial prompts via a Point-Line Prompt Encoder (PLP-Encoder), which encodes geometric attributes into compact and spatially aligned maps. A Cross-Guidance Line Decoder (CGL-Decoder) then refines predictions with sparse attention conditioned on complementary prompts, enforcing point-line consistency and efficiency. Experiments on Wireframe and YorkUrban show consistent improvements in accuracy and robustness, together with favorable real-time efficiency, demonstrating our effectiveness for structured geometry perception.]]></description>
<pubDate>Mon, 26 Jan 2026 08:16:02 +0000</pubDate>
</item>
<item>
<title><![CDATA[A multimodal vision foundation model for generalizable knee pathology]]></title>
<link>http://arxiv.org/abs/2601.18250v1</link>
<guid>2601.18250v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.CV, cs.AI
Authors: Kang Yu, Dingyu Wang, Zimu Yuan, Nan Zhou, Jiajun Liu et al.
Institution: 
Published: 2026-01-26
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Musculoskeletal disorders represent a leading cause of global disability, creating an urgent demand for precise interpretation of medical imaging. Current artificial intelligence (AI) approaches in orthopedics predominantly rely on task-specific, supervised learning paradigms. These methods are inherently fragmented, require extensive annotated datasets, and often lack generalizability across different modalities and clinical scenarios. The development of foundation models in this field has been constrained by the scarcity of large-scale, curated, and open-source musculoskeletal datasets. To address these challenges, we introduce OrthoFoundation, a multimodal vision foundation model optimized for musculoskeletal pathology. We constructed a pre-training dataset of 1.2 million unlabeled knee X-ray and MRI images from internal and public databases. Utilizing a Dinov3 backbone, the model was trained via self-supervised contrastive learning to capture robust radiological representations. OrthoFoundation achieves state-of-the-art (SOTA) performance across 14 downstream tasks. It attained superior accuracy in X-ray osteoarthritis diagnosis and ranked first in MRI structural injury detection. The model demonstrated remarkable label efficiency, matching supervised baselines using only 50% of labeled data. Furthermore, despite being pre-trained on knee images, OrthoFoundation exhibited exceptional cross-anatomy generalization to the hip, shoulder, and ankle. OrthoFoundation represents a significant advancement toward general-purpose AI for musculoskeletal imaging. By learning fundamental, joint-agnostic radiological semantics from large-scale multimodal data, it overcomes the limitations of conventional models, which provides a robust framework for reducing annotation burdens and enhancing diagnostic accuracy in clinical practice.]]></description>
<pubDate>Mon, 26 Jan 2026 08:14:51 +0000</pubDate>
</item>
<item>
<title><![CDATA[Tractable Gaussian Phase Retrieval with Heavy Tails and Adversarial Corruption with Near-Linear Sample Complexity]]></title>
<link>http://arxiv.org/abs/2601.18245v1</link>
<guid>2601.18245v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.LG
Authors: Santanu Das, Jatin Batra
Institution: 
Published: 2026-01-26
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Phase retrieval is the classical problem of recovering a signal $x^* \in \mathbb{R}^n$ from its noisy phaseless measurements $y_i = \langle a_i, x^* \rangle^2 + _i$ (where $_i$ denotes noise, and $a_i$ is the sensing vector) for $i \in [m]$. The problem of phase retrieval has a rich history, with a variety of applications such as optics, crystallography, heteroscedastic regression, astrophysics, etc. A major consideration in algorithms for phase retrieval is robustness against measurement errors. In recent breakthroughs in algorithmic robust statistics, efficient algorithms have been developed for several parameter estimation tasks such as mean estimation, covariance estimation, robust principal component analysis (PCA), etc. in the presence of heavy-tailed noise and adversarial corruptions. In this paper, we study efficient algorithms for robust phase retrieval with heavy-tailed noise when a constant fraction of both the measurements $y_i$ and the sensing vectors $a_i$ may be arbitrarily adversarially corrupted. For this problem, Buna and Rebeschini (AISTATS 2025) very recently gave an exponential time algorithm with sample complexity $O(n \log n)$. Their algorithm needs a robust spectral initialization, specifically, a robust estimate of the top eigenvector of a covariance matrix, which they deemed to be beyond known efficient algorithmic techniques (similar spectral initializations are a key ingredient of a large family of phase retrieval algorithms). In this work, we make a connection between robust spectral initialization and recent algorithmic advances in robust PCA, yielding the first polynomial-time algorithms for robust phase retrieval with both heavy-tailed noise and adversarial corruptions, in fact with near-linear (in $n$) sample complexity.]]></description>
<pubDate>Mon, 26 Jan 2026 08:06:16 +0000</pubDate>
</item>
<item>
<title><![CDATA[Vision-Language-Model-Guided Differentiable Ray Tracing for Fast and Accurate Multi-Material RF Parameter Estimation]]></title>
<link>http://arxiv.org/abs/2601.18242v1</link>
<guid>2601.18242v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.CV, cs.NI
Authors: Zerui Kang, Yishen Lim, Zhouyou Gu, Seung-Woo Ko, Tony Q. S. Quek et al.
Institution: 
Published: 2026-01-26
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Accurate radio-frequency (RF) material parameters are essential for electromagnetic digital twins in 6G systems, yet gradient-based inverse ray tracing (RT) remains sensitive to initialization and costly under limited measurements. This paper proposes a vision-language-model (VLM) guided framework that accelerates and stabilizes multi-material parameter estimation in a differentiable RT (DRT) engine. A VLM parses scene images to infer material categories and maps them to quantitative priors via an ITU-R material table, yielding informed conductivity initializations. The VLM further selects informative transmitter/receiver placements that promote diverse, material-discriminative paths. Starting from these priors, the DRT performs gradient-based refinement using measured received signal strengths. Experiments in NVIDIA Sionna on indoor scenes show 2-4$\times$ faster convergence and 10-100$\times$ lower final parameter error compared with uniform or random initialization and random placement baselines, achieving sub-0.1\% mean relative error with only a few receivers. Complexity analyses indicate per-iteration time scales near-linearly with the number of materials and measurement setups, while VLM-guided placement reduces the measurements required for accurate recovery. Ablations over RT depth and ray counts confirm further accuracy gains without significant per-iteration overhead. Results demonstrate that semantic priors from VLMs effectively guide physics-based optimization for fast and reliable RF material estimation.]]></description>
<pubDate>Mon, 26 Jan 2026 07:54:53 +0000</pubDate>
</item>
<item>
<title><![CDATA[TAM-Eval: Evaluating LLMs for Automated Unit Test Maintenance]]></title>
<link>http://arxiv.org/abs/2601.18241v1</link>
<guid>2601.18241v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.SE, cs.AI
Authors: Elena Bruches, Vadim Alperovich, Dari Baturova, Roman Derunets, Daniil Grebenkin et al.
Institution: 
Published: 2026-01-26
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

While Large Language Models (LLMs) have shown promise in software engineering, their application to unit testing remains largely confined to isolated test generation or oracle prediction, neglecting the broader challenge of test suite maintenance. We introduce TAM-Eval (Test Automated Maintenance Evaluation), a framework and benchmark designed to evaluate model performance across three core test maintenance scenarios: creation, repair, and updating of test suites. Unlike prior work limited to function-level tasks, TAM-Eval operates at the test file level, while maintaining access to full repository context during isolated evaluation, better reflecting real-world maintenance workflows. Our benchmark comprises 1,539 automatically extracted and validated scenarios from Python, Java, and Go projects. TAM-Eval supports system-agnostic evaluation of both raw LLMs and agentic workflows, using a reference-free protocol based on test suite pass rate, code coverage, and mutation testing. Empirical results indicate that state-of-the-art LLMs have limited capabilities in realistic test maintenance processes and yield only marginal improvements in test effectiveness. We release TAM-Eval as an open-source framework to support future research in automated software testing. Our data and code are publicly available at https://github.com/trndcenter/TAM-Eval.]]></description>
<pubDate>Mon, 26 Jan 2026 07:47:22 +0000</pubDate>
</item>
<item>
<title><![CDATA[V-Loop: Visual Logical Loop Verification for Hallucination Detection in Medical Visual Question Answering]]></title>
<link>http://arxiv.org/abs/2601.18240v1</link>
<guid>2601.18240v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.CV
Authors: Mengyuan Jin, Zehui Liao, Yong Xia
Institution: 
Published: 2026-01-26
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Multimodal Large Language Models (MLLMs) have shown remarkable capability in assisting disease diagnosis in medical visual question answering (VQA). However, their outputs remain vulnerable to hallucinations (i.e., responses that contradict visual facts), posing significant risks in high-stakes medical scenarios. Recent introspective detection methods, particularly uncertainty-based approaches, offer computational efficiency but are fundamentally indirect, as they estimate predictive uncertainty for an image-question pair rather than verifying the factual correctness of a specific answer. To address this limitation, we propose Visual Logical Loop Verification (V-Loop), a training-free and plug-and-play framework for hallucination detection in medical VQA. V-Loop introduces a bidirectional reasoning process that forms a visually grounded logical loop to verify factual correctness. Given an input, the MLLM produces an answer for the primary input pair. V-Loop extracts semantic units from the primary QA pair, generates a verification question by conditioning on the answer unit to re-query the question unit, and enforces visual attention consistency to ensure answering both primary question and verification question rely on the same image evidence. If the verification answer matches the expected semantic content, the logical loop closes, indicating factual grounding; otherwise, the primary answer is flagged as hallucinated. Extensive experiments on multiple medical VQA benchmarks and MLLMs show that V-Loop consistently outperforms existing introspective methods, remains highly efficient, and further boosts uncertainty-based approaches when used in combination.]]></description>
<pubDate>Mon, 26 Jan 2026 07:46:41 +0000</pubDate>
</item>
<item>
<title><![CDATA[TechING: Towards Real World Technical Image Understanding via VLMs]]></title>
<link>http://arxiv.org/abs/2601.18238v1</link>
<guid>2601.18238v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.CL, cs.CV, cs.LG
Authors: Tafazzul Nadeem, Bhavik Shangari, Manish Rai, Gagan Raj Gupta, Ashutosh Modi
Institution: 
Published: 2026-01-26
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Professionals working in technical domain typically hand-draw (on whiteboard, paper, etc.) technical diagrams (e.g., flowcharts, block diagrams, etc.) during discussions; however, if they want to edit these later, it needs to be drawn from scratch. Modern day VLMs have made tremendous progress in image understanding but they struggle when it comes to understanding technical diagrams. One way to overcome this problem is to fine-tune on real world hand-drawn images, but it is not practically possible to generate large number of such images. In this paper, we introduce a large synthetically generated corpus (reflective of real world images) for training VLMs and subsequently evaluate VLMs on a smaller corpus of hand-drawn images (with the help of humans). We introduce several new self-supervision tasks for training and perform extensive experiments with various baseline models and fine-tune Llama 3.2 11B-instruct model on synthetic images on these tasks to obtain LLama-VL-TUG, which significantly improves the ROUGE-L performance of Llama 3.2 11B-instruct by 2.14x and achieves the best all-round performance across all baseline models. On real-world images, human evaluation reveals that we achieve minimum compilation errors across all baselines in 7 out of 8 diagram types and improve the average F1 score of Llama 3.2 11B-instruct by 6.97x.]]></description>
<pubDate>Mon, 26 Jan 2026 07:43:55 +0000</pubDate>
</item>
<item>
<title><![CDATA[Generative AI in Saudi Arabia: A National Survey of Adoption, Risks, and Public Perceptions]]></title>
<link>http://arxiv.org/abs/2601.18234v1</link>
<guid>2601.18234v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.CY, cs.AI, cs.CL
Authors: Abdulaziz AlDakheel, Ali Alshehre, Esraa Alamoudi, Moslim AlKhabbaz, Ahmed Aljohani et al.
Institution: 
Published: 2026-01-26
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Generative Artificial Intelligence (GenAI) is rapidly becoming embedded in Saudi Arabia's digital transformation under Vision 2030, yet public awareness, adoption, and concerns surrounding these tools remain underexplored. This study provides an early snapshot of GenAI engagement among Saudi nationals. Using a nationwide survey of 330 participants across regions, age groups, and employment sectors, we examine seven dimensions of GenAI use: awareness and understanding, adoption patterns, perceived impacts, training needs, risks and barriers, data-sharing behaviors, and future expectations. Findings show that 93% of respondents actively use GenAI primarily for text-based tasks, while more advanced uses such as programming or multimodal generation are less common. Despite the prevalence of use, overall awareness and conceptual understanding remain uneven, with many reporting limited technical knowledge. Participants recognize GenAI's benefits for productivity, work quality, and understanding complex information, yet caution that sustained reliance may undermine critical thinking and key professional skills. Trust in AI-generated outputs remains cautious, with widespread concerns about privacy, misinformation, and ethical misuse, including potential job displacement. Respondents show strong interest in structured GenAI training that combines foundational skills, domain-specific applications, and clear guidance on privacy, ethics, and responsible use. These results establish a baseline for GenAI engagement in Saudi Arabia and highlight priorities for policymakers and developers: expanding AI literacy, ensuring culturally and linguistically aligned GenAI solutions, and strengthening frameworks for privacy and responsible deployment.]]></description>
<pubDate>Mon, 26 Jan 2026 07:40:41 +0000</pubDate>
</item>
<item>
<title><![CDATA[Rethinking Cross-Modal Fine-Tuning: Optimizing the Interaction between Feature Alignment and Target Fitting]]></title>
<link>http://arxiv.org/abs/2601.18231v1</link>
<guid>2601.18231v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.LG, cs.AI
Authors: Trong Khiem Tran, Manh Cuong Dao, Phi Le Nguyen, Thao Nguyen Truong, Trong Nghia Hoang
Institution: 
Published: 2026-01-26
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Adapting pre-trained models to unseen feature modalities has become increasingly important due to the growing need for cross-disciplinary knowledge integration.~A key challenge here is how to align the representation of new modalities with the most relevant parts of the pre-trained model's representation space to enable accurate knowledge transfer.~This requires combining feature alignment with target fine-tuning, but uncalibrated combinations can exacerbate misalignment between the source and target feature-label structures and reduce target generalization.~Existing work however lacks a theoretical understanding of this critical interaction between feature alignment and target fitting.~To bridge this gap, we develop a principled framework that establishes a provable generalization bound on the target error, which explains the interaction between feature alignment and target fitting through a novel concept of feature-label distortion.~This bound offers actionable insights into how this interaction should be optimized for practical algorithm design. The resulting approach achieves significantly improved performance over state-of-the-art methods across a wide range of benchmark datasets.]]></description>
<pubDate>Mon, 26 Jan 2026 07:34:15 +0000</pubDate>
</item>
<item>
<title><![CDATA[Facial Emotion Recognition on FER-2013 using an EfficientNetB2-Based Approach]]></title>
<link>http://arxiv.org/abs/2601.18228v1</link>
<guid>2601.18228v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.CV, cs.LG
Authors: Sahil Naik, Soham Bagayatkar, Pavankumar Singh
Institution: 
Published: 2026-01-26
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Detection of human emotions based on facial images in real-world scenarios is a difficult task due to low image quality, variations in lighting, pose changes, background distractions, small inter-class variations, noisy crowd-sourced labels, and severe class imbalance, as observed in the FER-2013 dataset of 48x48 grayscale images. Although recent approaches using large CNNs such as VGG and ResNet achieve reasonable accuracy, they are computationally expensive and memory-intensive, limiting their practicality for real-time applications. We address these challenges using a lightweight and efficient facial emotion recognition pipeline based on EfficientNetB2, trained using a two-stage warm-up and fine-tuning strategy. The model is enhanced with AdamW optimization, decoupled weight decay, label smoothing (epsilon = 0.06) to reduce annotation noise, and clipped class weights to mitigate class imbalance, along with dropout, mixed-precision training, and extensive real-time data augmentation. The model is trained using a stratified 87.5%/12.5% train-validation split while keeping the official test set intact, achieving a test accuracy of 68.78% with nearly ten times fewer parameters than VGG16-based baselines. Experimental results, including per-class metrics and learning dynamics, demonstrate stable training and strong generalization, making the proposed approach suitable for real-time and edge-based applications.]]></description>
<pubDate>Mon, 26 Jan 2026 07:29:50 +0000</pubDate>
</item>
<item>
<title><![CDATA[Yunjue Agent Tech Report: A Fully Reproducible, Zero-Start In-Situ Self-Evolving Agent System for Open-Ended Tasks]]></title>
<link>http://arxiv.org/abs/2601.18226v1</link>
<guid>2601.18226v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.AI
Authors: Haotian Li, Shijun Yang, Weizhen Qi, Silei Zhao, Rui Hua et al.
Institution: 
Published: 2026-01-26
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Conventional agent systems often struggle in open-ended environments where task distributions continuously drift and external supervision is scarce. Their reliance on static toolsets or offline training lags behind these dynamics, leaving the system's capability boundaries rigid and unknown. To address this, we propose the In-Situ Self-Evolving paradigm. This approach treats sequential task interactions as a continuous stream of experience, enabling the system to distill short-term execution feedback into long-term, reusable capabilities without access to ground-truth labels. Within this framework, we identify tool evolution as the critical pathway for capability expansion, which provides verifiable, binary feedback signals. Within this framework, we develop Yunjue Agent, a system that iteratively synthesizes, optimizes, and reuses tools to navigate emerging challenges. To optimize evolutionary efficiency, we further introduce a Parallel Batch Evolution strategy. Empirical evaluations across five diverse benchmarks under a zero-start setting demonstrate significant performance gains over proprietary baselines. Additionally, complementary warm-start evaluations confirm that the accumulated general knowledge can be seamlessly transferred to novel domains. Finally, we propose a novel metric to monitor evolution convergence, serving as a function analogous to training loss in conventional optimization. We open-source our codebase, system traces, and evolved tools to facilitate future research in resilient, self-evolving intelligence.]]></description>
<pubDate>Mon, 26 Jan 2026 07:27:47 +0000</pubDate>
</item>
<item>
<title><![CDATA[ShopSimulator: Evaluating and Exploring RL-Driven LLM Agent for Shopping Assistants]]></title>
<link>http://arxiv.org/abs/2601.18225v1</link>
<guid>2601.18225v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.AI
Authors: Pei Wang, Yanan Wu, Xiaoshuai Song, Weixun Wang, Gengru Chen et al.
Institution: 
Published: 2026-01-26
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Large language model (LLM)-based agents are increasingly deployed in e-commerce shopping. To perform thorough, user-tailored product searches, agents should interpret personal preferences, engage in multi-turn dialogues, and ultimately retrieve and discriminate among highly similar products. However, existing research has yet to provide a unified simulation environment that consistently captures all of these aspects, and always focuses solely on evaluation benchmarks without training support. In this paper, we introduce ShopSimulator, a large-scale and challenging Chinese shopping environment. Leveraging ShopSimulator, we evaluate LLMs across diverse scenarios, finding that even the best-performing models achieve less than 40% full-success rate. Error analysis reveals that agents struggle with deep search and product selection in long trajectories, fail to balance the use of personalization cues, and to effectively engage with users. Further training exploration provides practical guidance for overcoming these weaknesses, with the combination of supervised fine-tuning (SFT) and reinforcement learning (RL) yielding significant performance improvements. Code and data will be released at https://github.com/ShopAgent-Team/ShopSimulator.]]></description>
<pubDate>Mon, 26 Jan 2026 07:24:28 +0000</pubDate>
</item>
<item>
<title><![CDATA[HomoFM: Deep Homography Estimation with Flow Matching]]></title>
<link>http://arxiv.org/abs/2601.18222v1</link>
<guid>2601.18222v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.CV
Authors: Mengfan He, Liangzheng Sun, Chunyu Li, Ziyang Meng
Institution: 
Published: 2026-01-26
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Deep homography estimation has broad applications in computer vision and robotics. Remarkable progresses have been achieved while the existing methods typically treat it as a direct regression or iterative refinement problem and often struggling to capture complex geometric transformations or generalize across different domains. In this work, we propose HomoFM, a new framework that introduces the flow matching technique from generative modeling into the homography estimation task for the first time. Unlike the existing methods, we formulate homography estimation problem as a velocity field learning problem. By modeling a continuous and point-wise velocity field that transforms noisy distributions into registered coordinates, the proposed network recovers high-precision transformations through a conditional flow trajectory. Furthermore, to address the challenge of domain shifts issue, e.g., the cases of multimodal matching or varying illumination scenarios, we integrate a gradient reversal layer (GRL) into the feature extraction backbone. This domain adaptation strategy explicitly constrains the encoder to learn domain-invariant representations, significantly enhancing the network's robustness. Extensive experiments demonstrate the effectiveness of the proposed method, showing that HomoFM outperforms state-of-the-art methods in both estimation accuracy and robustness on standard benchmarks. Code and data resource are available at https://github.com/hmf21/HomoFM.]]></description>
<pubDate>Mon, 26 Jan 2026 07:17:32 +0000</pubDate>
</item>
<item>
<title><![CDATA[Automated HER2 scoring with uncertainty quantification using lensfree holography and deep learning]]></title>
<link>http://arxiv.org/abs/2601.18219v1</link>
<guid>2601.18219v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.CV, cs.LG
Authors: Che-Yung Shen, Xilin Yang, Yuzhu Li, Leon Lenk, Aydogan Ozcan
Institution: 
Published: 2026-01-26
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

Accurate assessment of human epidermal growth factor receptor 2 (HER2) expression is critical for breast cancer diagnosis, prognosis, and therapy selection; yet, most existing digital HER2 scoring methods rely on bulky and expensive optical systems. Here, we present a compact and cost-effective lensfree holography platform integrated with deep learning for automated HER2 scoring of immunohistochemically stained breast tissue sections. The system captures lensfree diffraction patterns of stained HER2 tissue sections under RGB laser illumination and acquires complex field information over a sample area of ~1,250 mm^2 at an effective throughput of ~84 mm^2 per minute. To enhance diagnostic reliability, we incorporated an uncertainty quantification strategy based on Bayesian Monte Carlo dropout, which provides autonomous uncertainty estimates for each prediction and supports reliable, robust HER2 scoring, with an overall correction rate of 30.4%. Using a blinded test set of 412 unique tissue samples, our approach achieved a testing accuracy of 84.9% for 4-class (0, 1+, 2+, 3+) HER2 classification and 94.8% for binary (0/1+ vs. 2+/3+) HER2 scoring with uncertainty quantification. Overall, this lensfree holography approach provides a practical pathway toward portable, high-throughput, and cost-effective HER2 scoring, particularly suited for resource-limited settings, where traditional digital pathology infrastructure is unavailable.]]></description>
<pubDate>Mon, 26 Jan 2026 07:09:08 +0000</pubDate>
</item>
<item>
<title><![CDATA[PaperTok: Exploring the Use of Generative AI for Creating Short-form Videos for Research Communication]]></title>
<link>http://arxiv.org/abs/2601.18218v1</link>
<guid>2601.18218v1</guid>
<description><![CDATA[Source: arXiv
Tags: cs.HC, cs.AI, cs.CL
Authors: Meziah Ruby Cristobal, Hyeonjeong Byeon, Tze-Yu Chen, Ruoxi Shang, Donghoon Shin et al.
Institution: 
Published: 2026-01-26
Score: 4/10
Citations: 0
Upvotes: 0
GitHub: 
Stars: 0

The dissemination of scholarly research is critical, yet researchers often lack the time and skills to create engaging content for popular media such as short-form videos. To address this gap, we explore the use of generative AI to help researchers transform their academic papers into accessible video content. Informed by a formative study with science communicators and content creators (N=8), we designed PaperTok, an end-to-end system that automates the initial creative labor by generating script options and corresponding audiovisual content from a source paper. Researchers can then refine based on their preferences with further prompting. A mixed-methods user study (N=18) and crowdsourced evaluation (N=100) demonstrate that PaperTok's workflow can help researchers create engaging and informative short-form videos. We also identified the need for more fine-grained controls in the creation process. To this end, we offer implications for future generative tools that support science outreach.]]></description>
<pubDate>Mon, 26 Jan 2026 07:08:57 +0000</pubDate>
</item>
</channel>
</rss>