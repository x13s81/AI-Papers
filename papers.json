{
  "generated_at": "2026-02-03T03:56:43Z",
  "date": "2026-02-03",
  "total_count": 249,
  "papers": [
    {
      "id": "2601.22642",
      "title": "Pushing the Boundaries of Natural Reasoning: Interleaved Bonus from Formal-Logic Verification",
      "link": "https://huggingface.co/papers/2601.22642",
      "pdf_link": "https://arxiv.org/pdf/2601.22642.pdf",
      "authors": "Chuxue Cao, Jinluan Yang, Haoran Li, Kunhao Pan, Zijian Zhao",
      "institution": "",
      "abstract": "Large Language Models (LLMs) show remarkable capabilities, yet their stochastic next-token prediction creates logical inconsistencies and reward hacking that formal symbolic systems avoid. To bridge this gap, we introduce a formal logic verification-guided framework that dynamically interleaves formal symbolic verification with the natural language generation process, providing real-time feedback to detect and rectify errors as they occur. Distinguished from previous neuro-symbolic methods limited by passive post-hoc validation, our approach actively penalizes intermediate fallacies during the reasoning chain. We operationalize this framework via a novel two-stage training pipeline that synergizes formal logic verification-guided supervised fine-tuning and policy optimization. Extensive evaluation on six benchmarks spanning mathematical, logical, and general reasoning demonstrates that our 7B and 14B models outperform state-of-the-art baselines by average margins of 10.4% and 14.2%, respectively. These results validate that formal verification can serve as a scalable mechanism to significantly push the performance boundaries of advanced LLM reasoning.",
      "source": "HuggingFace",
      "pubDateISO": "2026-01-30",
      "tags": [],
      "topics": [
        "Neuro-Symbolic Integration",
        "Formal Verification",
        "Large Language Models"
      ],
      "score": 9,
      "score_reason": "Bridges logic gap",
      "citations": 0,
      "upvotes": 7,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "The paper introduces a novel framework that dynamically interleaves formal symbolic verification with natural language generation, providing real-time feedback to detect and rectify errors during the reasoning process.",
      "why_it_matters": "This work matters because it addresses the long-standing issue of logical inconsistencies in Large Language Models, potentially leading to more reliable and trustworthy AI systems for high-stakes applications.",
      "limitations": "The main limitation of this approach is that it relies on the availability of formal logic specifications for the tasks and domains of interest, which may not always be feasible or scalable."
    },
    {
      "id": "2601.18005",
      "title": "Flow-based Extremal Mathematical Structure Discovery",
      "link": "https://huggingface.co/papers/2601.18005",
      "pdf_link": "https://arxiv.org/pdf/2601.18005.pdf",
      "authors": "Gergely Bérczi, Baran Hashemi, Jonas Klüver",
      "institution": "",
      "abstract": "The discovery of extremal structures in mathematics requires navigating vast and nonconvex landscapes where analytical methods offer little guidance and brute-force search becomes intractable. We introduce FlowBoost, a closed-loop generative framework that learns to discover rare and extremal geometric structures by combining three components: (i) a geometry-aware conditional flow-matching model that learns to sample high-quality configurations, (ii) reward-guided policy optimization with action exploration that directly optimizes the generation process toward the objective while maintaining diversity, and (iii) stochastic local search for both training-data generation and final refinement. Unlike prior open-loop approaches, such as PatternBoost that retrains on filtered discrete samples, or AlphaEvolve which relies on frozen Large Language Models (LLMs) as evolutionary mutation operators, FlowBoost enforces geometric feasibility during sampling, and propagates reward signal directly into the generative model, closing the optimization loop and requiring much smaller training sets and shorter training times, and reducing the required outer-loop iterations by orders of magnitude, while eliminating dependence on LLMs. We demonstrate the framework on four geometric optimization problems: sphere packing in hypercubes, circle packing maximizing sum of radii, the Heilbronn triangle problem, and star discrepancy minimization. In several cases, FlowBoost discovers configurations that match or exceed the best known results. For circle packings, we improve the best known lower bounds, surpassing the LLM-based system AlphaEvolve while using substantially fewer computational resources.",
      "source": "HuggingFace",
      "pubDateISO": "2026-01-25",
      "tags": [],
      "topics": [
        "Geometric Optimization",
        "Generative Models",
        "Reinforcement Learning"
      ],
      "score": 9,
      "score_reason": "Novel structure discovery",
      "citations": 0,
      "upvotes": 2,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "The paper introduces FlowBoost, a closed-loop generative framework that combines conditional flow-matching models, reward-guided policy optimization, and stochastic local search to discover rare and extremal geometric structures.",
      "why_it_matters": "This framework has the potential to significantly reduce the computational cost and improve the efficiency of discovering extremal mathematical structures, which is crucial in various fields such as geometry, optimization, and computer science.",
      "limitations": "The approach relies on careful tuning of the reward function and may not be directly applicable to problems with complex or high-dimensional search spaces, requiring further research to extend its applicability."
    },
    {
      "id": "2601.22975",
      "title": "Golden Goose: A Simple Trick to Synthesize Unlimited RLVR Tasks from Unverifiable Internet Text",
      "link": "https://huggingface.co/papers/2601.22975",
      "pdf_link": "https://arxiv.org/pdf/2601.22975.pdf",
      "authors": "Ximing Lu, David Acuna, Jaehun Jung, Jian Hu, Di Zhang",
      "institution": "",
      "abstract": "Reinforcement Learning with Verifiable Rewards (RLVR) has become a cornerstone for unlocking complex reasoning in Large Language Models (LLMs). Yet, scaling up RL is bottlenecked by limited existing verifiable data, where improvements increasingly saturate over prolonged training. To overcome this, we propose Golden Goose, a simple trick to synthesize unlimited RLVR tasks from unverifiable internet text by constructing a multiple-choice question-answering version of the fill-in-the-middle task. Given a source text, we prompt an LLM to identify and mask key reasoning steps, then generate a set of diverse, plausible distractors. This enables us to leverage reasoning-rich unverifiable corpora typically excluded from prior RLVR data construction (e.g., science textbooks) to synthesize GooseReason-0.7M, a large-scale RLVR dataset with over 0.7 million tasks spanning mathematics, programming, and general scientific domains. Empirically, GooseReason effectively revives models saturated on existing RLVR data, yielding robust, sustained gains under continuous RL and achieving new state-of-the-art results for 1.5B and 4B-Instruct models across 15 diverse benchmarks. Finally, we deploy Golden Goose in a real-world setting, synthesizing RLVR tasks from raw FineWeb scrapes for the cybersecurity domain, where no prior RLVR data exists. Training Qwen3-4B-Instruct on the resulting data GooseReason-Cyber sets a new state-of-the-art in cybersecurity, surpassing a 7B domain-specialized model with extensive domain-specific pre-training and post-training. This highlights the potential of automatically scaling up RLVR data by exploiting abundant, reasoning-rich, unverifiable internet text.",
      "source": "HuggingFace",
      "pubDateISO": "2026-01-30",
      "tags": [],
      "topics": [
        "Reinforcement Learning with Verifiable Rewards (RLVR)",
        "Large Language Models (LLMs)",
        "Natural Language Processing (NLP)"
      ],
      "score": 8,
      "score_reason": "Unlimited RLVR",
      "citations": 0,
      "upvotes": 48,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "The paper proposes Golden Goose, a novel method to synthesize unlimited Reinforcement Learning with Verifiable Rewards (RLVR) tasks from unverifiable internet text by constructing multiple-choice question-answering versions of fill-in-the-middle tasks.",
      "why_it_matters": "This contribution matters because it overcomes the limitation of scarce verifiable data for RLVR, enabling large language models to learn complex reasoning skills and achieve state-of-the-art results in various domains.",
      "limitations": "The main limitation of this approach is that the quality of the synthesized tasks relies on the ability of the large language model to identify and mask key reasoning steps, which may not always be accurate or effective."
    },
    {
      "id": "2601.23143",
      "title": "THINKSAFE: Self-Generated Safety Alignment for Reasoning Models",
      "link": "https://huggingface.co/papers/2601.23143",
      "pdf_link": "https://arxiv.org/pdf/2601.23143.pdf",
      "authors": "Seanie Lee, Sangwoo Park, Yumin Choi, Gyeongman Kim, Minki Kang",
      "institution": "",
      "abstract": "Large reasoning models (LRMs) achieve remarkable performance by leveraging reinforcement learning (RL) on reasoning tasks to generate long chain-of-thought (CoT) reasoning. However, this over-optimization often prioritizes compliance, making models vulnerable to harmful prompts. To mitigate this safety degradation, recent approaches rely on external teacher distillation, yet this introduces a distributional discrepancy that degrades native reasoning. We propose ThinkSafe, a self-generated alignment framework that restores safety alignment without external teachers. Our key insight is that while compliance suppresses safety mechanisms, models often retain latent knowledge to identify harm. ThinkSafe unlocks this via lightweight refusal steering, guiding the model to generate in-distribution safety reasoning traces. Fine-tuning on these self-generated responses effectively realigns the model while minimizing distribution shift. Experiments on DeepSeek-R1-Distill and Qwen3 show ThinkSafe significantly improves safety while preserving reasoning proficiency. Notably, it achieves superior safety and comparable reasoning to GRPO, with significantly reduced computational cost. Code, models, and datasets are available at https://github.com/seanie12/ThinkSafe.git.",
      "source": "HuggingFace",
      "pubDateISO": "2026-01-30",
      "tags": [],
      "topics": [
        "Reinforcement Learning",
        "Reasoning Models",
        "Adversarial Robustness"
      ],
      "score": 8,
      "score_reason": "Improves safety",
      "citations": 0,
      "upvotes": 35,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "This paper proposes ThinkSafe, a self-generated alignment framework that restores safety alignment in large reasoning models without relying on external teacher distillation, by leveraging lightweight refusal steering to unlock latent knowledge and generate in-distribution safety reasoning traces.",
      "why_it_matters": "This research matters because it addresses the critical issue of safety degradation in large reasoning models, which is essential for deploying these models in real-world applications where harmful prompts can have severe consequences.",
      "limitations": "The main limitation of this approach is that it assumes the model retains latent knowledge to identify harm, which may not always be the case, particularly in models that have been heavily optimized for compliance."
    },
    {
      "id": "2601.21998",
      "title": "Causal World Modeling for Robot Control",
      "link": "https://huggingface.co/papers/2601.21998",
      "pdf_link": "https://arxiv.org/pdf/2601.21998.pdf",
      "authors": "Lin Li, Qihang Zhang, Yiming Luo, Shuai Yang, Ruilin Wang",
      "institution": "",
      "abstract": "This work highlights that video world modeling, alongside vision-language pre-training, establishes a fresh and independent foundation for robot learning. Intuitively, video world models provide the ability to imagine the near future by understanding the causality between actions and visual dynamics. Inspired by this, we introduce LingBot-VA, an autoregressive diffusion framework that learns frame prediction and policy execution simultaneously. Our model features three carefully crafted designs: (1) a shared latent space, integrating vision and action tokens, driven by a Mixture-of-Transformers (MoT) architecture, (2) a closed-loop rollout mechanism, allowing for ongoing acquisition of environmental feedback with ground-truth observations, (3) an asynchronous inference pipeline, parallelizing action prediction and motor execution to support efficient control. We evaluate our model on both simulation benchmarks and real-world scenarios, where it shows significant promise in long-horizon manipulation, data efficiency in post-training, and strong generalizability to novel configurations. The code and model are made publicly available to facilitate the community.",
      "source": "HuggingFace",
      "pubDateISO": "2026-01-29",
      "tags": [],
      "topics": [
        "Robot Learning",
        "Causal World Modeling",
        "Autoregressive Diffusion Models"
      ],
      "score": 8,
      "score_reason": "Fresh Foundation",
      "citations": 0,
      "upvotes": 19,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "The introduction of LingBot-VA, an autoregressive diffusion framework that integrates vision and action tokens via a Mixture-of-Transformers architecture, enables simultaneous learning of frame prediction and policy execution for robot control.",
      "why_it_matters": "This work matters because it establishes a new foundation for robot learning, leveraging video world modeling and vision-language pre-training to improve long-horizon manipulation, data efficiency, and generalizability in real-world scenarios.",
      "limitations": "The main limitation of this approach is the requirement for large amounts of data and computational resources to train the complex Mixture-of-Transformers architecture and support the asynchronous inference pipeline."
    },
    {
      "id": "2601.23182",
      "title": "FourierSampler: Unlocking Non-Autoregressive Potential in Diffusion Language Models via Frequency-Guided Generation",
      "link": "https://huggingface.co/papers/2601.23182",
      "pdf_link": "https://arxiv.org/pdf/2601.23182.pdf",
      "authors": "Siyang He, Qiqi Wang, Xiaoran Liu, Hongnan Ma, Yiwei Shi",
      "institution": "",
      "abstract": "Despite the non-autoregressive potential of diffusion language models (dLLMs), existing decoding strategies demonstrate positional bias, failing to fully unlock the potential of arbitrary generation. In this work, we delve into the inherent spectral characteristics of dLLMs and present the first frequency-domain analysis showing that low-frequency components in hidden states primarily encode global structural information and long-range dependencies, while high-frequency components are responsible for characterizing local details. Based on this observation, we propose FourierSampler, which leverages a frequency-domain sliding window mechanism to dynamically guide the model to achieve a \"structure-to-detail\" generation. FourierSampler outperforms other inference enhancement strategies on LLADA and SDAR, achieving relative improvements of 20.4% on LLaDA1.5-8B and 16.0% on LLaDA-8B-Instruct. It notably surpasses similarly sized autoregressive models like Llama3.1-8B-Instruct.",
      "source": "HuggingFace",
      "pubDateISO": "2026-01-30",
      "tags": [],
      "topics": [
        "Diffusion Language Models",
        "Non-Autoregressive Generation",
        "Frequency-Domain Analysis"
      ],
      "score": 8,
      "score_reason": "Novel decoding strategy",
      "citations": 0,
      "upvotes": 18,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "This paper introduces FourierSampler, a novel frequency-domain decoding strategy that leverages spectral characteristics of diffusion language models to guide generation and mitigate positional bias.",
      "why_it_matters": "The proposed approach enables non-autoregressive diffusion language models to achieve state-of-the-art performance, surpassing similarly sized autoregressive models and unlocking new potential for efficient and flexible language generation.",
      "limitations": "The effectiveness of FourierSampler may be limited by its reliance on the specific spectral properties of the underlying diffusion language model, which may not generalize to all model architectures or tasks."
    },
    {
      "id": "2601.23184",
      "title": "ReGuLaR: Variational Latent Reasoning Guided by Rendered Chain-of-Thought",
      "link": "https://huggingface.co/papers/2601.23184",
      "pdf_link": "https://arxiv.org/pdf/2601.23184.pdf",
      "authors": "Fanmeng Wang, Haotian Liu, Guojiang Zhao, Hongteng Xu, Zhifeng Gao",
      "institution": "",
      "abstract": "While Chain-of-Thought (CoT) significantly enhances the performance of Large Language Models (LLMs), explicit reasoning chains introduce substantial computational redundancy. Recent latent reasoning methods attempt to mitigate this by compressing reasoning processes into latent space, but often suffer from severe performance degradation due to the lack of appropriate compression guidance. In this study, we propose Rendered CoT-Guided variational Latent Reasoning (ReGuLaR), a simple yet novel latent learning paradigm resolving this issue. Fundamentally, we formulate latent reasoning within the Variational Auto-Encoding (VAE) framework, sampling the current latent reasoning state from the posterior distribution conditioned on previous ones. Specifically, when learning this variational latent reasoning model, we render explicit reasoning chains as images, from which we extract dense visual-semantic representations to regularize the posterior distribution, thereby achieving efficient compression with minimal information loss. Extensive experiments demonstrate that ReGuLaR significantly outperforms existing latent reasoning methods across both computational efficiency and reasoning effectiveness, and even surpasses CoT through multi-modal reasoning, providing a new and insightful solution to latent reasoning. Code: https://github.com/FanmengWang/ReGuLaR.",
      "source": "HuggingFace",
      "pubDateISO": "2026-01-30",
      "tags": [],
      "topics": [
        "Latent Reasoning",
        "Variational Auto-Encoding (VAE)",
        "Chain-of-Thought (CoT) Prompting"
      ],
      "score": 8,
      "score_reason": "Latent reasoning",
      "citations": 0,
      "upvotes": 13,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "The paper proposes ReGuLaR, a novel latent learning paradigm that formulates latent reasoning within the Variational Auto-Encoding (VAE) framework and utilizes rendered explicit reasoning chains as images to regularize the posterior distribution.",
      "why_it_matters": "This work matters because it addresses the computational redundancy and performance degradation issues in latent reasoning methods, providing a more efficient and effective solution for Large Language Models (LLMs).",
      "limitations": "The main limitation of this approach is that it relies on the quality of the rendered images and the extracted visual-semantic representations, which may not always accurately capture the underlying reasoning processes."
    },
    {
      "id": "2601.21716",
      "title": "DreamActor-M2: Universal Character Image Animation via Spatiotemporal In-Context Learning",
      "link": "https://huggingface.co/papers/2601.21716",
      "pdf_link": "https://arxiv.org/pdf/2601.21716.pdf",
      "authors": "Mingshuang Luo, Shuang Liang, Zhengkun Rong, Yuxuan Luo, Tianshu Hu",
      "institution": "",
      "abstract": "Character image animation aims to synthesize high-fidelity videos by transferring motion from a driving sequence to a static reference image. Despite recent advancements, existing methods suffer from two fundamental challenges: (1) suboptimal motion injection strategies that lead to a trade-off between identity preservation and motion consistency, manifesting as a \"see-saw\", and (2) an over-reliance on explicit pose priors (e.g., skeletons), which inadequately capture intricate dynamics and hinder generalization to arbitrary, non-humanoid characters. To address these challenges, we present DreamActor-M2, a universal animation framework that reimagines motion conditioning as an in-context learning problem. Our approach follows a two-stage paradigm. First, we bridge the input modality gap by fusing reference appearance and motion cues into a unified latent space, enabling the model to jointly reason about spatial identity and temporal dynamics by leveraging the generative prior of foundational models. Second, we introduce a self-bootstrapped data synthesis pipeline that curates pseudo cross-identity training pairs, facilitating a seamless transition from pose-dependent control to direct, end-to-end RGB-driven animation. This strategy significantly enhances generalization across diverse characters and motion scenarios. To facilitate comprehensive evaluation, we further introduce AW Bench, a versatile benchmark encompassing a wide spectrum of characters types and motion scenarios. Extensive experiments demonstrate that DreamActor-M2 achieves state-of-the-art performance, delivering superior visual fidelity and robust cross-domain generalization. Project Page: https://grisoon.github.io/DreamActor-M2/",
      "source": "HuggingFace",
      "pubDateISO": "2026-01-29",
      "tags": [],
      "topics": [
        "Computer Vision",
        "Generative Models",
        "Motion Analysis"
      ],
      "score": 8,
      "score_reason": "Universal animation method",
      "citations": 0,
      "upvotes": 12,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "The paper introduces DreamActor-M2, a novel animation framework that reimagines motion conditioning as an in-context learning problem, leveraging a unified latent space and self-bootstrapped data synthesis pipeline to enhance generalization across diverse characters and motion scenarios.",
      "why_it_matters": "This work matters because it addresses the long-standing challenges of suboptimal motion injection and over-reliance on explicit pose priors in character image animation, enabling more realistic and flexible animation of arbitrary characters.",
      "limitations": "The main limitation of this approach is that it relies on the quality of the foundational models used to generate the unified latent space, which may not always capture the intricacies of complex motion dynamics."
    },
    {
      "id": "2601.21358",
      "title": "Latent Chain-of-Thought as Planning: Decoupling Reasoning from Verbalization",
      "link": "https://huggingface.co/papers/2601.21358",
      "pdf_link": "https://arxiv.org/pdf/2601.21358.pdf",
      "authors": "Jiecong Wang, Hao Peng, Chunyang Liu",
      "institution": "",
      "abstract": "Chain-of-Thought (CoT) empowers Large Language Models (LLMs) to tackle complex problems, but remains constrained by the computational cost and reasoning path collapse when grounded in discrete token spaces. Recent latent reasoning approaches attempt to optimize efficiency by performing reasoning within continuous hidden states. However, these methods typically operate as opaque end-to-end mappings from explicit reasoning steps to latent states, and often require a pre-defined number of latent steps during inference. In this work, we introduce PLaT (Planning with Latent Thoughts), a framework that reformulates latent reasoning as planning by fundamentally decouple reasoning from verbalization. We model reasoning as a deterministic trajectory of latent planning states, while a separate Decoder grounds these thoughts into text when necessary. This decoupling allows the model to dynamically determine when to terminate reasoning rather than relying on fixed hyperparameters. Empirical results on mathematical benchmarks reveal a distinct trade-off: while PLaT achieves lower greedy accuracy than baselines, it demonstrates superior scalability in terms of reasoning diversity. This indicates that PLaT learns a robust, broader solution space, offering a transparent and scalable foundation for inference-time search.",
      "source": "HuggingFace",
      "pubDateISO": "2026-01-29",
      "tags": [],
      "topics": [
        "Latent Reasoning",
        "Chain-of-Thought",
        "Large Language Models"
      ],
      "score": 8,
      "score_reason": "Decouples reasoning",
      "citations": 0,
      "upvotes": 5,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "The paper introduces PLaT, a framework that decouples reasoning from verbalization by modeling reasoning as a deterministic trajectory of latent planning states, allowing for dynamic termination of reasoning without relying on fixed hyperparameters.",
      "why_it_matters": "This work matters because it enables Large Language Models to tackle complex problems more efficiently and scalably, by reformulating latent reasoning as planning and allowing for a more robust and broader solution space.",
      "limitations": "The main limitation of PLaT is that it achieves lower greedy accuracy than baselines, indicating potential trade-offs between accuracy and scalability in certain scenarios."
    },
    {
      "id": "2601.23188",
      "title": "Deep Search with Hierarchical Meta-Cognitive Monitoring Inspired by Cognitive Neuroscience",
      "link": "https://huggingface.co/papers/2601.23188",
      "pdf_link": "https://arxiv.org/pdf/2601.23188.pdf",
      "authors": "Zhongxiang Sun, Qipeng Wang, Weijie Yu, Jingxuan Yang, Haolang Lu",
      "institution": "",
      "abstract": "Deep search agents powered by large language models have demonstrated strong capabilities in multi-step retrieval, reasoning, and long-horizon task execution. However, their practical failures often stem from the lack of mechanisms to monitor and regulate reasoning and retrieval states as tasks evolve under uncertainty. Insights from cognitive neuroscience suggest that human metacognition is hierarchically organized, integrating fast anomaly detection with selectively triggered, experience-driven reflection. In this work, we propose Deep Search with Meta-Cognitive Monitoring (DS-MCM), a deep search framework augmented with an explicit hierarchical metacognitive monitoring mechanism. DS-MCM integrates a Fast Consistency Monitor, which performs lightweight checks on the alignment between external evidence and internal reasoning confidence, and a Slow Experience-Driven Monitor, which is selectively activated to guide corrective intervention based on experience memory from historical agent trajectories. By embedding monitoring directly into the reasoning-retrieval loop, DS-MCM determines both when intervention is warranted and how corrective actions should be informed by prior experience. Experiments across multiple deep search benchmarks and backbone models demonstrate that DS-MCM consistently improves performance and robustness.",
      "source": "HuggingFace",
      "pubDateISO": "2026-01-30",
      "tags": [],
      "topics": [
        "Deep Search",
        "Meta-Cognitive Monitoring",
        "Cognitive Neuroscience-Inspired AI"
      ],
      "score": 8,
      "score_reason": "Meta-cognitive monitoring",
      "citations": 0,
      "upvotes": 4,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "This paper proposes a novel deep search framework, DS-MCM, which integrates a hierarchical metacognitive monitoring mechanism to regulate reasoning and retrieval states in large language models.",
      "why_it_matters": "The introduction of metacognitive monitoring has the potential to significantly improve the robustness and performance of deep search agents in complex, uncertain environments, which is crucial for real-world applications.",
      "limitations": "The framework's reliance on manually designed monitoring mechanisms and experience-driven reflection may limit its scalability and adaptability to novel, unseen tasks and environments."
    },
    {
      "id": "2601.21268",
      "title": "Reinforcement Learning from Meta-Evaluation: Aligning Language Models Without Ground-Truth Labels",
      "link": "https://huggingface.co/papers/2601.21268",
      "pdf_link": "https://arxiv.org/pdf/2601.21268.pdf",
      "authors": "Micah Rentschler, Jesse Roberts",
      "institution": "",
      "abstract": "Most reinforcement learning (RL) methods for training large language models (LLMs) require ground-truth labels or task-specific verifiers, limiting scalability when correctness is ambiguous or expensive to obtain. We introduce Reinforcement Learning from Meta-Evaluation (RLME), which optimizes a generator using reward derived from an evaluator's answers to natural-language meta-questions (e.g., \"Is the answer correct?\" or \"Is the reasoning logically consistent?\"). RLME treats the evaluator's probability of a positive judgment as a reward and updates the generator via group-relative policy optimization, enabling learning without labels. Across a suite of experiments, we show that RLME achieves accuracy and sample efficiency comparable to label-based training, enables controllable trade-offs among multiple objectives, steers models toward reliable reasoning patterns rather than post-hoc rationalization, and generalizes to open-domain settings where ground-truth labels are unavailable, broadening the domains in which LLMs may be trained with RL.",
      "source": "HuggingFace",
      "pubDateISO": "2026-01-29",
      "tags": [],
      "topics": [
        "Reinforcement Learning",
        "Language Models",
        "Meta-Learning"
      ],
      "score": 8,
      "score_reason": "Meta-evaluation breakthrough",
      "citations": 0,
      "upvotes": 3,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "The paper introduces Reinforcement Learning from Meta-Evaluation (RLME), a novel method that enables training large language models using reinforcement learning without requiring ground-truth labels by leveraging an evaluator's probability of positive judgment as a reward signal.",
      "why_it_matters": "This work matters because it addresses the scalability limitations of traditional reinforcement learning methods for language models, allowing for more efficient and flexible training in domains where labels are ambiguous, expensive, or unavailable.",
      "limitations": "The main limitation of RLME is that it relies on the quality and reliability of the evaluator's judgments, which may introduce bias or noise in the reward signal, potentially affecting the model's performance and generalizability."
    },
    {
      "id": "2601.22108",
      "title": "Value-Based Pre-Training with Downstream Feedback",
      "link": "https://huggingface.co/papers/2601.22108",
      "pdf_link": "https://arxiv.org/pdf/2601.22108.pdf",
      "authors": "Shuqi Ke, Giulia Fanti",
      "institution": "",
      "abstract": "Can a small amount of verified goal information steer the expensive self-supervised pretraining of foundation models? Standard pretraining optimizes a fixed proxy objective (e.g., next-token prediction), which can misallocate compute away from downstream capabilities of interest. We introduce V-Pretraining: a value-based, modality-agnostic method for controlled continued pretraining in which a lightweight task designer reshapes the pretraining task to maximize the value of each gradient step. For example, consider self-supervised learning (SSL) with sample augmentation. The V-Pretraining task designer selects pretraining tasks (e.g., augmentations) for which the pretraining loss gradient is aligned with a gradient computed over a downstream task (e.g., image segmentation). This helps steer pretraining towards relevant downstream capabilities. Notably, the pretrained model is never updated on downstream task labels; they are used only to shape the pretraining task. Under matched learner update budgets, V-Pretraining of 0.5B--7B language models improves reasoning (GSM8K test Pass@1) by up to 18% relative over standard next-token prediction using only 12% of GSM8K training examples as feedback. In vision SSL, we improve the state-of-the-art results on ADE20K by up to 1.07 mIoU and reduce NYUv2 RMSE while improving ImageNet linear accuracy, and we provide pilot evidence of improved token efficiency in continued pretraining.",
      "source": "HuggingFace",
      "pubDateISO": "2026-01-29",
      "tags": [],
      "topics": [
        "self-supervised learning",
        "pre-training",
        "value-based optimization"
      ],
      "score": 8,
      "score_reason": "Value-Based Pretraining",
      "citations": 0,
      "upvotes": 1,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "The paper introduces V-Pretraining, a novel value-based pre-training method that leverages downstream feedback to reshape the pre-training task and steer the optimization towards relevant downstream capabilities without requiring downstream task labels for model updates.",
      "why_it_matters": "This approach has the potential to improve the efficiency and effectiveness of self-supervised pre-training, allowing for better utilization of computational resources and improved performance on downstream tasks, particularly in scenarios where labeled data is scarce or expensive to obtain.",
      "limitations": "The method relies on the availability of a small amount of verified goal information, which may not always be accessible, and the effectiveness of the approach may be sensitive to the quality and relevance of the downstream feedback used to guide the pre-training process."
    },
    {
      "id": "2601.22813",
      "title": "Quartet II: Accurate LLM Pre-Training in NVFP4 by Improved Unbiased Gradient Estimation",
      "link": "https://huggingface.co/papers/2601.22813",
      "pdf_link": "https://arxiv.org/pdf/2601.22813.pdf",
      "authors": "Andrei Panferov, Erik Schultheis, Soroush Tabesh, Dan Alistarh",
      "institution": "",
      "abstract": "The NVFP4 lower-precision format, supported in hardware by NVIDIA Blackwell GPUs, promises to allow, for the first time, end-to-end fully-quantized pre-training of massive models such as LLMs. Yet, existing quantized training methods still sacrifice some of the representation capacity of this format in favor of more accurate unbiased quantized gradient estimation by stochastic rounding (SR), losing noticeable accuracy relative to standard FP16 and FP8 training. In this paper, improve the state of the art for quantized training in NVFP4 via a novel unbiased quantization routine for micro-scaled formats, called MS-EDEN, that has more than 2x lower quantization error than SR. We integrate it into a novel fully-NVFP4 quantization scheme for linear layers, called Quartet II. We show analytically that Quartet II achieves consistently better gradient estimation across all major matrix multiplications, both on the forward and on the backward passes. In addition, our proposal synergizes well with recent training improvements aimed specifically at NVFP4. We further validate Quartet II on end-to-end LLM training with up to 1.9B parameters on 38B tokens. We provide kernels for execution on NVIDIA Blackwell GPUs with up to 4.2x speedup over BF16. Our code is available at https://github.com/IST-DASLab/Quartet-II .",
      "source": "HuggingFace",
      "pubDateISO": "2026-01-30",
      "tags": [],
      "topics": [],
      "score": 7,
      "score_reason": "Accurate Pre-Training",
      "citations": 0,
      "upvotes": 42,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2601.21957",
      "title": "PaddleOCR-VL-1.5: Towards a Multi-Task 0.9B VLM for Robust In-the-Wild Document Parsing",
      "link": "https://huggingface.co/papers/2601.21957",
      "pdf_link": "https://arxiv.org/pdf/2601.21957.pdf",
      "authors": "Cheng Cui, Ting Sun, Suyin Liang, Tingquan Gao, Zelun Zhang",
      "institution": "",
      "abstract": "We introduce PaddleOCR-VL-1.5, an upgraded model achieving a new state-of-the-art (SOTA) accuracy of 94.5% on OmniDocBench v1.5. To rigorously evaluate robustness against real-world physical distortions, including scanning, skew, warping, screen-photography, and illumination, we propose the Real5-OmniDocBench benchmark. Experimental results demonstrate that this enhanced model attains SOTA performance on the newly curated benchmark. Furthermore, we extend the model's capabilities by incorporating seal recognition and text spotting tasks, while remaining a 0.9B ultra-compact VLM with high efficiency. Code: https://github.com/PaddlePaddle/PaddleOCR",
      "source": "HuggingFace",
      "pubDateISO": "2026-01-29",
      "tags": [],
      "topics": [],
      "score": 7,
      "score_reason": "State-of-the-art result",
      "citations": 0,
      "upvotes": 8,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2601.22904",
      "title": "DINO-SAE: DINO Spherical Autoencoder for High-Fidelity Image Reconstruction and Generation",
      "link": "https://huggingface.co/papers/2601.22904",
      "pdf_link": "https://arxiv.org/pdf/2601.22904.pdf",
      "authors": "Hun Chang, Byunghee Cha, Jong Chul Ye",
      "institution": "",
      "abstract": "Recent studies have explored using pretrained Vision Foundation Models (VFMs) such as DINO for generative autoencoders, showing strong generative performance. Unfortunately, existing approaches often suffer from limited reconstruction fidelity due to the loss of high-frequency details. In this work, we present the DINO Spherical Autoencoder (DINO-SAE), a framework that bridges semantic representation and pixel-level reconstruction. Our key insight is that semantic information in contrastive representations is primarily encoded in the direction of feature vectors, while forcing strict magnitude matching can hinder the encoder from preserving fine-grained details. To address this, we introduce Hierarchical Convolutional Patch Embedding module that enhances local structure and texture preservation, and Cosine Similarity Alignment objective that enforces semantic consistency while allowing flexible feature magnitudes for detail retention. Furthermore, leveraging the observation that SSL-based foundation model representations intrinsically lie on a hypersphere, we employ Riemannian Flow Matching to train a Diffusion Transformer (DiT) directly on this spherical latent manifold. Experiments on ImageNet-1K demonstrate that our approach achieves state-of-the-art reconstruction quality, reaching 0.37 rFID and 26.2 dB PSNR, while maintaining strong semantic alignment to the pretrained VFM. Notably, our Riemannian Flow Matching-based DiT exhibits efficient convergence, achieving a gFID of 3.47 at 80 epochs.",
      "source": "HuggingFace",
      "pubDateISO": "2026-01-30",
      "tags": [],
      "topics": [],
      "score": 7,
      "score_reason": "High-fidelity images",
      "citations": 0,
      "upvotes": 8,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2601.23161",
      "title": "DIFFA-2: A Practical Diffusion Large Language Model for General Audio Understanding",
      "link": "https://huggingface.co/papers/2601.23161",
      "pdf_link": "https://arxiv.org/pdf/2601.23161.pdf",
      "authors": "Jiaming Zhou, Xuxin Cheng, Shiwan Zhao, Yuhang Jia, Cao Liu",
      "institution": "",
      "abstract": "Autoregressive (AR) large audio language models (LALMs) such as Qwen-2.5-Omni have achieved strong performance on audio understanding and interaction, but scaling them remains costly in data and computation, and strictly sequential decoding limits inference efficiency. Diffusion large language models (dLLMs) have recently been shown to make effective use of limited training data, and prior work on DIFFA indicates that replacing an AR backbone with a diffusion counterpart can substantially improve audio understanding under matched settings, albeit at a proof-of-concept scale without large-scale instruction tuning, preference alignment, or practical decoding schemes. We introduce DIFFA-2, a practical diffusion-based LALM for general audio understanding. DIFFA-2 upgrades the speech encoder, employs dual semantic and acoustic adapters, and is trained with a four-stage curriculum that combines semantic and acoustic alignment, large-scale supervised fine-tuning, and variance-reduced preference optimization, using only fully open-source corpora. Experiments on MMSU, MMAU, and MMAR show that DIFFA-2 consistently improves over DIFFA and is competitive to strong AR LALMs under practical training budgets, supporting diffusion-based modeling is a viable backbone for large-scale audio understanding. Our code is available at https://github.com/NKU-HLT/DIFFA.git.",
      "source": "HuggingFace",
      "pubDateISO": "2026-01-30",
      "tags": [],
      "topics": [],
      "score": 7,
      "score_reason": "Efficient audio model",
      "citations": 0,
      "upvotes": 7,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2601.20732",
      "title": "Continual GUI Agents",
      "link": "https://huggingface.co/papers/2601.20732",
      "pdf_link": "https://arxiv.org/pdf/2601.20732.pdf",
      "authors": "Ziwei Liu, Borui Kang, Hangjie Yuan, Zixiang Zhao, Wei Li",
      "institution": "",
      "abstract": "As digital environments (data distribution) are in flux, with new GUI data arriving over time-introducing new domains or resolutions-agents trained on static environments deteriorate in performance. In this work, we introduce Continual GUI Agents, a new task that requires GUI agents to perform continual learning under shifted domains and resolutions. We find existing methods fail to maintain stable grounding as GUI distributions shift over time, due to the diversity of UI interaction points and regions in fluxing scenarios. To address this, we introduce GUI-Anchoring in Flux (GUI-AiF), a new reinforcement fine-tuning framework that stabilizes continual learning through two novel rewards: Anchoring Point Reward in Flux (APR-iF) and Anchoring Region Reward in Flux (ARR-iF). These rewards guide the agents to align with shifting interaction points and regions, mitigating the tendency of existing reward strategies to over-adapt to static grounding cues (e.g., fixed coordinates or element scales). Extensive experiments show GUI-AiF surpasses state-of-the-art baselines. Our work establishes the first continual learning framework for GUI agents, revealing the untapped potential of reinforcement fine-tuning for continual GUI Agents.",
      "source": "HuggingFace",
      "pubDateISO": "2026-01-28",
      "tags": [],
      "topics": [],
      "score": 7,
      "score_reason": "New task introduction",
      "citations": 0,
      "upvotes": 4,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2601.22032",
      "title": "Drive-JEPA: Video JEPA Meets Multimodal Trajectory Distillation for End-to-End Driving",
      "link": "https://huggingface.co/papers/2601.22032",
      "pdf_link": "https://arxiv.org/pdf/2601.22032.pdf",
      "authors": "Linhan Wang, Zichong Yang, Chen Bai, Guoxiang Zhang, Xiaotong Liu",
      "institution": "",
      "abstract": "End-to-end autonomous driving increasingly leverages self-supervised video pretraining to learn transferable planning representations. However, pretraining video world models for scene understanding has so far brought only limited improvements. This limitation is compounded by the inherent ambiguity of driving: each scene typically provides only a single human trajectory, making it difficult to learn multimodal behaviors. In this work, we propose Drive-JEPA, a framework that integrates Video Joint-Embedding Predictive Architecture (V-JEPA) with multimodal trajectory distillation for end-to-end driving. First, we adapt V-JEPA for end-to-end driving, pretraining a ViT encoder on large-scale driving videos to produce predictive representations aligned with trajectory planning. Second, we introduce a proposal-centric planner that distills diverse simulator-generated trajectories alongside human trajectories, with a momentum-aware selection mechanism to promote stable and safe behavior. When evaluated on NAVSIM, the V-JEPA representation combined with a simple transformer-based decoder outperforms prior methods by 3 PDMS in the perception-free setting. The complete Drive-JEPA framework achieves 93.3 PDMS on v1 and 87.8 EPDMS on v2, setting a new state-of-the-art.",
      "source": "HuggingFace",
      "pubDateISO": "2026-01-29",
      "tags": [],
      "topics": [
        "autonomous driving",
        "self-supervised learning",
        "multimodal trajectory distillation"
      ],
      "score": 7,
      "score_reason": "Multimodal Driving",
      "citations": 0,
      "upvotes": 2,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "The paper proposes Drive-JEPA, a novel framework that integrates Video Joint-Embedding Predictive Architecture (V-JEPA) with multimodal trajectory distillation for end-to-end autonomous driving.",
      "why_it_matters": "This work matters because it addresses the limitation of pretraining video world models for scene understanding in autonomous driving, which has significant implications for improving the safety and efficiency of self-driving systems.",
      "limitations": "The main limitation of this work is that it relies on large-scale driving videos and simulator-generated trajectories, which may not generalize well to real-world scenarios with diverse and complex environments."
    },
    {
      "id": "2601.22141",
      "title": "Routing the Lottery: Adaptive Subnetworks for Heterogeneous Data",
      "link": "https://huggingface.co/papers/2601.22141",
      "pdf_link": "https://arxiv.org/pdf/2601.22141.pdf",
      "authors": "Grzegorz Stefanski, Alberto Presta, Michal Byra",
      "institution": "",
      "abstract": "In pruning, the Lottery Ticket Hypothesis posits that large networks contain sparse subnetworks, or winning tickets, that can be trained in isolation to match the performance of their dense counterparts. However, most existing approaches assume a single universal winning ticket shared across all inputs, ignoring the inherent heterogeneity of real-world data. In this work, we propose Routing the Lottery (RTL), an adaptive pruning framework that discovers multiple specialized subnetworks, called adaptive tickets, each tailored to a class, semantic cluster, or environmental condition. Across diverse datasets and tasks, RTL consistently outperforms single- and multi-model baselines in balanced accuracy and recall, while using up to 10 times fewer parameters than independent models and exhibiting semantically aligned. Furthermore, we identify subnetwork collapse, a performance drop under aggressive pruning, and introduce a subnetwork similarity score that enables label-free diagnosis of oversparsification. Overall, our results recast pruning as a mechanism for aligning model structure with data heterogeneity, paving the way toward more modular and context-aware deep learning.",
      "source": "HuggingFace",
      "pubDateISO": "2026-01-29",
      "tags": [],
      "topics": [],
      "score": 7,
      "score_reason": "Advances pruning theory",
      "citations": 0,
      "upvotes": 2,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2601.22588",
      "title": "Rethinking LLM-as-a-Judge: Representation-as-a-Judge with Small Language Models via Semantic Capacity Asymmetry",
      "link": "https://huggingface.co/papers/2601.22588",
      "pdf_link": "https://arxiv.org/pdf/2601.22588.pdf",
      "authors": "Zhuochun Li, Yong Zhang, Ming Li, Yuelyu Ji, Yiming Zeng",
      "institution": "",
      "abstract": "Large language models (LLMs) are widely used as reference-free evaluators via prompting, but this \"LLM-as-a-Judge\" paradigm is costly, opaque, and sensitive to prompt design. In this work, we investigate whether smaller models can serve as efficient evaluators by leveraging internal representations instead of surface generation. We uncover a consistent empirical pattern: small LMs, despite with weak generative ability, encode rich evaluative signals in their hidden states. This motivates us to propose the Semantic Capacity Asymmetry Hypothesis: evaluation requires significantly less semantic capacity than generation and can be grounded in intermediate representations, suggesting that evaluation does not necessarily need to rely on large-scale generative models but can instead leverage latent features from smaller ones. Our findings motivate a paradigm shift from LLM-as-a-Judge to Representation-as-a-Judge, a decoding-free evaluation strategy that probes internal model structure rather than relying on prompted output. We instantiate this paradigm through INSPECTOR, a probing-based framework that predicts aspect-level evaluation scores from small model representations. Experiments on reasoning benchmarks (GSM8K, MATH, GPQA) show that INSPECTOR substantially outperforms prompting-based small LMs and closely approximates full LLM judges, while offering a more efficient, reliable, and interpretable alternative for scalable evaluation.",
      "source": "HuggingFace",
      "pubDateISO": "2026-01-30",
      "tags": [],
      "topics": [
        "Natural Language Processing",
        "Language Model Evaluation",
        "Efficient Inference"
      ],
      "score": 7,
      "score_reason": "Efficient Evaluation",
      "citations": 0,
      "upvotes": 1,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "The paper introduces the Representation-as-a-Judge paradigm, which leverages internal representations of small language models to perform evaluation tasks, challenging the conventional LLM-as-a-Judge approach that relies on large language models and prompted output.",
      "why_it_matters": "This work matters because it offers a more efficient, reliable, and interpretable alternative for scalable evaluation, enabling the use of smaller models for evaluation tasks, which can significantly reduce computational costs and environmental impact.",
      "limitations": "The proposed INSPECTOR framework relies on a probing-based approach, which may not generalize well to out-of-distribution data or tasks that require more complex evaluative signals, limiting its applicability to certain domains or applications."
    },
    {
      "id": "2602.00759",
      "title": "Adaptive Ability Decomposing for Unlocking Large Reasoning Model Effective Reinforcement Learning",
      "link": "https://huggingface.co/papers/2602.00759",
      "pdf_link": "https://arxiv.org/pdf/2602.00759.pdf",
      "authors": "Zhipeng Chen, Xiaobo Qin, Wayne Xin Zhao, Youbin Wu, Ji-Rong Wen",
      "institution": "",
      "abstract": "Reinforcement learning with verifiable rewards (RLVR) has shown great potential to enhance the reasoning ability of large language models (LLMs). However, due to the limited amount of information provided during the RLVR process, the model can only engage in largely blind exploration, which often results in failure on challenging problems. To provide additional information for the RLVR process without relying on a teacher model, we propose A^2D, an Adaptive Ability Decomposing method for enhancing the effectiveness of RLVR. Specifically, we first train a decomposer via RLVR without distillation, enabling it to decompose complex questions into a set of simpler sub-questions. Next, we use this decomposer to annotate sub-questions for each question in the training dataset, and then train the reasoner under RLVR with sub-question guidance. To better understand A^2D, we first compare its performance with competitive baselines, showing its effectiveness. Next, we observe that our method functions as a plug-and-play module that can be applied to different RLVR algorithms. Furthermore, we conduct an analysis of the decomposer, revealing how the RLVR process affects its performance and behavior, and which type of guidance is better suited for enhancing the reasoner's exploration and exploitation abilities.",
      "source": "HuggingFace",
      "pubDateISO": "2026-01-31",
      "tags": [],
      "topics": [
        "Reinforcement Learning",
        "Large Language Models",
        "Reasoning Ability Enhancement"
      ],
      "score": 7,
      "score_reason": "Improved Reinforcement",
      "citations": 0,
      "upvotes": 1,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "The paper proposes A^2D, an Adaptive Ability Decomposing method that enables large language models to decompose complex questions into simpler sub-questions, enhancing the effectiveness of reinforcement learning with verifiable rewards (RLVR) without relying on a teacher model.",
      "why_it_matters": "This research matters because it addresses the limitations of blind exploration in RLVR, potentially leading to more efficient and effective training of large language models for complex reasoning tasks.",
      "limitations": "The main limitation of this work is that the decomposer's performance and behavior are highly dependent on the quality of the training dataset and the specific RLVR algorithm used, which may not generalize well to other domains or tasks."
    },
    {
      "id": "2601.22680",
      "title": "Visual Personalization Turing Test",
      "link": "https://huggingface.co/papers/2601.22680",
      "pdf_link": "https://arxiv.org/pdf/2601.22680.pdf",
      "authors": "Rameen Abdal, James Burgess, Sergey Tulyakov, Kuan-Chieh Jackson Wang",
      "institution": "",
      "abstract": "We introduce the Visual Personalization Turing Test (VPTT), a new paradigm for evaluating contextual visual personalization based on perceptual indistinguishability, rather than identity replication. A model passes the VPTT if its output (image, video, 3D asset, etc.) is indistinguishable to a human or calibrated VLM judge from content a given person might plausibly create or share. To operationalize VPTT, we present the VPTT Framework, integrating a 10k-persona benchmark (VPTT-Bench), a visual retrieval-augmented generator (VPRAG), and the VPTT Score, a text-only metric calibrated against human and VLM judgments. We show high correlation across human, VLM, and VPTT evaluations, validating the VPTT Score as a reliable perceptual proxy. Experiments demonstrate that VPRAG achieves the best alignment-originality balance, offering a scalable and privacy-safe foundation for personalized generative AI.",
      "source": "HuggingFace",
      "pubDateISO": "2026-01-30",
      "tags": [],
      "topics": [],
      "score": 7,
      "score_reason": "Novel Paradigm",
      "citations": 0,
      "upvotes": 1,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2601.21558",
      "title": "ASTRA: Automated Synthesis of agentic Trajectories and Reinforcement Arenas",
      "link": "https://huggingface.co/papers/2601.21558",
      "pdf_link": "https://arxiv.org/pdf/2601.21558.pdf",
      "authors": "Xiaoyu Tian, Haotian Wang, Shuaiting Chen, Hao Zhou, Kaichi Yu",
      "institution": "",
      "abstract": "Large language models (LLMs) are increasingly used as tool-augmented agents for multi-step decision making, yet training robust tool-using agents remains challenging. Existing methods still require manual intervention, depend on non-verifiable simulated environments, rely exclusively on either supervised fine-tuning (SFT) or reinforcement learning (RL), and struggle with stable long-horizon, multi-turn learning. To address these challenges, we introduce ASTRA, a fully automated end-to-end framework for training tool-augmented language model agents via scalable data synthesis and verifiable reinforcement learning. ASTRA integrates two complementary components. First, a pipeline that leverages the static topology of tool-call graphs synthesizes diverse, structurally grounded trajectories, instilling broad and transferable tool-use competence. Second, an environment synthesis framework that captures the rich, compositional topology of human semantic reasoning converts decomposed question-answer traces into independent, code-executable, and rule-verifiable environments, enabling deterministic multi-turn RL. Based on this method, we develop a unified training methodology that integrates SFT with online RL using trajectory-level rewards to balance task completion and interaction efficiency. Experiments on multiple agentic tool-use benchmarks demonstrate that ASTRA-trained models achieve state-of-the-art performance at comparable scales, approaching closed-source systems while preserving core reasoning ability. We release the full pipelines, environments, and trained models at https://github.com/LianjiaTech/astra.",
      "source": "HuggingFace",
      "pubDateISO": "2026-01-29",
      "tags": [],
      "topics": [],
      "score": 6,
      "score_reason": "Automates agent training",
      "citations": 0,
      "upvotes": 49,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2601.22636",
      "title": "Statistical Estimation of Adversarial Risk in Large Language Models under Best-of-N Sampling",
      "link": "https://huggingface.co/papers/2601.22636",
      "pdf_link": "https://arxiv.org/pdf/2601.22636.pdf",
      "authors": "Mingqian Feng, Xiaodong Liu, Weiwei Yang, Chenliang Xu, Christopher White",
      "institution": "",
      "abstract": "Large Language Models (LLMs) are typically evaluated for safety under single-shot or low-budget adversarial prompting, which underestimates real-world risk. In practice, attackers can exploit large-scale parallel sampling to repeatedly probe a model until a harmful response is produced. While recent work shows that attack success increases with repeated sampling, principled methods for predicting large-scale adversarial risk remain limited. We propose a scaling-aware Best-of-N estimation of risk, SABER, for modeling jailbreak vulnerability under Best-of-N sampling. We model sample-level success probabilities using a Beta distribution, the conjugate prior of the Bernoulli distribution, and derive an analytic scaling law that enables reliable extrapolation of large-N attack success rates from small-budget measurements. Using only n=100 samples, our anchored estimator predicts ASR@1000 with a mean absolute error of 1.66, compared to 12.04 for the baseline, which is an 86.2% reduction in estimation error. Our results reveal heterogeneous risk scaling profiles and show that models appearing robust under standard evaluation can experience rapid nonlinear risk amplification under parallel adversarial pressure. This work provides a low-cost, scalable methodology for realistic LLM safety assessment. We will release our code and evaluation scripts upon publication to future research.",
      "source": "HuggingFace",
      "pubDateISO": "2026-01-30",
      "tags": [],
      "topics": [],
      "score": 6,
      "score_reason": "Adversarial risk estimation",
      "citations": 0,
      "upvotes": 14,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2601.22083",
      "title": "Latent Adversarial Regularization for Offline Preference Optimization",
      "link": "https://huggingface.co/papers/2601.22083",
      "pdf_link": "https://arxiv.org/pdf/2601.22083.pdf",
      "authors": "Enyi Jiang, Yibo Jacky Zhang, Yinglun Xu, Andreas Haupt, Nancy Amato",
      "institution": "",
      "abstract": "Learning from human feedback typically relies on preference optimization that constrains policy updates through token-level regularization. However, preference optimization for language models is particularly challenging because token-space similarity does not imply semantic or behavioral similarity. To address this challenge, we leverage latent-space regularization for language model preference optimization. We introduce GANPO, which achieves latent-space regularization by penalizing divergence between the internal representations of a policy model and a reference model. Given that latent representations are not associated with explicit probability densities, we adopt an adversarial approach inspired by GANs to minimize latent-space divergence. We integrate GANPO as a regularizer into existing offline preference optimization objectives. Experiments across multiple model architectures and tasks show consistent improvements from latent-space regularization. Further, by comparing GANPO-induced inferential biases with those from token-level regularization, we find that GANPO provides more robust structural feedback under distributional shift and noise while maintaining comparable downstream performance with minor computational overhead.",
      "source": "HuggingFace",
      "pubDateISO": "2026-01-29",
      "tags": [],
      "topics": [],
      "score": 6,
      "score_reason": "Regularization technique",
      "citations": 0,
      "upvotes": 12,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2601.22491",
      "title": "SSL: Sweet Spot Learning for Differentiated Guidance in Agentic Optimization",
      "link": "https://huggingface.co/papers/2601.22491",
      "pdf_link": "https://arxiv.org/pdf/2601.22491.pdf",
      "authors": "Jinyang Wu, Changpeng Yang, Yuhao Shen, Fangzhi Xu, Bolin Ni",
      "institution": "",
      "abstract": "Reinforcement learning with verifiable rewards has emerged as a powerful paradigm for training intelligent agents. However, existing methods typically employ binary rewards that fail to capture quality differences among trajectories achieving identical outcomes, thereby overlooking potential diversity within the solution space. Inspired by the ``sweet spot'' concept in tennis-the racket's core region that produces optimal hitting effects, we introduce Sweet Spot Learning (SSL), a novel framework that provides differentiated guidance for agent optimization. SSL follows a simple yet effective principle: progressively amplified, tiered rewards guide policies toward the sweet-spot region of the solution space. This principle naturally adapts across diverse tasks: visual perception tasks leverage distance-tiered modeling to reward proximity, while complex reasoning tasks reward incremental progress toward promising solutions. We theoretically demonstrate that SSL preserves optimal solution ordering and enhances the gradient signal-to-noise ratio, thereby fostering more directed optimization. Extensive experiments across GUI perception, short/long-term planning, and complex reasoning tasks show consistent improvements over strong baselines on 12 benchmarks, achieving up to 2.5X sample efficiency gains and effective cross-task transferability. Our work establishes SSL as a general principle for training capable and robust agents.",
      "source": "HuggingFace",
      "pubDateISO": "2026-01-30",
      "tags": [],
      "topics": [],
      "score": 6,
      "score_reason": "Guided optimization",
      "citations": 0,
      "upvotes": 11,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2601.22837",
      "title": "NativeTok: Native Visual Tokenization for Improved Image Generation",
      "link": "https://huggingface.co/papers/2601.22837",
      "pdf_link": "https://arxiv.org/pdf/2601.22837.pdf",
      "authors": "Bin Wu, Mengqi Huang, Weinan Jia, Zhendong Mao",
      "institution": "",
      "abstract": "VQ-based image generation typically follows a two-stage pipeline: a tokenizer encodes images into discrete tokens, and a generative model learns their dependencies for reconstruction. However, improved tokenization in the first stage does not necessarily enhance the second-stage generation, as existing methods fail to constrain token dependencies. This mismatch forces the generative model to learn from unordered distributions, leading to bias and weak coherence. To address this, we propose native visual tokenization, which enforces causal dependencies during tokenization. Building on this idea, we introduce NativeTok, a framework that achieves efficient reconstruction while embedding relational constraints within token sequences. NativeTok consists of: (1) a Meta Image Transformer (MIT) for latent image modeling, and (2) a Mixture of Causal Expert Transformer (MoCET), where each lightweight expert block generates a single token conditioned on prior tokens and latent features. We further design a Hierarchical Native Training strategy that updates only new expert blocks, ensuring training efficiency. Extensive experiments demonstrate the effectiveness of NativeTok.",
      "source": "HuggingFace",
      "pubDateISO": "2026-01-30",
      "tags": [],
      "topics": [],
      "score": 6,
      "score_reason": "Better tokenization",
      "citations": 0,
      "upvotes": 8,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2601.18241",
      "title": "TAM-Eval: Evaluating LLMs for Automated Unit Test Maintenance",
      "link": "https://huggingface.co/papers/2601.18241",
      "pdf_link": "https://arxiv.org/pdf/2601.18241.pdf",
      "authors": "Elena Bruches, Vadim Alperovich, Dari Baturova, Roman Derunets, Daniil Grebenkin",
      "institution": "",
      "abstract": "While Large Language Models (LLMs) have shown promise in software engineering, their application to unit testing remains largely confined to isolated test generation or oracle prediction, neglecting the broader challenge of test suite maintenance. We introduce TAM-Eval (Test Automated Maintenance Evaluation), a framework and benchmark designed to evaluate model performance across three core test maintenance scenarios: creation, repair, and updating of test suites. Unlike prior work limited to function-level tasks, TAM-Eval operates at the test file level, while maintaining access to full repository context during isolated evaluation, better reflecting real-world maintenance workflows. Our benchmark comprises 1,539 automatically extracted and validated scenarios from Python, Java, and Go projects. TAM-Eval supports system-agnostic evaluation of both raw LLMs and agentic workflows, using a reference-free protocol based on test suite pass rate, code coverage, and mutation testing. Empirical results indicate that state-of-the-art LLMs have limited capabilities in realistic test maintenance processes and yield only marginal improvements in test effectiveness. We release TAM-Eval as an open-source framework to support future research in automated software testing. Our data and code are publicly available at https://github.com/trndcenter/TAM-Eval.",
      "source": "HuggingFace",
      "pubDateISO": "2026-01-26",
      "tags": [],
      "topics": [],
      "score": 6,
      "score_reason": "Improves test maintenance",
      "citations": 0,
      "upvotes": 7,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2601.21468",
      "title": "MemOCR: Layout-Aware Visual Memory for Efficient Long-Horizon Reasoning",
      "link": "https://huggingface.co/papers/2601.21468",
      "pdf_link": "https://arxiv.org/pdf/2601.21468.pdf",
      "authors": "Yaorui Shi, Shugui Liu, Yu Yang, Wenyu Mao, Yuxin Chen",
      "institution": "",
      "abstract": "Long-horizon agentic reasoning necessitates effectively compressing growing interaction histories into a limited context window. Most existing memory systems serialize history as text, where token-level cost is uniform and scales linearly with length, often spending scarce budget on low-value details. To this end, we introduce MemOCR, a multimodal memory agent that improves long-horizon reasoning under tight context budgets by allocating memory space with adaptive information density through visual layout. Concretely, MemOCR maintains a structured rich-text memory (e.g., headings, highlights) and renders it into an image that the agent consults for memory access, visually prioritizing crucial evidence while aggressively compressing auxiliary details. To ensure robustness across varying memory budgets, we train MemOCR with reinforcement learning under budget-aware objectives that expose the agent to diverse compression levels. Across long-context multi-hop and single-hop question-answering benchmarks, MemOCR outperforms strong text-based baselines and achieves more effective context utilization under extreme budgets.",
      "source": "HuggingFace",
      "pubDateISO": "2026-01-29",
      "tags": [],
      "topics": [],
      "score": 6,
      "score_reason": "Memory efficiency",
      "citations": 0,
      "upvotes": 7,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2601.23228",
      "title": "Scaling Multiagent Systems with Process Rewards",
      "link": "https://huggingface.co/papers/2601.23228",
      "pdf_link": "https://arxiv.org/pdf/2601.23228.pdf",
      "authors": "Ed Li, Junyu Ren, Cat Yan",
      "institution": "",
      "abstract": "While multiagent systems have shown promise for tackling complex tasks via specialization, finetuning multiple agents simultaneously faces two key challenges: (1) credit assignment across agents, and (2) sample efficiency of expensive multiagent rollouts. In this work, we propose finetuning multiagent systems with per-action process rewards from AI feedback (MAPPA) to address both. Through assigning credit to individual agent actions rather than only at task completion, MAPPA enables fine-grained supervision without ground truth labels while extracting maximal training signal from each rollout. We demonstrate our approach on competition math problems and tool-augmented data analysis tasks. On unseen math problems, MAPPA achieves +5.0--17.5pp on AIME and +7.8--17.2pp on AMC. For data analysis tasks, our method improves success rate by +12.5pp while quality metrics improve by up to 30%, validating that per-action supervision can lead to improvements across different multiagent system on various domains. By addressing these challenges, our work takes a first step toward scaling multiagent systems for complex, long-horizon tasks with minimal human supervision.",
      "source": "HuggingFace",
      "pubDateISO": "2026-01-30",
      "tags": [],
      "topics": [],
      "score": 6,
      "score_reason": "Multiagent Scaling",
      "citations": 0,
      "upvotes": 6,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2601.22666",
      "title": "ExpAlign: Expectation-Guided Vision-Language Alignment for Open-Vocabulary Grounding",
      "link": "https://huggingface.co/papers/2601.22666",
      "pdf_link": "https://arxiv.org/pdf/2601.22666.pdf",
      "authors": "Junyi Hu, Tian Bai, Fengyi Wu, Wenyan Li, Zhenming Peng",
      "institution": "",
      "abstract": "Open-vocabulary grounding requires accurate vision-language alignment under weak supervision, yet existing methods either rely on global sentence embeddings that lack fine-grained expressiveness or introduce token-level alignment with explicit supervision or heavy cross-attention designs. We propose ExpAlign, a theoretically grounded vision-language alignment framework built on a principled multiple instance learning formulation. ExpAlign introduces an Expectation Alignment Head that performs attention-based soft MIL pooling over token-region similarities, enabling implicit token and instance selection without additional annotations. To further stabilize alignment learning, we develop an energy-based multi-scale consistency regularization scheme, including a Top-K multi-positive contrastive objective and a Geometry-Aware Consistency Objective derived from a Lagrangian-constrained free-energy minimization. Extensive experiments show that ExpAlign consistently improves open-vocabulary detection and zero-shot instance segmentation, particularly on long-tail categories. Most notably, it achieves 36.2 AP_r on the LVIS minival split, outperforming other state-of-the-art methods at comparable model scale, while remaining lightweight and inference-efficient.",
      "source": "HuggingFace",
      "pubDateISO": "2026-01-30",
      "tags": [],
      "topics": [],
      "score": 6,
      "score_reason": "Improved Alignment",
      "citations": 0,
      "upvotes": 3,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2601.21525",
      "title": "LMK > CLS: Landmark Pooling for Dense Embeddings",
      "link": "https://huggingface.co/papers/2601.21525",
      "pdf_link": "https://arxiv.org/pdf/2601.21525.pdf",
      "authors": "Meet Doshi, Aashka Trivedi, Vishwajeet Kumar, Parul Awasthy, Yulong Li",
      "institution": "",
      "abstract": "Representation learning is central to many downstream tasks such as search, clustering, classification, and reranking. State-of-the-art sequence encoders typically collapse a variable-length token sequence to a single vector using a pooling operator, most commonly a special [CLS] token or mean pooling over token embeddings. In this paper, we identify systematic weaknesses of these pooling strategies: [CLS] tends to concentrate information toward the initial positions of the sequence and can under-represent distributed evidence, while mean pooling can dilute salient local signals, sometimes leading to worse short-context performance. To address these issues, we introduce Landmark (LMK) pooling, which partitions a sequence into chunks, inserts landmark tokens between chunks, and forms the final representation by mean-pooling the landmark token embeddings. This simple mechanism improves long-context extrapolation without sacrificing local salient features, at the cost of introducing a small number of special tokens. We empirically demonstrate that LMK pooling matches existing methods on short-context retrieval tasks and yields substantial improvements on long-context tasks, making it a practical and scalable alternative to existing pooling methods.",
      "source": "HuggingFace",
      "pubDateISO": "2026-01-29",
      "tags": [],
      "topics": [],
      "score": 6,
      "score_reason": "Improved pooling operator",
      "citations": 0,
      "upvotes": 3,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2601.22664",
      "title": "Real-Time Aligned Reward Model beyond Semantics",
      "link": "https://huggingface.co/papers/2601.22664",
      "pdf_link": "https://arxiv.org/pdf/2601.22664.pdf",
      "authors": "Zixuan Huang, Xin Xia, Yuxi Ren, Jianbin Zheng, Xuefeng Xiao",
      "institution": "",
      "abstract": "Reinforcement Learning from Human Feedback (RLHF) is a pivotal technique for aligning large language models (LLMs) with human preferences, yet it is susceptible to reward overoptimization, in which policy models overfit to the reward model, exploit spurious reward patterns instead of faithfully capturing human intent. Prior mitigations primarily relies on surface semantic information and fails to efficiently address the misalignment between the reward model (RM) and the policy model caused by continuous policy distribution shifts. This inevitably leads to an increasing reward discrepancy, exacerbating reward overoptimization. To address these limitations, we introduce R2M (Real-Time Aligned Reward Model), a novel lightweight RLHF framework. R2M goes beyond vanilla reward models that solely depend on the semantic representations of a pretrained LLM. Instead, it leverages the evolving hidden states of the policy (namely policy feedback) to align with the real-time distribution shift of the policy during the RL process. This work points to a promising new direction for improving the performance of reward models through real-time utilization of feedback from policy models.",
      "source": "HuggingFace",
      "pubDateISO": "2026-01-30",
      "tags": [],
      "topics": [],
      "score": 6,
      "score_reason": "Improves RLHF",
      "citations": 0,
      "upvotes": 3,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.01851",
      "title": "How Well Do Models Follow Visual Instructions? VIBE: A Systematic Benchmark for Visual Instruction-Driven Image Editing",
      "link": "https://huggingface.co/papers/2602.01851",
      "pdf_link": "https://arxiv.org/pdf/2602.01851.pdf",
      "authors": "Huanyu Zhang, Xuehai Bai, Chengzu Li, Chen Liang, Haochen Tian",
      "institution": "",
      "abstract": "Recent generative models have achieved remarkable progress in image editing. However, existing systems and benchmarks remain largely text-guided. In contrast, human communication is inherently multimodal, where visual instructions such as sketches efficiently convey spatial and structural intent. To address this gap, we introduce VIBE, the Visual Instruction Benchmark for Image Editing with a three-level interaction hierarchy that captures deictic grounding, morphological manipulation, and causal reasoning. Across these levels, we curate high-quality and diverse test cases that reflect progressively increasing complexity in visual instruction following. We further propose a robust LMM-as-a-judge evaluation framework with task-specific metrics to enable scalable and fine-grained assessment. Through a comprehensive evaluation of 17 representative open-source and proprietary image editing models, we find that proprietary models exhibit early-stage visual instruction-following capabilities and consistently outperform open-source models. However, performance degrades markedly with increasing task difficulty even for the strongest systems, highlighting promising directions for future research.",
      "source": "HuggingFace",
      "pubDateISO": "2026-02-02",
      "tags": [],
      "topics": [],
      "score": 6,
      "score_reason": "New Benchmark",
      "citations": 0,
      "upvotes": 2,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2601.15394",
      "title": "Memorization Dynamics in Knowledge Distillation for Language Models",
      "link": "https://huggingface.co/papers/2601.15394",
      "pdf_link": "https://arxiv.org/pdf/2601.15394.pdf",
      "authors": "Jaydeep Borkar, Karan Chadha, Niloofar Mireshghallah, Yuchen Zhang, Irina-Elena Veliche",
      "institution": "",
      "abstract": "Knowledge Distillation (KD) is increasingly adopted to transfer capabilities from large language models to smaller ones, offering significant improvements in efficiency and utility while often surpassing standard fine-tuning. Beyond performance, KD is also explored as a privacy-preserving mechanism to mitigate the risk of training data leakage. While training data memorization has been extensively studied in standard pre-training and fine-tuning settings, its dynamics in a knowledge distillation setup remain poorly understood. In this work, we study memorization across the KD pipeline using three large language model (LLM) families (Pythia, OLMo-2, Qwen-3) and three datasets (FineWeb, Wikitext, Nemotron-CC-v2). We find: (1) distilled models memorize significantly less training data than standard fine-tuning (reducing memorization by more than 50%); (2) some examples are inherently easier to memorize and account for a large fraction of memorization during distillation (over ~95%); (3) student memorization is predictable prior to distillation using features based on zlib entropy, KL divergence, and perplexity; and (4) while soft and hard distillation have similar overall memorization rates, hard distillation poses a greater risk: it inherits 2.7times more teacher-specific examples than soft distillation. Overall, we demonstrate that distillation can provide both improved generalization and reduced memorization risks compared to standard fine-tuning.",
      "source": "HuggingFace",
      "pubDateISO": "2026-01-21",
      "tags": [],
      "topics": [],
      "score": 6,
      "score_reason": "Knowledge Distillation",
      "citations": 0,
      "upvotes": 2,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.01566",
      "title": "FS-Researcher: Test-Time Scaling for Long-Horizon Research Tasks with File-System-Based Agents",
      "link": "https://huggingface.co/papers/2602.01566",
      "pdf_link": "https://arxiv.org/pdf/2602.01566.pdf",
      "authors": "Chiwei Zhu, Benfeng Xu, Mingxuan Du, Shaohan Wang, Xiaorui Wang",
      "institution": "",
      "abstract": "Deep research is emerging as a representative long-horizon task for large language model (LLM) agents. However, long trajectories in deep research often exceed model context limits, compressing token budgets for both evidence collection and report writing, and preventing effective test-time scaling. We introduce FS-Researcher, a file-system-based, dual-agent framework that scales deep research beyond the context window via a persistent workspace. Specifically, a Context Builder agent acts as a librarian which browses the internet, writes structured notes, and archives raw sources into a hierarchical knowledge base that can grow far beyond context length. A Report Writer agent then composes the final report section by section, treating the knowledge base as the source of facts. In this framework, the file system serves as a durable external memory and a shared coordination medium across agents and sessions, enabling iterative refinement beyond the context window. Experiments on two open-ended benchmarks (DeepResearch Bench and DeepConsult) show that FS-Researcher achieves state-of-the-art report quality across different backbone models. Further analyses demonstrate a positive correlation between final report quality and the computation allocated to the Context Builder, validating effective test-time scaling under the file-system paradigm. The code and data are anonymously open-sourced at https://github.com/Ignoramus0817/FS-Researcher.",
      "source": "HuggingFace",
      "pubDateISO": "2026-02-02",
      "tags": [],
      "topics": [],
      "score": 6,
      "score_reason": "Test-Time Scaling",
      "citations": 0,
      "upvotes": 1,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2601.21666",
      "title": "SONIC-O1: A Real-World Benchmark for Evaluating Multimodal Large Language Models on Audio-Video Understanding",
      "link": "https://huggingface.co/papers/2601.21666",
      "pdf_link": "https://arxiv.org/pdf/2601.21666.pdf",
      "authors": "Ahmed Y. Radwan, Christos Emmanouilidis, Hina Tabassum, Deval Pandya, Shaina Raza",
      "institution": "",
      "abstract": "Multimodal Large Language Models (MLLMs) are a major focus of recent AI research. However, most prior work focuses on static image understanding, while their ability to process sequential audio-video data remains underexplored. This gap highlights the need for a high-quality benchmark to systematically evaluate MLLM performance in a real-world setting. We introduce SONIC-O1, a comprehensive, fully human-verified benchmark spanning 13 real-world conversational domains with 4,958 annotations and demographic metadata. SONIC-O1 evaluates MLLMs on key tasks, including open-ended summarization, multiple-choice question (MCQ) answering, and temporal localization with supporting rationales (reasoning). Experiments on closed- and open-source models reveal limitations. While the performance gap in MCQ accuracy between two model families is relatively small, we observe a substantial 22.6% performance difference in temporal localization between the best performing closed-source and open-source models. Performance further degrades across demographic groups, indicating persistent disparities in model behavior. Overall, SONIC-O1 provides an open evaluation suite for temporally grounded and socially robust multimodal understanding. We release SONIC-O1 for reproducibility and research: Project page: https://vectorinstitute.github.io/sonic-o1/ Dataset: https://huggingface.co/datasets/vector-institute/sonic-o1 Github: https://github.com/vectorinstitute/sonic-o1 Leaderboard: https://huggingface.co/spaces/vector-institute/sonic-o1-leaderboard",
      "source": "HuggingFace",
      "pubDateISO": "2026-01-29",
      "tags": [],
      "topics": [],
      "score": 6,
      "score_reason": "New Benchmark",
      "citations": 0,
      "upvotes": 1,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2601.23265",
      "title": "PaperBanana: Automating Academic Illustration for AI Scientists",
      "link": "https://huggingface.co/papers/2601.23265",
      "pdf_link": "https://arxiv.org/pdf/2601.23265.pdf",
      "authors": "Dawei Zhu, Rui Meng, Yale Song, Xiyu Wei, Sujian Li",
      "institution": "",
      "abstract": "Despite rapid advances in autonomous AI scientists powered by language models, generating publication-ready illustrations remains a labor-intensive bottleneck in the research workflow. To lift this burden, we introduce PaperBanana, an agentic framework for automated generation of publication-ready academic illustrations. Powered by state-of-the-art VLMs and image generation models, PaperBanana orchestrates specialized agents to retrieve references, plan content and style, render images, and iteratively refine via self-critique. To rigorously evaluate our framework, we introduce PaperBananaBench, comprising 292 test cases for methodology diagrams curated from NeurIPS 2025 publications, covering diverse research domains and illustration styles. Comprehensive experiments demonstrate that PaperBanana consistently outperforms leading baselines in faithfulness, conciseness, readability, and aesthetics. We further show that our method effectively extends to the generation of high-quality statistical plots. Collectively, PaperBanana paves the way for the automated generation of publication-ready illustrations.",
      "source": "HuggingFace",
      "pubDateISO": "2026-01-30",
      "tags": [],
      "topics": [],
      "score": 5,
      "score_reason": "Nice tool",
      "citations": 0,
      "upvotes": 26,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2601.22628",
      "title": "TTCS: Test-Time Curriculum Synthesis for Self-Evolving",
      "link": "https://huggingface.co/papers/2601.22628",
      "pdf_link": "https://arxiv.org/pdf/2601.22628.pdf",
      "authors": "Chengyi Yang, Zhishang Xiang, Yunbo Tang, Zongpei Teng, Chengsong Huang",
      "institution": "",
      "abstract": "Test-Time Training offers a promising way to improve the reasoning ability of large language models (LLMs) by adapting the model using only the test questions. However, existing methods struggle with difficult reasoning problems for two reasons: raw test questions are often too difficult to yield high-quality pseudo-labels, and the limited size of test sets makes continuous online updates prone to instability. To address these limitations, we propose TTCS, a co-evolving test-time training framework. Specifically, TTCS initializes two policies from the same pretrained model: a question synthesizer and a reasoning solver. These policies evolve through iterative optimization: the synthesizer generates progressively challenging question variants conditioned on the test questions, creating a structured curriculum tailored to the solver's current capability, while the solver updates itself using self-consistency rewards computed from multiple sampled responses on both original test and synthetic questions. Crucially, the solver's feedback guides the synthesizer to generate questions aligned with the model's current capability, and the generated question variants in turn stabilize the solver's test-time training. Experiments show that TTCS consistently strengthens the reasoning ability on challenging mathematical benchmarks and transfers to general-domain tasks across different LLM backbones, highlighting a scalable path towards dynamically constructing test-time curricula for self-evolving. Our code and implementation details are available at https://github.com/XMUDeepLIT/TTCS.",
      "source": "HuggingFace",
      "pubDateISO": "2026-01-30",
      "tags": [],
      "topics": [],
      "score": 5,
      "score_reason": "Minor test-time gain",
      "citations": 0,
      "upvotes": 25,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2601.21192",
      "title": "Do Reasoning Models Enhance Embedding Models?",
      "link": "https://huggingface.co/papers/2601.21192",
      "pdf_link": "https://arxiv.org/pdf/2601.21192.pdf",
      "authors": "Wun Yu Chan, Shaojin Chen, Huihao Jing, Kwun Hang Lau, Elton Chun-Chai Li",
      "institution": "",
      "abstract": "State-of-the-art embedding models are increasingly derived from decoder-only Large Language Model (LLM) backbones adapted via contrastive learning. Given the emergence of reasoning models trained via Reinforcement Learning with Verifiable Rewards (RLVR), a natural question arises: do enhanced reasoning translate to superior semantic representations when these models serve as embedding initializations? Contrary to expectation, our evaluation on MTEB and BRIGHT reveals a **null effect**: embedding models initialized from RLVR-tuned backbones yield no consistent performance advantage over their base counterparts when subjected to identical training recipes. To unpack this paradox, we introduce **H**ierarchical **R**epresentation **S**imilarity **A**nalysis (HRSA), a framework that decomposes similarity across representation, geometry, and function levels. HRSA reveals that while RLVR induces irreversible latent manifold's local geometry reorganization and reversible coordinate basis drift, it preserves the global manifold geometry and linear readout. Consequently, subsequent contrastive learning drives strong alignment between base- and reasoning-initialized models, a phenomenon we term **Manifold Realignment**. Empirically, our findings suggest that unlike Supervised Fine-Tuning (SFT), RLVR optimizes trajectories within an existing semantic landscape rather than fundamentally restructuring the landscape itself.",
      "source": "HuggingFace",
      "pubDateISO": "2026-01-29",
      "tags": [],
      "topics": [],
      "score": 5,
      "score_reason": "Reasoning Models",
      "citations": 0,
      "upvotes": 22,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2601.20218",
      "title": "DenseGRPO: From Sparse to Dense Reward for Flow Matching Model Alignment",
      "link": "https://huggingface.co/papers/2601.20218",
      "pdf_link": "https://arxiv.org/pdf/2601.20218.pdf",
      "authors": "Haoyou Deng, Keyu Yan, Chaojie Mao, Xiang Wang, Yu Liu",
      "institution": "",
      "abstract": "Recent GRPO-based approaches built on flow matching models have shown remarkable improvements in human preference alignment for text-to-image generation. Nevertheless, they still suffer from the sparse reward problem: the terminal reward of the entire denoising trajectory is applied to all intermediate steps, resulting in a mismatch between the global feedback signals and the exact fine-grained contributions at intermediate denoising steps. To address this issue, we introduce DenseGRPO, a novel framework that aligns human preference with dense rewards, which evaluates the fine-grained contribution of each denoising step. Specifically, our approach includes two key components: (1) we propose to predict the step-wise reward gain as dense reward of each denoising step, which applies a reward model on the intermediate clean images via an ODE-based approach. This manner ensures an alignment between feedback signals and the contributions of individual steps, facilitating effective training; and (2) based on the estimated dense rewards, a mismatch drawback between the uniform exploration setting and the time-varying noise intensity in existing GRPO-based methods is revealed, leading to an inappropriate exploration space. Thus, we propose a reward-aware scheme to calibrate the exploration space by adaptively adjusting a timestep-specific stochasticity injection in the SDE sampler, ensuring a suitable exploration space at all timesteps. Extensive experiments on multiple standard benchmarks demonstrate the effectiveness of the proposed DenseGRPO and highlight the critical role of the valid dense rewards in flow matching model alignment.",
      "source": "HuggingFace",
      "pubDateISO": "2026-01-28",
      "tags": [],
      "topics": [],
      "score": 5,
      "score_reason": "Dense reward improvement",
      "citations": 0,
      "upvotes": 12,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.00158",
      "title": "RAPTOR: Ridge-Adaptive Logistic Probes",
      "link": "https://huggingface.co/papers/2602.00158",
      "pdf_link": "https://arxiv.org/pdf/2602.00158.pdf",
      "authors": "Ziqi Gao, Yaotian Zhu, Qingcheng Zeng, Xu Zhao, Ziqing Wang",
      "institution": "",
      "abstract": "Probing studies what information is encoded in a frozen LLM's layer representations by training a lightweight predictor on top of them. Beyond analysis, probes are often used operationally in probe-then-steer pipelines: a learned concept vector is extracted from a probe and injected via additive activation steering by adding it to a layer representation during the forward pass. The effectiveness of this pipeline hinges on estimating concept vectors that are accurate, directionally stable under ablation, and inexpensive to obtain. Motivated by these desiderata, we propose RAPTOR (Ridge-Adaptive Logistic Probe), a simple L2-regularized logistic probe whose validation-tuned ridge strength yields concept vectors from normalized weights. Across extensive experiments on instruction-tuned LLMs and human-written concept datasets, RAPTOR matches or exceeds strong baselines in accuracy while achieving competitive directional stability and substantially lower training cost; these quantitative results are supported by qualitative downstream steering demonstrations. Finally, using the Convex Gaussian Min-max Theorem (CGMT), we provide a mechanistic characterization of ridge logistic regression in an idealized Gaussian teacher-student model in the high-dimensional few-shot regime, explaining how penalty strength mediates probe accuracy and concept-vector stability and yielding structural predictions that qualitatively align with trends observed on real LLM embeddings.",
      "source": "HuggingFace",
      "pubDateISO": "2026-01-29",
      "tags": [],
      "topics": [],
      "score": 5,
      "score_reason": "Probing Method",
      "citations": 0,
      "upvotes": 7,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.01479",
      "title": "Ebisu: Benchmarking Large Language Models in Japanese Finance",
      "link": "https://huggingface.co/papers/2602.01479",
      "pdf_link": "https://arxiv.org/pdf/2602.01479.pdf",
      "authors": "Xueqing Peng, Ruoyu Xiang, Fan Zhang, Mingzi Song, Mingyang Jiang",
      "institution": "",
      "abstract": "Japanese finance combines agglutinative, head-final linguistic structure, mixed writing systems, and high-context communication norms that rely on indirect expression and implicit commitment, posing a substantial challenge for LLMs. We introduce Ebisu, a benchmark for native Japanese financial language understanding, comprising two linguistically and culturally grounded, expert-annotated tasks: JF-ICR, which evaluates implicit commitment and refusal recognition in investor-facing Q&A, and JF-TE, which assesses hierarchical extraction and ranking of nested financial terminology from professional disclosures. We evaluate a diverse set of open-source and proprietary LLMs spanning general-purpose, Japanese-adapted, and financial models. Results show that even state-of-the-art systems struggle on both tasks. While increased model scale yields limited improvements, language- and domain-specific adaptation does not reliably improve performance, leaving substantial gaps unresolved. Ebisu provides a focused benchmark for advancing linguistically and culturally grounded financial NLP. All datasets and evaluation scripts are publicly released.",
      "source": "HuggingFace",
      "pubDateISO": "2026-02-01",
      "tags": [],
      "topics": [],
      "score": 5,
      "score_reason": "Domain Specific",
      "citations": 0,
      "upvotes": 3,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2601.15625",
      "title": "Robust Tool Use via Fission-GRPO: Learning to Recover from Execution Errors",
      "link": "https://huggingface.co/papers/2601.15625",
      "pdf_link": "https://arxiv.org/pdf/2601.15625.pdf",
      "authors": "Zhiwei Zhang, Fei Zhao, Rui Wang, Zezhong Wang, Bin Liang",
      "institution": "",
      "abstract": "Large language models (LLMs) can call tools effectively, yet they remain brittle in multi-turn execution: following a tool call error, smaller models often degenerate into repetitive invalid re-invocations, failing to interpret error feedback and self-correct. This brittleness hinders reliable real-world deployment, where the execution errors are inherently inevitable during tool interaction procedures. We identify a key limitation of current approaches: standard reinforcement learning (RL) treats errors as sparse negative rewards, providing no guidance on how to recover, while pre-collected synthetic error-correction datasets suffer from distribution mismatch with the model's on-policy error modes. To bridge this gap, we propose Fission-GRPO, a framework that converts execution errors into corrective supervision within the RL training loop. Our core mechanism fissions each failed trajectory into a new training instance by augmenting it with diagnostic feedback from a finetuned Error Simulator, then resampling recovery rollouts on-policy. This enables the model to learn from the precise errors it makes during exploration, rather than from static, pre-collected error cases. On the BFCL v4 Multi-Turn, Fission-GRPO improves the error recovery rate of Qwen3-8B by 5.7% absolute, crucially, yielding a 4% overall accuracy gain (42.75% to 46.75%) over GRPO and outperforming specialized tool-use agents.",
      "source": "HuggingFace",
      "pubDateISO": "2026-01-22",
      "tags": [],
      "topics": [],
      "score": 5,
      "score_reason": "Error recovery mechanism",
      "citations": 0,
      "upvotes": 3,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2601.21709",
      "title": "Why Attention Patterns Exist: A Unifying Temporal Perspective Analysis",
      "link": "https://huggingface.co/papers/2601.21709",
      "pdf_link": "https://arxiv.org/pdf/2601.21709.pdf",
      "authors": "Qingyue Yang, Jie Wang, Xing Li, Yinqi Bai, Xialiang Tong",
      "institution": "",
      "abstract": "Attention patterns play a crucial role in both training and inference of large language models (LLMs). Prior works have identified individual patterns such as retrieval heads, sink heads, and diagonal traces, yet these observations remain fragmented and lack a unifying explanation. To bridge this gap, we introduce Temporal Attention Pattern Predictability Analysis (TAPPA), a unifying framework that explains diverse attention patterns by analyzing their underlying mathematical formulations from a temporally continuous perspective. TAPPA both deepens the understanding of attention behavior and guides inference acceleration approaches. Specifically, TAPPA characterizes attention patterns as predictable patterns with clear regularities and unpredictable patterns that appear effectively random. Our analysis further reveals that this distinction can be explained by the degree of query self-similarity along the temporal dimension. Focusing on the predictable patterns, we further provide a detailed mathematical analysis of three representative cases through the joint effect of queries, keys, and Rotary Positional Embeddings (RoPE). We validate TAPPA by applying its insights to KV cache compression and LLM pruning tasks. Across these tasks, a simple metric motivated by TAPPA consistently improves performance over baseline methods. The code is available at https://github.com/MIRALab-USTC/LLM-TAPPA.",
      "source": "HuggingFace",
      "pubDateISO": "2026-01-29",
      "tags": [],
      "topics": [],
      "score": 5,
      "score_reason": "Unifying Perspective",
      "citations": 0,
      "upvotes": 2,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2601.21526",
      "title": "KAPSO: A Knowledge-grounded framework for Autonomous Program Synthesis and Optimization",
      "link": "https://huggingface.co/papers/2601.21526",
      "pdf_link": "https://arxiv.org/pdf/2601.21526.pdf",
      "authors": "Alireza Nadaf, Alireza Mohammadshahi, Majid Yazdani",
      "institution": "",
      "abstract": "We introduce KAPSO, a modular framework for autonomous program synthesis and optimization. Given a natural language goal and an evaluation method, KAPSO iteratively performs ideation, code synthesis and editing, execution, evaluation, and learning to improve a runnable artifact toward measurable objectives. Rather than treating synthesis as the endpoint, KAPSO uses synthesis as an operator within a long-horizon optimization loop, where progress is defined by evaluator outcomes.\n  KAPSO targets long-horizon failures common in coding agents, including lost experimental state, brittle debugging, and weak reuse of domain expertise, by integrating three tightly coupled components. First, a git-native experimentation engine isolates each attempt as a branch, producing reproducible artifacts and preserving provenance across iterations. Second, a knowledge system ingests heterogeneous sources, including repositories, internal playbooks, and curated external resources such as documentation, scientific papers, and web search results, and organizes them into a structured representation that supports retrieval over workflows, implementations, and environment constraints. Third, a cognitive memory layer coordinates retrieval and maintains an episodic store of reusable lessons distilled from experiment traces (run logs, diffs, and evaluator feedback), reducing repeated error modes and accelerating convergence.\n  We evaluated KAPSO on MLE-Bench (Kaggle-style ML competitions) and ALE-Bench (AtCoder heuristic optimization), and report end-to-end performance.\n  Code Available at: https://github.com/Leeroo-AI/kapso",
      "source": "HuggingFace",
      "pubDateISO": "2026-01-29",
      "tags": [],
      "topics": [],
      "score": 5,
      "score_reason": "Modular Framework",
      "citations": 0,
      "upvotes": 1,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2601.23134",
      "title": "Machine Learning for Energy-Performance-aware Scheduling",
      "link": "https://huggingface.co/papers/2601.23134",
      "pdf_link": "https://arxiv.org/pdf/2601.23134.pdf",
      "authors": "Zheyuan Hu, Yifei Shi",
      "institution": "",
      "abstract": "In the post-Dennard era, optimizing embedded systems requires navigating complex trade-offs between energy efficiency and latency. Traditional heuristic tuning is often inefficient in such high-dimensional, non-smooth landscapes. In this work, we propose a Bayesian Optimization framework using Gaussian Processes to automate the search for optimal scheduling configurations on heterogeneous multi-core architectures. We explicitly address the multi-objective nature of the problem by approximating the Pareto Frontier between energy and time. Furthermore, by incorporating Sensitivity Analysis (fANOVA) and comparing different covariance kernels (e.g., Matérn vs. RBF), we provide physical interpretability to the black-box model, revealing the dominant hardware parameters driving system performance.",
      "source": "HuggingFace",
      "pubDateISO": "2026-01-30",
      "tags": [],
      "topics": [],
      "score": 5,
      "score_reason": "Energy optimization",
      "citations": 0,
      "upvotes": 1,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2601.17883",
      "title": "EEG Foundation Models: Progresses, Benchmarking, and Open Problems",
      "link": "https://huggingface.co/papers/2601.17883",
      "pdf_link": "https://arxiv.org/pdf/2601.17883.pdf",
      "authors": "Dingkun Liu, Yuheng Chen, Zhu Chen, Zhenyao Cui, Yaozhi Wen",
      "institution": "",
      "abstract": "Electroencephalography (EEG) foundation models have recently emerged as a promising paradigm for brain-computer interfaces (BCIs), aiming to learn transferable neural representations from large-scale heterogeneous recordings. Despite rapid progresses, there lacks fair and comprehensive comparisons of existing EEG foundation models, due to inconsistent pre-training objectives, preprocessing choices, and downstream evaluation protocols. This paper fills this gap. We first review 50 representative models and organize their design choices into a unified taxonomic framework including data standardization, model architectures, and self-supervised pre-training strategies. We then evaluate 12 open-source foundation models and competitive specialist baselines across 13 EEG datasets spanning nine BCI paradigms. Emphasizing real-world deployments, we consider both cross-subject generalization under a leave-one-subject-out protocol and rapid calibration under a within-subject few-shot setting. We further compare full-parameter fine-tuning with linear probing to assess the transferability of pre-trained representations, and examine the relationship between model scale and downstream performance. Our results indicate that: 1) linear probing is frequently insufficient; 2) specialist models trained from scratch remain competitive across many tasks; and, 3) larger foundation models do not necessarily yield better generalization performance under current data regimes and training practices.",
      "source": "HuggingFace",
      "pubDateISO": "2026-01-25",
      "tags": [],
      "topics": [],
      "score": 4,
      "score_reason": "EEG foundation review",
      "citations": 0,
      "upvotes": 19,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2601.13097",
      "title": "RM -RF: Reward Model for Run-Free Unit Test Evaluation",
      "link": "https://huggingface.co/papers/2601.13097",
      "pdf_link": "https://arxiv.org/pdf/2601.13097.pdf",
      "authors": "Elena Bruches, Daniil Grebenkin, Mikhail Klementev, Vadim Alperovich, Roman Derunets",
      "institution": "",
      "abstract": "We present RM-RF, a lightweight reward model for run-free evaluation of automatically generated unit tests. Instead of repeatedly compiling and executing candidate tests, RM-RF predicts - from source and test code alone - three execution-derived signals: (1) whether the augmented test suite compiles and runs successfully, (2) whether the generated test cases increase code coverage, and (3) whether the generated test cases improve the mutation kill rate. To train and evaluate RM-RF we assemble a multilingual dataset (Java, Python, Go) of focal files, test files, and candidate test additions labeled by an execution-based pipeline, and we release an associated dataset and methodology for comparative evaluation. We tested multiple model families and tuning regimes (zero-shot, full fine-tuning, and PEFT via LoRA), achieving an average F1 of 0.69 across the three targets. Compared to conventional compile-and-run instruments, RM-RF provides substantially lower latency and infrastructure cost while delivering competitive predictive fidelity, enabling fast, scalable feedback for large-scale test generation and RL-based code optimization.",
      "source": "HuggingFace",
      "pubDateISO": "2026-01-19",
      "tags": [],
      "topics": [],
      "score": 4,
      "score_reason": "Minor Contribution",
      "citations": 1,
      "upvotes": 8,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2601.21419",
      "title": "Revisiting Diffusion Model Predictions Through Dimensionality",
      "link": "https://huggingface.co/papers/2601.21419",
      "pdf_link": "https://arxiv.org/pdf/2601.21419.pdf",
      "authors": "Qing Jin, Chaoyang Wang",
      "institution": "",
      "abstract": "Recent advances in diffusion and flow matching models have highlighted a shift in the preferred prediction target -- moving from noise (varepsilon) and velocity (v) to direct data (x) prediction -- particularly in high-dimensional settings. However, a formal explanation of why the optimal target depends on the specific properties of the data remains elusive. In this work, we provide a theoretical framework based on a generalized prediction formulation that accommodates arbitrary output targets, of which varepsilon-, v-, and x-prediction are special cases. We derive the analytical relationship between data's geometry and the optimal prediction target, offering a rigorous justification for why x-prediction becomes superior when the ambient dimension significantly exceeds the data's intrinsic dimension. Furthermore, while our theory identifies dimensionality as the governing factor for the optimal prediction target, the intrinsic dimension of manifold-bound data is typically intractable to estimate in practice. To bridge this gap, we propose k-Diff, a framework that employs a data-driven approach to learn the optimal prediction parameter k directly from data, bypassing the need for explicit dimension estimation. Extensive experiments in both latent-space and pixel-space image generation demonstrate that k-Diff consistently outperforms fixed-target baselines across varying architectures and data scales, providing a principled and automated approach to enhancing generative performance.",
      "source": "HuggingFace",
      "pubDateISO": "2026-01-29",
      "tags": [],
      "topics": [],
      "score": 4,
      "score_reason": "Theoretical explanation",
      "citations": 0,
      "upvotes": 4,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.02067v1",
      "title": "Multi-View Stenosis Classification Leveraging Transformer-Based Multiple-Instance Learning Using Real-World Clinical Data",
      "link": "http://arxiv.org/abs/2602.02067v1",
      "pdf_link": "https://arxiv.org/pdf/2602.02067v1",
      "authors": "Nikola Cenikj, Özgün Turgut, Alexander Müller, Alexander Steger, Jan Kehrer et al.",
      "institution": "",
      "abstract": "Coronary artery stenosis is a leading cause of cardiovascular disease, diagnosed by analyzing the coronary arteries from multiple angiography views. Although numerous deep-learning models have been proposed for stenosis detection from a single angiography view, their performance heavily relies on expensive view-level annotations, which are often not readily available in hospital systems. Moreover, these models fail to capture the temporal dynamics and dependencies among multiple views, which are crucial for clinical diagnosis. To address this, we propose SegmentMIL, a transformer-based multi-view multiple-instance learning framework for patient-level stenosis classification. Trained on a real-world clinical dataset, using patient-level supervision and without any view-level annotations, SegmentMIL jointly predicts the presence of stenosis and localizes the affected anatomical region, distinguishing between the right and left coronary arteries and their respective segments. SegmentMIL obtains high performance on internal and external evaluations and outperforms both view-level models and classical MIL baselines, underscoring its potential as a clinically viable and scalable solution for coronary stenosis diagnosis. Our code is available at https://github.com/NikolaCenic/mil-stenosis.",
      "source": "arXiv",
      "pubDateISO": "2026-02-02",
      "tags": [
        "cs.CV",
        "cs.AI"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.02063v1",
      "title": "See2Refine: Vision-Language Feedback Improves LLM-Based eHMI Action Designers",
      "link": "http://arxiv.org/abs/2602.02063v1",
      "pdf_link": "https://arxiv.org/pdf/2602.02063v1",
      "authors": "Ding Xia, Xinyue Gui, Mark Colley, Fan Gao, Zhongyi Zhou et al.",
      "institution": "",
      "abstract": "Automated vehicles lack natural communication channels with other road users, making external Human-Machine Interfaces (eHMIs) essential for conveying intent and maintaining trust in shared environments. However, most eHMI studies rely on developer-crafted message-action pairs, which are difficult to adapt to diverse and dynamic traffic contexts. A promising alternative is to use Large Language Models (LLMs) as action designers that generate context-conditioned eHMI actions, yet such designers lack perceptual verification and typically depend on fixed prompts or costly human-annotated feedback for improvement. We present See2Refine, a human-free, closed-loop framework that uses vision-language model (VLM) perceptual evaluation as automated visual feedback to improve an LLM-based eHMI action designer. Given a driving context and a candidate eHMI action, the VLM evaluates the perceived appropriateness of the action, and this feedback is used to iteratively revise the designer's outputs, enabling systematic refinement without human supervision. We evaluate our framework across three eHMI modalities (lightbar, eyes, and arm) and multiple LLM model sizes. Across settings, our framework consistently outperforms prompt-only LLM designers and manually specified baselines in both VLM-based metrics and human-subject evaluations. Results further indicate that the improvements generalize across modalities and that VLM evaluations are well aligned with human preferences, supporting the robustness and effectiveness of See2Refine for scalable action design.",
      "source": "arXiv",
      "pubDateISO": "2026-02-02",
      "tags": [
        "cs.HC",
        "cs.AI"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.02061v1",
      "title": "Learning to Route and Schedule LLMs from User Retrials via Contextual Queueing Bandits",
      "link": "http://arxiv.org/abs/2602.02061v1",
      "pdf_link": "https://arxiv.org/pdf/2602.02061v1",
      "authors": "Seoungbin Bae, Junyoung Son, Dabeen Lee",
      "institution": "",
      "abstract": "Explosive demands for LLMs often cause user queries to accumulate in server queues, requiring efficient routing (query-LLM matching) and scheduling (query prioritization) mechanisms. Several online algorithms are being deployed, but they overlook the following two key challenges inherent to conversational LLM services: (1) unsatisfied users may retry queries, increasing the server backlog, and (2) requests for ``explicit\" feedback, such as ratings, degrade user experiences. In this paper, we develop a joint routing and scheduling algorithm that leverages ``implicit\" feedback inferred from user retrial behaviors. The key idea is to propose and study the framework of contextual queueing bandits with multinomial logit feedback (CQB-MNL). CQB-MNL models query retrials, as well as context-based learning for user preferences over LLMs. Our algorithm, anytime CQB (ACQB), achieves efficient learning while maintaining queue stability by combining Thompson sampling with forced exploration at a decaying rate. We show that ACQB simultaneously achieves a cumulative regret of $\\widetilde{\\mathcal{O}}(\\sqrt{t})$ for routing and a queue length regret of $\\widetilde{\\mathcal{O}}(t^{-1/4})$ for any large $t$. For experiments, we refine query embeddings via contrastive learning while adopting a disjoint parameter model to learn LLM-specific parameters. Experiments on SPROUT, EmbedLLM, and RouterBench datasets confirm that both algorithms consistently outperform baselines.",
      "source": "arXiv",
      "pubDateISO": "2026-02-02",
      "tags": [
        "cs.LG"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.02060v1",
      "title": "FiLoRA: Focus-and-Ignore LoRA for Controllable Feature Reliance",
      "link": "http://arxiv.org/abs/2602.02060v1",
      "pdf_link": "https://arxiv.org/pdf/2602.02060v1",
      "authors": "Hyunsuk Chung, Caren Han, Yerin Choi, Seungyeon Ji, Jinwoo Kim et al.",
      "institution": "",
      "abstract": "Multimodal foundation models integrate heterogeneous signals across modalities, yet it remains poorly understood how their predictions depend on specific internal feature groups and whether such reliance can be deliberately controlled. Existing studies of shortcut and spurious behavior largely rely on post hoc analyses or feature removal, offering limited insight into whether reliance can be modulated without altering task semantics. We introduce FiLoRA (Focus-and-Ignore LoRA), an instruction-conditioned, parameter-efficient adaptation framework that enables explicit control over internal feature reliance while keeping the predictive objective fixed. FiLoRA decomposes adaptation into feature group-aligned LoRA modules and applies instruction-conditioned gating, allowing natural language instructions to act as computation-level control signals rather than task redefinitions. Across text--image and audio--visual benchmarks, we show that instruction-conditioned gating induces consistent and causal shifts in internal computation, selectively amplifying or suppressing core and spurious feature groups without modifying the label space or training objective. Further analyses demonstrate that FiLoRA yields improved robustness under spurious feature interventions, revealing a principled mechanism to regulate reliance beyond correlation-driven learning.",
      "source": "arXiv",
      "pubDateISO": "2026-02-02",
      "tags": [
        "cs.LG",
        "cs.AI"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.02056v1",
      "title": "Ultrafast On-chip Online Learning via Spline Locality in Kolmogorov-Arnold Networks",
      "link": "http://arxiv.org/abs/2602.02056v1",
      "pdf_link": "https://arxiv.org/pdf/2602.02056v1",
      "authors": "Duc Hoang, Aarush Gupta, Philip Harris",
      "institution": "",
      "abstract": "Ultrafast online learning is essential for high-frequency systems, such as controls for quantum computing and nuclear fusion, where adaptation must occur on sub-microsecond timescales. Meeting these requirements demands low-latency, fixed-precision computation under strict memory constraints, a regime in which conventional Multi-Layer Perceptrons (MLPs) are both inefficient and numerically unstable. We identify key properties of Kolmogorov-Arnold Networks (KANs) that align with these constraints. Specifically, we show that: (i) KAN updates exploiting B-spline locality are sparse, enabling superior on-chip resource scaling, and (ii) KANs are inherently robust to fixed-point quantization. By implementing fixed-point online training on Field-Programmable Gate Arrays (FPGAs), a representative platform for on-chip computation, we demonstrate that KAN-based online learners are significantly more efficient and expressive than MLPs across a range of low-latency and resource-constrained tasks. To our knowledge, this work is the first to demonstrate model-free online learning at sub-microsecond latencies.",
      "source": "arXiv",
      "pubDateISO": "2026-02-02",
      "tags": [
        "cs.AR",
        "cs.LG",
        "stat.ML"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.02055v1",
      "title": "FORLER: Federated Offline Reinforcement Learning with Q-Ensemble and Actor Rectification",
      "link": "http://arxiv.org/abs/2602.02055v1",
      "pdf_link": "https://arxiv.org/pdf/2602.02055v1",
      "authors": "Nan Qiao, Sheng Yue",
      "institution": "",
      "abstract": "In Internet-of-Things systems, federated learning has advanced online reinforcement learning (RL) by enabling parallel policy training without sharing raw data. However, interacting with real environments online can be risky and costly, motivating offline federated RL (FRL), where local devices learn from fixed datasets. Despite its promise, offline FRL may break down under low-quality, heterogeneous data. Offline RL tends to get stuck in local optima, and in FRL, one device's suboptimal policy can degrade the aggregated model, i.e., policy pollution. We present FORLER, combining Q-ensemble aggregation on the server with actor rectification on devices. The server robustly merges device Q-functions to curb policy pollution and shift heavy computation off resource-constrained hardware without compromising privacy. Locally, actor rectification enriches policy gradients via a zeroth-order search for high-Q actions plus a bespoke regularizer that nudges the policy toward them. A $δ$-periodic strategy further reduces local computation. We theoretically provide safe policy improvement performance guarantees. Extensive experiments show FORLER consistently outperforms strong baselines under varying data quality and heterogeneity.",
      "source": "arXiv",
      "pubDateISO": "2026-02-02",
      "tags": [
        "cs.LG",
        "cs.AI"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.02053v1",
      "title": "WildGraphBench: Benchmarking GraphRAG with Wild-Source Corpora",
      "link": "http://arxiv.org/abs/2602.02053v1",
      "pdf_link": "https://arxiv.org/pdf/2602.02053v1",
      "authors": "Pengyu Wang, Benfeng Xu, Licheng Zhang, Shaohan Wang, Mingxuan Du et al.",
      "institution": "",
      "abstract": "Graph-based Retrieval-Augmented Generation (GraphRAG) organizes external knowledge as a hierarchical graph, enabling efficient retrieval and aggregation of scattered evidence across multiple documents. However, many existing benchmarks for GraphRAG rely on short, curated passages as external knowledge, failing to adequately evaluate systems in realistic settings involving long contexts and large-scale heterogeneous documents. To bridge this gap, we introduce WildGraphBench, a benchmark designed to assess GraphRAG performance in the wild. We leverage Wikipedia's unique structure, where cohesive narratives are grounded in long and heterogeneous external reference documents, to construct a benchmark reflecting real-word scenarios. Specifically, we sample articles across 12 top-level topics, using their external references as the retrieval corpus and citation-linked statements as ground truth, resulting in 1,100 questions spanning three levels of complexity: single-fact QA, multi-fact QA, and section-level summarization. Experiments across multiple baselines reveal that current GraphRAG pipelines help on multi-fact aggregation when evidence comes from a moderate number of sources, but this aggregation paradigm may overemphasize high-level statements at the expense of fine-grained details, leading to weaker performance on summarization tasks. Project page:https://github.com/BstWPY/WildGraphBench.",
      "source": "arXiv",
      "pubDateISO": "2026-02-02",
      "tags": [
        "cs.CL"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.02051v1",
      "title": "SIDiffAgent: Self-Improving Diffusion Agent",
      "link": "http://arxiv.org/abs/2602.02051v1",
      "pdf_link": "https://arxiv.org/pdf/2602.02051v1",
      "authors": "Shivank Garg, Ayush Singh, Gaurav Kumar Nayak",
      "institution": "",
      "abstract": "Text-to-image diffusion models have revolutionized generative AI, enabling high-quality and photorealistic image synthesis. However, their practical deployment remains hindered by several limitations: sensitivity to prompt phrasing, ambiguity in semantic interpretation (e.g., ``mouse\" as animal vs. a computer peripheral), artifacts such as distorted anatomy, and the need for carefully engineered input prompts. Existing methods often require additional training and offer limited controllability, restricting their adaptability in real-world applications. We introduce Self-Improving Diffusion Agent (SIDiffAgent), a training-free agentic framework that leverages the Qwen family of models (Qwen-VL, Qwen-Image, Qwen-Edit, Qwen-Embedding) to address these challenges. SIDiffAgent autonomously manages prompt engineering, detects and corrects poor generations, and performs fine-grained artifact removal, yielding more reliable and consistent outputs. It further incorporates iterative self-improvement by storing a memory of previous experiences in a database. This database of past experiences is then used to inject prompt-based guidance at each stage of the agentic pipeline. \\modelour achieved an average VQA score of 0.884 on GenAIBench, significantly outperforming open-source, proprietary models and agentic methods. We will publicly release our code upon acceptance.",
      "source": "arXiv",
      "pubDateISO": "2026-02-02",
      "tags": [
        "cs.AI"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.02050v1",
      "title": "Rethinking the Role of Entropy in Optimizing Tool-Use Behaviors for Large Language Model Agents",
      "link": "http://arxiv.org/abs/2602.02050v1",
      "pdf_link": "https://arxiv.org/pdf/2602.02050v1",
      "authors": "Zeping Li, Hongru Wang, Yiwen Zhao, Guanhua Chen, Yixia Li et al.",
      "institution": "",
      "abstract": "Tool-using agents based on Large Language Models (LLMs) excel in tasks such as mathematical reasoning and multi-hop question answering. However, in long trajectories, agents often trigger excessive and low-quality tool calls, increasing latency and degrading inference performance, making managing tool-use behavior challenging. In this work, we conduct entropy-based pilot experiments and observe a strong positive correlation between entropy reduction and high-quality tool calls. Building on this finding, we propose using entropy reduction as a supervisory signal and design two reward strategies to address the differing needs of optimizing tool-use behavior. Sparse outcome rewards provide coarse, trajectory-level guidance to improve efficiency, while dense process rewards offer fine-grained supervision to enhance performance. Experiments across diverse domains show that both reward designs improve tool-use behavior: the former reduces tool calls by 72.07% compared to the average of baselines, while the latter improves performance by 22.27%. These results position entropy reduction as a key mechanism for enhancing tool-use behavior, enabling agents to be more adaptive in real-world applications.",
      "source": "arXiv",
      "pubDateISO": "2026-02-02",
      "tags": [
        "cs.AI",
        "cs.SE"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.02047v1",
      "title": "Dissecting Outlier Dynamics in LLM NVFP4 Pretraining",
      "link": "http://arxiv.org/abs/2602.02047v1",
      "pdf_link": "https://arxiv.org/pdf/2602.02047v1",
      "authors": "Peijie Dong, Ruibo Fan, Yuechen Tao, Di Mou, Wenhu Hu et al.",
      "institution": "",
      "abstract": "Training large language models using 4-bit arithmetic enhances throughput and memory efficiency. Yet, the limited dynamic range of FP4 increases sensitivity to outliers. While NVFP4 mitigates quantization error via hierarchical microscaling, a persistent loss gap remains compared to BF16. This study conducts a longitudinal analysis of outlier dynamics across architecture during NVFP4 pretraining, focusing on where they localize, why they occur, and how they evolve temporally. We find that, compared with Softmax Attention (SA), Linear Attention (LA) reduces per-tensor heavy tails but still exhibits persistent block-level spikes under block quantization. Our analysis attributes outliers to specific architectural components: Softmax in SA, gating in LA, and SwiGLU in FFN, with \"post-QK\" operations exhibiting higher sensitivity to quantization. Notably, outliers evolve from transient spikes early in training to a small set of persistent hot channels (i.e., channels with persistently large magnitudes) in later stages. Based on these findings, we introduce Hot-Channel Patch (HCP), an online compensation mechanism that identifies hot channels and reinjects residuals using hardware-efficient kernels. We then develop CHON, an NVFP4 training recipe integrating HCP with post-QK operation protection. On GLA-1.3B model trained for 60B tokens, CHON reduces the loss gap to BF16 from 0.94% to 0.58% while maintaining downstream accuracy.",
      "source": "arXiv",
      "pubDateISO": "2026-02-02",
      "tags": [
        "cs.LG",
        "cs.CL"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.02045v1",
      "title": "On Stability and Robustness of Diffusion Posterior Sampling for Bayesian Inverse Problems",
      "link": "http://arxiv.org/abs/2602.02045v1",
      "pdf_link": "https://arxiv.org/pdf/2602.02045v1",
      "authors": "Yiming Yang, Xiaoyuan Cheng, Yi He, Kaiyu Li, Wenxuan Yuan et al.",
      "institution": "",
      "abstract": "Diffusion models have recently emerged as powerful learned priors for Bayesian inverse problems (BIPs). Diffusion-based solvers rely on a presumed likelihood for the observations in BIPs to guide the generation process. However, the link between likelihood and recovery quality for BIPs is unclear in previous works. We bridge this gap by characterizing the posterior approximation error and proving the \\emph{stability} of the diffusion-based solvers. Meanwhile, an immediate result of our findings on stability demonstrates the lack of robustness in diffusion-based solvers, which remains unexplored. This can degrade performance when the presumed likelihood mismatches the unknown true data generation processes. To address this issue, we propose a simple yet effective solution, \\emph{robust diffusion posterior sampling}, which is provably \\emph{robust} and compatible with existing gradient-based posterior samplers. Empirical results on scientific inverse problems and natural image tasks validate the effectiveness and robustness of our method, showing consistent performance improvements under challenging likelihood misspecifications.",
      "source": "arXiv",
      "pubDateISO": "2026-02-02",
      "tags": [
        "cs.LG"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.02044v1",
      "title": "Twinning Complex Networked Systems: Data-Driven Calibration of the mABCD Synthetic Graph Generator",
      "link": "http://arxiv.org/abs/2602.02044v1",
      "pdf_link": "https://arxiv.org/pdf/2602.02044v1",
      "authors": "Piotr Bródka, Michał Czuba, Bogumił Kamiński, Łukasz Kraiński, Katarzyna Musial et al.",
      "institution": "",
      "abstract": "The increasing availability of relational data has contributed to a growing reliance on network-based representations of complex systems. Over time, these models have evolved to capture more nuanced properties, such as the heterogeneity of relationships, leading to the concept of multilayer networks. However, the analysis and evaluation of methods for these structures is often hindered by the limited availability of large-scale empirical data. As a result, graph generators are commonly used as a workaround, albeit at the cost of introducing systematic biases. In this paper, we address the inverse-generator problem by inferring the configuration parameters of a multilayer network generator, mABCD, from a real-world system. Our goal is to identify parameter settings that enable the generator to produce synthetic networks that act as digital twins of the original structure. We propose a method for estimating matching configurations and for quantifying the associated error. Our results demonstrate that this task is non-trivial, as strong interdependencies between configuration parameters weaken independent estimation and instead favour a joint-prediction approach.",
      "source": "arXiv",
      "pubDateISO": "2026-02-02",
      "tags": [
        "cs.SI",
        "cs.LG"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.02043v1",
      "title": "Auto-Comp: An Automated Pipeline for Scalable Compositional Probing of Contrastive Vision-Language Models",
      "link": "http://arxiv.org/abs/2602.02043v1",
      "pdf_link": "https://arxiv.org/pdf/2602.02043v1",
      "authors": "Cristian Sbrolli, Matteo Matteucci, Toshihiko Yamasaki",
      "institution": "",
      "abstract": "Modern Vision-Language Models (VLMs) exhibit a critical flaw in compositional reasoning, often confusing \"a red cube and a blue sphere\" with \"a blue cube and a red sphere\". Disentangling the visual and linguistic roots of these failures is a fundamental challenge for robust evaluation. To enable fine-grained, controllable analysis, we introduce Auto-Comp, a fully automated and synthetic pipeline for generating scalable benchmarks. Its controllable nature is key to dissecting and isolating different reasoning skills. Auto-Comp generates paired images from Minimal (e.g., \"a monitor to the left of a bicycle on a white background\") and LLM-generated Contextual captions (e.g., \"In a brightly lit photography studio, a monitor is positioned to the left of a bicycle\"), allowing a controlled A/B test to disentangle core binding ability from visio-linguistic complexity. Our evaluation of 20 VLMs on novel benchmarks for color binding and spatial relations reveals universal compositional failures in both CLIP and SigLIP model families. Crucially, our novel \"Confusion Benchmark\" reveals a deeper flaw beyond simple attribute swaps: models are highly susceptible to low-entropy distractors (e.g., repeated objects or colors), demonstrating their compositional failures extend beyond known bag-of-words limitations. we uncover a surprising trade-off: visio-linguistic context, which provides global scene cues, aids spatial reasoning but simultaneously hinders local attribute binding by introducing visual clutter. We release the Auto-Comp pipeline to facilitate future benchmark creation, alongside all our generated benchmarks (https://huggingface.co/AutoComp).",
      "source": "arXiv",
      "pubDateISO": "2026-02-02",
      "tags": [
        "cs.CV",
        "cs.AI"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.02039v1",
      "title": "Hunt Instead of Wait: Evaluating Deep Data Research on Large Language Models",
      "link": "http://arxiv.org/abs/2602.02039v1",
      "pdf_link": "https://arxiv.org/pdf/2602.02039v1",
      "authors": "Wei Liu, Peijie Yu, Michele Orini, Yali Du, Yulan He",
      "institution": "",
      "abstract": "The agency expected of Agentic Large Language Models goes beyond answering correctly, requiring autonomy to set goals and decide what to explore. We term this investigatory intelligence, distinguishing it from executional intelligence, which merely completes assigned tasks. Data Science provides a natural testbed, as real-world analysis starts from raw data rather than explicit queries, yet few benchmarks focus on it. To address this, we introduce Deep Data Research (DDR), an open-ended task where LLMs autonomously extract key insights from databases, and DDR-Bench, a large-scale, checklist-based benchmark that enables verifiable evaluation. Results show that while frontier models display emerging agency, long-horizon exploration remains challenging. Our analysis highlights that effective investigatory intelligence depends not only on agent scaffolding or merely scaling, but also on intrinsic strategies of agentic models.",
      "source": "arXiv",
      "pubDateISO": "2026-02-02",
      "tags": [
        "cs.AI",
        "cs.CL",
        "cs.DB",
        "cs.LG"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.02035v1",
      "title": "Bandwidth-Efficient Multi-Agent Communication through Information Bottleneck and Vector Quantization",
      "link": "http://arxiv.org/abs/2602.02035v1",
      "pdf_link": "https://arxiv.org/pdf/2602.02035v1",
      "authors": "Ahmad Farooq, Kamran Iqbal",
      "institution": "",
      "abstract": "Multi-agent reinforcement learning systems deployed in real-world robotics applications face severe communication constraints that significantly impact coordination effectiveness. We present a framework that combines information bottleneck theory with vector quantization to enable selective, bandwidth-efficient communication in multi-agent environments. Our approach learns to compress and discretize communication messages while preserving task-critical information through principled information-theoretic optimization. We introduce a gated communication mechanism that dynamically determines when communication is necessary based on environmental context and agent states. Experimental evaluation on challenging coordination tasks demonstrates that our method achieves 181.8% performance improvement over no-communication baselines while reducing bandwidth usage by 41.4%. Comprehensive Pareto frontier analysis shows dominance across the entire success-bandwidth spectrum with area-under-curve of 0.198 vs 0.142 for next-best methods. Our approach significantly outperforms existing communication strategies and establishes a theoretically grounded framework for deploying multi-agent systems in bandwidth-constrained environments such as robotic swarms, autonomous vehicle fleets, and distributed sensor networks.",
      "source": "arXiv",
      "pubDateISO": "2026-02-02",
      "tags": [
        "cs.RO",
        "cs.AI",
        "cs.IT",
        "cs.LG",
        "cs.MA"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.02034v1",
      "title": "Constrained Process Maps for Multi-Agent Generative AI Workflows",
      "link": "http://arxiv.org/abs/2602.02034v1",
      "pdf_link": "https://arxiv.org/pdf/2602.02034v1",
      "authors": "Ananya Joshi, Michael Rudow",
      "institution": "",
      "abstract": "Large language model (LLM)-based agents are increasingly used to perform complex, multi-step workflows in regulated settings such as compliance and due diligence. However, many agentic architectures rely primarily on prompt engineering of a single agent, making it difficult to observe or compare how models handle uncertainty and coordination across interconnected decision stages and with human oversight. We introduce a multi-agent system formalized as a finite-horizon Markov Decision Process (MDP) with a directed acyclic structure. Each agent corresponds to a specific role or decision stage (e.g., content, business, or legal review in a compliance workflow), with predefined transitions representing task escalation or completion. Epistemic uncertainty is quantified at the agent level using Monte Carlo estimation, while system-level uncertainty is captured by the MDP's termination in either an automated labeled state or a human-review state. We illustrate the approach through a case study in AI safety evaluation for self-harm detection, implemented as a multi-agent compliance system. Results demonstrate improvements over a single-agent baseline, including up to a 19\\% increase in accuracy, up to an 85x reduction in required human review, and, in some configurations, reduced processing time.",
      "source": "arXiv",
      "pubDateISO": "2026-02-02",
      "tags": [
        "cs.AI"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.02033v1",
      "title": "One Size, Many Fits: Aligning Diverse Group-Wise Click Preferences in Large-Scale Advertising Image Generation",
      "link": "http://arxiv.org/abs/2602.02033v1",
      "pdf_link": "https://arxiv.org/pdf/2602.02033v1",
      "authors": "Shuo Lu, Haohan Wang, Wei Feng, Weizhen Wang, Shen Zhang et al.",
      "institution": "",
      "abstract": "Advertising image generation has increasingly focused on online metrics like Click-Through Rate (CTR), yet existing approaches adopt a ``one-size-fits-all\" strategy that optimizes for overall CTR while neglecting preference diversity among user groups. This leads to suboptimal performance for specific groups, limiting targeted marketing effectiveness. To bridge this gap, we present \\textit{One Size, Many Fits} (OSMF), a unified framework that aligns diverse group-wise click preferences in large-scale advertising image generation. OSMF begins with product-aware adaptive grouping, which dynamically organizes users based on their attributes and product characteristics, representing each group with rich collective preference features. Building on these groups, preference-conditioned image generation employs a Group-aware Multimodal Large Language Model (G-MLLM) to generate tailored images for each group. The G-MLLM is pre-trained to simultaneously comprehend group features and generate advertising images. Subsequently, we fine-tune the G-MLLM using our proposed Group-DPO for group-wise preference alignment, which effectively enhances each group's CTR on the generated images. To further advance this field, we introduce the Grouped Advertising Image Preference Dataset (GAIP), the first large-scale public dataset of group-wise image preferences, including around 600K groups built from 40M users. Extensive experiments demonstrate that our framework achieves the state-of-the-art performance in both offline and online settings. Our code and datasets will be released at https://github.com/JD-GenX/OSMF.",
      "source": "arXiv",
      "pubDateISO": "2026-02-02",
      "tags": [
        "cs.CV",
        "cs.AI"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.02029v1",
      "title": "Canonical Intermediate Representation for LLM-based optimization problem formulation and code generation",
      "link": "http://arxiv.org/abs/2602.02029v1",
      "pdf_link": "https://arxiv.org/pdf/2602.02029v1",
      "authors": "Zhongyuan Lyu, Shuoyu Hu, Lujie Liu, Hongxia Yang, Ming LI",
      "institution": "",
      "abstract": "Automatically formulating optimization models from natural language descriptions is a growing focus in operations research, yet current LLM-based approaches struggle with the composite constraints and appropriate modeling paradigms required by complex operational rules. To address this, we introduce the Canonical Intermediate Representation (CIR): a schema that LLMs explicitly generate between problem descriptions and optimization models. CIR encodes the semantics of operational rules through constraint archetypes and candidate modeling paradigms, thereby decoupling rule logic from its mathematical instantiation. Upon a newly generated CIR knowledge base, we develop the rule-to-constraint (R2C) framework, a multi-agent pipeline that parses problem texts, synthesizes CIR implementations by retrieving domain knowledge, and instantiates optimization models. To systematically evaluate rule-to-constraint reasoning, we test R2C on our newly constructed benchmark featuring rich operational rules, and benchmarks from prior work. Extensive experiments show that R2C achieves state-of-the-art accuracy on the proposed benchmark (47.2% Accuracy Rate). On established benchmarks from the literature, R2C delivers highly competitive results, approaching the performance of proprietary models (e.g., GPT-5). Moreover, with a reflection mechanism, R2C achieves further gains and sets new best-reported results on some benchmarks.",
      "source": "arXiv",
      "pubDateISO": "2026-02-02",
      "tags": [
        "cs.AI",
        "cs.SE"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.02028v1",
      "title": "Edit Knowledge, Not Just Facts via Multi-Step Reasoning over Background Stories",
      "link": "http://arxiv.org/abs/2602.02028v1",
      "pdf_link": "https://arxiv.org/pdf/2602.02028v1",
      "authors": "Ya Gao, Kalle Kujanpää, Pekka Marttinen, Harri Valpola, Alexander Ilin",
      "institution": "",
      "abstract": "Enabling artificial intelligence systems, particularly large language models, to integrate new knowledge and flexibly apply it during reasoning remains a central challenge. Existing knowledge editing approaches emphasize atomic facts, improving factual recall but often failing to integrate new information into a coherent framework usable across contexts. In this work, we argue that knowledge internalization is fundamentally a reasoning problem rather than a memorization problem. Consequently, a model should be trained in situations where the new information is instrumental to solving a task, combined with pre-existing knowledge, and exercised through multi-step reasoning. Based on this insight, we propose a training strategy based on three principles. First, new knowledge is introduced as a coherent background story that contextualizes novel facts and explains their relation to existing knowledge. Second, models are trained using self-generated multi-hop questions that require multi-step reasoning involving the new information. Third, training is done using knowledge distillation, forcing a student model to internalize the teacher's reasoning behavior without access to the novel information. Experiments show that models trained with this strategy effectively leverage newly acquired knowledge during reasoning and achieve remarkable performance on challenging questions that require combining multiple new facts.",
      "source": "arXiv",
      "pubDateISO": "2026-02-02",
      "tags": [
        "cs.AI"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.02027v1",
      "title": "Light Alignment Improves LLM Safety via Model Self-Reflection with a Single Neuron",
      "link": "http://arxiv.org/abs/2602.02027v1",
      "pdf_link": "https://arxiv.org/pdf/2602.02027v1",
      "authors": "Sicheng Shen, Mingyang Lv, Han Shen, Jialin Wu, Binghao Wang et al.",
      "institution": "",
      "abstract": "The safety of large language models (LLMs) has increasingly emerged as a fundamental aspect of their development. Existing safety alignment for LLMs is predominantly achieved through post-training methods, which are computationally expensive and often fail to generalize well across different models. A small number of lightweight alignment approaches either rely heavily on prior-computed safety injections or depend excessively on the model's own capabilities, resulting in limited generalization and degraded efficiency and usability during generation. In this work, we propose a safety-aware decoding method that requires only low-cost training of an expert model and employs a single neuron as a gating mechanism. By effectively balancing the model's intrinsic capabilities with external guidance, our approach simultaneously preserves utility and enhances output safety. It demonstrates clear advantages in training overhead and generalization across model scales, offering a new perspective on lightweight alignment for the safe and practical deployment of large language models. Code: https://github.com/Beijing-AISI/NGSD.",
      "source": "arXiv",
      "pubDateISO": "2026-02-02",
      "tags": [
        "cs.AI",
        "cs.LG"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.02025v1",
      "title": "Hippasus: Effective and Efficient Automatic Feature Augmentation for Machine Learning Tasks on Relational Data",
      "link": "http://arxiv.org/abs/2602.02025v1",
      "pdf_link": "https://arxiv.org/pdf/2602.02025v1",
      "authors": "Serafeim Papadias, Kostas Patroumpas, Dimitrios Skoutas",
      "institution": "MIT",
      "abstract": "Machine learning models depend critically on feature quality, yet useful features are often scattered across multiple relational tables. Feature augmentation enriches a base table by discovering and integrating features from related tables through join operations. However, scaling this process to complex schemas with many tables and multi-hop paths remains challenging. Feature augmentation must address three core tasks: identify promising join paths that connect the base table to candidate tables, execute these joins to materialize augmented data, and select the most informative features from the results. Existing approaches face a fundamental tradeoff between effectiveness and efficiency: achieving high accuracy requires exploring many candidate paths, but exhaustive exploration is computationally prohibitive. Some methods compromise by considering only immediate neighbors, limiting their effectiveness, while others employ neural models that require expensive training data and introduce scalability limitations. We present Hippasus, a modular framework that achieves both goals through three key contributions. First, we combine lightweight statistical signals with semantic reasoning from Large Language Models to prune unpromising join paths before execution, focusing computational resources on high-quality candidates. Second, we employ optimized multi-way join algorithms and consolidate features from multiple paths, substantially reducing execution time. Third, we integrate LLM-based semantic understanding with statistical measures to select features that are both semantically meaningful and empirically predictive. Our experimental evaluation on publicly available datasets shows that Hippasus substantially improves feature augmentation accuracy by up to 26.8% over state-of-the-art baselines while also offering high runtime performance.",
      "source": "arXiv",
      "pubDateISO": "2026-02-02",
      "tags": [
        "cs.DB",
        "cs.LG"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.02024v1",
      "title": "Adaptive Quality-Diversity Trade-offs for Large-Scale Batch Recommendation",
      "link": "http://arxiv.org/abs/2602.02024v1",
      "pdf_link": "https://arxiv.org/pdf/2602.02024v1",
      "authors": "Clémence Réda, Tomas Rigaux, Hiba Bederina, Koh Takeuchi, Hisashi Kashima et al.",
      "institution": "",
      "abstract": "A core research question in recommender systems is to propose batches of highly relevant and diverse items, that is, items personalized to the user's preferences, but which also might get the user out of their comfort zone. This diversity might induce properties of serendipidity and novelty which might increase user engagement or revenue. However, many real-life problems arise in that case: e.g., avoiding to recommend distinct but too similar items to reduce the churn risk, and computational cost for large item libraries, up to millions of items. First, we consider the case when the user feedback model is perfectly observed and known in advance, and introduce an efficient algorithm called B-DivRec combining determinantal point processes and a fuzzy denuding procedure to adjust the degree of item diversity. This helps enforcing a quality-diversity trade-off throughout the user history. Second, we propose an approach to adaptively tailor the quality-diversity trade-off to the user, so that diversity in recommendations can be enhanced if it leads to positive feedback, and vice-versa. Finally, we illustrate the performance and versatility of B-DivRec in the two settings on synthetic and real-life data sets on movie recommendation and drug repurposing.",
      "source": "arXiv",
      "pubDateISO": "2026-02-02",
      "tags": [
        "cs.IR",
        "cs.LG"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.02020v1",
      "title": "Scale-covariant spiking wavelets",
      "link": "http://arxiv.org/abs/2602.02020v1",
      "pdf_link": "https://arxiv.org/pdf/2602.02020v1",
      "authors": "Jens Egholm Pedersen, Tony Lindeberg, Peter Gerstoft",
      "institution": "",
      "abstract": "We establish a theoretical connection between wavelet transforms and spiking neural networks through scale-space theory. We rely on the scale-covariant guarantees in the leaky integrate-and-fire neurons to implement discrete mother wavelets that approximate continuous wavelets. A reconstruction experiment demonstrates the feasibility of the approach and warrants further analysis to mitigate current approximation errors. Our work suggests a novel spiking signal representation that could enable more energy-efficient signal processing algorithms.",
      "source": "arXiv",
      "pubDateISO": "2026-02-02",
      "tags": [
        "cs.NE",
        "cs.LG"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.02018v1",
      "title": "Do I Really Know? Learning Factual Self-Verification for Hallucination Reduction",
      "link": "http://arxiv.org/abs/2602.02018v1",
      "pdf_link": "https://arxiv.org/pdf/2602.02018v1",
      "authors": "Enes Altinisik, Masoomali Fatehkia, Fatih Deniz, Nadir Durrani, Majd Hawasly et al.",
      "institution": "",
      "abstract": "Factual hallucination remains a central challenge for large language models (LLMs). Existing mitigation approaches primarily rely on either external post-hoc verification or mapping uncertainty directly to abstention during fine-tuning, often resulting in overly conservative behavior. We propose VeriFY, a training-time framework that teaches LLMs to reason about factual uncertainty through consistency-based self-verification. VeriFY augments training with structured verification traces that guide the model to produce an initial answer, generate and answer a probing verification query, issue a consistency judgment, and then decide whether to answer or abstain. To address the risk of reinforcing hallucinated content when training on augmented traces, we introduce a stage-level loss masking approach that excludes hallucinated answer stages from the training objective while preserving supervision over verification behavior. Across multiple model families and scales, VeriFY reduces factual hallucination rates by 9.7 to 53.3 percent, with only modest reductions in recall (0.4 to 5.7 percent), and generalizes across datasets when trained on a single source. The source code, training data, and trained model checkpoints will be released upon acceptance.",
      "source": "arXiv",
      "pubDateISO": "2026-02-02",
      "tags": [
        "cs.AI"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.02016v1",
      "title": "DASH: Faster Shampoo via Batched Block Preconditioning and Efficient Inverse-Root Solvers",
      "link": "http://arxiv.org/abs/2602.02016v1",
      "pdf_link": "https://arxiv.org/pdf/2602.02016v1",
      "authors": "Ionut-Vlad Modoranu, Philip Zmushko, Erik Schultheis, Mher Safaryan, Dan Alistarh",
      "institution": "",
      "abstract": "Shampoo is one of the leading approximate second-order optimizers: a variant of it has won the MLCommons AlgoPerf competition, and it has been shown to produce models with lower activation outliers that are easier to compress. Yet, applying Shampoo currently comes at the cost of significant computational slowdown, due to its expensive internal operations. In this paper, we take a significant step to address this shortcoming by proposing \\method (for \\textbf{D}istributed \\textbf{A}ccelerated \\textbf{SH}ampoo), a faster implementation of Distributed Shampoo based on two main new techniques: First, we show that preconditioner blocks can be stacked into 3D tensors to significantly improve GPU utilization; second, we introduce the Newton-DB iteration and the Chebyshev polynomial approximations as novel and faster approaches for computing the inverse matrix roots required by Shampoo. Along with these algorithmic contributions, we provide a first in-depth analysis of how matrix scaling critically affects Shampoo convergence. On the practical side, our GPU-aware implementation achieves up to $4.83\\times$ faster optimizer steps compared to the well-optimized Distributed Shampoo, while Newton-DB attains the lowest validation perplexity per iteration among all tested methods. Our code is available at https://github.com/IST-DASLab/DASH.",
      "source": "arXiv",
      "pubDateISO": "2026-02-02",
      "tags": [
        "cs.LG"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.02015v1",
      "title": "Robust Domain Generalization under Divergent Marginal and Conditional Distributions",
      "link": "http://arxiv.org/abs/2602.02015v1",
      "pdf_link": "https://arxiv.org/pdf/2602.02015v1",
      "authors": "Jewon Yeom, Kyubyung Chae, Hyunggyu Lim, Yoonna Oh, Dongyoon Yang et al.",
      "institution": "",
      "abstract": "Domain generalization (DG) aims to learn predictive models that can generalize to unseen domains. Most existing DG approaches focus on learning domain-invariant representations under the assumption of conditional distribution shift (i.e., primarily addressing changes in $P(X\\mid Y)$ while assuming $P(Y)$ remains stable). However, real-world scenarios with multiple domains often involve compound distribution shifts where both the marginal label distribution $P(Y)$ and the conditional distribution $P(X\\mid Y)$ vary simultaneously. To address this, we propose a unified framework for robust domain generalization under divergent marginal and conditional distributions. We derive a novel risk bound for unseen domains by explicitly decomposing the joint distribution into marginal and conditional components and characterizing risk gaps arising from both sources of divergence. To operationalize this bound, we design a meta-learning procedure that minimizes and validates the proposed risk bound across seen domains, ensuring strong generalization to unseen ones. Empirical evaluations demonstrate that our method achieves state-of-the-art performance not only on conventional DG benchmarks but also in challenging multi-domain long-tailed recognition settings where both marginal and conditional shifts are pronounced.",
      "source": "arXiv",
      "pubDateISO": "2026-02-02",
      "tags": [
        "cs.LG"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.02014v1",
      "title": "Rethinking Genomic Modeling Through Optical Character Recognition",
      "link": "http://arxiv.org/abs/2602.02014v1",
      "pdf_link": "https://arxiv.org/pdf/2602.02014v1",
      "authors": "Hongxin Xiang, Pengsen Ma, Yunkang Cao, Di Yu, Haowen Chen et al.",
      "institution": "",
      "abstract": "Recent genomic foundation models largely adopt large language model architectures that treat DNA as a one-dimensional token sequence. However, exhaustive sequential reading is structurally misaligned with sparse and discontinuous genomic semantics, leading to wasted computation on low-information background and preventing understanding-driven compression for long contexts. Here, we present OpticalDNA, a vision-based framework that reframes genomic modeling as Optical Character Recognition (OCR)-style document understanding. OpticalDNA renders DNA into structured visual layouts and trains an OCR-capable vision--language model with a \\emph{visual DNA encoder} and a \\emph{document decoder}, where the encoder produces compact, reconstructible visual tokens for high-fidelity compression. Building on this representation, OpticalDNA defines prompt-conditioned objectives over core genomic primitives-reading, region grounding, subsequence retrieval, and masked span completion-thereby learning layout-aware DNA representations that retain fine-grained genomic information under a reduced effective token budget. Across diverse genomic benchmarks, OpticalDNA consistently outperforms recent baselines; on sequences up to 450k bases, it achieves the best overall performance with nearly $20\\times$ fewer effective tokens, and surpasses models with up to $985\\times$ more activated parameters while tuning only 256k \\emph{trainable} parameters.",
      "source": "arXiv",
      "pubDateISO": "2026-02-02",
      "tags": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.02013v1",
      "title": "SNAP: A Self-Consistent Agreement Principle with Application to Robust Computation",
      "link": "http://arxiv.org/abs/2602.02013v1",
      "pdf_link": "https://arxiv.org/pdf/2602.02013v1",
      "authors": "Xiaoyi Jiang, Andreas Nienkötter",
      "institution": "",
      "abstract": "We introduce SNAP (Self-coNsistent Agreement Principle), a self-supervised framework for robust computation based on mutual agreement. Based on an Agreement-Reliability Hypothesis SNAP assigns weights that quantify agreement, emphasizing trustworthy items and downweighting outliers without supervision or prior knowledge. A key result is the Exponential Suppression of Outlier Weights, ensuring that outliers contribute negligibly to computations, even in high-dimensional settings. We study properties of SNAP weighting scheme and show its practical benefits on vector averaging and subspace estimation. Particularly, we demonstrate that non-iterative SNAP outperforms the iterative Weiszfeld algorithm and two variants of multivariate median of means. SNAP thus provides a flexible, easy-to-use, broadly applicable approach to robust computation.",
      "source": "arXiv",
      "pubDateISO": "2026-02-02",
      "tags": [
        "cs.LG",
        "stat.ML"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.02010v1",
      "title": "NEAT: Neuron-Based Early Exit for Large Reasoning Models",
      "link": "http://arxiv.org/abs/2602.02010v1",
      "pdf_link": "https://arxiv.org/pdf/2602.02010v1",
      "authors": "Kang Liu, Yongkang Liu, Xiaocui Yang, Peidong Wang, Wen Zhang et al.",
      "institution": "",
      "abstract": "Large Reasoning Models (LRMs) often suffer from \\emph{overthinking}, a phenomenon in which redundant reasoning steps are generated after a correct solution has already been reached. Existing early reasoning exit methods primarily rely on output-level heuristics or trained probing models to skip redundant reasoning steps, thereby mitigating overthinking. However, these approaches typically require additional rollout computation or externally labeled datasets. In this paper, we propose \\textbf{NEAT}, a \\textbf{N}euron-based \\textbf{E}arly re\\textbf{A}soning exi\\textbf{T} framework that monitors neuron-level activation dynamics to enable training-free early exits, without introducing additional test-time computation. NEAT identifies exit-associated neurons and tracks their activation patterns during reasoning to dynamically trigger early exit or suppress reflection, thereby reducing unnecessary reasoning while preserving solution quality. Experiments on four reasoning benchmarks across six models with different scales and architectures show that, for each model, NEAT achieves an average token reduction of 22\\% to 28\\% when averaged over the four benchmarks, while maintaining accuracy.",
      "source": "arXiv",
      "pubDateISO": "2026-02-02",
      "tags": [
        "cs.CL"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.02009v1",
      "title": "Logic-Guided Vector Fields for Constrained Generative Modeling",
      "link": "http://arxiv.org/abs/2602.02009v1",
      "pdf_link": "https://arxiv.org/pdf/2602.02009v1",
      "authors": "Ali Baheri",
      "institution": "",
      "abstract": "Neuro-symbolic systems aim to combine the expressive structure of symbolic logic with the flexibility of neural learning; yet, generative models typically lack mechanisms to enforce declarative constraints at generation time. We propose Logic-Guided Vector Fields (LGVF), a neuro-symbolic framework that injects symbolic knowledge, specified as differentiable relaxations of logical constraints, into flow matching generative models. LGVF couples two complementary mechanisms: (1) a training-time logic loss that penalizes constraint violations along continuous flow trajectories, with weights that emphasize correctness near the target distribution; and (2) an inference-time adjustment that steers sampling using constraint gradients, acting as a lightweight, logic-informed correction to the learned dynamics. We evaluate LGVF on three constrained generation case studies spanning linear, nonlinear, and multi-region feasibility constraints. Across all settings, LGVF reduces constraint violations by 59-82% compared to standard flow matching and achieves the lowest violation rates in each case. In the linear and ring settings, LGVF also improves distributional fidelity as measured by MMD, while in the multi-obstacle setting, we observe a satisfaction-fidelity trade-off, with improved feasibility but increased MMD. Beyond quantitative gains, LGVF yields constraint-aware vector fields exhibiting emergent obstacle-avoidance behavior, routing samples around forbidden regions without explicit path planning.",
      "source": "arXiv",
      "pubDateISO": "2026-02-02",
      "tags": [
        "cs.LG"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.02007v1",
      "title": "Beyond RAG for Agent Memory: Retrieval by Decoupling and Aggregation",
      "link": "http://arxiv.org/abs/2602.02007v1",
      "pdf_link": "https://arxiv.org/pdf/2602.02007v1",
      "authors": "Zhanghao Hu, Qinglin Zhu, Hanqi Yan, Yulan He, Lin Gui",
      "institution": "",
      "abstract": "Agent memory systems often adopt the standard Retrieval-Augmented Generation (RAG) pipeline, yet its underlying assumptions differ in this setting. RAG targets large, heterogeneous corpora where retrieved passages are diverse, whereas agent memory is a bounded, coherent dialogue stream with highly correlated spans that are often duplicates. Under this shift, fixed top-$k$ similarity retrieval tends to return redundant context, and post-hoc pruning can delete temporally linked prerequisites needed for correct reasoning. We argue retrieval should move beyond similarity matching and instead operate over latent components, following decoupling to aggregation: disentangle memories into semantic components, organise them into a hierarchy, and use this structure to drive retrieval. We propose xMemory, which builds a hierarchy of intact units and maintains a searchable yet faithful high-level node organisation via a sparsity--semantics objective that guides memory split and merge. At inference, xMemory retrieves top-down, selecting a compact, diverse set of themes and semantics for multi-fact queries, and expanding to episodes and raw messages only when it reduces the reader's uncertainty. Experiments on LoCoMo and PerLTQA across the three latest LLMs show consistent gains in answer quality and token efficiency.",
      "source": "arXiv",
      "pubDateISO": "2026-02-02",
      "tags": [
        "cs.CL",
        "cs.AI"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.02005v1",
      "title": "Position: The Need for Ultrafast Training",
      "link": "http://arxiv.org/abs/2602.02005v1",
      "pdf_link": "https://arxiv.org/pdf/2602.02005v1",
      "authors": "Duc Hoang",
      "institution": "",
      "abstract": "Domain-specialized FPGAs have delivered unprecedented performance for low-latency inference across scientific and industrial workloads, yet nearly all existing accelerators assume static models trained offline, relegating learning and adaptation to slower CPUs or GPUs. This separation fundamentally limits systems that must operate in non-stationary, high-frequency environments, where model updates must occur at the timescale of the underlying physics. In this paper, I argue for a shift from inference-only accelerators to ultrafast on-chip learning, in which both inference and training execute directly within the FPGA fabric under deterministic, sub-microsecond latency constraints. Bringing learning into the same real-time datapath as inference would enable closed-loop systems that adapt as fast as the physical processes they control, with applications spanning quantum error correction, cryogenic qubit calibration, plasma and fusion control, accelerator tuning, and autonomous scientific experiments. Enabling such regimes requires rethinking algorithms, architectures, and toolflows jointly, but promises to transform FPGAs from static inference engines into real-time learning machines.",
      "source": "arXiv",
      "pubDateISO": "2026-02-02",
      "tags": [
        "cs.AR",
        "cs.LG"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.02004v1",
      "title": "ClueTracer: Question-to-Vision Clue Tracing for Training-Free Hallucination Suppression in Multimodal Reasoning",
      "link": "http://arxiv.org/abs/2602.02004v1",
      "pdf_link": "https://arxiv.org/pdf/2602.02004v1",
      "authors": "Gongli Xi, Kun Wang, Zeming Gao, Huahui Yi, Haolang Lu et al.",
      "institution": "",
      "abstract": "Large multimodal reasoning models solve challenging visual problems via explicit long-chain inference: they gather visual clues from images and decode clues into textual tokens. Yet this capability also increases hallucinations, where the model generates content that is not supported by the input image or the question. To understand this failure mode, we identify \\emph{reasoning drift}: during clue gathering, the model over-focuses on question-irrelevant entities, diluting focus on task-relevant cues and gradually decoupling the reasoning trace from visual grounding. As a consequence, many inference-time localization or intervention methods developed for non-reasoning models fail to pinpoint the true clues in reasoning settings. Motivated by these insights, we introduce ClueRecall, a metric for assessing visual clue retrieval, and present ClueTracer, a training-free, parameter-free, and architecture-agnostic plugin for hallucination suppression. ClueTracer starts from the question and traces how key clues propagate along the model's reasoning pathway (question $\\rightarrow$ outputs $\\rightarrow$ visual tokens), thereby localizing task-relevant patches while suppressing spurious attention to irrelevant regions. Remarkably, \\textbf{without any additional training}, ClueTracer improves all \\textbf{reasoning} architectures (including \\texttt{R1-OneVision}, \\texttt{Ocean-R1}, \\texttt{MM-Eureka}, \\emph{etc}.) by $\\mathbf{1.21\\times}$ on reasoning benchmarks. When transferred to \\textbf{non-reasoning} settings, it yields a $\\mathbf{1.14\\times}$ gain.",
      "source": "arXiv",
      "pubDateISO": "2026-02-02",
      "tags": [
        "cs.CV",
        "cs.AI"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.02002v1",
      "title": "UniDriveDreamer: A Single-Stage Multimodal World Model for Autonomous Driving",
      "link": "http://arxiv.org/abs/2602.02002v1",
      "pdf_link": "https://arxiv.org/pdf/2602.02002v1",
      "authors": "Guosheng Zhao, Yaozeng Wang, Xiaofeng Wang, Zheng Zhu, Tingdong Yu et al.",
      "institution": "",
      "abstract": "World models have demonstrated significant promise for data synthesis in autonomous driving. However, existing methods predominantly concentrate on single-modality generation, typically focusing on either multi-camera video or LiDAR sequence synthesis. In this paper, we propose UniDriveDreamer, a single-stage unified multimodal world model for autonomous driving, which directly generates multimodal future observations without relying on intermediate representations or cascaded modules. Our framework introduces a LiDAR-specific variational autoencoder (VAE) designed to encode input LiDAR sequences, alongside a video VAE for multi-camera images. To ensure cross-modal compatibility and training stability, we propose Unified Latent Anchoring (ULA), which explicitly aligns the latent distributions of the two modalities. The aligned features are fused and processed by a diffusion transformer that jointly models their geometric correspondence and temporal evolution. Additionally, structured scene layout information is projected per modality as a conditioning signal to guide the synthesis. Extensive experiments demonstrate that UniDriveDreamer outperforms previous state-of-the-art methods in both video and LiDAR generation, while also yielding measurable improvements in downstream",
      "source": "arXiv",
      "pubDateISO": "2026-02-02",
      "tags": [
        "cs.CV"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.02001v1",
      "title": "Preserve-Then-Quantize: Balancing Rank Budgets for Quantization Error Reconstruction in LLMs",
      "link": "http://arxiv.org/abs/2602.02001v1",
      "pdf_link": "https://arxiv.org/pdf/2602.02001v1",
      "authors": "Yoonjun Cho, Dongjae Jeon, Soeun Kim, Moongyu Jeon, Albert No",
      "institution": "",
      "abstract": "Quantization Error Reconstruction (QER) reduces accuracy loss in Post-Training Quantization (PTQ) by approximating weights as $\\mathbf{W} \\approx \\mathbf{Q} + \\mathbf{L}\\mathbf{R}$, using a rank-$r$ correction to reconstruct quantization error. Prior methods devote the full rank budget to error reconstruction, which is suboptimal when $\\mathbf{W}$ has intrinsic low-rank structure and quantization corrupts dominant directions. We propose Structured Residual Reconstruction (SRR), a rank-allocation framework that preserves the top-$k$ singular subspace of the activation-scaled weight before quantization, quantizes only the residual, and uses the remaining rank $r-k$ for error reconstruction. We derive a theory-guided criterion for selecting $k$ by balancing quantization-exposed energy and unrecoverable error under rank constraints. We further show that resulting $\\mathbf{Q} + \\mathbf{L}\\mathbf{R}$ parameterization naturally supports Quantized Parameter-Efficient Fine-Tuning (QPEFT), and stabilizes fine-tuning via gradient scaling along preserved directions. Experiments demonstrate consistent perplexity reductions across diverse models and quantization settings in PTQ, along with a 5.9 percentage-point average gain on GLUE under 2-bit QPEFT.",
      "source": "arXiv",
      "pubDateISO": "2026-02-02",
      "tags": [
        "cs.LG",
        "cs.AI"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.02000v1",
      "title": "SurfSplat: Conquering Feedforward 2D Gaussian Splatting with Surface Continuity Priors",
      "link": "http://arxiv.org/abs/2602.02000v1",
      "pdf_link": "https://arxiv.org/pdf/2602.02000v1",
      "authors": "Bing He, Jingnan Gao, Yunuo Chen, Ning Cao, Gang Chen et al.",
      "institution": "",
      "abstract": "Reconstructing 3D scenes from sparse images remains a challenging task due to the difficulty of recovering accurate geometry and texture without optimization. Recent approaches leverage generalizable models to generate 3D scenes using 3D Gaussian Splatting (3DGS) primitive. However, they often fail to produce continuous surfaces and instead yield discrete, color-biased point clouds that appear plausible at normal resolution but reveal severe artifacts under close-up views. To address this issue, we present SurfSplat, a feedforward framework based on 2D Gaussian Splatting (2DGS) primitive, which provides stronger anisotropy and higher geometric precision. By incorporating a surface continuity prior and a forced alpha blending strategy, SurfSplat reconstructs coherent geometry together with faithful textures. Furthermore, we introduce High-Resolution Rendering Consistency (HRRC), a new evaluation metric designed to evaluate high-resolution reconstruction quality. Extensive experiments on RealEstate10K, DL3DV, and ScanNet demonstrate that SurfSplat consistently outperforms prior methods on both standard metrics and HRRC, establishing a robust solution for high-fidelity 3D reconstruction from sparse inputs. Project page: https://hebing-sjtu.github.io/SurfSplat-website/",
      "source": "arXiv",
      "pubDateISO": "2026-02-02",
      "tags": [
        "cs.CV",
        "cs.AI"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.01999v1",
      "title": "From Latent Signals to Reflection Behavior: Tracing Meta-Cognitive Activation Trajectory in R1-Style LLMs",
      "link": "http://arxiv.org/abs/2602.01999v1",
      "pdf_link": "https://arxiv.org/pdf/2602.01999v1",
      "authors": "Yanrui Du, Yibo Gao, Sendong Zhao, Jiayun Li, Haochun Wang et al.",
      "institution": "",
      "abstract": "R1-style LLMs have attracted growing attention for their capacity for self-reflection, yet the internal mechanisms underlying such behavior remain unclear. To bridge this gap, we anchor on the onset of reflection behavior and trace its layer-wise activation trajectory. Using the logit lens to read out token-level semantics, we uncover a structured progression: (i) Latent-control layers, where an approximate linear direction encodes the semantics of thinking budget; (ii) Semantic-pivot layers, where discourse-level cues, including turning-point and summarization cues, surface and dominate the probability mass; and (iii) Behavior-overt layers, where the likelihood of reflection-behavior tokens begins to rise until they become highly likely to be sampled. Moreover, our targeted interventions uncover a causal chain across these stages: prompt-level semantics modulate the projection of activations along latent-control directions, thereby inducing competition between turning-point and summarization cues in semantic-pivot layers, which in turn regulates the sampling likelihood of reflection-behavior tokens in behavior-overt layers. Collectively, our findings suggest a human-like meta-cognitive process-progressing from latent monitoring, to discourse-level regulation, and to finally overt self-reflection. Our analysis code can be found at https://github.com/DYR1/S3-CoT.",
      "source": "arXiv",
      "pubDateISO": "2026-02-02",
      "tags": [
        "cs.CL"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.01997v1",
      "title": "On the Limits of Layer Pruning for Generative Reasoning in LLMs",
      "link": "http://arxiv.org/abs/2602.01997v1",
      "pdf_link": "https://arxiv.org/pdf/2602.01997v1",
      "authors": "Safal Shrestha, Anubhav Shrestha, Aadim Nepal, Minwu Kim, Keith Ross",
      "institution": "",
      "abstract": "Recent works have shown that layer pruning can compress large language models (LLMs) while retaining strong performance on classification benchmarks with little or no finetuning. However, existing pruning techniques often suffer severe degradation on generative reasoning tasks. Through a systematic study across multiple model families, we find that tasks requiring multi-step reasoning are particularly sensitive to depth reduction. Beyond surface-level text degeneration, we observe degradation of critical algorithmic capabilities, including arithmetic computation for mathematical reasoning and balanced parenthesis generation for code synthesis. Under realistic post-training constraints, without access to pretraining-scale data or compute, we evaluate a simple mitigation strategy based on supervised finetuning with Self-Generated Responses. This approach achieves strong recovery on classification tasks, retaining up to 90\\% of baseline performance, and yields substantial gains of up to 20--30 percentage points on generative benchmarks compared to prior post-pruning techniques. Crucially, despite these gains, recovery for generative reasoning remains fundamentally limited relative to classification tasks and is viable primarily at lower pruning ratios. Overall, we characterize the practical limits of layer pruning for generative reasoning and provide guidance on when depth reduction can be applied effectively under constrained post-training regimes.",
      "source": "arXiv",
      "pubDateISO": "2026-02-02",
      "tags": [
        "cs.LG",
        "cs.AI"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.01995v1",
      "title": "Thinking Like a Doctor: Conversational Diagnosis through the Exploration of Diagnostic Knowledge Graphs",
      "link": "http://arxiv.org/abs/2602.01995v1",
      "pdf_link": "https://arxiv.org/pdf/2602.01995v1",
      "authors": "Jeongmoon Won, Seungwon Kook, Yohan Jo",
      "institution": "",
      "abstract": "Conversational diagnosis requires multi-turn history-taking, where an agent asks clarifying questions to refine differential diagnoses under incomplete information. Existing approaches often rely on the parametric knowledge of a model or assume that patients provide rich and concrete information, which is unrealistic. To address these limitations, we propose a conversational diagnosis system that explores a diagnostic knowledge graph to reason in two steps: (i) generating diagnostic hypotheses from the dialogue context, and (ii) verifying hypotheses through clarifying questions, which are repeated until a final diagnosis is reached. Since evaluating the system requires a realistic patient simulator that responds to the system's questions, we adopt a well-established simulator along with patient profiles from MIMIC-IV. We further adapt it to describe symptoms vaguely to reflect real-world patients during early clinical encounters. Experiments show improved diagnostic accuracy and efficiency over strong baselines, and evaluations by physicians support the realism of our simulator and the clinical utility of the generated questions. Our code will be released upon publication.",
      "source": "arXiv",
      "pubDateISO": "2026-02-02",
      "tags": [
        "cs.AI"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.01996v1",
      "title": "Optimizing Tensor Train Decomposition in DNNs for RISC-V Architectures Using Design Space Exploration and Compiler Optimizations",
      "link": "http://arxiv.org/abs/2602.01996v1",
      "pdf_link": "https://arxiv.org/pdf/2602.01996v1",
      "authors": "Theologos Anthimopoulos, Milad Kokhazadeh, Vasilios Kelefouras, Benjamin Himpel, Georgios Keramidas",
      "institution": "Mila",
      "abstract": "Deep neural networks (DNNs) have become indispensable in many real-life applications like natural language processing, and autonomous systems. However, deploying DNNs on resource-constrained devices, e.g., in RISC-V platforms, remains challenging due to the high computational and memory demands of fully connected (FC) layers, which dominate resource consumption. Low-rank factorization (LRF) offers an effective approach to compressing FC layers, but the vast design space of LRF solutions involves complex trade-offs among FLOPs, memory size, inference time, and accuracy, making the LRF process complex and time-consuming. This paper introduces an end-to-end LRF design space exploration methodology and a specialized design tool for optimizing FC layers on RISC-V processors. Using Tensor Train Decomposition (TTD) offered by TensorFlow T3F library, the proposed work prunes the LRF design space by excluding first, inefficient decomposition shapes and second, solutions with poor inference performance on RISC-V architectures. Compiler optimizations are then applied to enhance custom T3F layer performance, minimizing inference time and boosting computational efficiency. On average, our TT-decomposed layers run 3x faster than IREE and 8x faster than Pluto on the same compressed model. This work provides an efficient solution for deploying DNNs on edge and embedded devices powered by RISC-V architectures.",
      "source": "arXiv",
      "pubDateISO": "2026-02-02",
      "tags": [
        "cs.LG",
        "cs.AI",
        "cs.AR",
        "cs.MS"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.01992v1",
      "title": "Emergent Analogical Reasoning in Transformers",
      "link": "http://arxiv.org/abs/2602.01992v1",
      "pdf_link": "https://arxiv.org/pdf/2602.01992v1",
      "authors": "Gouki Minegishi, Jingyuan Feng, Hiroki Furuta, Takeshi Kojima, Yusuke Iwasawa et al.",
      "institution": "",
      "abstract": "Analogy is a central faculty of human intelligence, enabling abstract patterns discovered in one domain to be applied to another. Despite its central role in cognition, the mechanisms by which Transformers acquire and implement analogical reasoning remain poorly understood. In this work, inspired by the notion of functors in category theory, we formalize analogical reasoning as the inference of correspondences between entities across categories. Based on this formulation, we introduce synthetic tasks that evaluate the emergence of analogical reasoning under controlled settings. We find that the emergence of analogical reasoning is highly sensitive to data characteristics, optimization choices, and model scale. Through mechanistic analysis, we show that analogical reasoning in Transformers decomposes into two key components: (1) geometric alignment of relational structure in the embedding space, and (2) the application of a functor within the Transformer. These mechanisms enable models to transfer relational structure from one category to another, realizing analogy. Finally, we quantify these effects and find that the same trends are observed in pretrained LLMs. In doing so, we move analogy from an abstract cognitive notion to a concrete, mechanistically grounded phenomenon in modern neural networks.",
      "source": "arXiv",
      "pubDateISO": "2026-02-02",
      "tags": [
        "cs.AI"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.01991v1",
      "title": "Leveraging Latent Vector Prediction for Localized Control in Image Generation via Diffusion Models",
      "link": "http://arxiv.org/abs/2602.01991v1",
      "pdf_link": "https://arxiv.org/pdf/2602.01991v1",
      "authors": "Pablo Domingo-Gregorio, Javier Ruiz-Hidalgo",
      "institution": "",
      "abstract": "Diffusion models emerged as a leading approach in text-to-image generation, producing high-quality images from textual descriptions. However, attempting to achieve detailed control to get a desired image solely through text remains a laborious trial-and-error endeavor. Recent methods have introduced image-level controls alongside with text prompts, using prior images to extract conditional information such as edges, segmentation and depth maps. While effective, these methods apply conditions uniformly across the entire image, limiting localized control. In this paper, we propose a novel methodology to enable precise local control over user-defined regions of an image, while leaving to the diffusion model the task of autonomously generating the remaining areas according to the original prompt. Our approach introduces a new training framework that incorporates masking features and an additional loss term, which leverages the prediction of the initial latent vector at any diffusion step to enhance the correspondence between the current step and the final sample in the latent space. Extensive experiments demonstrate that our method effectively synthesizes high-quality images with controlled local conditions.",
      "source": "arXiv",
      "pubDateISO": "2026-02-02",
      "tags": [
        "cs.CV"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.01990v1",
      "title": "SAME: Stabilized Mixture-of-Experts for Multimodal Continual Instruction Tuning",
      "link": "http://arxiv.org/abs/2602.01990v1",
      "pdf_link": "https://arxiv.org/pdf/2602.01990v1",
      "authors": "Zhen-Hao Xie, Jun-Tao Tang, Yu-Cheng Shi, Han-Jia Ye, De-Chuan Zhan et al.",
      "institution": "",
      "abstract": "Multimodal Large Language Models (MLLMs) achieve strong performance through instruction tuning, but real-world deployment requires them to continually expand their capabilities, making Multimodal Continual Instruction Tuning (MCIT) essential. Recent methods leverage sparse expert routing to promote task specialization, but we find that the expert routing process suffers from drift as the data distribution evolves. For example, a grounding query that previously activated localization experts may instead be routed to irrelevant experts after learning OCR tasks. Meanwhile, the grounding-related experts can be overwritten by new tasks and lose their original functionality. Such failure reflects two problems: router drift, where expert selection becomes inconsistent over time, and expert drift, where shared experts are overwritten across tasks. Therefore, we propose StAbilized Mixture-of-Experts (SAME) for MCIT. To address router drift, SAME stabilizes expert selection by decomposing routing dynamics into orthogonal subspaces and updating only task-relevant directions. To mitigate expert drift, we regulate expert updates via curvature-aware scaling using historical input covariance in a rehearsal-free manner. SAME also introduces adaptive expert activation to freeze selected experts during training, reducing redundant computation and cross-task interference. Extensive experiments demonstrate its SOTA performance.",
      "source": "arXiv",
      "pubDateISO": "2026-02-02",
      "tags": [
        "cs.LG",
        "cs.AI"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.01988v1",
      "title": "Stochastic Interpolants in Hilbert Spaces",
      "link": "http://arxiv.org/abs/2602.01988v1",
      "pdf_link": "https://arxiv.org/pdf/2602.01988v1",
      "authors": "James Boran Yu, RuiKang OuYang, Julien Horwood, José Miguel Hernández-Lobato",
      "institution": "",
      "abstract": "Although diffusion models have successfully extended to function-valued data, stochastic interpolants -- which offer a flexible way to bridge arbitrary distributions -- remain limited to finite-dimensional settings. This work bridges this gap by establishing a rigorous framework for stochastic interpolants in infinite-dimensional Hilbert spaces. We provide comprehensive theoretical foundations, including proofs of well-posedness and explicit error bounds. We demonstrate the effectiveness of the proposed framework for conditional generation, focusing particularly on complex PDE-based benchmarks. By enabling generative bridges between arbitrary functional distributions, our approach achieves state-of-the-art results, offering a powerful, general-purpose tool for scientific discovery.",
      "source": "arXiv",
      "pubDateISO": "2026-02-02",
      "tags": [
        "stat.ML",
        "cs.LG"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.01984v1",
      "title": "Enhancing Multi-Image Understanding through Delimiter Token Scaling",
      "link": "http://arxiv.org/abs/2602.01984v1",
      "pdf_link": "https://arxiv.org/pdf/2602.01984v1",
      "authors": "Minyoung Lee, Yeji Park, Dongjun Hwang, Yejin Kim, Seong Joon Oh et al.",
      "institution": "",
      "abstract": "Large Vision-Language Models (LVLMs) achieve strong performance on single-image tasks, but their performance declines when multiple images are provided as input. One major reason is the cross-image information leakage, where the model struggles to distinguish information across different images. Existing LVLMs already employ delimiter tokens to mark the start and end of each image, yet our analysis reveals that these tokens fail to effectively block cross-image information leakage. To enhance their effectiveness, we propose a method that scales the hidden states of delimiter tokens. This enhances the model's ability to preserve image-specific information by reinforcing intra-image interaction and limiting undesired cross-image interactions. Consequently, the model is better able to distinguish between images and reason over them more accurately. Experiments show performance gains on multi-image benchmarks such as Mantis, MuirBench, MIRB, and QBench2. We further evaluate our method on text-only tasks that require clear distinction. The method improves performance on multi-document and multi-table understanding benchmarks, including TQABench, MultiNews, and WCEP-10. Notably, our method requires no additional training or inference cost.",
      "source": "arXiv",
      "pubDateISO": "2026-02-02",
      "tags": [
        "cs.CV"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.01983v1",
      "title": "Evolving from Tool User to Creator via Training-Free Experience Reuse in Multimodal Reasoning",
      "link": "http://arxiv.org/abs/2602.01983v1",
      "pdf_link": "https://arxiv.org/pdf/2602.01983v1",
      "authors": "Xintian Shen, Jiawei Chen, Lihao Zheng, Hao Ma, Tao Wei et al.",
      "institution": "",
      "abstract": "Existing Tool-Integrated Reasoning (TIR) models have effectively extended the question-answering capabilities of LLMs by incorporating external tools. However, real-world scenarios present numerous open-ended problems where fixed tools often fail to meet task requirements. Furthermore, the lack of self-optimization mechanisms means that erroneous tool outputs can mislead the LLM's responses. Additionally, the construction of existing tools entails significant manual effort, which consequently constrains their applicability. Recognizing that the reasoning traces of LLMs encapsulate implicit problem-solving capabilities, we propose UCT, a novel training-free framework that transforms agents from tool users to tool creators. This approach harvests reasoning experiences and distills them into reusable assets. This method transforms the agent from a mere tool user into a tool creator, enabling adaptive tool creation and self-updating during the inference process. We also introduce a memory consolidation mechanism to maintain the tool library, ensuring high reusability of retained experiential memory for subsequent reasoning tasks. This novel automated tool construction paradigm continuously improves tool quality during reasoning, allowing the overall agent system to progress without additional training. Extensive experiments demonstrate that our method serves as a novel paradigm for enhancing the capabilities of TIR models. In particular, the significant performance gains achieved +20.86%$\\uparrow$ and +23.04%$\\uparrow$ on benchmarks across multi-domain mathematical and scientific reasoning tasks validate the self-evolving capability of the agent.",
      "source": "arXiv",
      "pubDateISO": "2026-02-02",
      "tags": [
        "cs.AI"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.01982v1",
      "title": "S3-CoT: Self-Sampled Succinct Reasoning Enables Efficient Chain-of-Thought LLMs",
      "link": "http://arxiv.org/abs/2602.01982v1",
      "pdf_link": "https://arxiv.org/pdf/2602.01982v1",
      "authors": "Yanrui Du, Sendong Zhao, Yibo Gao, Danyang Zhao, Qika Lin et al.",
      "institution": "",
      "abstract": "Large language models (LLMs) equipped with chain-of-thought (CoT) achieve strong performance and offer a window into LLM behavior. However, recent evidence suggests that improvements in CoT capabilities often come with redundant reasoning processes, motivating a key question: Can LLMs acquire a fast-thinking mode analogous to human System 1 reasoning? To explore this, our study presents a self-sampling framework based on activation steering for efficient CoT learning. Our method can induce style-aligned and variable-length reasoning traces from target LLMs themselves without any teacher guidance, thereby alleviating a central bottleneck of SFT-based methods-the scarcity of high-quality supervision data. Using filtered data by gold answers, we perform SFT for efficient CoT learning with (i) a human-like dual-cognitive system, and (ii) a progressive compression curriculum. Furthermore, we explore a self-evolution regime in which SFT is driven solely by prediction-consistent data of variable-length variants, eliminating the need for gold answers. Extensive experiments on math benchmarks, together with cross-domain generalization tests in medicine, show that our method yields stable improvements for both general and R1-style LLMs. Our data and model checkpoints can be found at https://github.com/DYR1/S3-CoT.",
      "source": "arXiv",
      "pubDateISO": "2026-02-02",
      "tags": [
        "cs.CL"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.01978v1",
      "title": "SpikingGamma: Surrogate-Gradient Free and Temporally Precise Online Training of Spiking Neural Networks with Smoothed Delays",
      "link": "http://arxiv.org/abs/2602.01978v1",
      "pdf_link": "https://arxiv.org/pdf/2602.01978v1",
      "authors": "Roel Koopman, Sebastian Otte, Sander Bohté",
      "institution": "",
      "abstract": "Neuromorphic hardware implementations of Spiking Neural Networks (SNNs) promise energy-efficient, low-latency AI through sparse, event-driven computation. Yet, training SNNs under fine temporal discretization remains a major challenge, hindering both low-latency responsiveness and the mapping of software-trained SNNs to efficient hardware. In current approaches, spiking neurons are modeled as self-recurrent units, embedded into recurrent networks to maintain state over time, and trained with BPTT or RTRL variants based on surrogate gradients. These methods scale poorly with temporal resolution, while online approximations often exhibit instability for long sequences and tend to fail at capturing temporal patterns precisely. To address these limitations, we develop spiking neurons with internal recursive memory structures that we combine with sigma-delta spike-coding. We show that this SpikingGamma model supports direct error backpropagation without surrogate gradients, can learn fine temporal patterns with minimal spiking in an online manner, and scale feedforward SNNs to complex tasks and benchmarks with competitive accuracy, all while being insensitive to the temporal resolution of the model. Our approach offers both an alternative to current recurrent SNNs trained with surrogate gradients, and a direct route for mapping SNNs to neuromorphic hardware.",
      "source": "arXiv",
      "pubDateISO": "2026-02-02",
      "tags": [
        "cs.NE",
        "cs.LG"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.01977v1",
      "title": "Beyond Local Edits: Embedding-Virtualized Knowledge for Broader Evaluation and Preservation of Model Editing",
      "link": "http://arxiv.org/abs/2602.01977v1",
      "pdf_link": "https://arxiv.org/pdf/2602.01977v1",
      "authors": "Shuainan Liu, Xuanang Chen, Ben He, Le Sun",
      "institution": "",
      "abstract": "Knowledge editing methods for large language models are commonly evaluated using predefined benchmarks that assess edited facts together with a limited set of related or neighboring knowledge. While effective, such evaluations remain confined to finite, dataset-bounded samples, leaving the broader impact of editing on the model's knowledge system insufficiently understood. To address this gap, we introduce Embedding-Virtualized Knowledge (EVK) that characterizes model knowledge through controlled perturbations in embedding space, enabling the exploration of a substantially broader and virtualized knowledge region beyond explicit data annotations. Based on EVK, we construct an embedding-level evaluation benchmark EVK-Bench that quantifies potential knowledge drift induced by editing, revealing effects that are not captured by conventional sample-based metrics. Furthermore, we propose a plug-and-play EVK-Align module that constrains embedding-level knowledge drift during editing and can be seamlessly integrated into existing editing methods. Experiments demonstrate that our approach enables more comprehensive evaluation while significantly improving knowledge preservation without sacrificing editing accuracy.",
      "source": "arXiv",
      "pubDateISO": "2026-02-02",
      "tags": [
        "cs.CL"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.01976v1",
      "title": "FlyPrompt: Brain-Inspired Random-Expanded Routing with Temporal-Ensemble Experts for General Continual Learning",
      "link": "http://arxiv.org/abs/2602.01976v1",
      "pdf_link": "https://arxiv.org/pdf/2602.01976v1",
      "authors": "Hongwei Yan, Guanglong Sun, Kanglei Zhou, Qian Li, Liyuan Wang et al.",
      "institution": "",
      "abstract": "General continual learning (GCL) challenges intelligent systems to learn from single-pass, non-stationary data streams without clear task boundaries. While recent advances in continual parameter-efficient tuning (PET) of pretrained models show promise, they typically rely on multiple training epochs and explicit task cues, limiting their effectiveness in GCL scenarios. Moreover, existing methods often lack targeted design and fail to address two fundamental challenges in continual PET: how to allocate expert parameters to evolving data distributions, and how to improve their representational capacity under limited supervision. Inspired by the fruit fly's hierarchical memory system characterized by sparse expansion and modular ensembles, we propose FlyPrompt, a brain-inspired framework that decomposes GCL into two subproblems: expert routing and expert competence improvement. FlyPrompt introduces a randomly expanded analytic router for instance-level expert activation and a temporal ensemble of output heads to dynamically adapt decision boundaries over time. Extensive theoretical and empirical evaluations demonstrate FlyPrompt's superior performance, achieving up to 11.23%, 12.43%, and 7.62% gains over state-of-the-art baselines on CIFAR-100, ImageNet-R, and CUB-200, respectively. Our source code is available at https://github.com/AnAppleCore/FlyGCL.",
      "source": "arXiv",
      "pubDateISO": "2026-02-02",
      "tags": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.01975v1",
      "title": "IntraSlice: Towards High-Performance Structural Pruning with Block-Intra PCA for LLMs",
      "link": "http://arxiv.org/abs/2602.01975v1",
      "pdf_link": "https://arxiv.org/pdf/2602.01975v1",
      "authors": "Meng Li, Peisong Wang, Yuantian Shao, Qinghao Hu, Hongjian Fang et al.",
      "institution": "",
      "abstract": "Large Language Models (LLMs) achieve strong performance across diverse tasks but face deployment challenges due to their massive size. Structured pruning offers acceleration benefits but leads to significant performance degradation. Recent PCA-based pruning methods have alleviated this issue by retaining key activation components, but are only applied between modules in order to fuse the transformation matrix, which introduces extra parameters and severely disrupts activation distributions due to residual connections. To address these issues, we propose IntraSlice, a framework that applies block-wise module-intra PCA compression pruning. By leveraging the structural characteristics of Transformer modules, we design an approximate PCA method whose transformation matrices can be fully fused into the model without additional parameters. We also introduce a PCA-based global pruning ratio estimator that further considers the distribution of compressed activations, building on conventional module importance. We validate our method on Llama2, Llama3, and Phi series across various language benchmarks. Experimental results demonstrate that our approach achieves superior compression performance compared to recent baselines at the same compression ratio or inference speed.",
      "source": "arXiv",
      "pubDateISO": "2026-02-02",
      "tags": [
        "cs.LG",
        "cs.AI"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.01973v1",
      "title": "Your AI-Generated Image Detector Can Secretly Achieve SOTA Accuracy, If Calibrated",
      "link": "http://arxiv.org/abs/2602.01973v1",
      "pdf_link": "https://arxiv.org/pdf/2602.01973v1",
      "authors": "Muli Yang, Gabriel James Goenawan, Henan Wang, Huaiyuan Qin, Chenghao Xu et al.",
      "institution": "",
      "abstract": "Despite being trained on balanced datasets, existing AI-generated image detectors often exhibit systematic bias at test time, frequently misclassifying fake images as real. We hypothesize that this behavior stems from distributional shift in fake samples and implicit priors learned during training. Specifically, models tend to overfit to superficial artifacts that do not generalize well across different generation methods, leading to a misaligned decision threshold when faced with test-time distribution shift. To address this, we propose a theoretically grounded post-hoc calibration framework based on Bayesian decision theory. In particular, we introduce a learnable scalar correction to the model's logits, optimized on a small validation set from the target distribution while keeping the backbone frozen. This parametric adjustment compensates for distributional shift in model output, realigning the decision boundary even without requiring ground-truth labels. Experiments on challenging benchmarks show that our approach significantly improves robustness without retraining, offering a lightweight and principled solution for reliable and adaptive AI-generated image detection in the open world. Code is available at https://github.com/muliyangm/AIGI-Det-Calib.",
      "source": "arXiv",
      "pubDateISO": "2026-02-02",
      "tags": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.01970v1",
      "title": "Small Generalizable Prompt Predictive Models Can Steer Efficient RL Post-Training of Large Reasoning Models",
      "link": "http://arxiv.org/abs/2602.01970v1",
      "pdf_link": "https://arxiv.org/pdf/2602.01970v1",
      "authors": "Yun Qu, Qi Wang, Yixiu Mao, Heming Zou, Yuhang Jiang et al.",
      "institution": "",
      "abstract": "Reinforcement learning enhances the reasoning capabilities of large language models but often involves high computational costs due to rollout-intensive optimization. Online prompt selection presents a plausible solution by prioritizing informative prompts to improve training efficiency. However, current methods either depend on costly, exact evaluations or construct prompt-specific predictive models lacking generalization across prompts. This study introduces Generalizable Predictive Prompt Selection (GPS), which performs Bayesian inference towards prompt difficulty using a lightweight generative model trained on the shared optimization history. Intermediate-difficulty prioritization and history-anchored diversity are incorporated into the batch acquisition principle to select informative prompt batches. The small predictive model also generalizes at test-time for efficient computational allocation. Experiments across varied reasoning benchmarks indicate GPS's substantial improvements in training efficiency, final performance, and test-time efficiency over superior baseline methods.",
      "source": "arXiv",
      "pubDateISO": "2026-02-02",
      "tags": [
        "cs.AI",
        "cs.LG"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.01969v1",
      "title": "Orthogonal Hierarchical Decomposition for Structure-Aware Table Understanding with Large Language Models",
      "link": "http://arxiv.org/abs/2602.01969v1",
      "pdf_link": "https://arxiv.org/pdf/2602.01969v1",
      "authors": "Bin Cao, Huixian Lu, Chenwen Ma, Ting Wang, Ruizhe Li et al.",
      "institution": "",
      "abstract": "Complex tables with multi-level headers, merged cells and heterogeneous layouts pose persistent challenges for LLMs in both understanding and reasoning. Existing approaches typically rely on table linearization or normalized grid modeling. However, these representations struggle to explicitly capture hierarchical structures and cross-dimensional dependencies, which can lead to misalignment between structural semantics and textual representations for non-standard tables. To address this issue, we propose an Orthogonal Hierarchical Decomposition (OHD) framework that constructs structure-preserving input representations of complex tables for LLMs. OHD introduces an Orthogonal Tree Induction (OTI) method based on spatial--semantic co-constraints, which decomposes irregular tables into a column tree and a row tree to capture vertical and horizontal hierarchical dependencies, respectively. Building on this representation, we design a dual-pathway association protocol to symmetrically reconstruct semantic lineage of each cell, and incorporate an LLM as a semantic arbitrator to align multi-level semantic information. We evaluate OHD framework on two complex table question answering benchmarks, AITQA and HiTab. Experimental results show that OHD consistently outperforms existing representation paradigms across multiple evaluation metrics.",
      "source": "arXiv",
      "pubDateISO": "2026-02-02",
      "tags": [
        "cs.CL",
        "cs.IR"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.01967v1",
      "title": "Mixture-of-Experts with Intermediate CTC Supervision for Accented Speech Recognition",
      "link": "http://arxiv.org/abs/2602.01967v1",
      "pdf_link": "https://arxiv.org/pdf/2602.01967v1",
      "authors": "Wonjun Lee, Hyounghun Kim, Gary Geunbae Lee",
      "institution": "",
      "abstract": "Accented speech remains a persistent challenge for automatic speech recognition (ASR), as most models are trained on data dominated by a few high-resource English varieties, leading to substantial performance degradation for other accents. Accent-agnostic approaches improve robustness yet struggle with heavily accented or unseen varieties, while accent-specific methods rely on limited and often noisy labels. We introduce Moe-Ctc, a Mixture-of-Experts architecture with intermediate CTC supervision that jointly promotes expert specialization and generalization. During training, accent-aware routing encourages experts to capture accent-specific patterns, which gradually transitions to label-free routing for inference. Each expert is equipped with its own CTC head to align routing with transcription quality, and a routing-augmented loss further stabilizes optimization. Experiments on the Mcv-Accent benchmark demonstrate consistent gains across both seen and unseen accents in low- and high-resource conditions, achieving up to 29.3% relative WER reduction over strong FastConformer baselines.",
      "source": "arXiv",
      "pubDateISO": "2026-02-02",
      "tags": [
        "cs.CL",
        "cs.AI"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.01966v1",
      "title": "Self-Consolidation for Self-Evolving Agents",
      "link": "http://arxiv.org/abs/2602.01966v1",
      "pdf_link": "https://arxiv.org/pdf/2602.01966v1",
      "authors": "Hongzhuo Yu, Fei Zhu, Guo-Sen Xie, Ling Shao",
      "institution": "",
      "abstract": "While large language model (LLM) agents have demonstrated impressive problem-solving capabilities, they typically operate as static systems, lacking the ability to evolve through lifelong interaction. Existing attempts to bridge this gap primarily rely on retrieving successful past trajectories as demonstrations. However, this paradigm faces two critical limitations. First, by focusing solely on success, agents overlook the rich pedagogical value embedded in failed attempts, preventing them from identifying and avoiding recurrent pitfalls. Second, continually accumulating textual experiences not only increases the time consumption during retrieval but also inevitably introduces noise and exhausts the largest context window of current LLMs. To address these challenges, we propose a novel self-evolving framework for LLM agents that introduces a complementary evolution mechanism: First, a contrastive reflection strategy is introduced to explicitly summarize error-prone patterns and capture reusable insights. Second, we propose a self-consolidation mechanism that distills non-parametric textual experience into compact learnable parameters. This enables the agent to internalize extensive historical experience directly into its latent space. Extensive experiments demonstrate the advantages of our method in long-term agent evolution.",
      "source": "arXiv",
      "pubDateISO": "2026-02-02",
      "tags": [
        "cs.LG"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.01965v1",
      "title": "Breaking the Static Graph: Context-Aware Traversal for Robust Retrieval-Augmented Generation",
      "link": "http://arxiv.org/abs/2602.01965v1",
      "pdf_link": "https://arxiv.org/pdf/2602.01965v1",
      "authors": "Kwun Hang Lau, Fangyuan Zhang, Boyu Ruan, Yingli Zhou, Qintian Guo et al.",
      "institution": "",
      "abstract": "Recent advances in Retrieval-Augmented Generation (RAG) have shifted from simple vector similarity to structure-aware approaches like HippoRAG, which leverage Knowledge Graphs (KGs) and Personalized PageRank (PPR) to capture multi-hop dependencies. However, these methods suffer from a \"Static Graph Fallacy\": they rely on fixed transition probabilities determined during indexing. This rigidity ignores the query-dependent nature of edge relevance, causing semantic drift where random walks are diverted into high-degree \"hub\" nodes before reaching critical downstream evidence. Consequently, models often achieve high partial recall but fail to retrieve the complete evidence chain required for multi-hop queries. To address this, we propose CatRAG, Context-Aware Traversal for robust RAG, a framework that builds on the HippoRAG 2 architecture and transforms the static KG into a query-adaptive navigation structure. We introduce a multi-faceted framework to steer the random walk: (1) Symbolic Anchoring, which injects weak entity constraints to regularize the random walk; (2) Query-Aware Dynamic Edge Weighting, which dynamically modulates graph structure, to prune irrelevant paths while amplifying those aligned with the query's intent; and (3) Key-Fact Passage Weight Enhancement, a cost-efficient bias that structurally anchors the random walk to likely evidence. Experiments across four multi-hop benchmarks demonstrate that CatRAG consistently outperforms state of the art baselines. Our analysis reveals that while standard Recall metrics show modest gains, CatRAG achieves substantial improvements in reasoning completeness, the capacity to recover the entire evidence path without gaps. These results reveal that our approach effectively bridges the gap between retrieving partial context and enabling fully grounded reasoning. Resources are available at https://github.com/kwunhang/CatRAG.",
      "source": "arXiv",
      "pubDateISO": "2026-02-02",
      "tags": [
        "cs.CL",
        "cs.AI"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.01962v1",
      "title": "Zero-Shot Off-Policy Learning",
      "link": "http://arxiv.org/abs/2602.01962v1",
      "pdf_link": "https://arxiv.org/pdf/2602.01962v1",
      "authors": "Arip Asadulaev, Maksim Bobrin, Salem Lahlou, Dmitry Dylov, Fakhri Karray et al.",
      "institution": "MIT",
      "abstract": "Off-policy learning methods seek to derive an optimal policy directly from a fixed dataset of prior interactions. This objective presents significant challenges, primarily due to the inherent distributional shift and value function overestimation bias. These issues become even more noticeable in zero-shot reinforcement learning, where an agent trained on reward-free data must adapt to new tasks at test time without additional training. In this work, we address the off-policy problem in a zero-shot setting by discovering a theoretical connection of successor measures to stationary density ratios. Using this insight, our algorithm can infer optimal importance sampling ratios, effectively performing a stationary distribution correction with an optimal policy for any task on the fly. We benchmark our method in motion tracking tasks on SMPL Humanoid, continuous control on ExoRL, and for the long-horizon OGBench tasks. Our technique seamlessly integrates into forward-backward representation frameworks and enables fast-adaptation to new tasks in a training-free regime. More broadly, this work bridges off-policy learning and zero-shot adaptation, offering benefits to both research areas.",
      "source": "arXiv",
      "pubDateISO": "2026-02-02",
      "tags": [
        "cs.LG",
        "cs.AI"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.01960v1",
      "title": "Grounding Generated Videos in Feasible Plans via World Models",
      "link": "http://arxiv.org/abs/2602.01960v1",
      "pdf_link": "https://arxiv.org/pdf/2602.01960v1",
      "authors": "Christos Ziakas, Amir Bar, Alessandra Russo",
      "institution": "",
      "abstract": "Large-scale video generative models have shown emerging capabilities as zero-shot visual planners, yet video-generated plans often violate temporal consistency and physical constraints, leading to failures when mapped to executable actions. To address this, we propose Grounding Video Plans with World Models (GVP-WM), a planning method that grounds video-generated plans into feasible action sequences using a learned action-conditioned world model. At test-time, GVP-WM first generates a video plan from initial and goal observations, then projects the video guidance onto the manifold of dynamically feasible latent trajectories via video-guided latent collocation. In particular, we formulate grounding as a goal-conditioned latent-space trajectory optimization problem that jointly optimizes latent states and actions under world-model dynamics, while preserving semantic alignment with the video-generated plan. Empirically, GVP-WM recovers feasible long-horizon plans from zero-shot image-to-video-generated and motion-blurred videos that violate physical constraints, across navigation and manipulation simulation tasks.",
      "source": "arXiv",
      "pubDateISO": "2026-02-02",
      "tags": [
        "cs.LG"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.01956v1",
      "title": "Efficient Epistemic Uncertainty Estimation for Large Language Models via Knowledge Distillation",
      "link": "http://arxiv.org/abs/2602.01956v1",
      "pdf_link": "https://arxiv.org/pdf/2602.01956v1",
      "authors": "Seonghyeon Park, Jewon Yeom, Jaewon Sok, Jeongjae Park, Heejun Kim et al.",
      "institution": "",
      "abstract": "Quantifying uncertainty in Large Language Models (LLMs) is essential for mitigating hallucinations and enabling risk-aware deployment in safety-critical tasks. However, estimating Epistemic Uncertainty(EU) via Deep Ensembles is computationally prohibitive at the scale of modern models. We propose a framework that leverages the small draft models to efficiently estimate token-level EU, bypassing the need for full-scale ensembling. Theoretically grounded in a Bias-Variance Decomposition, our approach approximates EU via Jensen-Shannon divergence among drafts (variance proxy) and KL divergence between the draft mixture and the target (bias proxy). To further ensure accuracy without significant overhead, we introduce Online Stochastic Distillation (OSD) to efficiently approximate target aggregation and the Data-Diverse Drafts (DDD) strategy to enhance draft diversity for better target approximation. Extensive experiments on GSM8K demonstrate that our method reduces the estimation error (RMSE) by up to 37% compared to baselines. Crucially, our approach achieves Hallucination Detection performance competitive with heavy perturbation-based methods like TokUR while incurring negligible inference costs, offering a practical solution for uncertainty-aware LLM deployment.",
      "source": "arXiv",
      "pubDateISO": "2026-02-02",
      "tags": [
        "cs.LG",
        "cs.AI"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.01954v1",
      "title": "Beyond Open Vocabulary: Multimodal Prompting for Object Detection in Remote Sensing Images",
      "link": "http://arxiv.org/abs/2602.01954v1",
      "pdf_link": "https://arxiv.org/pdf/2602.01954v1",
      "authors": "Shuai Yang, Ziyue Huang, Jiaxin Chen, Qingjie Liu, Yunhong Wang",
      "institution": "",
      "abstract": "Open-vocabulary object detection in remote sensing commonly relies on text-only prompting to specify target categories, implicitly assuming that inference-time category queries can be reliably grounded through pretraining-induced text-visual alignment. In practice, this assumption often breaks down in remote sensing scenarios due to task- and application-specific category semantics, resulting in unstable category specification under open-vocabulary settings. To address this limitation, we propose RS-MPOD, a multimodal open-vocabulary detection framework that reformulates category specification beyond text-only prompting by incorporating instance-grounded visual prompts, textual prompts, and their multimodal integration. RS-MPOD introduces a visual prompt encoder to extract appearance-based category cues from exemplar instances, enabling text-free category specification, and a multimodal fusion module to integrate visual and textual information when both modalities are available. Extensive experiments on standard, cross-dataset, and fine-grained remote sensing benchmarks show that visual prompting yields more reliable category specification under semantic ambiguity and distribution shifts, while multimodal prompting provides a flexible alternative that remains competitive when textual semantics are well aligned.",
      "source": "arXiv",
      "pubDateISO": "2026-02-02",
      "tags": [
        "cs.CV"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.01953v1",
      "title": "Deep Multivariate Models with Parametric Conditionals",
      "link": "http://arxiv.org/abs/2602.01953v1",
      "pdf_link": "https://arxiv.org/pdf/2602.01953v1",
      "authors": "Dmitrij Schlesinger, Boris Flach, Alexander Shekhovtsov",
      "institution": "MIT",
      "abstract": "We consider deep multivariate models for heterogeneous collections of random variables. In the context of computer vision, such collections may e.g. consist of images, segmentations, image attributes, and latent variables. When developing such models, most existing works start from an application task and design the model components and their dependencies to meet the needs of the chosen task. This has the disadvantage of limiting the applicability of the resulting model for other downstream tasks. Here, instead, we propose to represent the joint probability distribution by means of conditional probability distributions for each group of variables conditioned on the rest. Such models can then be used for practically any possible downstream task. Their learning can be approached as training a parametrised Markov chain kernel by maximising the data likelihood of its limiting distribution. This has the additional advantage of allowing a wide range of semi-supervised learning scenarios.",
      "source": "arXiv",
      "pubDateISO": "2026-02-02",
      "tags": [
        "cs.LG",
        "stat.ML"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.01951v1",
      "title": "Enabling Progressive Whole-slide Image Analysis with Multi-scale Pyramidal Network",
      "link": "http://arxiv.org/abs/2602.01951v1",
      "pdf_link": "https://arxiv.org/pdf/2602.01951v1",
      "authors": "Shuyang Wu, Yifu Qiu, Ines P. Nearchou, Sandrine Prost, Jonathan A Fallowfield et al.",
      "institution": "",
      "abstract": "Multiple-instance Learning (MIL) is commonly used to undertake computational pathology (CPath) tasks, and the use of multi-scale patches allows diverse features across scales to be learned. Previous studies using multi-scale features in clinical applications rely on multiple inputs across magnifications with late feature fusion, which does not retain the link between features across scales while the inputs are dependent on arbitrary, manufacturer-defined magnifications, being inflexible and computationally expensive. In this paper, we propose the Multi-scale Pyramidal Network (MSPN), which is plug-and-play over attention-based MIL that introduces progressive multi-scale analysis on WSI. Our MSPN consists of (1) grid-based remapping that uses high magnification features to derive coarse features and (2) the coarse guidance network (CGN) that learns coarse contexts. We benchmark MSPN as an add-on module to 4 attention-based frameworks using 4 clinically relevant tasks across 3 types of foundation model, as well as the pre-trained MIL framework. We show that MSPN consistently improves MIL across the compared configurations and tasks, while being lightweight and easy-to-use.",
      "source": "arXiv",
      "pubDateISO": "2026-02-02",
      "tags": [
        "cs.CV"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.01949v1",
      "title": "Boundary-Constrained Diffusion Models for Floorplan Generation: Balancing Realism and Diversity",
      "link": "http://arxiv.org/abs/2602.01949v1",
      "pdf_link": "https://arxiv.org/pdf/2602.01949v1",
      "authors": "Leonardo Stoppani, Davide Bacciu, Shahab Mokarizadeh",
      "institution": "",
      "abstract": "Diffusion models have become widely popular for automated floorplan generation, producing highly realistic layouts conditioned on user-defined constraints. However, optimizing for perceptual metrics such as the Fréchet Inception Distance (FID) causes limited design diversity. To address this, we propose the Diversity Score (DS), a metric that quantifies layout diversity under fixed constraints. Moreover, to improve geometric consistency, we introduce a Boundary Cross-Attention (BCA) module that enables conditioning on building boundaries. Our experiments show that BCA significantly improves boundary adherence, while prolonged training drives diversity collapse undiagnosed by FID, revealing a critical trade-off between realism and diversity. Out-Of-Distribution evaluations further demonstrate the models' reliance on dataset priors, emphasizing the need for generative systems that explicitly balance fidelity, diversity, and generalization in architectural design tasks.",
      "source": "arXiv",
      "pubDateISO": "2026-02-02",
      "tags": [
        "cs.LG",
        "cs.CV"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.01942v1",
      "title": "Human Society-Inspired Approaches to Agentic AI Security: The 4C Framework",
      "link": "http://arxiv.org/abs/2602.01942v1",
      "pdf_link": "https://arxiv.org/pdf/2602.01942v1",
      "authors": "Alsharif Abuadbba, Nazatul Sultan, Surya Nepal, Sanjay Jha",
      "institution": "",
      "abstract": "AI is moving from domain-specific autonomy in closed, predictable settings to large-language-model-driven agents that plan and act in open, cross-organizational environments. As a result, the cybersecurity risk landscape is changing in fundamental ways. Agentic AI systems can plan, act, collaborate, and persist over time, functioning as participants in complex socio-technical ecosystems rather than as isolated software components. Although recent work has strengthened defenses against model and pipeline level vulnerabilities such as prompt injection, data poisoning, and tool misuse, these system centric approaches may fail to capture risks that arise from autonomy, interaction, and emergent behavior. This article introduces the 4C Framework for multi-agent AI security, inspired by societal governance. It organizes agentic risks across four interdependent dimensions: Core (system, infrastructure, and environmental integrity), Connection (communication, coordination, and trust), Cognition (belief, goal, and reasoning integrity), and Compliance (ethical, legal, and institutional governance). By shifting AI security from a narrow focus on system-centric protection to the broader preservation of behavioral integrity and intent, the framework complements existing AI security strategies and offers a principled foundation for building agentic AI systems that are trustworthy, governable, and aligned with human values.",
      "source": "arXiv",
      "pubDateISO": "2026-02-02",
      "tags": [
        "cs.CR",
        "cs.AI"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.01941v1",
      "title": "FluxNet: Learning Capacity-Constrained Local Transport Operators for Conservative and Bounded PDE Surrogates",
      "link": "http://arxiv.org/abs/2602.01941v1",
      "pdf_link": "https://arxiv.org/pdf/2602.01941v1",
      "authors": "Zishuo Lan, Junjie Li, Lei Wang, Jincheng Wang",
      "institution": "",
      "abstract": "Autoregressive learning of time-stepping operators offers an effective approach to data-driven PDE simulation on grids. For conservation laws, however, long-horizon rollouts are often destabilized when learned updates violate global conservation and, in many applications, additional state bounds such as nonnegative mass and densities or concentrations constrained to [0,1]. Enforcing these coupled constraints via direct next-state regression remains difficult. We introduce a framework for learning conservative transport operators on regular grids, inspired by lattice Boltzmann-style discrete-velocity transport representations. Instead of predicting the next state, the model outputs local transport operators that update cells through neighborhood exchanges, guaranteeing discrete conservation by construction. For bounded quantities, we parameterize transport within a capacity-constrained feasible set, enforcing bounds structurally rather than by post-hoc clipping. We validate FluxNet on 1D convection-diffusion, 2D shallow water equations, 1D traffic flow, and 2D spinodal decomposition. Experiments on shallow-water equations and traffic flow show improved rollout stability and physical consistency over strong baselines. On phase-field spinodal decomposition, the method enables large time-steps with long-range transport, accelerating simulation while preserving microstructure evolution in both pointwise and statistical measures.",
      "source": "arXiv",
      "pubDateISO": "2026-02-02",
      "tags": [
        "cs.CE",
        "cs.LG"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.01939v1",
      "title": "Towards Exploratory and Focused Manipulation with Bimanual Active Perception: A New Problem, Benchmark and Strategy",
      "link": "http://arxiv.org/abs/2602.01939v1",
      "pdf_link": "https://arxiv.org/pdf/2602.01939v1",
      "authors": "Yuxin He, Ruihao Zhang, Tianao Shen, Cheng Liu, Qiang Nie",
      "institution": "",
      "abstract": "Recently, active vision has reemerged as an important concept for manipulation, since visual occlusion occurs more frequently when main cameras are mounted on the robot heads. We reflect on the visual occlusion issue and identify its essence as the absence of information useful for task completion. Inspired by this, we come up with the more fundamental problem of Exploratory and Focused Manipulation (EFM). The proposed problem is about actively collecting information to complete challenging manipulation tasks that require exploration or focus. As an initial attempt to address this problem, we establish the EFM-10 benchmark that consists of 4 categories of tasks that align with our definition (10 tasks in total). We further come up with a Bimanual Active Perception (BAP) strategy, which leverages one arm to provide active vision and another arm to provide force sensing while manipulating. Based on this idea, we collect a dataset named BAPData for the tasks in EFM-10. With the dataset, we successfully verify the effectiveness of the BAP strategy in an imitation learning manner. We hope that the EFM-10 benchmark along with the BAP strategy can become a cornerstone that facilitates future research towards this direction. Project website: EFManipulation.github.io.",
      "source": "arXiv",
      "pubDateISO": "2026-02-02",
      "tags": [
        "cs.RO",
        "cs.AI"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.01937v1",
      "title": "T-LLM: Teaching Large Language Models to Forecast Time Series via Temporal Distillation",
      "link": "http://arxiv.org/abs/2602.01937v1",
      "pdf_link": "https://arxiv.org/pdf/2602.01937v1",
      "authors": "Suhan Guo, Bingxu Wang, Shaodan Zhang, Furao Shen",
      "institution": "",
      "abstract": "Time series forecasting plays a critical role in decision-making across many real-world applications. Unlike data in vision and language domains, time series data is inherently tied to the evolution of underlying processes and can only accumulate as real-world time progresses, limiting the effectiveness of scale-driven pretraining alone. This time-bound constraint poses a challenge for enabling large language models (LLMs) to acquire forecasting capability, as existing approaches primarily rely on representation-level alignment or inference-time temporal modules rather than explicitly teaching forecasting behavior to the LLM. We propose T-LLM, a temporal distillation framework that equips general-purpose LLMs with time series forecasting capability by transferring predictive behavior from a lightweight temporal teacher during training. The teacher combines trend modeling and frequency-domain analysis to provide structured temporal supervision, and is removed entirely at inference, leaving the LLM as the sole forecasting model. Experiments on benchmark datasets and infectious disease forecasting tasks demonstrate that T-LLM consistently outperforms existing LLM-based forecasting methods under full-shot, few-shot, and zero-shot settings, while enabling a simple and efficient deployment pipeline.",
      "source": "arXiv",
      "pubDateISO": "2026-02-02",
      "tags": [
        "cs.LG",
        "cs.AI"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.01936v1",
      "title": "PIMCST: Physics-Informed Multi-Phase Consensus and Spatio-Temporal Few-Shot Learning for Traffic Flow Forecasting",
      "link": "http://arxiv.org/abs/2602.01936v1",
      "pdf_link": "https://arxiv.org/pdf/2602.01936v1",
      "authors": "Abdul Joseph Fofanah, Lian Wen, David Chen",
      "institution": "",
      "abstract": "Accurate traffic flow prediction remains a fundamental challenge in intelligent transportation systems, particularly in cross-domain, data-scarce scenarios where limited historical data hinders model training and generalisation. The complex spatio-temporal dependencies and nonlinear dynamics of urban mobility networks further complicate few-shot learning across different cities. This paper proposes MCPST, a novel Multi-phase Consensus Spatio-Temporal framework for few-shot traffic forecasting that reconceptualises traffic prediction as a multi-phase consensus learning problem. Our framework introduces three core innovations: (1) a multi-phase engine that models traffic dynamics through diffusion, synchronisation, and spectral embeddings for comprehensive dynamic characterisation; (2) an adaptive consensus mechanism that dynamically fuses phase-specific predictions while enforcing consistency; and (3) a structured meta-learning strategy for rapid adaptation to new cities with minimal data. We establish extensive theoretical guarantees, including representation theorems with bounded approximation errors and generalisation bounds for few-shot adaptation. Through experiments on four real-world datasets, MCPST outperforms fourteen state-of-the-art methods in spatio-temporal graph learning methods, dynamic graph transfer learning methods, prompt-based spatio-temporal prediction methods and cross-domain few-shot settings, improving prediction accuracy while reducing required training data and providing interpretable insights. The implementation code is available at https://github.com/afofanah/MCPST.",
      "source": "arXiv",
      "pubDateISO": "2026-02-02",
      "tags": [
        "cs.LG",
        "cs.AI"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.01935v1",
      "title": "COLT: Lightweight Multi-LLM Collaboration through Shared MCTS Reasoning for Model Compilation",
      "link": "http://arxiv.org/abs/2602.01935v1",
      "pdf_link": "https://arxiv.org/pdf/2602.01935v1",
      "authors": "Annabelle Sujun Tang, Christopher Priebe, Lianhui Qin, Hadi Esmaeilzadeh",
      "institution": "",
      "abstract": "Model serving costs dominate AI systems, making compiler optimization essential for scalable deployment. Recent works show that a large language model (LLM) can guide compiler search by reasoning over program structure and optimization history. However, using a single large model throughout the search is expensive, while smaller models are less reliable when used alone. Thus, this paper seeks to answer whether multi-LLM collaborative reasoning relying primarily on small LLMs can match or exceed the performance of a single large model. As such, we propose a lightweight collaborative multi-LLM framework, dubbed COLT, for compiler optimization that enables coordinated reasoning across multiple models within a single Monte Carlo tree search (MCTS) process. A key contribution is the use of a single shared MCTS tree as the collaboration substrate across LLMs, enabling the reuse of transformation prefixes and cross-model value propagation. Hence, we circumvent both heavy internal reasoning mechanisms and conventional agentic machinery that relies on external planners, multiple concurrent LLMs, databases, external memory/versioning of intermediate results, and controllers by simply endogenizing model selection within the lightweight MCTS optimization loop. Every iteration, the acting LLM proposes a joint action: (compiler transformation, model to be queried next). We also introduce a model-aware tree policy that biases search toward smaller models while preserving exploration, and a course-alteration mechanism that escalates to the largest model when the search exhibits persistent regressions attributable to smaller models.",
      "source": "arXiv",
      "pubDateISO": "2026-02-02",
      "tags": [
        "cs.LG",
        "cs.AI",
        "cs.PL"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.01933v1",
      "title": "Large Language Model and Formal Concept Analysis: a comparative study for Topic Modeling",
      "link": "http://arxiv.org/abs/2602.01933v1",
      "pdf_link": "https://arxiv.org/pdf/2602.01933v1",
      "authors": "Fabrice Boissier, Monica Sen, Irina Rychkova",
      "institution": "",
      "abstract": "Topic modeling is a research field finding increasing applications: historically from document retrieving, to sentiment analysis and text summarization. Large Language Models (LLM) are currently a major trend in text processing, but few works study their usefulness for this task. Formal Concept Analysis (FCA) has recently been presented as a candidate for topic modeling, but no real applied case study has been conducted. In this work, we compare LLM and FCA to better understand their strengths and weakneses in the topic modeling field. FCA is evaluated through the CREA pipeline used in past experiments on topic modeling and visualization, whereas GPT-5 is used for the LLM. A strategy based on three prompts is applied with GPT-5 in a zero-shot setup: topic generation from document batches, merging of batch results into final topics, and topic labeling. A first experiment reuses the teaching materials previously used to evaluate CREA, while a second experiment analyzes 40 research articles in information systems to compare the extracted topics with the underling subfields.",
      "source": "arXiv",
      "pubDateISO": "2026-02-02",
      "tags": [
        "cs.AI"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.01930v1",
      "title": "LIEREx: Language-Image Embeddings for Robotic Exploration",
      "link": "http://arxiv.org/abs/2602.01930v1",
      "pdf_link": "https://arxiv.org/pdf/2602.01930v1",
      "authors": "Felix Igelbrink, Lennart Niecksch, Marian Renz, Martin Günther, Martin Atzmueller",
      "institution": "",
      "abstract": "Semantic maps allow a robot to reason about its surroundings to fulfill tasks such as navigating known environments, finding specific objects, and exploring unmapped areas. Traditional mapping approaches provide accurate geometric representations but are often constrained by pre-designed symbolic vocabularies. The reliance on fixed object classes makes it impractical to handle out-of-distribution knowledge not defined at design time. Recent advances in Vision-Language Foundation Models, such as CLIP, enable open-set mapping, where objects are encoded as high-dimensional embeddings rather than fixed labels. In LIEREx, we integrate these VLFMs with established 3D Semantic Scene Graphs to enable target-directed exploration by an autonomous agent in partially unknown environments.",
      "source": "arXiv",
      "pubDateISO": "2026-02-02",
      "tags": [
        "cs.RO",
        "cs.CV"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.01929v1",
      "title": "Probabilistic function-on-function nonlinear autoregressive model for emulation and reliability analysis of dynamical systems",
      "link": "http://arxiv.org/abs/2602.01929v1",
      "pdf_link": "https://arxiv.org/pdf/2602.01929v1",
      "authors": "Zhouzhou Song, Marcos A. Valdebenito, Styfen Schär, Stefano Marelli, Bruno Sudret et al.",
      "institution": "",
      "abstract": "Constructing accurate and computationally efficient surrogate models (or emulators) for predicting dynamical system responses is critical in many engineering domains, yet remains challenging due to the strongly nonlinear and high-dimensional mapping from external excitations and system parameters to system responses. This work introduces a novel Function-on-Function Nonlinear AutoRegressive model with eXogenous inputs (F2NARX), which reformulates the conventional NARX model from a function-on-function regression perspective, inspired by the recently proposed $\\mathcal{F}$-NARX method. The proposed framework substantially improves predictive efficiency while maintaining high accuracy. By combining principal component analysis with Gaussian process regression, F2NARX further enables probabilistic predictions of dynamical responses via the unscented transform in an autoregressive manner. The effectiveness of the method is demonstrated through case studies of varying complexity. Results show that F2NARX outperforms state-of-the-art NARX model by orders of magnitude in efficiency while achieving higher accuracy in general. Moreover, its probabilistic prediction capabilities facilitate active learning, enabling accurate estimation of first-passage failure probabilities of dynamical systems using only a small number of training time histories.",
      "source": "arXiv",
      "pubDateISO": "2026-02-02",
      "tags": [
        "stat.CO",
        "stat.ML"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.01928v1",
      "title": "Privacy Amplification by Missing Data",
      "link": "http://arxiv.org/abs/2602.01928v1",
      "pdf_link": "https://arxiv.org/pdf/2602.01928v1",
      "authors": "Simon Roburin, Rafaël Pinot, Erwan Scornet",
      "institution": "",
      "abstract": "Privacy preservation is a fundamental requirement in many high-stakes domains such as medicine and finance, where sensitive personal data must be analyzed without compromising individual confidentiality. At the same time, these applications often involve datasets with missing values due to non-response, data corruption, or deliberate anonymization. Missing data is traditionally viewed as a limitation because it reduces the information available to analysts and can degrade model performance. In this work, we take an alternative perspective and study missing data from a privacy preservation standpoint. Intuitively, when features are missing, less information is revealed about individuals, suggesting that missingness could inherently enhance privacy. We formalize this intuition by analyzing missing data as a privacy amplification mechanism within the framework of differential privacy. We show, for the first time, that incomplete data can yield privacy amplification for differentially private algorithms.",
      "source": "arXiv",
      "pubDateISO": "2026-02-02",
      "tags": [
        "stat.ML",
        "cs.LG"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.01924v1",
      "title": "Bayesian Integration of Nonlinear Incomplete Clinical Data",
      "link": "http://arxiv.org/abs/2602.01924v1",
      "pdf_link": "https://arxiv.org/pdf/2602.01924v1",
      "authors": "Lucía González-Zamorano, Nuria Balbás-Esteban, Vanessa Gómez-Verdejo, Albert Belenguer-Llorens, Carlos Sevilla-Salcedo",
      "institution": "",
      "abstract": "Multimodal clinical data are characterized by high dimensionality, heterogeneous representations, and structured missingness, posing significant challenges for predictive modeling, data integration, and interpretability. We propose BIONIC (Bayesian Integration of Nonlinear Incomplete Clinical data), a unified probabilistic framework that integrates heterogeneous multimodal data under missingness through a joint generative-discriminative latent architecture. BIONIC uses pretrained embeddings for complex modalities such as medical images and clinical text, while incorporating structured clinical variables directly within a Bayesian multimodal formulation. The proposed framework enables robust learning in partially observed and semi-supervised settings by explicitly modeling modality-level and variable-level missingness, as well as missing labels. We evaluate BIONIC on three multimodal clinical and biomedical datasets, demonstrating strong and consistent discriminative performance compared to representative multimodal baselines, particularly under incomplete data scenarios. Beyond predictive accuracy, BIONIC provides intrinsic interpretability through its latent structure, enabling population-level analysis of modality relevance and supporting clinically meaningful insight.",
      "source": "arXiv",
      "pubDateISO": "2026-02-02",
      "tags": [
        "cs.LG",
        "cs.CY"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.01922v1",
      "title": "Embedding Learning on Multiplex Networks for Link Prediction",
      "link": "http://arxiv.org/abs/2602.01922v1",
      "pdf_link": "https://arxiv.org/pdf/2602.01922v1",
      "authors": "Orell Trautmann, Olaf Wolkenhauer, Clémence Réda",
      "institution": "",
      "abstract": "Over the past years, embedding learning on networks has shown tremendous results in link prediction tasks for complex systems, with a wide range of real-life applications. Learning a representation for each node in a knowledge graph allows us to capture topological and semantic information, which can be processed in downstream analyses later. In the link prediction task, high-dimensional network information is encoded into low-dimensional vectors, which are then fed to a predictor to infer new connections between nodes in the network. As the network complexity (that is, the numbers of connections and types of interactions) grows, embedding learning turns out increasingly challenging. This review covers published models on embedding learning on multiplex networks for link prediction. First, we propose refined taxonomies to classify and compare models, depending on the type of embeddings and embedding techniques. Second, we review and address the problem of reproducible and fair evaluation of embedding learning on multiplex networks for the link prediction task. Finally, we tackle evaluation on directed multiplex networks by proposing a novel and fair testing procedure. This review constitutes a crucial step towards the development of more performant and tractable embedding learning approaches for multiplex networks and their fair evaluation for the link prediction task. We also suggest guidelines on the evaluation of models, and provide an informed perspective on the challenges and tools currently available to address downstream analyses applied to multiplex networks.",
      "source": "arXiv",
      "pubDateISO": "2026-02-02",
      "tags": [
        "cs.LG"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.01920v1",
      "title": "PIMPC-GNN: Physics-Informed Multi-Phase Consensus Learning for Enhancing Imbalanced Node Classification in Graph Neural Networks",
      "link": "http://arxiv.org/abs/2602.01920v1",
      "pdf_link": "https://arxiv.org/pdf/2602.01920v1",
      "authors": "Abdul Joseph Fofanah, Lian Wen, David Chen",
      "institution": "",
      "abstract": "Graph neural networks (GNNs) often struggle in class-imbalanced settings, where minority classes are under-represented and predictions are biased toward majorities. We propose \\textbf{PIMPC-GNN}, a physics-informed multi-phase consensus framework for imbalanced node classification. Our method integrates three complementary dynamics: (i) thermodynamic diffusion, which spreads minority labels to capture long-range dependencies, (ii) Kuramoto synchronisation, which aligns minority nodes through oscillatory consensus, and (iii) spectral embedding, which separates classes via structural regularisation. These perspectives are combined through class-adaptive ensemble weighting and trained with an imbalance-aware loss that couples balanced cross-entropy with physics-based constraints. Across five benchmark datasets and imbalance ratios from 5-100, PIMPC-GNN outperforms 16 state-of-the-art baselines, achieving notable gains in minority-class recall (up to +12.7\\%) and balanced accuracy (up to +8.3\\%). Beyond empirical improvements, the framework also provides interpretable insights into consensus dynamics in graph learning. The code is available at \\texttt{https://github.com/afofanah/PIMPC-GNN}.",
      "source": "arXiv",
      "pubDateISO": "2026-02-02",
      "tags": [
        "cs.LG",
        "cs.AI"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.01919v1",
      "title": "From Code-Centric to Concept-Centric: Teaching NLP with LLM-Assisted \"Vibe Coding\"",
      "link": "http://arxiv.org/abs/2602.01919v1",
      "pdf_link": "https://arxiv.org/pdf/2602.01919v1",
      "authors": "Hend Al-Khalifa",
      "institution": "",
      "abstract": "The rapid advancement of Large Language Models (LLMs) presents both challenges and opportunities for Natural Language Processing (NLP) education. This paper introduces ``Vibe Coding,'' a pedagogical approach that leverages LLMs as coding assistants while maintaining focus on conceptual understanding and critical thinking. We describe the implementation of this approach in a senior-level undergraduate NLP course, where students completed seven labs using LLMs for code generation while being assessed primarily on conceptual understanding through critical reflection questions. Analysis of end-of-course feedback from 19 students reveals high satisfaction (mean scores 4.4-4.6/5.0) across engagement, conceptual learning, and assessment fairness. Students particularly valued the reduced cognitive load from debugging, enabling deeper focus on NLP concepts. However, challenges emerged around time constraints, LLM output verification, and the need for clearer task specifications. Our findings suggest that when properly structured with mandatory prompt logging and reflection-based assessment, LLM-assisted learning can shift focus from syntactic fluency to conceptual mastery, preparing students for an AI-augmented professional landscape.",
      "source": "arXiv",
      "pubDateISO": "2026-02-02",
      "tags": [
        "cs.CL"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.01917v1",
      "title": "GuideWeb: A Benchmark for Automatic In-App Guide Generation on Real-World Web UIs",
      "link": "http://arxiv.org/abs/2602.01917v1",
      "pdf_link": "https://arxiv.org/pdf/2602.01917v1",
      "authors": "Chengguang Gan, Yoshihiro Tsujii, Yunhao Liang, Tatsunori Mori, Shiwen Ni et al.",
      "institution": "",
      "abstract": "Digital Adoption Platform (DAP) provide web-based overlays that deliver operation guidance and contextual hints to help users navigate complex websites. Although modern DAP tools enable non-experts to author such guidance, maintaining these guides remains labor-intensive because website layouts and functionalities evolve continuously, which requires repeated manual updates and re-annotation. In this work, we introduce \\textbf{GuideWeb}, a new benchmark for automatic in-app guide generation on real-world web UIs. GuideWeb formulates the task as producing page-level guidance by selecting \\textbf{guide target elements} grounded in the webpage and generating concise guide text aligned with user intent. We also propose a comprehensive evaluation suite that jointly measures the accuracy of guide target element selection and the quality of generated intents and guide texts. Experiments show that our proposed \\textbf{GuideWeb Agent} achieves \\textbf{30.79\\%} accuracy in guide target element prediction, while obtaining BLEU scores of \\textbf{44.94} for intent generation and \\textbf{21.34} for guide-text generation. Existing baselines perform substantially worse, which highlights that automatic guide generation remains challenging and that further advances are necessary before such systems can be reliably deployed in real-world settings.",
      "source": "arXiv",
      "pubDateISO": "2026-02-02",
      "tags": [
        "cs.CL"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.01915v1",
      "title": "VLM-Guided Experience Replay",
      "link": "http://arxiv.org/abs/2602.01915v1",
      "pdf_link": "https://arxiv.org/pdf/2602.01915v1",
      "authors": "Elad Sharony, Tom Jurgenson, Orr Krupnik, Dotan Di Castro, Shie Mannor",
      "institution": "",
      "abstract": "Recent advances in Large Language Models (LLMs) and Vision-Language Models (VLMs) have enabled powerful semantic and multimodal reasoning capabilities, creating new opportunities to enhance sample efficiency, high-level planning, and interpretability in reinforcement learning (RL). While prior work has integrated LLMs and VLMs into various components of RL, the replay buffer, a core component for storing and reusing experiences, remains unexplored. We propose addressing this gap by leveraging VLMs to guide the prioritization of experiences in the replay buffer. Our key idea is to use a frozen, pre-trained VLM (requiring no fine-tuning) as an automated evaluator to identify and prioritize promising sub-trajectories from the agent's experiences. Across scenarios, including game-playing and robotics, spanning both discrete and continuous domains, agents trained with our proposed prioritization method achieve 11-52% higher average success rates and improve sample efficiency by 19-45% compared to previous approaches. https://esharony.me/projects/vlm-rb/",
      "source": "arXiv",
      "pubDateISO": "2026-02-02",
      "tags": [
        "cs.LG",
        "cs.AI"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.01914v1",
      "title": "Towards Long-Horizon Interpretability: Efficient and Faithful Multi-Token Attribution for Reasoning LLMs",
      "link": "http://arxiv.org/abs/2602.01914v1",
      "pdf_link": "https://arxiv.org/pdf/2602.01914v1",
      "authors": "Wenbo Pan, Zhichao Liu, Xianlong Wang, Haining Yu, Xiaohua Jia",
      "institution": "",
      "abstract": "Token attribution methods provide intuitive explanations for language model outputs by identifying causally important input tokens. However, as modern LLMs increasingly rely on extended reasoning chains, existing schemes face two critical challenges: (1) efficiency bottleneck, where attributing a target span of M tokens within a context of length N requires O(M*N) operations, making long-context attribution prohibitively slow; and (2) faithfulness drop, where intermediate reasoning tokens absorb attribution mass, preventing importance from propagating back to the original input. To address these, we introduce FlashTrace, an efficient multi-token attribution method that employs span-wise aggregation to compute attribution over multi-token targets in a single pass, while maintaining faithfulness. Moreover, we design a recursive attribution mechanism that traces importance through intermediate reasoning chains back to source inputs. Extensive experiments on long-context retrieval (RULER) and multi-step reasoning (MATH, MorehopQA) tasks demonstrate that FlashTrace achieves over 130x speedup over existing baselines while maintaining superior faithfulness. We further analyze the dynamics of recursive attribution, showing that even a single recursive hop improves faithfulness by tracing importance through the reasoning chain.",
      "source": "arXiv",
      "pubDateISO": "2026-02-02",
      "tags": [
        "cs.LG"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.01912v1",
      "title": "Reliable Real-Time Value at Risk Estimation via Quantile Regression Forest with Conformal Calibration",
      "link": "http://arxiv.org/abs/2602.01912v1",
      "pdf_link": "https://arxiv.org/pdf/2602.01912v1",
      "authors": "Du-Yi Wang, Guo Liang, Kun Zhang, Qianwen Zhu",
      "institution": "",
      "abstract": "Rapidly evolving market conditions call for real-time risk monitoring, but its online estimation remains challenging. In this paper, we study the online estimation of one of the most widely used risk measures, Value at Risk (VaR). Its accurate and reliable estimation is essential for timely risk control and informed decision-making. We propose to use the quantile regression forest in the offline-simulation-online-estimation (OSOA) framework. Specifically, the quantile regression forest is trained offline to learn the relationship between the online VaR and risk factors, and real-time VaR estimates are then produced online by incorporating observed risk factors. To further ensure reliability, we develop a conformalized estimator that calibrates the online VaR estimates. To the best of our knowledge, we are the first to leverage conformal calibration to estimate real-time VaR reliably based on the OSOA formulation. Theoretical analysis establishes the consistency and coverage validity of the proposed estimators. Numerical experiments confirm the proposed method and demonstrate its effectiveness in practice.",
      "source": "arXiv",
      "pubDateISO": "2026-02-02",
      "tags": [
        "stat.ML",
        "cs.AI",
        "cs.LG"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.01910v1",
      "title": "DomusFM: A Foundation Model for Smart-Home Sensor Data",
      "link": "http://arxiv.org/abs/2602.01910v1",
      "pdf_link": "https://arxiv.org/pdf/2602.01910v1",
      "authors": "Michele Fiori, Gabriele Civitarese, Flora D. Salim, Claudio Bettini",
      "institution": "",
      "abstract": "Smart-home sensor data holds significant potential for several applications, including healthcare monitoring and assistive technologies. Existing approaches, however, face critical limitations. Supervised models require impractical amounts of labeled data. Foundation models for activity recognition focus only on inertial sensors, failing to address the unique characteristics of smart-home binary sensor events: their sparse, discrete nature combined with rich semantic associations. LLM-based approaches, while tested in this domain, still raise several issues regarding the need for natural language descriptions or prompting, and reliance on either external services or expensive hardware, making them infeasible in real-life scenarios due to privacy and cost concerns. We introduce DomusFM, the first foundation model specifically designed and pretrained for smart-home sensor data. DomusFM employs a self-supervised dual contrastive learning paradigm to capture both token-level semantic attributes and sequence-level temporal dependencies. By integrating semantic embeddings from a lightweight language model and specialized encoders for temporal patterns and binary states, DomusFM learns generalizable representations that transfer across environments and tasks related to activity and event analysis. Through leave-one-dataset-out evaluation across seven public smart-home datasets, we demonstrate that DomusFM outperforms state-of-the-art baselines on different downstream tasks, achieving superior performance even with only 5% of labeled training data available for fine-tuning. Our approach addresses data scarcity while maintaining practical deployability for real-world smart-home systems.",
      "source": "arXiv",
      "pubDateISO": "2026-02-02",
      "tags": [
        "cs.AI"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.01909v1",
      "title": "Propagating the prior from far to near offset: A self-supervised diffusion framework for progressively recovering near-offsets of towed-streamer data",
      "link": "http://arxiv.org/abs/2602.01909v1",
      "pdf_link": "https://arxiv.org/pdf/2602.01909v1",
      "authors": "Shijun Cheng, Tariq Alkhalifah",
      "institution": "",
      "abstract": "In marine towed-streamer seismic acquisition, the nearest hydrophone is often two hundred meter away from the source resulting in missing near-offset traces, which degrades critical processing workflows such as surface-related multiple elimination, velocity analysis, and full-waveform inversion. Existing reconstruction methods, like transform-domain interpolation, often produce kinematic inconsistencies and amplitude distortions, while supervised deep learning approaches require complete ground-truth near-offset data that are unavailable in realistic acquisition scenarios. To address these limitations, we propose a self-supervised diffusion-based framework that reconstructs missing near-offset traces without requiring near-offset reference data. Our method leverages overlapping patch extraction with single-trace shifts from the available far-offset section to train a conditional diffusion model, which learns offset-dependent statistical patterns governing event curvature, amplitude variation, and wavelet characteristics. At inference, we perform trace-by-trace recursive extrapolation from the nearest recorded offset toward zero offset, progressively propagating learned prior information from far to near offsets. The generative formulation further provides uncertainty estimates via ensemble sampling, quantifying prediction confidence where validation data are absent. Controlled validation experiments on synthetic and field datasets show substantial performance gains over conventional parabolic Radon transform baselines. Operational deployment on actual near-offset gaps demonstrates practical viability where ground-truth validation is impossible. Notably, the reconstructed waveforms preserve realistic amplitude-versus-offset trends despite training exclusively on far-offset observations, and uncertainty maps accurately identify challenging extrapolation regions.",
      "source": "arXiv",
      "pubDateISO": "2026-02-02",
      "tags": [
        "cs.LG"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.01906v1",
      "title": "DSXFormer: Dual-Pooling Spectral Squeeze-Expansion and Dynamic Context Attention Transformer for Hyperspectral Image Classification",
      "link": "http://arxiv.org/abs/2602.01906v1",
      "pdf_link": "https://arxiv.org/pdf/2602.01906v1",
      "authors": "Farhan Ullah, Irfan Ullah, Khalil Khan, Giovanni Pau, JaKeoung Koo",
      "institution": "",
      "abstract": "Hyperspectral image classification (HSIC) is a challenging task due to high spectral dimensionality, complex spectral-spatial correlations, and limited labeled training samples. Although transformer-based models have shown strong potential for HSIC, existing approaches often struggle to achieve sufficient spectral discriminability while maintaining computational efficiency. To address these limitations, we propose a novel DSXFormer, a novel dual-pooling spectral squeeze-expansion transformer with Dynamic Context Attention for HSIC. The proposed DSXFormer introduces a Dual-Pooling Spectral Squeeze-Expansion (DSX) block, which exploits complementary global average and max pooling to adaptively recalibrate spectral feature channels, thereby enhancing spectral discriminability and inter-band dependency modeling. In addition, DSXFormer incorporates a Dynamic Context Attention (DCA) mechanism within a window-based transformer architecture to dynamically capture local spectral-spatial relationships while significantly reducing computational overhead. The joint integration of spectral dual-pooling squeeze-expansion and DCA enables DSXFormer to achieve an effective balance between spectral emphasis and spatial contextual representation. Furthermore, patch extraction, embedding, and patch merging strategies are employed to facilitate efficient multi-scale feature learning. Extensive experiments conducted on four widely used hyperspectral benchmark datasets, including Salinas (SA), Indian Pines (IP), Pavia University (PU), and Kennedy Space Center (KSC), demonstrate that DSXFormer consistently outperforms state-of-the-art methods, achieving classification accuracies of 99.95%, 98.91%, 99.85%, and 98.52%, respectively.",
      "source": "arXiv",
      "pubDateISO": "2026-02-02",
      "tags": [
        "cs.CV",
        "cs.AI"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.01905v1",
      "title": "Learning Sparse Visual Representations via Spatial-Semantic Factorization",
      "link": "http://arxiv.org/abs/2602.01905v1",
      "pdf_link": "https://arxiv.org/pdf/2602.01905v1",
      "authors": "Theodore Zhengde Zhao, Sid Kiblawi, Jianwei Yang, Naoto Usuyama, Reuben Tan et al.",
      "institution": "",
      "abstract": "Self-supervised learning (SSL) faces a fundamental conflict between semantic understanding and image reconstruction. High-level semantic SSL (e.g., DINO) relies on global tokens that are forced to be location-invariant for augmentation alignment, a process that inherently discards the spatial coordinates required for reconstruction. Conversely, generative SSL (e.g., MAE) preserves dense feature grids for reconstruction but fails to produce high-level abstractions. We introduce STELLAR, a framework that resolves this tension by factorizing visual features into a low-rank product of semantic concepts and their spatial distributions. This disentanglement allows us to perform DINO-style augmentation alignment on the semantic tokens while maintaining the precise spatial mapping in the localization matrix necessary for pixel-level reconstruction. We demonstrate that as few as 16 sparse tokens under this factorized form are sufficient to simultaneously support high-quality reconstruction (2.60 FID) and match the semantic performance of dense backbones (79.10% ImageNet accuracy). Our results highlight STELLAR as a versatile sparse representation that bridges the gap between discriminative and generative vision by strategically separating semantic identity from spatial geometry. Code available at https://aka.ms/stellar.",
      "source": "arXiv",
      "pubDateISO": "2026-02-02",
      "tags": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.01903v1",
      "title": "Data- and Variance-dependent Regret Bounds for Online Tabular MDPs",
      "link": "http://arxiv.org/abs/2602.01903v1",
      "pdf_link": "https://arxiv.org/pdf/2602.01903v1",
      "authors": "Mingyi Li, Taira Tsuchiya, Kenji Yamanishi",
      "institution": "",
      "abstract": "This work studies online episodic tabular Markov decision processes (MDPs) with known transitions and develops best-of-both-worlds algorithms that achieve refined data-dependent regret bounds in the adversarial regime and variance-dependent regret bounds in the stochastic regime. We quantify MDP complexity using a first-order quantity and several new data-dependent measures for the adversarial regime, including a second-order quantity and a path-length measure, as well as variance-based measures for the stochastic regime. To adapt to these measures, we develop algorithms based on global optimization and policy optimization, both built on optimistic follow-the-regularized-leader with log-barrier regularization. For global optimization, our algorithms achieve first-order, second-order, and path-length regret bounds in the adversarial regime, and in the stochastic regime, they achieve a variance-aware gap-independent bound and a variance-aware gap-dependent bound that is polylogarithmic in the number of episodes. For policy optimization, our algorithms achieve the same data- and variance-dependent adaptivity, up to a factor of the episode horizon, by exploiting a new optimistic $Q$-function estimator. Finally, we establish regret lower bounds in terms of data-dependent complexity measures for the adversarial regime and a variance measure for the stochastic regime, implying that the regret upper bounds achieved by the global-optimization approach are nearly optimal.",
      "source": "arXiv",
      "pubDateISO": "2026-02-02",
      "tags": [
        "cs.LG",
        "stat.ML"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.01901v1",
      "title": "Q Cache: Visual Attention is Valuable in Less than Half of Decode Layers for Multimodal Large Language Model",
      "link": "http://arxiv.org/abs/2602.01901v1",
      "pdf_link": "https://arxiv.org/pdf/2602.01901v1",
      "authors": "Jiedong Zhuang, Lu Lu, Ming Dai, Rui Hu, Jian Chen et al.",
      "institution": "",
      "abstract": "Multimodal large language models (MLLMs) are plagued by exorbitant inference costs attributable to the profusion of visual tokens within the vision encoder. The redundant visual tokens engenders a substantial computational load and key-value (KV) cache footprint bottleneck. Existing approaches focus on token-wise optimization, leveraging diverse intricate token pruning techniques to eliminate non-crucial visual tokens. Nevertheless, these methods often unavoidably undermine the integrity of the KV cache, resulting in failures in long-text generation tasks. To this end, we conduct an in-depth investigation towards the attention mechanism of the model from a new perspective, and discern that attention within more than half of all decode layers are semantic similar. Upon this finding, we contend that the attention in certain layers can be streamlined by inheriting the attention from their preceding layers. Consequently, we propose Lazy Attention, an efficient attention mechanism that enables cross-layer sharing of similar attention patterns. It ingeniously reduces layer-wise redundant computation in attention. In Lazy Attention, we develop a novel layer-shared cache, Q Cache, tailored for MLLMs, which facilitates the reuse of queries across adjacent layers. In particular, Q Cache is lightweight and fully compatible with existing inference frameworks, including Flash Attention and KV cache. Additionally, our method is highly flexible as it is orthogonal to existing token-wise techniques and can be deployed independently or combined with token pruning approaches. Empirical evaluations on multiple benchmarks demonstrate that our method can reduce KV cache usage by over 35% and achieve 1.5x throughput improvement, while sacrificing only approximately 1% of performance on various MLLMs. Compared with SOTA token-wise methods, our technique achieves superior accuracy preservation.",
      "source": "arXiv",
      "pubDateISO": "2026-02-02",
      "tags": [
        "cs.CV"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.01899v1",
      "title": "Multi-Task Learning for Robot Perception with Imbalanced Data",
      "link": "http://arxiv.org/abs/2602.01899v1",
      "pdf_link": "https://arxiv.org/pdf/2602.01899v1",
      "authors": "Ozgur Erkent",
      "institution": "",
      "abstract": "Multi-task problem solving has been shown to improve the accuracy of the individual tasks, which is an important feature for robots, as they have a limited resource. However, when the number of labels for each task is not equal, namely imbalanced data exist, a problem may arise due to insufficient number of samples, and labeling is not very easy for mobile robots in every environment. We propose a method that can learn tasks even in the absence of the ground truth labels for some of the tasks. We also provide a detailed analysis of the proposed method. An interesting finding is related to the interaction of the tasks. We show a methodology to find out which tasks can improve the performance of other tasks. We investigate this by training the teacher network with the task outputs such as depth as inputs. We further provide empirical evidence when trained with a small amount of data. We use semantic segmentation and depth estimation tasks on different datasets, NYUDv2 and Cityscapes.",
      "source": "arXiv",
      "pubDateISO": "2026-02-02",
      "tags": [
        "cs.RO",
        "cs.CV"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.01898v1",
      "title": "Observation-dependent Bayesian active learning via input-warped Gaussian processes",
      "link": "http://arxiv.org/abs/2602.01898v1",
      "pdf_link": "https://arxiv.org/pdf/2602.01898v1",
      "authors": "Sanna Jarl, Maria Bånkestad, Jonathan J. S. Scragg, Jens Sjölund",
      "institution": "",
      "abstract": "Bayesian active learning relies on the precise quantification of predictive uncertainty to explore unknown function landscapes. While Gaussian process surrogates are the standard for such tasks, an underappreciated fact is that their posterior variance depends on the observed outputs only through the hyperparameters, rendering exploration largely insensitive to the actual measurements. We propose to inject observation-dependent feedback by warping the input space with a learned, monotone reparameterization. This mechanism allows the design policy to expand or compress regions of the input space in response to observed variability, thereby shaping the behavior of variance-based acquisition functions. We demonstrate that while such warps can be trained via marginal likelihood, a novel self-supervised objective yields substantially better performance. Our approach improves sample efficiency across a range of active learning benchmarks, particularly in regimes where non-stationarity challenges traditional methods.",
      "source": "arXiv",
      "pubDateISO": "2026-02-02",
      "tags": [
        "cs.LG",
        "stat.ML"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.01897v1",
      "title": "Internal Flow Signatures for Self-Checking and Refinement in LLMs",
      "link": "http://arxiv.org/abs/2602.01897v1",
      "pdf_link": "https://arxiv.org/pdf/2602.01897v1",
      "authors": "Sungheon Jeong, Sanggeon Yun, Ryozo Masukawa, Wenjun Haung, Hanning Chen et al.",
      "institution": "",
      "abstract": "Large language models can generate fluent answers that are unfaithful to the provided context, while many safeguards rely on external verification or a separate judge after generation. We introduce \\emph{internal flow signatures} that audit decision formation from depthwise dynamics at a fixed inter-block monitoring boundary. The method stabilizes token-wise motion via bias-centered monitoring, then summarizes trajectories in compact \\emph{moving} readout-aligned subspaces constructed from the top token and its close competitors within each depth window. Neighboring window frames are aligned by an orthogonal transport, yielding depth-comparable transported step lengths, turning angles, and subspace drift summaries that are invariant to within-window basis choices. A lightweight GRU validator trained on these signatures performs self-checking without modifying the base model. Beyond detection, the validator localizes a culprit depth event and enables a targeted refinement: the model rolls back to the culprit token and clamps an abnormal transported step at the identified block while preserving the orthogonal residual. The resulting pipeline provides actionable localization and low-overhead self-checking from internal decision dynamics. \\emph{Code is available at} \\texttt{github.com/EavnJeong/Internal-Flow-Signatures-for-Self-Checking-and-Refinement-in-LLMs}.",
      "source": "arXiv",
      "pubDateISO": "2026-02-02",
      "tags": [
        "cs.LG"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.01893v1",
      "title": "Geometric Analysis of Token Selection in Multi-Head Attention",
      "link": "http://arxiv.org/abs/2602.01893v1",
      "pdf_link": "https://arxiv.org/pdf/2602.01893v1",
      "authors": "Timur Mudarisov, Mikhal Burtsev, Tatiana Petrova, Radu State",
      "institution": "",
      "abstract": "We present a geometric framework for analysing multi-head attention in large language models (LLMs). Without altering the mechanism, we view standard attention through a top-N selection lens and study its behaviour directly in value-state space. We define geometric metrics - Precision, Recall, and F-score - to quantify separability between selected and non-selected tokens, and derive non-asymptotic bounds with explicit dependence on dimension and margin under empirically motivated assumptions (stable value norms with a compressed sink token, exponential similarity decay, and piecewise attention weight profiles). The theory predicts a small-N operating regime of strongest non-trivial separability and clarifies how sequence length and sink similarity shape the metrics. Empirically, across LLaMA-2-7B, Gemma-7B, and Mistral-7B, measurements closely track the theoretical envelopes: top-N selection sharpens separability, sink similarity correlates with Recall. We also found that in LLaMA-2-7B heads specialize into three regimes - Retriever, Mixer, Reset - with distinct geometric signatures. Overall, attention behaves as a structured geometric classifier with measurable criteria for token selection, offering head level interpretability and informing geometry-aware sparsification and design of attention in LLMs.",
      "source": "arXiv",
      "pubDateISO": "2026-02-02",
      "tags": [
        "cs.AI",
        "cs.LG"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.01885v1",
      "title": "ES-MemEval: Benchmarking Conversational Agents on Personalized Long-Term Emotional Support",
      "link": "http://arxiv.org/abs/2602.01885v1",
      "pdf_link": "https://arxiv.org/pdf/2602.01885v1",
      "authors": "Tiantian Chen, Jiaqi Lu, Ying Shen, Lin Zhang",
      "institution": "",
      "abstract": "Large Language Models (LLMs) have shown strong potential as conversational agents. Yet, their effectiveness remains limited by deficiencies in robust long-term memory, particularly in complex, long-term web-based services such as online emotional support. However, existing long-term dialogue benchmarks primarily focus on static and explicit fact retrieval, failing to evaluate agents in critical scenarios where user information is dispersed, implicit, and continuously evolving. To address this gap, we introduce ES-MemEval, a comprehensive benchmark that systematically evaluates five core memory capabilities: information extraction, temporal reasoning, conflict detection, abstention, and user modeling, in long-term emotional support settings, covering question answering, summarization, and dialogue generation tasks. To support the benchmark, we also propose EvoEmo, a multi-session dataset for personalized long-term emotional support that captures fragmented, implicit user disclosures and evolving user states. Extensive experiments on open-source long-context, commercial, and retrieval-augmented (RAG) LLMs show that explicit long-term memory is essential for reducing hallucinations and enabling effective personalization. At the same time, RAG improves factual consistency but struggles with temporal dynamics and evolving user states. These findings highlight both the potential and limitations of current paradigms and motivate more robust integration of memory and retrieval for long-term personalized dialogue systems.",
      "source": "arXiv",
      "pubDateISO": "2026-02-02",
      "tags": [
        "cs.CL",
        "cs.AI"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.01884v1",
      "title": "Entropy-Guided Data-Efficient Training for Multimodal Reasoning Reward Models",
      "link": "http://arxiv.org/abs/2602.01884v1",
      "pdf_link": "https://arxiv.org/pdf/2602.01884v1",
      "authors": "Shidong Yang, Tongwen Huang, Hao Wen, Yong Wang, Li Chen et al.",
      "institution": "",
      "abstract": "Multimodal reward models are crucial for aligning multimodal large language models with human preferences. Recent works have incorporated reasoning capabilities into these models, achieving promising results. However, training these models suffers from two critical challenges: (1) the inherent noise in preference datasets, which degrades model performance, and (2) the inefficiency of conventional training methods, which ignore the differences in sample difficulty. In this paper, we identify a strong correlation between response entropy and accuracy, indicating that entropy can serve as a reliable and unsupervised proxy for annotation noise and sample difficulty. Based on this insight, we propose a novel Entropy-Guided Training (EGT) approach for multimodal reasoning reward models, which combines two strategies: (1) entropy-guided data curation to mitigate the impact of unreliable samples, and (2) an entropy-guided training strategy that progressively introduces more complex examples. Extensive experiments across three benchmarks show that the EGT-trained model consistently outperforms state-of-the-art multimodal reward models.",
      "source": "arXiv",
      "pubDateISO": "2026-02-02",
      "tags": [
        "cs.AI",
        "cs.LG"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.01881v1",
      "title": "ProxyImg: Towards Highly-Controllable Image Representation via Hierarchical Disentangled Proxy Embedding",
      "link": "http://arxiv.org/abs/2602.01881v1",
      "pdf_link": "https://arxiv.org/pdf/2602.01881v1",
      "authors": "Ye Chen, Yupeng Zhu, Xiongzhen Zhang, Zhewen Wan, Yingzhe Li et al.",
      "institution": "",
      "abstract": "Prevailing image representation methods, including explicit representations such as raster images and Gaussian primitives, as well as implicit representations such as latent images, either suffer from representation redundancy that leads to heavy manual editing effort, or lack a direct mapping from latent variables to semantic instances or parts, making fine-grained manipulation difficult. These limitations hinder efficient and controllable image and video editing. To address these issues, we propose a hierarchical proxy-based parametric image representation that disentangles semantic, geometric, and textural attributes into independent and manipulable parameter spaces. Based on a semantic-aware decomposition of the input image, our representation constructs hierarchical proxy geometries through adaptive Bezier fitting and iterative internal region subdivision and meshing. Multi-scale implicit texture parameters are embedded into the resulting geometry-aware distributed proxy nodes, enabling continuous high-fidelity reconstruction in the pixel domain and instance- or part-independent semantic editing. In addition, we introduce a locality-adaptive feature indexing mechanism to ensure spatial texture coherence, which further supports high-quality background completion without relying on generative models. Extensive experiments on image reconstruction and editing benchmarks, including ImageNet, OIR-Bench, and HumanEdit, demonstrate that our method achieves state-of-the-art rendering fidelity with significantly fewer parameters, while enabling intuitive, interactive, and physically plausible manipulation. Moreover, by integrating proxy nodes with Position-Based Dynamics, our framework supports real-time physics-driven animation using lightweight implicit rendering, achieving superior temporal consistency and visual realism compared with generative approaches.",
      "source": "arXiv",
      "pubDateISO": "2026-02-02",
      "tags": [
        "cs.CV"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.01877v1",
      "title": "Autocorrelated Optimize-via-Estimate: Predict-then-Optimize versus Finite-sample Optimal",
      "link": "http://arxiv.org/abs/2602.01877v1",
      "pdf_link": "https://arxiv.org/pdf/2602.01877v1",
      "authors": "Zichun Wang, Gar Goei Loke, Ruiting Zuo",
      "institution": "",
      "abstract": "Models that directly optimize for out-of-sample performance in the finite-sample regime have emerged as a promising alternative to traditional estimate-then-optimize approaches in data-driven optimization. In this work, we compare their performance in the context of autocorrelated uncertainties, specifically, under a Vector Autoregressive Moving Average VARMA(p,q) process. We propose an autocorrelated Optimize-via-Estimate (A-OVE) model that obtains an out-of-sample optimal solution as a function of sufficient statistics, and propose a recursive form for computing its sufficient statistics. We evaluate these models on a portfolio optimization problem with trading costs. A-OVE achieves low regret relative to a perfect information oracle, outperforming predict-then-optimize machine learning benchmarks. Notably, machine learning models with higher accuracy can have poorer decision quality, echoing the growing literature in data-driven optimization. Performance is retained under small mis-specification.",
      "source": "arXiv",
      "pubDateISO": "2026-02-02",
      "tags": [
        "cs.LG"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.01875v1",
      "title": "PretrainRL: Alleviating Factuality Hallucination of Large Language Models at the Beginning",
      "link": "http://arxiv.org/abs/2602.01875v1",
      "pdf_link": "https://arxiv.org/pdf/2602.01875v1",
      "authors": "Langming Liu, Kangtao Lv, Haibin Chen, Weidong Zhang, Yejing Wang et al.",
      "institution": "",
      "abstract": "Large language models (LLMs), despite their powerful capabilities, suffer from factual hallucinations where they generate verifiable falsehoods. We identify a root of this issue: the imbalanced data distribution in the pretraining corpus, which leads to a state of \"low-probability truth\" and \"high-probability falsehood\". Recent approaches, such as teaching models to say \"I don't know\" or post-hoc knowledge editing, either evade the problem or face catastrophic forgetting. To address this issue from its root, we propose \\textbf{PretrainRL}, a novel framework that integrates reinforcement learning into the pretraining phase to consolidate factual knowledge. The core principle of PretrainRL is \"\\textbf{debiasing then learning}.\" It actively reshapes the model's probability distribution by down-weighting high-probability falsehoods, thereby making \"room\" for low-probability truths to be learned effectively. To enable this, we design an efficient negative sampling strategy to discover these high-probability falsehoods and introduce novel metrics to evaluate the model's probabilistic state concerning factual knowledge. Extensive experiments on three public benchmarks demonstrate that PretrainRL significantly alleviates factual hallucinations and outperforms state-of-the-art methods.",
      "source": "arXiv",
      "pubDateISO": "2026-02-02",
      "tags": [
        "cs.CL"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.01872v1",
      "title": "Grappa: Gradient-Only Communication for Scalable Graph Neural Network Training",
      "link": "http://arxiv.org/abs/2602.01872v1",
      "pdf_link": "https://arxiv.org/pdf/2602.01872v1",
      "authors": "Chongyang Xu, Christoph Siebenbrunner, Laurent Bindschaedler",
      "institution": "",
      "abstract": "Cross-partition edges dominate the cost of distributed GNN training: fetching remote features and activations per iteration overwhelms the network as graphs deepen and partition counts grow. Grappa is a distributed GNN training framework that enforces gradient-only communication: during each iteration, partitions train in isolation and exchange only gradients for the global update. To recover accuracy lost to isolation, Grappa (i) periodically repartitions to expose new neighborhoods and (ii) applies a lightweight coverage-corrected gradient aggregation inspired by importance sampling. We prove the corrected estimator is asymptotically unbiased under standard support and boundedness assumptions, and we derive a batch-level variant for compatibility with common deep-learning packages that minimizes mean-squared deviation from the ideal node-level correction. We also introduce a shrinkage version that improves stability in practice. Empirical results on real and synthetic graphs show that Grappa trains GNNs 4 times faster on average (up to 13 times) than state-of-the-art systems, achieves better accuracy especially for deeper models, and sustains training at the trillion-edge scale on commodity hardware. Grappa is model-agnostic, supports full-graph and mini-batch training, and does not rely on high-bandwidth interconnects or caching.",
      "source": "arXiv",
      "pubDateISO": "2026-02-02",
      "tags": [
        "cs.DC",
        "cs.LG"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.01869v1",
      "title": "ProcMEM: Learning Reusable Procedural Memory from Experience via Non-Parametric PPO for LLM Agents",
      "link": "http://arxiv.org/abs/2602.01869v1",
      "pdf_link": "https://arxiv.org/pdf/2602.01869v1",
      "authors": "Qirui Mi, Zhijian Ma, Mengyue Yang, Haoxuan Li, Yisen Wang et al.",
      "institution": "",
      "abstract": "LLM-driven agents demonstrate strong performance in sequential decision-making but often rely on on-the-fly reasoning, re-deriving solutions even in recurring scenarios. This insufficient experience reuse leads to computational redundancy and execution instability. To bridge this gap, we propose ProcMEM, a framework that enables agents to autonomously learn procedural memory from interaction experiences without parameter updates. By formalizing a Skill-MDP, ProcMEM transforms passive episodic narratives into executable Skills defined by activation, execution, and termination conditions to ensure executability. To achieve reliable reusability without capability degradation, we introduce Non-Parametric PPO, which leverages semantic gradients for high-quality candidate generation and a PPO Gate for robust Skill verification. Through score-based maintenance, ProcMEM sustains compact, high-quality procedural memory. Experimental results across in-domain, cross-task, and cross-agent scenarios demonstrate that ProcMEM achieves superior reuse rates and significant performance gains with extreme memory compression. Visualized evolutionary trajectories and Skill distributions further reveal how ProcMEM transparently accumulates, refines, and reuses procedural knowledge to facilitate long-term autonomy.",
      "source": "arXiv",
      "pubDateISO": "2026-02-02",
      "tags": [
        "cs.AI"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.01865v1",
      "title": "GRAB: An LLM-Inspired Sequence-First Click-Through Rate Prediction Modeling Paradigm",
      "link": "http://arxiv.org/abs/2602.01865v1",
      "pdf_link": "https://arxiv.org/pdf/2602.01865v1",
      "authors": "Shaopeng Chen, Chuyue Xie, Huimin Ren, Shaozong Zhang, Han Zhang et al.",
      "institution": "",
      "abstract": "Traditional Deep Learning Recommendation Models (DLRMs) face increasing bottlenecks in performance and efficiency, often struggling with generalization and long-sequence modeling. Inspired by the scaling success of Large Language Models (LLMs), we propose Generative Ranking for Ads at Baidu (GRAB), an end-to-end generative framework for Click-Through Rate (CTR) prediction. GRAB integrates a novel Causal Action-aware Multi-channel Attention (CamA) mechanism to effectively capture temporal dynamics and specific action signals within user behavior sequences. Full-scale online deployment demonstrates that GRAB significantly outperforms established DLRMs, delivering a 3.05% increase in revenue and a 3.49% rise in CTR. Furthermore, the model demonstrates desirable scaling behavior: its expressive power shows a monotonic and approximately linear improvement as longer interaction sequences are utilized.",
      "source": "arXiv",
      "pubDateISO": "2026-02-02",
      "tags": [
        "cs.IR",
        "cs.AI"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.01864v1",
      "title": "Trust but Verify: Adaptive Conditioning for Reference-Based Diffusion Super-Resolution via Implicit Reference Correlation Modeling",
      "link": "http://arxiv.org/abs/2602.01864v1",
      "pdf_link": "https://arxiv.org/pdf/2602.01864v1",
      "authors": "Yuan Wang, Yuhao Wan, Siming Zheng, Bo Li, Qibin Hou et al.",
      "institution": "",
      "abstract": "Recent works have explored reference-based super-resolution (RefSR) to mitigate hallucinations in diffusion-based image restoration. A key challenge is that real-world degradations make correspondences between low-quality (LQ) inputs and reference (Ref) images unreliable, requiring adaptive control of reference usage. Existing methods either ignore LQ-Ref correlations or rely on brittle explicit matching, leading to over-reliance on misleading references or under-utilization of valuable cues. To address this, we propose Ada-RefSR, a single-step diffusion framework guided by a \"Trust but Verify\" principle: reference information is leveraged when reliable and suppressed otherwise. Its core component, Adaptive Implicit Correlation Gating (AICG), employs learnable summary tokens to distill dominant reference patterns and capture implicit correlations with LQ features. Integrated into the attention backbone, AICG provides lightweight, adaptive regulation of reference guidance, serving as a built-in safeguard against erroneous fusion. Experiments on multiple datasets demonstrate that Ada-RefSR achieves a strong balance of fidelity, naturalness, and efficiency, while remaining robust under varying reference alignment.",
      "source": "arXiv",
      "pubDateISO": "2026-02-02",
      "tags": [
        "cs.CV"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.01863v1",
      "title": "Transformers as Measure-Theoretic Associative Memory: A Statistical Perspective and Minimax Optimality",
      "link": "http://arxiv.org/abs/2602.01863v1",
      "pdf_link": "https://arxiv.org/pdf/2602.01863v1",
      "authors": "Ryotaro Kawata, Taiji Suzuki",
      "institution": "",
      "abstract": "Transformers excel through content-addressable retrieval and the ability to exploit contexts of, in principle, unbounded length. We recast associative memory at the level of probability measures, treating a context as a distribution over tokens and viewing attention as an integral operator on measures. Concretely, for mixture contexts $ν= I^{-1} \\sum_{i=1}^I μ^{(i^*)}$ and a query $x_{\\mathrm{q}}(i^*)$, the task decomposes into (i) recall of the relevant component $μ^{(i^*)}$ and (ii) prediction from $(μ_{i^*},x_\\mathrm{q})$. We study learned softmax attention (not a frozen kernel) trained by empirical risk minimization and show that a shallow measure-theoretic Transformer composed with an MLP learns the recall-and-predict map under a spectral assumption on the input densities. We further establish a matching minimax lower bound with the same rate exponent (up to multiplicative constants), proving sharpness of the convergence order. The framework offers a principled recipe for designing and analyzing Transformers that recall from arbitrarily long, distributional contexts with provable generalization guarantees.",
      "source": "arXiv",
      "pubDateISO": "2026-02-02",
      "tags": [
        "stat.ML",
        "cs.LG"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.01861v1",
      "title": "RIR-Former: Coordinate-Guided Transformer for Continuous Reconstruction of Room Impulse Responses",
      "link": "http://arxiv.org/abs/2602.01861v1",
      "pdf_link": "https://arxiv.org/pdf/2602.01861v1",
      "authors": "Shaoheng Xu, Chunyi Sun,  Jihui,  Zhang, Prasanga N. Samarasinghe et al.",
      "institution": "",
      "abstract": "Room impulse responses (RIRs) are essential for many acoustic signal processing tasks, yet measuring them densely across space is often impractical. In this work, we propose RIR-Former, a grid-free, one-step feed-forward model for RIR reconstruction. By introducing a sinusoidal encoding module into a transformer backbone, our method effectively incorporates microphone position information, enabling interpolation at arbitrary array locations. Furthermore, a segmented multi-branch decoder is designed to separately handle early reflections and late reverberation, improving reconstruction across the entire RIR. Experiments on diverse simulated acoustic environments demonstrate that RIR-Former consistently outperforms state-of-the-art baselines in terms of normalized mean square error (NMSE) and cosine distance (CD), under varying missing rates and array configurations. These results highlight the potential of our approach for practical deployment and motivate future work on scaling from randomly spaced linear arrays to complex array geometries, dynamic acoustic scenes, and real-world environments.",
      "source": "arXiv",
      "pubDateISO": "2026-02-02",
      "tags": [
        "cs.LG"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.01858v1",
      "title": "SOPRAG: Multi-view Graph Experts Retrieval for Industrial Standard Operating Procedures",
      "link": "http://arxiv.org/abs/2602.01858v1",
      "pdf_link": "https://arxiv.org/pdf/2602.01858v1",
      "authors": "Liangtao Lin, Zhaomeng Zhu, Tianwei Zhang, Yonggang Wen",
      "institution": "",
      "abstract": "Standard Operating Procedures (SOPs) are essential for ensuring operational safety and consistency in industrial environments. However, retrieving and following these procedures presents unique challenges, such as rigid proprietary structures, condition-dependent relevance, and actionable execution requirement, which standard semantic-driven Retrieval-Augmented Generation (RAG) paradigms fail to address. Inspired by the Mixture-of-Experts (MoE) paradigm, we propose SOPRAG, a novel framework specifically designed to address the above pain points in SOP retrieval. SOPRAG replaces flat chunking with specialized Entity, Causal, and Flow graph experts to resolve industrial structural and logical complexities. To optimize and coordinate these experts, we propose a Procedure Card layer that prunes the search space to eliminate computational noise, and an LLM-Guided gating mechanism that dynamically weights these experts to align retrieval with operator intent. To address the scarcity of domain-specific data, we also introduce an automated, multi-agent workflow for benchmark construction. Extensive experiments across four industrial domains demonstrate that SOPRAG significantly outperforms strong lexical, dense, and graph-based RAG baselines in both retrieval accuracy and response utility, achieving perfect execution scores in real-world critical tasks.",
      "source": "arXiv",
      "pubDateISO": "2026-02-02",
      "tags": [
        "cs.AI"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.01855v1",
      "title": "Time2Vec-Integrated Transformer for Robust Gesture Recognition from Low-Density sEMG",
      "link": "http://arxiv.org/abs/2602.01855v1",
      "pdf_link": "https://arxiv.org/pdf/2602.01855v1",
      "authors": "Blagoj Hristov, Hristijan Gjoreski, Vesna Ojleska Latkoska, Gorjan Nadzinski",
      "institution": "",
      "abstract": "Accurate and responsive myoelectric prosthesis control typically relies on complex, dense multi-sensor arrays, which limits consumer accessibility. This paper presents a novel, data-efficient deep learning framework designed to achieve precise and accurate control using minimal sensor hardware. Leveraging an external dataset of 8 subjects, our approach implements a hybrid Transformer optimized for sparse, two-channel surface electromyography (sEMG). Unlike standard architectures that use fixed positional encodings, we integrate Time2Vec learnable temporal embeddings to capture the stochastic temporal warping inherent in biological signals. Furthermore, we employ a normalized additive fusion strategy that aligns the latent distributions of spatial and temporal features, preventing the destructive interference common in standard implementations. A two-stage curriculum learning protocol is utilized to ensure robust feature extraction despite data scarcity. The proposed architecture achieves a state-of-the-art multi-subject F1-score of 95.7% $\\pm$ 0.20% for a 10-class movement set, statistically outperforming both a standard Transformer with fixed encodings and a recurrent CNN-LSTM model. Architectural optimization reveals that a balanced allocation of model capacity between spatial and temporal dimensions yields the highest stability. Furthermore, while direct transfer to a new unseen subject led to poor accuracy due to domain shifts, a rapid calibration protocol utilizing only two trials per gesture recovered performance from 21.0% $\\pm$ 2.98% to 96.9% $\\pm$ 0.52%. By validating that high-fidelity temporal embeddings can compensate for low spatial resolution, this work challenges the necessity of high-density sensing. The proposed framework offers a robust, cost-effective blueprint for next-generation prosthetic interfaces capable of rapid personalization.",
      "source": "arXiv",
      "pubDateISO": "2026-02-02",
      "tags": [
        "cs.LG",
        "cs.AI"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.01854v1",
      "title": "Fact or Fake? Assessing the Role of Deepfake Detectors in Multimodal Misinformation Detection",
      "link": "http://arxiv.org/abs/2602.01854v1",
      "pdf_link": "https://arxiv.org/pdf/2602.01854v1",
      "authors": "A S M Sharifuzzaman Sagar, Mohammed Bennamoun, Farid Boussaid, Naeha Sharif, Lian Xu et al.",
      "institution": "",
      "abstract": "In multimodal misinformation, deception usually arises not just from pixel-level manipulations in an image, but from the semantic and contextual claim jointly expressed by the image-text pair. Yet most deepfake detectors, engineered to detect pixel-level forgeries, do not account for claim-level meaning, despite their growing integration in automated fact-checking (AFC) pipelines. This raises a central scientific and practical question: Do pixel-level detectors contribute useful signal for verifying image-text claims, or do they instead introduce misleading authenticity priors that undermine evidence-based reasoning? We provide the first systematic analysis of deepfake detectors in the context of multimodal misinformation detection. Using two complementary benchmarks, MMFakeBench and DGM4, we evaluate: (1) state-of-the-art image-only deepfake detectors, (2) an evidence-driven fact-checking system that performs tool-guided retrieval via Monte Carlo Tree Search (MCTS) and engages in deliberative inference through Multi-Agent Debate (MAD), and (3) a hybrid fact-checking system that injects detector outputs as auxiliary evidence. Results across both benchmark datasets show that deepfake detectors offer limited standalone value, achieving F1 scores in the range of 0.26-0.53 on MMFakeBench and 0.33-0.49 on DGM4, and that incorporating their predictions into fact-checking pipelines consistently reduces performance by 0.04-0.08 F1 due to non-causal authenticity assumptions. In contrast, the evidence-centric fact-checking system achieves the highest performance, reaching F1 scores of approximately 0.81 on MMFakeBench and 0.55 on DGM4. Overall, our findings demonstrate that multimodal claim verification is driven primarily by semantic understanding and external evidence, and that pixel-level artifact signals do not reliably enhance reasoning over real-world image-text misinformation.",
      "source": "arXiv",
      "pubDateISO": "2026-02-02",
      "tags": [
        "cs.CV"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.01853v1",
      "title": "Designing Time Series Experiments in A/B Testing with Transformer Reinforcement Learning",
      "link": "http://arxiv.org/abs/2602.01853v1",
      "pdf_link": "https://arxiv.org/pdf/2602.01853v1",
      "authors": "Xiangkun Wu, Qianglin Wen, Yingying Zhang, Hongtu Zhu, Ting Li et al.",
      "institution": "",
      "abstract": "A/B testing has become a gold standard for modern technological companies to conduct policy evaluation. Yet, its application to time series experiments, where policies are sequentially assigned over time, remains challenging. Existing designs suffer from two limitations: (i) they do not fully leverage the entire history for treatment allocation; (ii) they rely on strong assumptions to approximate the objective function (e.g., the mean squared error of the estimated treatment effect) for optimizing the design. We first establish an impossibility theorem showing that failure to condition on the full history leads to suboptimal designs, due to the dynamic dependencies in time series experiments. To address both limitations simultaneously, we next propose a transformer reinforcement learning (RL) approach which leverages transformers to condition allocation on the entire history and employs RL to directly optimize the MSE without relying on restrictive assumptions. Empirical evaluations on synthetic data, a publicly available dispatch simulator, and a real-world ridesharing dataset demonstrate that our proposal consistently outperforms existing designs.",
      "source": "arXiv",
      "pubDateISO": "2026-02-02",
      "tags": [
        "cs.LG",
        "stat.ME",
        "stat.ML"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.01852v1",
      "title": "FUPareto: Bridging the Forgetting-Utility Gap in Federated Unlearning via Pareto Augmented Optimization",
      "link": "http://arxiv.org/abs/2602.01852v1",
      "pdf_link": "https://arxiv.org/pdf/2602.01852v1",
      "authors": "Zeyan Wang, Zhengmao Liu, Yongxin Cai, Chi Li, Xiaoying Tang et al.",
      "institution": "",
      "abstract": "Federated Unlearning (FU) aims to efficiently remove the influence of specific client data from a federated model while preserving utility for the remaining clients. However, three key challenges remain: (1) existing unlearning objectives often compromise model utility or increase vulnerability to Membership Inference Attacks (MIA); (2) there is a persistent conflict between forgetting and utility, where further unlearning inevitably harms retained performance; and (3) support for concurrent multi-client unlearning is poor, as gradient conflicts among clients degrade the quality of forgetting. To address these issues, we propose FUPareto, an efficient unlearning framework via Pareto-augmented optimization. We first introduce the Minimum Boundary Shift (MBS) Loss, which enforces unlearning by suppressing the target class logit below the highest non-target class logit; this can improve the unlearning efficiency and mitigate MIA risks. During the unlearning process, FUPareto performs Pareto improvement steps to preserve model utility and executes Pareto expansion to guarantee forgetting. Specifically, during Pareto expansion, the framework integrates a Null-Space Projected Multiple Gradient Descent Algorithm (MGDA) to decouple gradient conflicts. This enables effective, fair, and concurrent unlearning for multiple clients while minimizing utility degradation. Extensive experiments across diverse scenarios demonstrate that FUPareto consistently outperforms state-of-the-art FU methods in both unlearning efficacy and retained utility.",
      "source": "arXiv",
      "pubDateISO": "2026-02-02",
      "tags": [
        "cs.LG",
        "cs.DC"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.01850v1",
      "title": "WS-IMUBench: Can Weakly Supervised Methods from Audio, Image, and Video Be Adapted for IMU-based Temporal Action Localization?",
      "link": "http://arxiv.org/abs/2602.01850v1",
      "pdf_link": "https://arxiv.org/pdf/2602.01850v1",
      "authors": "Pei Li, Jiaxi Yin, Lei Ouyang, Shihan Pan, Ge Wang et al.",
      "institution": "",
      "abstract": "IMU-based Human Activity Recognition (HAR) has enabled a wide range of ubiquitous computing applications, yet its dominant clip classification paradigm cannot capture the rich temporal structure of real-world behaviors. This motivates a shift toward IMU Temporal Action Localization (IMU-TAL), which predicts both action categories and their start/end times in continuous streams. However, current progress is strongly bottlenecked by the need for dense, frame-level boundary annotations, which are costly and difficult to scale. To address this bottleneck, we introduce WS-IMUBench, a systematic benchmark study of weakly supervised IMU-TAL (WS-IMU-TAL) under only sequence-level labels. Rather than proposing a new localization algorithm, we evaluate how well established weakly supervised localization paradigms from audio, image, and video transfer to IMU-TAL under only sequence-level labels. We benchmark seven representative weakly supervised methods on seven public IMU datasets, resulting in over 3,540 model training runs and 7,080 inference evaluations. Guided by three research questions on transferability, effectiveness, and insights, our findings show that (i) transfer is modality-dependent, with temporal-domain methods generally more stable than image-derived proposal-based approaches; (ii) weak supervision can be competitive on favorable datasets (e.g., with longer actions and higher-dimensional sensing); and (iii) dominant failure modes arise from short actions, temporal ambiguity, and proposal quality. Finally, we outline concrete directions for advancing WS-IMU-TAL (e.g., IMU-specific proposal generation, boundary-aware objectives, and stronger temporal reasoning). Beyond individual results, WS-IMUBench establishes a reproducible benchmarking template, datasets, protocols, and analyses, to accelerate community-wide progress toward scalable WS-IMU-TAL.",
      "source": "arXiv",
      "pubDateISO": "2026-02-02",
      "tags": [
        "cs.CV"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.01849v1",
      "title": "Self-Rewarding Sequential Monte Carlo for Masked Diffusion Language Models",
      "link": "http://arxiv.org/abs/2602.01849v1",
      "pdf_link": "https://arxiv.org/pdf/2602.01849v1",
      "authors": "Ziwei Luo, Ziqi Jin, Lei Wang, Lidong Bing, Thomas B. Schön",
      "institution": "",
      "abstract": "This work presents self-rewarding sequential Monte Carlo (SMC), an inference-time scaling algorithm enabling effective sampling of masked diffusion language models (MDLMs). Our algorithm stems from the observation that most existing MDLMs rely on a confidence-based sampling strategy, where only tokens with the highest prediction confidence are preserved at each step. This restricts the generation to a noise-sensitive, greedy decoding paradigm, resulting in an inevitable collapse in the diversity of possible paths. We address this problem by launching multiple interacting diffusion processes in parallel, referred to as particles, for trajectory exploration. Importantly, we introduce the trajectory-level confidence as a self-rewarding signal for assigning particle importance weights. During sampling, particles are iteratively weighted and resampled to systematically steer generation towards globally confident, high-quality samples. Our self-rewarding SMC is verified on various masked diffusion language models and benchmarks, achieving significant improvement without extra training or reward guidance, while effectively converting parallel inference capacity into improved sampling quality. Our code is available at https://github.com/Algolzw/self-rewarding-smc.",
      "source": "arXiv",
      "pubDateISO": "2026-02-02",
      "tags": [
        "cs.LG"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.01848v1",
      "title": "ROMA: Recursive Open Meta-Agent Framework for Long-Horizon Multi-Agent Systems",
      "link": "http://arxiv.org/abs/2602.01848v1",
      "pdf_link": "https://arxiv.org/pdf/2602.01848v1",
      "authors": "Salaheddin Alzu'bi, Baran Nama, Arda Kaz, Anushri Eswaran, Weiyuan Chen et al.",
      "institution": "",
      "abstract": "Current agentic frameworks underperform on long-horizon tasks. As reasoning depth increases, sequential orchestration becomes brittle, context windows impose hard limits that degrade performance, and opaque execution traces make failures difficult to localize or debug. We introduce ROMA (Recursive Open Meta-Agents), a domain-agnostic framework that addresses these limitations through recursive task decomposition and structured aggregation. ROMA decomposes goals into dependency-aware subtask trees that can be executed in parallel, while aggregation compresses and validates intermediate results to control context growth. Our framework standardizes agent construction around four modular roles --Atomizer (which decides whether a task should be decomposed), Planner, Executor, and Aggregator -- which cleanly separate orchestration from model selection and enable transparent, hierarchical execution traces. This design supports heterogeneous multi-agent systems that mix models and tools according to cost, latency, and capability. To adapt ROMA to specific tasks without fine-tuning, we further introduce GEPA$+$, an improved Genetic-Pareto prompt proposer that searches over prompts within ROMA's component hierarchy while preserving interface contracts. We show that ROMA, combined with GEPA+, delivers leading system-level performance on reasoning and long-form generation benchmarks. On SEAL-0, which evaluates reasoning over conflicting web evidence, ROMA instantiated with GLM-4.6 improves accuracy by 9.9\\% over Kimi-Researcher. On EQ-Bench, a long-form writing benchmark, ROMA enables DeepSeek-V3 to match the performance of leading closed-source models such as Claude Sonnet 4.5. Our results demonstrate that recursive, modular agent architectures can scale reasoning depth while remaining interpretable, flexible, and model-agnostic.",
      "source": "arXiv",
      "pubDateISO": "2026-02-02",
      "tags": [
        "cs.AI",
        "cs.MA"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.01845v1",
      "title": "No Generation without Representation: Efficient Causal Protein Language Models Enable Zero-Shot Fitness Estimation",
      "link": "http://arxiv.org/abs/2602.01845v1",
      "pdf_link": "https://arxiv.org/pdf/2602.01845v1",
      "authors": "Furkan Eris",
      "institution": "",
      "abstract": "Protein language models (PLMs) face a fundamental divide: masked language models (MLMs) excel at fitness prediction while causal models enable generation, forcing practitioners to maintain separate architectures. We introduce \\textbf{Proust}, a 309M-parameter causal PLM that bridges this gap through architectural innovations adapted from recent LLM research, including grouped-query attention with shared K/V projections, cross-layer value residuals, and depthwise causal convolutions. Trained on 33B tokens in 40 B200 GPU-hours, Proust achieves Spearman $ρ= 0.390$ on ProteinGym substitutions, competitive with MLMs requiring 50--200$\\times$ the compute. On indels, Proust sets a new state-of-the-art, outperforming models up to 20$\\times$ larger. On EVEREST viral fitness benchmarks, it approaches structure-aware methods using sequence alone. These powerful representations position Proust in a sweet spot as it also retains native generative capabilities that MLMs lack by design. Interpretability analysis reveals that per-position entropy variance predicts, to an extent, when retrieval augmentation helps and hurts. Such insights can grow in both quantity and quality at scale and inform capabilities such as test-time scaling. Code and weights are available at https://github.com/Furkan9015/proust-inference",
      "source": "arXiv",
      "pubDateISO": "2026-02-02",
      "tags": [
        "cs.LG"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.01844v1",
      "title": "CloDS: Visual-Only Unsupervised Cloth Dynamics Learning in Unknown Conditions",
      "link": "http://arxiv.org/abs/2602.01844v1",
      "pdf_link": "https://arxiv.org/pdf/2602.01844v1",
      "authors": "Yuliang Zhan, Jian Li, Wenbing Huang, Wenbing Huang, Yang Liu et al.",
      "institution": "",
      "abstract": "Deep learning has demonstrated remarkable capabilities in simulating complex dynamic systems. However, existing methods require known physical properties as supervision or inputs, limiting their applicability under unknown conditions. To explore this challenge, we introduce Cloth Dynamics Grounding (CDG), a novel scenario for unsupervised learning of cloth dynamics from multi-view visual observations. We further propose Cloth Dynamics Splatting (CloDS), an unsupervised dynamic learning framework designed for CDG. CloDS adopts a three-stage pipeline that first performs video-to-geometry grounding and then trains a dynamics model on the grounded meshes. To cope with large non-linear deformations and severe self-occlusions during grounding, we introduce a dual-position opacity modulation that supports bidirectional mapping between 2D observations and 3D geometry via mesh-based Gaussian splatting in video-to-geometry grounding stage. It jointly considers the absolute and relative position of Gaussian components. Comprehensive experimental evaluations demonstrate that CloDS effectively learns cloth dynamics from visual data while maintaining strong generalization capabilities for unseen configurations. Our code is available at https://github.com/whynot-zyl/CloDS. Visualization results are available at https://github.com/whynot-zyl/CloDS_video}.%\\footnote{As in this example.",
      "source": "arXiv",
      "pubDateISO": "2026-02-02",
      "tags": [
        "cs.CV",
        "cs.AI"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.01843v1",
      "title": "SPIRIT: Adapting Vision Foundation Models for Unified Single- and Multi-Frame Infrared Small Target Detection",
      "link": "http://arxiv.org/abs/2602.01843v1",
      "pdf_link": "https://arxiv.org/pdf/2602.01843v1",
      "authors": "Qian Xu, Xi Li, Fei Gao, Jie Guo, Haojuan Yuan et al.",
      "institution": "",
      "abstract": "Infrared small target detection (IRSTD) is crucial for surveillance and early-warning, with deployments spanning both single-frame analysis and video-mode tracking. A practical solution should leverage vision foundation models (VFMs) to mitigate infrared data scarcity, while adopting a memory-attention-based temporal propagation framework that unifies single- and multi-frame inference. However, infrared small targets exhibit weak radiometric signals and limited semantic cues, which differ markedly from visible-spectrum imagery. This modality gap makes direct use of semantics-oriented VFMs and appearance-driven cross-frame association unreliable for IRSTD: hierarchical feature aggregation can submerge localized target peaks, and appearance-only memory attention becomes ambiguous, leading to spurious clutter associations. To address these challenges, we propose SPIRIT, a unified and VFM-compatible framework that adapts VFMs to IRSTD via lightweight physics-informed plug-ins. Spatially, PIFR refines features by approximating rank-sparsity decomposition to suppress structured background components and enhance sparse target-like signals. Temporally, PGMA injects history-derived soft spatial priors into memory cross-attention to constrain cross-frame association, enabling robust video detection while naturally reverting to single-frame inference when temporal context is absent. Experiments on multiple IRSTD benchmarks show consistent gains over VFM-based baselines and SOTA performance.",
      "source": "arXiv",
      "pubDateISO": "2026-02-02",
      "tags": [
        "cs.CV"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.01842v1",
      "title": "Prism: Efficient Test-Time Scaling via Hierarchical Search and Self-Verification for Discrete Diffusion Language Models",
      "link": "http://arxiv.org/abs/2602.01842v1",
      "pdf_link": "https://arxiv.org/pdf/2602.01842v1",
      "authors": "Jinbin Bai, Yixuan Li, Yuchen Zhu, Yi Xin, Qingyu Shi et al.",
      "institution": "",
      "abstract": "Inference-time compute has re-emerged as a practical way to improve LLM reasoning. Most test-time scaling (TTS) algorithms rely on autoregressive decoding, which is ill-suited to discrete diffusion language models (dLLMs) due to their parallel decoding over the entire sequence. As a result, developing effective and efficient TTS methods to unlock dLLMs' full generative potential remains an underexplored challenge. To address this, we propose Prism (Pruning, Remasking, and Integrated Self-verification Method), an efficient TTS framework for dLLMs that (i) performs Hierarchical Trajectory Search (HTS) which dynamically prunes and reallocates compute in an early-to-mid denoising window, (ii) introduces Local branching with partial remasking to explore diverse implementations while preserving high-confidence tokens, and (iii) replaces external verifiers with Self-Verified Feedback (SVF) obtained via self-evaluation prompts on intermediate completions. Across four mathematical reasoning and code generation benchmarks on three dLLMs, including LLaDA 8B Instruct, Dream 7B Instruct, and LLaDA 2.0-mini, our Prism achieves a favorable performance-efficiency trade-off, matching best-of-N performance with substantially fewer function evaluations (NFE). The code is released at https://github.com/viiika/Prism.",
      "source": "arXiv",
      "pubDateISO": "2026-02-02",
      "tags": [
        "cs.LG"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.01840v1",
      "title": "Read As Human: Compressing Context via Parallelizable Close Reading and Skimming",
      "link": "http://arxiv.org/abs/2602.01840v1",
      "pdf_link": "https://arxiv.org/pdf/2602.01840v1",
      "authors": "Jiwei Tang, Shilei Liu, Zhicheng Zhang, Qingsong Lv, Runsong Zhao et al.",
      "institution": "",
      "abstract": "Large Language Models (LLMs) demonstrate exceptional capability across diverse tasks. However, their deployment in long-context scenarios is hindered by two challenges: computational inefficiency and redundant information. We propose RAM (Read As HuMan), a context compression framework that adopts an adaptive hybrid reading strategy, to address these challenges. Inspired by human reading behavior (i.e., close reading important content while skimming less relevant content), RAM partitions the context into segments and encodes them with the input query in parallel. High-relevance segments are fully retained (close reading), while low-relevance ones are query-guided compressed into compact summary vectors (skimming). Both explicit textual segments and implicit summary vectors are concatenated and fed into decoder to achieve both superior performance and natural language format interpretability. To refine the decision boundary between close reading and skimming, we further introduce a contrastive learning objective based on positive and negative query-segment pairs. Experiments demonstrate that RAM outperforms existing baselines on multiple question answering and summarization benchmarks across two backbones, while delivering up to a 12x end-to-end speedup on long inputs (average length 16K; maximum length 32K).",
      "source": "arXiv",
      "pubDateISO": "2026-02-02",
      "tags": [
        "cs.CL"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.01839v1",
      "title": "DOGMA: Weaving Structural Information into Data-centric Single-cell Transcriptomics Analysis",
      "link": "http://arxiv.org/abs/2602.01839v1",
      "pdf_link": "https://arxiv.org/pdf/2602.01839v1",
      "authors": "Ru Zhang, Xunkai Li, Yaxin Deng, Sicheng Liu, Daohan Su et al.",
      "institution": "",
      "abstract": "Recently, data-centric AI methodology has been a dominant paradigm in single-cell transcriptomics analysis, which treats data representation rather than model complexity as the fundamental bottleneck. In the review of current studies, earlier sequence methods treat cells as independent entities and adapt prevalent ML models to analyze their directly inherited sequence data. Despite their simplicity and intuition, these methods overlook the latent intercellular relationships driven by the functional mechanisms of biological systems and the inherent quality issues of the raw sequence data. Therefore, a series of structured methods has emerged. Although they employ various heuristic rules to capture intricate intercellular relationships and enhance the raw sequencing data, these methods often neglect biological prior knowledge. This omission incurs substantial overhead and yields suboptimal graph representations, thereby hindering the utility of ML models.\n  To address them, we propose DOGMA, a holistic data-centric framework designed for the structural reshaping and semantic enhancement of raw data through multi-level biological prior knowledge. Transcending reliance on stochastic heuristics, DOGMA redefines graph construction by integrating Statistical Anchors with Cell Ontology and Phylogenetic Trees to enable deterministic structure discovery and robust cross-species alignment. Furthermore, Gene Ontology is utilized to bridge the feature-level semantic gap by incorporating functional priors. In complex multi-species and multi-organ benchmarks, DOGMA achieves SOTA performance, exhibiting superior zero-shot robustness and sample efficiency while operating with significantly lower computational cost.",
      "source": "arXiv",
      "pubDateISO": "2026-02-02",
      "tags": [
        "cs.LG",
        "cs.AI"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.01838v1",
      "title": "AXE: Low-Cost Cross-Domain Web Structured Information Extraction",
      "link": "http://arxiv.org/abs/2602.01838v1",
      "pdf_link": "https://arxiv.org/pdf/2602.01838v1",
      "authors": "Abdelrahman Mansour, Khaled W. Alshaer, Moataz Elsaban",
      "institution": "",
      "abstract": "Extracting structured data from the web is often a trade-off between the brittle nature of manual heuristics and the prohibitive cost of Large Language Models. We introduce AXE (Adaptive X-Path Extractor), a pipeline that rethinks this process by treating the HTML DOM as a tree that needs pruning rather than just a wall of text to be read. AXE uses a specialized \"pruning\" mechanism to strip away boilerplate and irrelevant nodes, leaving behind a distilled, high-density context that allows a tiny 0.6B LLM to generate precise, structured outputs. To keep the model honest, we implement Grounded XPath Resolution (GXR), ensuring every extraction is physically traceable to a source node. Despite its low footprint, AXE achieves state-of-the-art zero-shot performance, outperforming several much larger, fully-trained alternatives with an F1 score of 88.1% on the SWDE dataset. By releasing our specialized adaptors, we aim to provide a practical, cost-effective path for large-scale web information extraction.",
      "source": "arXiv",
      "pubDateISO": "2026-02-02",
      "tags": [
        "cs.CL"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.01836v1",
      "title": "Efficient Cross-Country Data Acquisition Strategy for ADAS via Street-View Imagery",
      "link": "http://arxiv.org/abs/2602.01836v1",
      "pdf_link": "https://arxiv.org/pdf/2602.01836v1",
      "authors": "Yin Wu, Daniel Slieter, Carl Esselborn, Ahmed Abouelazm, Tsung Yuan Tseng et al.",
      "institution": "",
      "abstract": "Deploying ADAS and ADS across countries remains challenging due to differences in legislation, traffic infrastructure, and visual conventions, which introduce domain shifts that degrade perception performance. Traditional cross-country data collection relies on extensive on-road driving, making it costly and inefficient to identify representative locations. To address this, we propose a street-view-guided data acquisition strategy that leverages publicly available imagery to identify places of interest (POI). Two POI scoring methods are introduced: a KNN-based feature distance approach using a vision foundation model, and a visual-attribution approach using a vision-language model. To enable repeatable evaluation, we adopt a collect-detect protocol and construct a co-located dataset by pairing the Zenseact Open Dataset with Mapillary street-view images. Experiments on traffic sign detection, a task particularly sensitive to cross-country variations in sign appearance, show that our approach achieves performance comparable to random sampling while using only half of the target-domain data. We further provide cost estimations for full-country analysis, demonstrating that large-scale street-view processing remains economically feasible. These results highlight the potential of street-view-guided data acquisition for efficient and cost-effective cross-country model adaptation.",
      "source": "arXiv",
      "pubDateISO": "2026-02-02",
      "tags": [
        "cs.CV"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.01832v1",
      "title": "Synesthesia of Vehicles: Tactile Data Synthesis from Visual Inputs",
      "link": "http://arxiv.org/abs/2602.01832v1",
      "pdf_link": "https://arxiv.org/pdf/2602.01832v1",
      "authors": "Rui Wang, Yaoguang Cao, Yuyi Chen, Jianyi Xu, Zhuoyang Li et al.",
      "institution": "",
      "abstract": "Autonomous vehicles (AVs) rely on multi-modal fusion for safety, but current visual and optical sensors fail to detect road-induced excitations which are critical for vehicles' dynamic control. Inspired by human synesthesia, we propose the Synesthesia of Vehicles (SoV), a novel framework to predict tactile excitations from visual inputs for autonomous vehicles. We develop a cross-modal spatiotemporal alignment method to address temporal and spatial disparities. Furthermore, a visual-tactile synesthetic (VTSyn) generative model using latent diffusion is proposed for unsupervised high-quality tactile data synthesis. A real-vehicle perception system collected a multi-modal dataset across diverse road and lighting conditions. Extensive experiments show that VTSyn outperforms existing models in temporal, frequency, and classification performance, enhancing AV safety through proactive tactile perception.",
      "source": "arXiv",
      "pubDateISO": "2026-02-02",
      "tags": [
        "cs.AI"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.01828v1",
      "title": "Hyperbolic Graph Neural Networks Under the Microscope: The Role of Geometry-Task Alignment",
      "link": "http://arxiv.org/abs/2602.01828v1",
      "pdf_link": "https://arxiv.org/pdf/2602.01828v1",
      "authors": "Dionisia Naddeo, Jonas Linkerhägner, Nicola Toschi, Geri Skenderi, Veronica Lachi",
      "institution": "",
      "abstract": "Many complex networks exhibit hyperbolic structural properties, making hyperbolic space a natural candidate for representing hierarchical and tree-like graphs with low distortion. Based on this observation, Hyperbolic Graph Neural Networks (HGNNs) have been widely adopted as a principled choice for representation learning on tree-like graphs. In this work, we question this paradigm by proposing an additional condition of geometry-task alignment, i.e., whether the metric structure of the target follows that of the input graph. We theoretically and empirically demonstrate the capability of HGNNs to recover low-distortion representations on two synthetic regression problems, and show that their geometric inductive bias becomes helpful when the problem requires preserving metric structure. Additionally, we evaluate HGNNs on the tasks of link prediction and node classification by jointly analyzing predictive performance and embedding distortion, revealing that only link prediction is geometry-aligned. Overall, our findings shift the focus from only asking \"Is the graph hyperbolic?\" to also questioning \"Is the task aligned with hyperbolic geometry?\", showing that HGNNs consistently outperform Euclidean models under such alignment, while their advantage vanishes otherwise.",
      "source": "arXiv",
      "pubDateISO": "2026-02-02",
      "tags": [
        "cs.LG"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.01826v1",
      "title": "Beyond Precision: Training-Inference Mismatch is an Optimization Problem and Simple LR Scheduling Fixes It",
      "link": "http://arxiv.org/abs/2602.01826v1",
      "pdf_link": "https://arxiv.org/pdf/2602.01826v1",
      "authors": "Yaxiang Zhang, Yingru Li, Jiacai Liu, Jiawei Xu, Ziniu Li et al.",
      "institution": "",
      "abstract": "Reinforcement Learning (RL) for training Large Language Models is notoriously unstable. While recent studies attribute this to \"training inference mismatch stemming\" from inconsistent hybrid engines, standard remedies, such as Importance Sampling, might fail during extended training runs. In this work, we analyze this instability through the lens of optimization, demonstrating that gradient noise and training-inference mismatch escalate in tandem as training progresses. Meanwhile, we find that the mismatch can be effectively suppressed by shrinking the update size. Taken together, we deduce that the mismatch is not merely a static numerical discrepancy, but a dynamic failure coupled with the model's optimization. Based on this insight, we propose a simple yet effective solution: a specialized Learning Rate (LR) scheduler. Instead of pre-defined decay schedule in traditional LR scheduler, our method dynamically triggers LR decay based on response length, which we identify as a reliable early-warning signal for impending instability. Empirical evidence suggests that by reducing the learning rate as gradient noise rises, we can consistently stabilize RL training and keep the training-inference mismatch at a safe level.",
      "source": "arXiv",
      "pubDateISO": "2026-02-02",
      "tags": [
        "cs.LG",
        "cs.AI"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.01825v1",
      "title": "Learning Sequential Decisions from Multiple Sources via Group-Robust Markov Decision Processes",
      "link": "http://arxiv.org/abs/2602.01825v1",
      "pdf_link": "https://arxiv.org/pdf/2602.01825v1",
      "authors": "Mingyuan Xu, Zongqi Xia, Tianxi Cai, Doudou Zhou, Nian Si",
      "institution": "",
      "abstract": "We often collect data from multiple sites (e.g., hospitals) that share common structure but also exhibit heterogeneity. This paper aims to learn robust sequential decision-making policies from such offline, multi-site datasets. To model cross-site uncertainty, we study distributionally robust MDPs with a group-linear structure: all sites share a common feature map, and both the transition kernels and expected reward functions are linear in these shared features. We introduce feature-wise (d-rectangular) uncertainty sets, which preserve tractable robust Bellman recursions while maintaining key cross-site structure. Building on this, we then develop an offline algorithm based on pessimistic value iteration that includes: (i) per-site ridge regression for Bellman targets, (ii) feature-wise worst-case (row-wise minimization) aggregation, and (iii) a data-dependent pessimism penalty computed from the diagonals of the inverse design matrices. We further propose a cluster-level extension that pools similar sites to improve sample efficiency, guided by prior knowledge of site similarity. Under a robust partial coverage assumption, we prove a suboptimality bound for the resulting policy. Overall, our framework addresses multi-site learning with heterogeneous data sources and provides a principled approach to robust planning without relying on strong state-action rectangularity assumptions.",
      "source": "arXiv",
      "pubDateISO": "2026-02-02",
      "tags": [
        "stat.ME",
        "cs.LG",
        "stat.ML"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.01816v1",
      "title": "Seeing Is Believing? A Benchmark for Multimodal Large Language Models on Visual Illusions and Anomalies",
      "link": "http://arxiv.org/abs/2602.01816v1",
      "pdf_link": "https://arxiv.org/pdf/2602.01816v1",
      "authors": "Wenjin Hou, Wei Liu, Han Hu, Xiaoxiao Sun, Serena Yeung-Levy et al.",
      "institution": "",
      "abstract": "Multimodal Large Language Models (MLLMs) have shown remarkable proficiency on general-purpose vision-language benchmarks, reaching or even exceeding human-level performance. However, these evaluations typically rely on standard in-distribution data, leaving the robustness of MLLMs largely unexamined when faced with scenarios that defy common-sense priors. To address this gap, we introduce VIA-Bench, a challenging benchmark designed to probe model performance on visual illusions and anomalies. It includes six core categories: color illusions, motion illusions, gestalt illusions, geometric and spatial illusions, general visual illusions, and visual anomalies. Through careful human-in-the-loop review, we construct over 1K high-quality question-answer pairs that require nuanced visual reasoning. Extensive evaluation of over 20 state-of-the-art MLLMs, including proprietary, open-source, and reasoning-enhanced models, uncovers significant vulnerabilities. Notably, we find that Chain-of-Thought (CoT) reasoning offers negligible robustness, often yielding ``brittle mirages'' where the model's logic collapses under illusory stimuli. Our findings reveal a fundamental divergence between machine and human perception, suggesting that resolving such perceptual bottlenecks is critical for the advancement of artificial general intelligence. The benchmark data and code will be released.",
      "source": "arXiv",
      "pubDateISO": "2026-02-02",
      "tags": [
        "cs.CV"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.01815v1",
      "title": "INDIBATOR: Diverse and Fact-Grounded Individuality for Multi-Agent Debate in Molecular Discovery",
      "link": "http://arxiv.org/abs/2602.01815v1",
      "pdf_link": "https://arxiv.org/pdf/2602.01815v1",
      "authors": "Yunhui Jang, Seonghyun Park, Jaehyung Kim, Sungsoo Ahn",
      "institution": "",
      "abstract": "Multi-agent systems have emerged as a powerful paradigm for automating scientific discovery. To differentiate agent behavior in the multi-agent system, current frameworks typically assign generic role-based personas such as ''reviewer'' or ''writer'' or rely on coarse grained keyword-based personas. While functional, this approach oversimplifies how human scientists operate, whose contributions are shaped by their unique research trajectories. In response, we propose INDIBATOR, a framework for molecular discovery that grounds agents in individualized scientist profiles constructed from two modalities: publication history for literature-derived knowledge and molecular history for structural priors. These agents engage in multi-turn debate through proposal, critique, and voting phases. Our evaluation demonstrates that these fine-grained individuality-grounded agents consistently outperform systems relying on coarse-grained personas, achieving competitive or state-of-the-art performance. These results validate that capturing the ``scientific DNA'' of individual agents is essential for high-quality discovery.",
      "source": "arXiv",
      "pubDateISO": "2026-02-02",
      "tags": [
        "cs.AI"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.01814v1",
      "title": "GPD: Guided Progressive Distillation for Fast and High-Quality Video Generation",
      "link": "http://arxiv.org/abs/2602.01814v1",
      "pdf_link": "https://arxiv.org/pdf/2602.01814v1",
      "authors": "Xiao Liang, Yunzhu Zhang, Linchao Zhu",
      "institution": "",
      "abstract": "Diffusion models have achieved remarkable success in video generation; however, the high computational cost of the denoising process remains a major bottleneck. Existing approaches have shown promise in reducing the number of diffusion steps, but they often suffer from significant quality degradation when applied to video generation. We propose Guided Progressive Distillation (GPD), a framework that accelerates the diffusion process for fast and high-quality video generation. GPD introduces a novel training strategy in which a teacher model progressively guides a student model to operate with larger step sizes. The framework consists of two key components: (1) an online-generated training target that reduces optimization difficulty while improving computational efficiency, and (2) frequency-domain constraints in the latent space that promote the preservation of fine-grained details and temporal dynamics. Applied to the Wan2.1 model, GPD reduces the number of sampling steps from 48 to 6 while maintaining competitive visual quality on VBench. Compared with existing distillation methods, GPD demonstrates clear advantages in both pipeline simplicity and quality preservation.",
      "source": "arXiv",
      "pubDateISO": "2026-02-02",
      "tags": [
        "cs.CV"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.01812v1",
      "title": "LDRNet: Large Deformation Registration Model for Chest CT Registration",
      "link": "http://arxiv.org/abs/2602.01812v1",
      "pdf_link": "https://arxiv.org/pdf/2602.01812v1",
      "authors": "Cheng Wang, Qiyu Gao, Fandong Zhang, Shu Zhang, Yizhou Yu",
      "institution": "",
      "abstract": "Most of the deep learning based medical image registration algorithms focus on brain image registration tasks.Compared with brain registration, the chest CT registration has larger deformation, more complex background and region over-lap. In this paper, we propose a fast unsupervised deep learning method, LDRNet, for large deformation image registration of chest CT images. We first predict a coarse resolution registration field, then refine it from coarse to fine. We propose two innovative technical components: 1) a refine block that is used to refine the registration field in different resolutions, 2) a rigid block that is used to learn transformation matrix from high-level features. We train and evaluate our model on the private dataset and public dataset SegTHOR. We compare our performance with state-of-the-art traditional registration methods as well as deep learning registration models VoxelMorph, RCN, and LapIRN. The results demonstrate that our model achieves state-of-the-art performance for large deformation images registration and is much faster.",
      "source": "arXiv",
      "pubDateISO": "2026-02-02",
      "tags": [
        "cs.CV"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.01807v1",
      "title": "Sentence Curve Language Models",
      "link": "http://arxiv.org/abs/2602.01807v1",
      "pdf_link": "https://arxiv.org/pdf/2602.01807v1",
      "authors": "DongNyeong Heo, Heelyoul Choi",
      "institution": "",
      "abstract": "Language models (LMs) are a central component of modern AI systems, and diffusion-based language models (DLMs) have recently emerged as a competitive alternative. Both paradigms rely on word embeddings not only to represent the input sentence, but also to represent the target sentence that backbone models are trained to predict. We argue that such static embedding of the target word is insensitive to neighboring words, encouraging locally accurate word prediction while neglecting global structure across the target sentence. To address this limitation, we propose a continuous sentence representation, termed sentence curve, defined as a spline curve whose control points affect multiple words in the sentence. Based on this representation, we introduce sentence curve language model (SCLM), which extends DLMs to predict sentence curves instead of the static word embeddings. We theoretically show that sentence curve prediction induces a regularization effect that promotes global structure modeling, and characterize how different sentence curve types affect this behavior. Empirically, SCLM achieves SOTA performance among DLMs on IWSLT14 and WMT14, shows stable training without burdensome knowledge distillation, and demonstrates promising potential compared to discrete DLMs on LM1B.",
      "source": "arXiv",
      "pubDateISO": "2026-02-02",
      "tags": [
        "cs.CL",
        "cs.LG"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.01805v1",
      "title": "FlowBypass: Rectified Flow Trajectory Bypass for Training-Free Image Editing",
      "link": "http://arxiv.org/abs/2602.01805v1",
      "pdf_link": "https://arxiv.org/pdf/2602.01805v1",
      "authors": "Menglin Han, Zhangkai Ni",
      "institution": "",
      "abstract": "Training-free image editing has attracted increasing attention for its efficiency and independence from training data. However, existing approaches predominantly rely on inversion-reconstruction trajectories, which impose an inherent trade-off: longer trajectories accumulate errors and compromise fidelity, while shorter ones fail to ensure sufficient alignment with the edit prompt. Previous attempts to address this issue typically employ backbone-specific feature manipulations, limiting general applicability. To address these challenges, we propose FlowBypass, a novel and analytical framework grounded in Rectified Flow that constructs a bypass directly connecting inversion and reconstruction trajectories, thereby mitigating error accumulation without relying on feature manipulations. We provide a formal derivation of two trajectories, from which we obtain an approximate bypass formulation and its numerical solution, enabling seamless trajectory transitions. Extensive experiments demonstrate that FlowBypass consistently outperforms state-of-the-art image editing methods, achieving stronger prompt alignment while preserving high-fidelity details in irrelevant regions.",
      "source": "arXiv",
      "pubDateISO": "2026-02-02",
      "tags": [
        "cs.CV"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.01801v1",
      "title": "Fast Autoregressive Video Diffusion and World Models with Temporal Cache Compression and Sparse Attention",
      "link": "http://arxiv.org/abs/2602.01801v1",
      "pdf_link": "https://arxiv.org/pdf/2602.01801v1",
      "authors": "Dvir Samuel, Issar Tzachor, Matan Levy, Micahel Green, Gal Chechik et al.",
      "institution": "",
      "abstract": "Autoregressive video diffusion models enable streaming generation, opening the door to long-form synthesis, video world models, and interactive neural game engines. However, their core attention layers become a major bottleneck at inference time: as generation progresses, the KV cache grows, causing both increasing latency and escalating GPU memory, which in turn restricts usable temporal context and harms long-range consistency. In this work, we study redundancy in autoregressive video diffusion and identify three persistent sources: near-duplicate cached keys across frames, slowly evolving (largely semantic) queries/keys that make many attention computations redundant, and cross-attention over long prompts where only a small subset of tokens matters per frame. Building on these observations, we propose a unified, training-free attention framework for autoregressive diffusion: TempCache compresses the KV cache via temporal correspondence to bound cache growth; AnnCA accelerates cross-attention by selecting frame-relevant prompt tokens using fast approximate nearest neighbor (ANN) matching; and AnnSA sparsifies self-attention by restricting each query to semantically matched keys, also using a lightweight ANN. Together, these modules reduce attention, compute, and memory and are compatible with existing autoregressive diffusion backbones and world models. Experiments demonstrate up to x5--x10 end-to-end speedups while preserving near-identical visual quality and, crucially, maintaining stable throughput and nearly constant peak GPU memory usage over long rollouts, where prior methods progressively slow down and suffer from increasing memory usage.",
      "source": "arXiv",
      "pubDateISO": "2026-02-02",
      "tags": [
        "cs.CV",
        "cs.AI"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.01799v1",
      "title": "Spatio-Temporal Transformers for Long-Term NDVI Forecasting",
      "link": "http://arxiv.org/abs/2602.01799v1",
      "pdf_link": "https://arxiv.org/pdf/2602.01799v1",
      "authors": "Ido Faran, Nathan S. Netanyahu, Maxim Shoshany",
      "institution": "",
      "abstract": "Long-term satellite image time series (SITS) analysis in heterogeneous landscapes faces significant challenges, particularly in Mediterranean regions where complex spatial patterns, seasonal variations, and multi-decade environmental changes interact across different scales. This paper presents the Spatio-Temporal Transformer for Long Term Forecasting (STT-LTF ), an extended framework that advances beyond purely temporal analysis to integrate spatial context modeling with temporal sequence prediction. STT-LTF processes multi-scale spatial patches alongside temporal sequences (up to 20 years) through a unified transformer architecture, capturing both local neighborhood relationships and regional climate influences. The framework employs comprehensive self-supervised learning with spatial masking, temporal masking, and horizon sampling strategies, enabling robust model training from 40 years of unlabeled Landsat imagery. Unlike autoregressive approaches, STT-LTF directly predicts arbitrary future time points without error accumulation, incorporating spatial patch embeddings, cyclical temporal encoding, and geographic coordinates to learn complex dependencies across heterogeneous Mediterranean ecosystems. Experimental evaluation on Landsat data (1984-2024) demonstrates that STT-LTF achieves a Mean Absolute Error (MAE) of 0.0328 and R^2 of 0.8412 for next-year predictions, outperforming traditional statistical methods, CNN-based approaches, LSTM networks, and standard transformers. The framework's ability to handle irregular temporal sampling and variable prediction horizons makes it particularly suitable for analysis of heterogeneous landscapes experiencing rapid ecological transitions.",
      "source": "arXiv",
      "pubDateISO": "2026-02-02",
      "tags": [
        "cs.CV",
        "cs.LG"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.01797v1",
      "title": "ORCH: many analyses, one merge-a deterministic multi-agent orchestrator for discrete-choice reasoning with EMA-guided routing",
      "link": "http://arxiv.org/abs/2602.01797v1",
      "pdf_link": "https://arxiv.org/pdf/2602.01797v1",
      "authors": "Hanlin Zhou, Huah Yong Chan",
      "institution": "",
      "abstract": "Recent advances in large-scale language models (LLMs) have made multi-agent architectures attractive for challenging reasoning tasks. However, many existing systems rely on stochastic routing or ad-hoc heuristics, making their behavior difficult to reproduce and their decision process hard to interpret. We propose ORCH, a deterministic coordination framework for discrete-choice reasoning that orchestrates heterogeneous LLMs. ORCH follows a ``many analyses, one decision'' paradigm: multiple base models independently produce structured analyses, and a dedicated merge agent outputs the final choice. The framework uses fixed rules for task decomposition and answer aggregation, keeping the pipeline predictable, reproducible, and training-free. Determinism here refers to fixed routing and aggregation rules under a fixed evaluation protocol, rather than strict bit-level reproducibility across deployments. To exploit model complementarity, we optionally introduce an EMA-guided router that updates agent selection using historical accuracy, latency, or cost; since it relies on answer-based feedback, it is mainly intended for benchmarking, controlled evaluation, or delayed-feedback settings. Experiments on MMLU, MMLU-Pro, and GSM8K show that ORCH consistently outperforms single-model baselines and a majority-vote ensemble. On MMLU-Pro, ORCH improves accuracy by over 10 points compared to the strongest baseline, and on GSM8K it yields gains exceeding 50 points; McNemar tests confirm statistical significance. The EMA router provides an additional 0.7--2.0 point accuracy boost, and ablations show that both multi-agent collaboration and routing contribute substantially. Overall, ORCH offers a practical path toward controllable, interpretable, and deployment-ready LLM-based agent systems for discrete-choice reasoning.",
      "source": "arXiv",
      "pubDateISO": "2026-02-02",
      "tags": [
        "cs.AI"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.01795v1",
      "title": "RedVisor: Reasoning-Aware Prompt Injection Defense via Zero-Copy KV Cache Reuse",
      "link": "http://arxiv.org/abs/2602.01795v1",
      "pdf_link": "https://arxiv.org/pdf/2602.01795v1",
      "authors": "Mingrui Liu, Sixiao Zhang, Cheng Long, Kwok-Yan Lam",
      "institution": "",
      "abstract": "Large Language Models (LLMs) are increasingly vulnerable to Prompt Injection (PI) attacks, where adversarial instructions hidden within retrieved contexts hijack the model's execution flow. Current defenses typically face a critical trade-off: prevention-based fine-tuning often degrades general utility via the \"alignment tax\", while detection-based filtering incurs prohibitive latency and memory costs. To bridge this gap, we propose RedVisor, a unified framework that synthesizes the explainability of detection systems with the seamless integration of prevention strategies. To the best of our knowledge, RedVisor is the first approach to leverage fine-grained reasoning paths to simultaneously detect attacks and guide the model's safe response. We implement this via a lightweight, removable adapter positioned atop the frozen backbone. This adapter serves a dual function: it first generates an explainable analysis that precisely localizes the injection and articulates the threat, which then explicitly conditions the model to reject the malicious command. Uniquely, the adapter is active only during this reasoning phase and is effectively muted during the subsequent response generation. This architecture yields two distinct advantages: (1) it mathematically preserves the backbone's original utility on benign inputs; and (2) it enables a novel KV Cache Reuse strategy, eliminating the redundant prefill computation inherent to decoupled pipelines. We further pioneer the integration of this defense into the vLLM serving engine with custom kernels. Experiments demonstrate that RedVisor outperforms state-of-the-art defenses in detection accuracy and throughput while incurring negligible utility loss.",
      "source": "arXiv",
      "pubDateISO": "2026-02-02",
      "tags": [
        "cs.CR",
        "cs.AI",
        "cs.LG"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.01791v1",
      "title": "Grad2Reward: From Sparse Judgment to Dense Rewards for Improving Open-Ended LLM Reasoning",
      "link": "http://arxiv.org/abs/2602.01791v1",
      "pdf_link": "https://arxiv.org/pdf/2602.01791v1",
      "authors": "Zheng Zhang, Ao Lu, Yuanhao Zeng, Ziwei Shan, Jinjin Guo et al.",
      "institution": "",
      "abstract": "Reinforcement Learning with Verifiable Rewards (RLVR) has catalyzed significant breakthroughs in complex LLM reasoning within verifiable domains, such as mathematics and programming. Recent efforts have sought to extend this paradigm to open-ended tasks by employing LLMs-as-a-Judge to provide sequence-level rewards for policy optimization. However, these rewards are inherently sparse, failing to provide the fine-grained supervision necessary for generating complex, long-form trajectories. Furthermore, current work treats the Judge as a black-box oracle, discarding the rich intermediate feedback signals encoded in it. To address these limitations, we introduce Grad2Reward, a novel framework that extracts dense process rewards directly from the Judge's model inference process via a single backward pass. By leveraging gradient-based attribution, Grad2Reward enables precise token-level credit assignment, substantially enhancing training efficiency and reasoning quality. Additionally, Grad2Reward introduces a self-judging mechanism, allowing the policy to improve through its own evaluative signals without training specialized reward models or reliance on superior external Judges. The experiments demonstrate that policies optimized with Grad2Reward achieve outstanding performance across diverse open-ended tasks, affirming its effectiveness and broad generalizability.",
      "source": "arXiv",
      "pubDateISO": "2026-02-02",
      "tags": [
        "cs.LG"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.01785v1",
      "title": "CodeOCR: On the Effectiveness of Vision Language Models in Code Understanding",
      "link": "http://arxiv.org/abs/2602.01785v1",
      "pdf_link": "https://arxiv.org/pdf/2602.01785v1",
      "authors": "Yuling Shi, Chaoxiang Xie, Zhensu Sun, Yeheng Chen, Chenxu Zhang et al.",
      "institution": "",
      "abstract": "Large Language Models (LLMs) have achieved remarkable success in source code understanding, yet as software systems grow in scale, computational efficiency has become a critical bottleneck. Currently, these models rely on a text-based paradigm that treats source code as a linear sequence of tokens, which leads to a linear increase in context length and associated computational costs. The rapid advancement of Multimodal LLMs (MLLMs) introduces an opportunity to optimize efficiency by representing source code as rendered images. Unlike text, which is difficult to compress without losing semantic meaning, the image modality is inherently suitable for compression. By adjusting resolution, images can be scaled to a fraction of their original token cost while remaining recognizable to vision-capable models. To explore the feasibility of this approach, we conduct the first systematic study on the effectiveness of MLLMs for code understanding. Our experiments reveal that: (1) MLLMs can effectively understand code with substantial token reduction, achieving up to 8x compression; (2) MLLMs can effectively leverage visual cues such as syntax highlighting, improving code completion performance under 4x compression; and (3) Code-understanding tasks like clone detection exhibit exceptional resilience to visual compression, with some compression ratios even slightly outperforming raw text inputs. Our findings highlight both the potential and current limitations of MLLMs in code understanding, which points out a shift toward image-modality code representation as a pathway to more efficient inference.",
      "source": "arXiv",
      "pubDateISO": "2026-02-02",
      "tags": [
        "cs.CL",
        "cs.SE"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.01783v1",
      "title": "Automated Discontinuity Set Characterisation in Enclosed Rock Face Point Clouds Using Single-Shot Filtering and Cyclic Orientation Transformation",
      "link": "http://arxiv.org/abs/2602.01783v1",
      "pdf_link": "https://arxiv.org/pdf/2602.01783v1",
      "authors": "Dibyayan Patra, Pasindu Ranasinghe, Bikram Banerjee, Simit Raval",
      "institution": "MIT",
      "abstract": "Characterisation of structural discontinuity sets in exposed rock faces of underground mine cavities is essential for assessing rock-mass stability, excavation safety, and operational efficiency. UAV and other mobile laser-scanning techniques provide efficient means of collecting point clouds from rock faces. However, the development of a robust and efficient approach for automatic characterisation of discontinuity sets in real-world scenarios, like fully enclosed rock faces in cavities, remains an open research problem. In this study, a new approach is proposed for automatic discontinuity set characterisation that uses a single-shot filtering strategy, an innovative cyclic orientation transformation scheme and a hierarchical clustering technique. The single-shot filtering step isolates planar regions while robustly suppressing noise and high-curvature artefacts in one pass using a signal-processing technique. To address the limitations of Cartesian clustering on polar orientation data, a cyclic orientation transformation scheme is developed, enabling accurate representation of dip angle and dip direction in Cartesian space. The transformed orientations are then characterised into sets using a hierarchical clustering technique, which handles varying density distributions and identifies clusters without requiring user-defined set numbers. The accuracy of the method is validated on real-world mine stope and against ground truth obtained using manually handpicked discontinuity planes identified with the Virtual Compass tool, as well as widely used automated structure mapping techniques. The proposed approach outperforms the other techniques by exhibiting the lowest mean absolute error in estimating discontinuity set orientations in real-world stope data with errors of 1.95° and 2.20° in nominal dip angle and dip direction, respectively, and dispersion errors lying below 3°.",
      "source": "arXiv",
      "pubDateISO": "2026-02-02",
      "tags": [
        "cs.CV"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.01780v1",
      "title": "DDP-WM: Disentangled Dynamics Prediction for Efficient World Models",
      "link": "http://arxiv.org/abs/2602.01780v1",
      "pdf_link": "https://arxiv.org/pdf/2602.01780v1",
      "authors": "Shicheng Yin, Kaixuan Yin, Weixing Chen, Yang Liu, Guanbin Li et al.",
      "institution": "",
      "abstract": "World models are essential for autonomous robotic planning. However, the substantial computational overhead of existing dense Transformerbased models significantly hinders real-time deployment. To address this efficiency-performance bottleneck, we introduce DDP-WM, a novel world model centered on the principle of Disentangled Dynamics Prediction (DDP). We hypothesize that latent state evolution in observed scenes is heterogeneous and can be decomposed into sparse primary dynamics driven by physical interactions and secondary context-driven background updates. DDP-WM realizes this decomposition through an architecture that integrates efficient historical processing with dynamic localization to isolate primary dynamics. By employing a crossattention mechanism for background updates, the framework optimizes resource allocation and provides a smooth optimization landscape for planners. Extensive experiments demonstrate that DDP-WM achieves significant efficiency and performance across diverse tasks, including navigation, precise tabletop manipulation, and complex deformable or multi-body interactions. Specifically, on the challenging Push-T task, DDP-WM achieves an approximately 9 times inference speedup and improves the MPC success rate from 90% to98% compared to state-of-the-art dense models. The results establish a promising path for developing efficient, high-fidelity world models. Codes will be available at https://github.com/HCPLabSYSU/DDP-WM.",
      "source": "arXiv",
      "pubDateISO": "2026-02-02",
      "tags": [
        "cs.CV",
        "cs.RO"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.01779v1",
      "title": "LingLanMiDian: Systematic Evaluation of LLMs on TCM Knowledge and Clinical Reasoning",
      "link": "http://arxiv.org/abs/2602.01779v1",
      "pdf_link": "https://arxiv.org/pdf/2602.01779v1",
      "authors": "Rui Hua, Yu Wei, Zixin Shu, Kai Chang, Dengying Yan et al.",
      "institution": "",
      "abstract": "Large language models (LLMs) are advancing rapidly in medical NLP, yet Traditional Chinese Medicine (TCM) with its distinctive ontology, terminology, and reasoning patterns requires domain-faithful evaluation. Existing TCM benchmarks are fragmented in coverage and scale and rely on non-unified or generation-heavy scoring that hinders fair comparison. We present the LingLanMiDian (LingLan) benchmark, a large-scale, expert-curated, multi-task suite that unifies evaluation across knowledge recall, multi-hop reasoning, information extraction, and real-world clinical decision-making. LingLan introduces a consistent metric design, a synonym-tolerant protocol for clinical labels, a per-dataset 400-item Hard subset, and a reframing of diagnosis and treatment recommendation into single-choice decision recognition. We conduct comprehensive, zero-shot evaluations on 14 leading open-source and proprietary LLMs, providing a unified perspective on their strengths and limitations in TCM commonsense knowledge understanding, reasoning, and clinical decision support; critically, the evaluation on Hard subset reveals a substantial gap between current models and human experts in TCM-specialized reasoning. By bridging fundamental knowledge and applied reasoning through standardized evaluation, LingLan establishes a unified, quantitative, and extensible foundation for advancing TCM LLMs and domain-specific medical AI research. All evaluation data and code are available at https://github.com/TCMAI-BJTU/LingLan and http://tcmnlp.com.",
      "source": "arXiv",
      "pubDateISO": "2026-02-02",
      "tags": [
        "cs.AI"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.01778v1",
      "title": "Data Distribution Matters: A Data-Centric Perspective on Context Compression for Large Language Model",
      "link": "http://arxiv.org/abs/2602.01778v1",
      "pdf_link": "https://arxiv.org/pdf/2602.01778v1",
      "authors": "Kangtao Lv, Jiwei Tang, Langming Liu, Haibin Chen, Weidong Zhang et al.",
      "institution": "",
      "abstract": "The deployment of Large Language Models (LLMs) in long-context scenarios is hindered by computational inefficiency and significant information redundancy. Although recent advancements have widely adopted context compression to address these challenges, existing research only focus on model-side improvements, the impact of the data distribution itself on context compression remains largely unexplored. To bridge this gap, we are the first to adopt a data-centric perspective to systematically investigate how data distribution impacts compression quality, including two dimensions: input data and intrinsic data (i.e., the model's internal pretrained knowledge). We evaluate the semantic integrity of compressed representations using an autoencoder-based framework to systematically investigate it. Our experimental results reveal that: (1) encoder-measured input entropy negatively correlates with compression quality, while decoder-measured entropy shows no significant relationship under a frozen-decoder setting; and (2) the gap between intrinsic data of the encoder and decoder significantly diminishes compression gains, which is hard to mitigate. Based on these findings, we further present practical guidelines to optimize compression gains.",
      "source": "arXiv",
      "pubDateISO": "2026-02-02",
      "tags": [
        "cs.CL"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.01777v1",
      "title": "Stein-Rule Shrinkage for Stochastic Gradient Estimation in High Dimensions",
      "link": "http://arxiv.org/abs/2602.01777v1",
      "pdf_link": "https://arxiv.org/pdf/2602.01777v1",
      "authors": "M. Arashi, M. Amintoosi",
      "institution": "",
      "abstract": "Stochastic gradient methods are central to large-scale learning, yet their analysis typically treats mini-batch gradients as unbiased estimators of the population gradient. In high-dimensional settings, however, classical results from statistical decision theory show that unbiased estimators are generally inadmissible under quadratic loss, suggesting that standard stochastic gradients may be suboptimal from a risk perspective. In this work, we formulate stochastic gradient computation as a high-dimensional estimation problem and introduce a decision-theoretic framework based on Stein-rule shrinkage. We construct a shrinkage gradient estimator that adaptively contracts noisy mini-batch gradients toward a stable restricted estimator derived from historical momentum. The shrinkage intensity is determined in a data-driven manner using an online estimate of gradient noise variance, leveraging second-moment statistics commonly maintained by adaptive optimization methods. Under a Gaussian noise model and for dimension p>=3, we show that the proposed estimator uniformly dominates the standard stochastic gradient under squared error loss and is minimax-optimal in the classical decision-theoretic sense. We further demonstrate how this estimator can be incorporated into the Adam optimizer, yielding a practical algorithm with negligible additional computational cost. Empirical evaluations on CIFAR10 and CIFAR100, across multiple levels of label noise, show consistent improvements over Adam in the large-batch regime. Ablation studies indicate that the gains arise primarily from selectively applying shrinkage to high-dimensional convolutional layers, while indiscriminate shrinkage across all parameters degrades performance. These results illustrate that classical shrinkage principles provide a principled and effective approach to improving stochastic gradient estimation in modern deep learning.",
      "source": "arXiv",
      "pubDateISO": "2026-02-02",
      "tags": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.01776v1",
      "title": "Position: Beyond Model-Centric Prediction -- Agentic Time Series Forecasting",
      "link": "http://arxiv.org/abs/2602.01776v1",
      "pdf_link": "https://arxiv.org/pdf/2602.01776v1",
      "authors": "Mingyue Cheng, Xiaoyu Tao, Qi Liu, Ze Guo, Enhong Chen",
      "institution": "",
      "abstract": "Time series forecasting has traditionally been formulated as a model-centric, static, and single-pass prediction problem that maps historical observations to future values. While this paradigm has driven substantial progress, it proves insufficient in adaptive and multi-turn settings where forecasting requires informative feature extraction, reasoning-driven inference, iterative refinement, and continual adaptation over time. In this paper, we argue for agentic time series forecasting (ATSF), which reframes forecasting as an agentic process composed of perception, planning, action, reflection, and memory. Rather than focusing solely on predictive models, ATSF emphasizes organizing forecasting as an agentic workflow that can interact with tools, incorporate feedback from outcomes, and evolve through experience accumulation. We outline three representative implementation paradigms -- workflow-based design, agentic reinforcement learning, and a hybrid agentic workflow paradigm -- and discuss the opportunities and challenges that arise when shifting from model-centric prediction to agentic forecasting. Together, this position aims to establish agentic forecasting as a foundation for future research at the intersection of time series forecasting.",
      "source": "arXiv",
      "pubDateISO": "2026-02-02",
      "tags": [
        "cs.LG"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.01775v1",
      "title": "Efficient Cross-Architecture Knowledge Transfer for Large-Scale Online User Response Prediction",
      "link": "http://arxiv.org/abs/2602.01775v1",
      "pdf_link": "https://arxiv.org/pdf/2602.01775v1",
      "authors": "Yucheng Wu, Yuekui Yang, Hongzheng Li, Anan Liu, Jian Xiao et al.",
      "institution": "",
      "abstract": "Deploying new architectures in large-scale user response prediction systems incurs high model switching costs due to expensive retraining on massive historical data and performance degradation under data retention constraints. Existing knowledge distillation methods struggle with architectural heterogeneity and the prohibitive cost of transferring large embedding tables. We propose CrossAdapt, a two-stage framework for efficient cross-architecture knowledge transfer. The offline stage enables rapid embedding transfer via dimension-adaptive projections without iterative training, combined with progressive network distillation and strategic sampling to reduce computational cost. The online stage introduces asymmetric co-distillation, where students update frequently while teachers update infrequently, together with a distribution-aware adaptation mechanism that dynamically balances historical knowledge preservation and fast adaptation to evolving data. Experiments on three public datasets show that CrossAdapt achieves 0.27-0.43% AUC improvements while reducing training time by 43-71%. Large-scale deployment on Tencent WeChat Channels (~10M daily samples) further demonstrates its effectiveness, significantly mitigating AUC degradation, LogLoss increase, and prediction bias compared to standard distillation baselines.",
      "source": "arXiv",
      "pubDateISO": "2026-02-02",
      "tags": [
        "cs.AI",
        "cs.LG"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.01774v1",
      "title": "Cost-Aware Bayesian Optimization for Prototyping Interactive Devices",
      "link": "http://arxiv.org/abs/2602.01774v1",
      "pdf_link": "https://arxiv.org/pdf/2602.01774v1",
      "authors": "Thomas Langerak, Renate Zhang, Ziyuan Wang, Per Ola Kristensson, Antti Oulasvirta",
      "institution": "",
      "abstract": "Deciding which idea is worth prototyping is a central concern in iterative design. A prototype should be produced when the expected improvement is high and the cost is low. However, this is hard to decide, because costs can vary drastically: a simple parameter tweak may take seconds, while fabricating hardware consumes material and energy. Such asymmetries, can discourage a designer from exploring the design space. In this paper, we present an extension of cost-aware Bayesian optimization to account for diverse prototyping costs. The method builds on the power of Bayesian optimization and requires only a minimal modification to the acquisition function. The key idea is to use designer-estimated costs to guide sampling toward more cost-effective prototypes. In technical evaluations, the method achieved comparable utility to a cost-agnostic baseline while requiring only ${\\approx}70\\%$ of the cost; under strict budgets, it outperformed the baseline threefold. A within-subjects study with 12 participants in a realistic joystick design task demonstrated similar benefits. These results show that accounting for prototyping costs can make Bayesian optimization more compatible with real-world design projects.",
      "source": "arXiv",
      "pubDateISO": "2026-02-02",
      "tags": [
        "cs.HC",
        "cs.LG"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.01772v1",
      "title": "DIA-CLIP: a universal representation learning framework for zero-shot DIA proteomics",
      "link": "http://arxiv.org/abs/2602.01772v1",
      "pdf_link": "https://arxiv.org/pdf/2602.01772v1",
      "authors": "Yucheng Liao, Han Wen, Weinan E, Weijie Zhang",
      "institution": "",
      "abstract": "Data-independent acquisition mass spectrometry (DIA-MS) has established itself as a cornerstone of proteomic profiling and large-scale systems biology, offering unparalleled depth and reproducibility. Current DIA analysis frameworks, however, require semi-supervised training within each run for peptide-spectrum match (PSM) re-scoring. This approach is prone to overfitting and lacks generalizability across diverse species and experimental conditions. Here, we present DIA-CLIP, a pre-trained model shifting the DIA analysis paradigm from semi-supervised training to universal cross-modal representation learning. By integrating dual-encoder contrastive learning framework with encoder-decoder architecture, DIA-CLIP establishes a unified cross-modal representation for peptides and corresponding spectral features, achieving high-precision, zero-shot PSM inference. Extensive evaluations across diverse benchmarks demonstrate that DIA-CLIP consistently outperforms state-of-the-art tools, yielding up to a 45% increase in protein identification while achieving a 12% reduction in entrapment identifications. Moreover, DIA-CLIP holds immense potential for diverse practical applications, such as single-cell and spatial proteomics, where its enhanced identification depth facilitates the discovery of novel biomarkers and the elucidates of intricate cellular mechanisms.",
      "source": "arXiv",
      "pubDateISO": "2026-02-02",
      "tags": [
        "cs.LG",
        "cs.AI"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.01771v1",
      "title": "<SOG_k>: One LLM Token for Explicit Graph Structural Understanding",
      "link": "http://arxiv.org/abs/2602.01771v1",
      "pdf_link": "https://arxiv.org/pdf/2602.01771v1",
      "authors": "Jingyao Wu, Bin Lu, Zijun Di, Xiaoying Gan, Meng Jin et al.",
      "institution": "",
      "abstract": "Large language models show great potential in unstructured data understanding, but still face significant challenges with graphs due to their structural hallucination. Existing approaches mainly either verbalize graphs into natural language, which leads to excessive token consumption and scattered attention, or transform graphs into trainable continuous embeddings (i.e., soft prompt), but exhibit severe misalignment with original text tokens. To solve this problem, we propose to incorporate one special token <SOG_k> to fully represent the Structure Of Graph within a unified token space, facilitating explicit topology input and structural information sharing. Specifically, we propose a topology-aware structural tokenizer that maps each graph topology into a highly selective single token. Afterwards, we construct a set of hybrid structure Question-Answering corpora to align new structural tokens with existing text tokens. With this approach, <SOG_k> empowers LLMs to understand, generate, and reason in a concise and accurate manner. Extensive experiments on five graph-level benchmarks demonstrate the superiority of our method, achieving a performance improvement of 9.9% to 41.4% compared to the baselines while exhibiting interpretability and consistency. Furthermore, our method provides a flexible extension to node-level tasks, enabling both global and local structural understanding. The codebase is publicly available at https://github.com/Jingyao-Wu/SOG.",
      "source": "arXiv",
      "pubDateISO": "2026-02-02",
      "tags": [
        "cs.CL",
        "cs.AI",
        "cs.NI"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.01769v1",
      "title": "IRIS: Implicit Reward-Guided Internal Sifting for Mitigating Multimodal Hallucination",
      "link": "http://arxiv.org/abs/2602.01769v1",
      "pdf_link": "https://arxiv.org/pdf/2602.01769v1",
      "authors": "Yuanshuai Li, Yuping Yan, Jirui Han, Fei Ming, Lingjuan Lv et al.",
      "institution": "",
      "abstract": "Hallucination remains a fundamental challenge for Multimodal Large Language Models (MLLMs). While Direct Preference Optimization (DPO) is a key alignment framework, existing approaches often rely heavily on costly external evaluators for scoring or rewriting, incurring off-policy learnability gaps and discretization loss. Due to the lack of access to internal states, such feedback overlooks the fine-grained conflicts between different modalities that lead to hallucinations during generation.\n  To address this issue, we propose IRIS (Implicit Reward-Guided Internal Sifting), which leverages continuous implicit rewards in the native log-probability space to preserve full information density and capture internal modal competition. This on-policy paradigm eliminates learnability gaps by utilizing self-generated preference pairs. By sifting these pairs based on multimodal implicit rewards, IRIS ensures that optimization is driven by signals that directly resolve modal conflicts. Extensive experiments demonstrate that IRIS achieves highly competitive performance on key hallucination benchmarks using only 5.7k samples, without requiring any external feedback during preference alignment. These results confirm that IRIS provides an efficient and principled paradigm for mitigating MLLM hallucinations.",
      "source": "arXiv",
      "pubDateISO": "2026-02-02",
      "tags": [
        "cs.LG",
        "cs.AI"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.01766v1",
      "title": "CoMeT: Collaborative Memory Transformer for Efficient Long Context Modeling",
      "link": "http://arxiv.org/abs/2602.01766v1",
      "pdf_link": "https://arxiv.org/pdf/2602.01766v1",
      "authors": "Runsong Zhao, Shilei Liu, Jiwei Tang, Langming Liu, Haibin Chen et al.",
      "institution": "",
      "abstract": "The quadratic complexity and indefinitely growing key-value (KV) cache of standard Transformers pose a major barrier to long-context processing. To overcome this, we introduce the Collaborative Memory Transformer (CoMeT), a novel architecture that enables LLMs to handle arbitrarily long sequences with constant memory usage and linear time complexity. Designed as an efficient, plug-in module, CoMeT can be integrated into pre-trained models with only minimal fine-tuning. It operates on sequential data chunks, using a dual-memory system to manage context: a temporary memory on a FIFO queue for recent events, and a global memory with a gated update rule for long-range dependencies. These memories then act as a dynamic soft prompt for the next chunk. To enable efficient fine-tuning on extremely long contexts, we introduce a novel layer-level pipeline parallelism strategy. The effectiveness of our approach is remarkable: a model equipped with CoMeT and fine-tuned on 32k contexts can accurately retrieve a passkey from any position within a 1M token sequence. On the SCROLLS benchmark, CoMeT surpasses other efficient methods and achieves performance comparable to a full-attention baseline on summarization tasks. Its practical effectiveness is further validated on real-world agent and user behavior QA tasks. The code is available at: https://anonymous.4open.science/r/comet-B00B/",
      "source": "arXiv",
      "pubDateISO": "2026-02-02",
      "tags": [
        "cs.LG",
        "cs.AI"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.01765v1",
      "title": "Backdoor Sentinel: Detecting and Detoxifying Backdoors in Diffusion Models via Temporal Noise Consistency",
      "link": "http://arxiv.org/abs/2602.01765v1",
      "pdf_link": "https://arxiv.org/pdf/2602.01765v1",
      "authors": "Bingzheng Wang, Xiaoyan Gu, Hongbo Xu, Hongcheng Li, Zimo Yu et al.",
      "institution": "",
      "abstract": "Diffusion models have been widely deployed in AIGC services; however, their reliance on opaque training data and procedures exposes a broad attack surface for backdoor injection. In practical auditing scenarios, due to the protection of intellectual property and commercial confidentiality, auditors are typically unable to access model parameters, rendering existing white-box or query-intensive detection methods impractical. More importantly, even after the backdoor is detected, existing detoxification approaches are often trapped in a dilemma between detoxification effectiveness and generation quality.\n  In this work, we identify a previously unreported phenomenon called temporal noise unconsistency, where the noise predictions between adjacent diffusion timesteps is disrupted in specific temporal segments when the input is triggered, while remaining stable under clean inputs. Leveraging this finding, we propose Temporal Noise Consistency Defense (TNC-Defense), a unified framework for backdoor detection and detoxification. The framework first uses the adjacent timestep noise consistency to design a gray-box detection module, for identifying and locating anomalous diffusion timesteps. Furthermore, the framework uses the identified anomalous timesteps to construct a trigger-agnostic, timestep-aware detoxification module, which directly corrects the backdoor generation path. This effectively suppresses backdoor behavior while significantly reducing detoxification costs.\n  We evaluate the proposed method under five representative backdoor attack scenarios and compare it with state-of-the-art defenses. The results show that TNC-Defense improves the average detection accuracy by $11\\%$ with negligible additional overhead, and invalidates an average of $98.5\\%$ of triggered samples with only a mild degradation in generation quality.",
      "source": "arXiv",
      "pubDateISO": "2026-02-02",
      "tags": [
        "cs.CR",
        "cs.AI"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.01764v1",
      "title": "GDPR-Compliant Person Recognition in Industrial Environments Using MEMS-LiDAR and Hybrid Data",
      "link": "http://arxiv.org/abs/2602.01764v1",
      "pdf_link": "https://arxiv.org/pdf/2602.01764v1",
      "authors": "Dennis Basile, Dennis Sprute, Helene Dörksen, Holger Flatt",
      "institution": "",
      "abstract": "The reliable detection of unauthorized individuals in safety-critical industrial indoor spaces is crucial to avoid plant shutdowns, property damage, and personal hazards. Conventional vision-based methods that use deep-learning approaches for person recognition provide image information but are sensitive to lighting and visibility conditions and often violate privacy regulations, such as the General Data Protection Regulation (GDPR) in the European Union. Typically, detection systems based on deep learning require annotated data for training. Collecting and annotating such data, however, is highly time-consuming and due to manual treatments not necessarily error free. Therefore, this paper presents a privacy-compliant approach based on Micro-Electro-Mechanical Systems LiDAR (MEMS-LiDAR), which exclusively captures anonymized 3D point clouds and avoids personal identification features. To compensate for the large amount of time required to record real LiDAR data and for post-processing and annotation, real recordings are augmented with synthetically generated scenes from the CARLA simulation framework. The results demonstrate that the hybrid data improves the average precision by 44 percentage points compared to a model trained exclusively with real data while reducing the manual annotation effort by 50 %. Thus, the proposed approach provides a scalable, cost-efficient alternative to purely real-data-based methods and systematically shows how synthetic LiDAR data can combine high performance in person detection with GDPR compliance in an industrial environment.",
      "source": "arXiv",
      "pubDateISO": "2026-02-02",
      "tags": [
        "cs.CV"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.01763v1",
      "title": "A Provable Expressiveness Hierarchy in Hybrid Linear-Full Attention",
      "link": "http://arxiv.org/abs/2602.01763v1",
      "pdf_link": "https://arxiv.org/pdf/2602.01763v1",
      "authors": "Xiaowei Ye, Xiaoyu He, Chao Liao, Chen Wu, Pinyan Lu",
      "institution": "",
      "abstract": "Transformers serve as the foundation of most modern large language models. To mitigate the quadratic complexity of standard full attention, various efficient attention mechanisms, such as linear and hybrid attention, have been developed. A fundamental gap remains: their expressive power relative to full attention lacks a rigorous theoretical characterization. In this work, we theoretically characterize the performance differences among these attention mechanisms. Our theory applies to all linear attention variants that can be formulated as a recurrence, including Mamba, DeltaNet, etc. Specifically, we establish an expressiveness hierarchy: for the sequential function composition-a multi-step reasoning task that must occur within a model's forward pass, an ($L+1$)-layer full attention network is sufficient, whereas any hybrid network interleaving $L-1$ layers of full attention with a substantially larger number ($2^{3L^2}$) of linear attention layers cannot solve it. This result demonstrates a clear separation in expressive power between the two types of attention. Our work provides the first provable separation between hybrid attention and standard full attention, offering a theoretical perspective for understanding the fundamental capabilities and limitations of different attention mechanisms.",
      "source": "arXiv",
      "pubDateISO": "2026-02-02",
      "tags": [
        "cs.LG",
        "cs.AI",
        "cs.CC"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.01762v1",
      "title": "PRISM: Parametrically Refactoring Inference for Speculative Sampling Draft Models",
      "link": "http://arxiv.org/abs/2602.01762v1",
      "pdf_link": "https://arxiv.org/pdf/2602.01762v1",
      "authors": "Xuliang Wang, Yuetao Chen, Maochan Zhen, Fang Liu, Xinzhou Zheng et al.",
      "institution": "",
      "abstract": "Large Language Models (LLMs), constrained by their auto-regressive nature, suffer from slow decoding. Speculative decoding methods have emerged as a promising solution to accelerate LLM decoding, attracting attention from both systems and AI research communities. Recently, the pursuit of better draft quality has driven a trend toward parametrically larger draft models, which inevitably introduces substantial computational overhead. While existing work attempts to balance the trade-off between prediction accuracy and compute latency, we address this fundamental dilemma through architectural innovation.\n  We propose PRISM, which disaggregates the computation of each predictive step across different parameter sets, refactoring the computational pathways of draft models to successfully decouple model capacity from inference cost. Through extensive experiments, we demonstrate that PRISM outperforms all existing draft architectures, achieving exceptional acceptance lengths while maintaining minimal draft latency for superior end-to-end speedup. We also re-examine scaling laws with PRISM, revealing that PRISM scales more effectively with expanding data volumes than other draft architectures. Through rigorous and fair comparison, we show that PRISM boosts the decoding throughput of an already highly optimized inference engine by more than 2.6x.",
      "source": "arXiv",
      "pubDateISO": "2026-02-02",
      "tags": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.01760v1",
      "title": "MagicFuse: Single Image Fusion for Visual and Semantic Reinforcement",
      "link": "http://arxiv.org/abs/2602.01760v1",
      "pdf_link": "https://arxiv.org/pdf/2602.01760v1",
      "authors": "Hao Zhang, Yanping Zha, Zizhuo Li, Meiqi Gong, Jiayi Ma",
      "institution": "",
      "abstract": "This paper focuses on a highly practical scenario: how to continue benefiting from the advantages of multi-modal image fusion under harsh conditions when only visible imaging sensors are available. To achieve this goal, we propose a novel concept of single-image fusion, which extends conventional data-level fusion to the knowledge level. Specifically, we develop MagicFuse, a novel single image fusion framework capable of deriving a comprehensive cross-spectral scene representation from a single low-quality visible image. MagicFuse first introduces an intra-spectral knowledge reinforcement branch and a cross-spectral knowledge generation branch based on the diffusion models. They mine scene information obscured in the visible spectrum and learn thermal radiation distribution patterns transferred to the infrared spectrum, respectively. Building on them, we design a multi-domain knowledge fusion branch that integrates the probabilistic noise from the diffusion streams of these two branches, from which a cross-spectral scene representation can be obtained through successive sampling. Then, we impose both visual and semantic constraints to ensure that this scene representation can satisfy human observation while supporting downstream semantic decision-making. Extensive experiments show that our MagicFuse achieves visual and semantic representation performance comparable to or even better than state-of-the-art fusion methods with multi-modal inputs, despite relying solely on a single degraded visible image.",
      "source": "arXiv",
      "pubDateISO": "2026-02-02",
      "tags": [
        "cs.CV"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.01757v1",
      "title": "Zero2Text: Zero-Training Cross-Domain Inversion Attacks on Textual Embeddings",
      "link": "http://arxiv.org/abs/2602.01757v1",
      "pdf_link": "https://arxiv.org/pdf/2602.01757v1",
      "authors": "Doohyun Kim, Donghwa Kang, Kyungjae Lee, Hyeongboo Baek, Brent Byunghoon Kang",
      "institution": "",
      "abstract": "The proliferation of retrieval-augmented generation (RAG) has established vector databases as critical infrastructure, yet they introduce severe privacy risks via embedding inversion attacks. Existing paradigms face a fundamental trade-off: optimization-based methods require computationally prohibitive queries, while alignment-based approaches hinge on the unrealistic assumption of accessible in-domain training data. These constraints render them ineffective in strict black-box and cross-domain settings. To dismantle these barriers, we introduce Zero2Text, a novel training-free framework based on recursive online alignment. Unlike methods relying on static datasets, Zero2Text synergizes LLM priors with a dynamic ridge regression mechanism to iteratively align generation to the target embedding on-the-fly. We further demonstrate that standard defenses, such as differential privacy, fail to effectively mitigate this adaptive threat. Extensive experiments across diverse benchmarks validate Zero2Text; notably, on MS MARCO against the OpenAI victim model, it achieves 1.8x higher ROUGE-L and 6.4x higher BLEU-2 scores compared to baselines, recovering sentences from unknown domains without a single leaked data pair.",
      "source": "arXiv",
      "pubDateISO": "2026-02-02",
      "tags": [
        "cs.CL",
        "cs.LG"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.01756v1",
      "title": "Mind-Brush: Integrating Agentic Cognitive Search and Reasoning into Image Generation",
      "link": "http://arxiv.org/abs/2602.01756v1",
      "pdf_link": "https://arxiv.org/pdf/2602.01756v1",
      "authors": "Jun He, Junyan Ye, Zilong Huang, Dongzhi Jiang, Chenjue Zhang et al.",
      "institution": "",
      "abstract": "While text-to-image generation has achieved unprecedented fidelity, the vast majority of existing models function fundamentally as static text-to-pixel decoders. Consequently, they often fail to grasp implicit user intentions. Although emerging unified understanding-generation models have improved intent comprehension, they still struggle to accomplish tasks involving complex knowledge reasoning within a single model. Moreover, constrained by static internal priors, these models remain unable to adapt to the evolving dynamics of the real world. To bridge these gaps, we introduce Mind-Brush, a unified agentic framework that transforms generation into a dynamic, knowledge-driven workflow. Simulating a human-like 'think-research-create' paradigm, Mind-Brush actively retrieves multimodal evidence to ground out-of-distribution concepts and employs reasoning tools to resolve implicit visual constraints. To rigorously evaluate these capabilities, we propose Mind-Bench, a comprehensive benchmark comprising 500 distinct samples spanning real-time news, emerging concepts, and domains such as mathematical and Geo-Reasoning. Extensive experiments demonstrate that Mind-Brush significantly enhances the capabilities of unified models, realizing a zero-to-one capability leap for the Qwen-Image baseline on Mind-Bench, while achieving superior results on established benchmarks like WISE and RISE.",
      "source": "arXiv",
      "pubDateISO": "2026-02-02",
      "tags": [
        "cs.CV"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.01754v1",
      "title": "Spot-Wise Smart Parking: An Edge-Enabled Architecture with YOLOv11 and Digital Twin Integration",
      "link": "http://arxiv.org/abs/2602.01754v1",
      "pdf_link": "https://arxiv.org/pdf/2602.01754v1",
      "authors": "Gustavo P. C. P. da Luz, Alvaro M. Aspilcueta Narvaez, Tiago Godoi Bannwart, Gabriel Massuyoshi Sato, Luis Fernando Gomez Gonzalez et al.",
      "institution": "",
      "abstract": "Smart parking systems help reduce congestion and minimize users' search time, thereby contributing to smart city adoption and enhancing urban mobility. In previous works, we presented a system developed on a university campus to monitor parking availability by estimating the number of free spaces from vehicle counts within a region of interest. Although this approach achieved good accuracy, it restricted the system's ability to provide spot-level insights and support more advanced applications. To overcome this limitation, we extend the system with a spot-wise monitoring strategy based on a distance-aware matching method with spatial tolerance, enhanced through an Adaptive Bounding Box Partitioning method for challenging spaces. The proposed approach achieves a balanced accuracy of 98.80% while maintaining an inference time of 8 seconds on a resource-constrained edge device, enhancing the capabilities of YOLOv11m, a model that has a size of 40.5 MB. In addition, two new components were introduced: (i) a Digital Shadow that visually represents parking lot entities as a base to evolve to a full Digital Twin, and (ii) an application support server based on a repurposed TV box. The latter not only enables scalable communication among cloud services, the parking totem, and a bot that provides detailed spot occupancy statistics, but also promotes hardware reuse as a step towards greater sustainability.",
      "source": "arXiv",
      "pubDateISO": "2026-02-02",
      "tags": [
        "cs.CV"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.01753v1",
      "title": "ObjEmbed: Towards Universal Multimodal Object Embeddings",
      "link": "http://arxiv.org/abs/2602.01753v1",
      "pdf_link": "https://arxiv.org/pdf/2602.01753v1",
      "authors": "Shenghao Fu, Yukun Su, Fengyun Rao, Jing Lyu, Xiaohua Xie et al.",
      "institution": "",
      "abstract": "Aligning objects with corresponding textual descriptions is a fundamental challenge and a realistic requirement in vision-language understanding. While recent multimodal embedding models excel at global image-text alignment, they often struggle with fine-grained alignment between image regions and specific phrases. In this work, we present ObjEmbed, a novel MLLM embedding model that decomposes the input image into multiple regional embeddings, each corresponding to an individual object, along with global embeddings. It supports a wide range of visual understanding tasks like visual grounding, local image retrieval, and global image retrieval. ObjEmbed enjoys three key properties: (1) Object-Oriented Representation: It captures both semantic and spatial aspects of objects by generating two complementary embeddings for each region: an object embedding for semantic matching and an IoU embedding that predicts localization quality. The final object matching score combines semantic similarity with the predicted IoU, enabling more accurate retrieval. (2) Versatility: It seamlessly handles both region-level and image-level tasks. (3) Efficient Encoding: All objects in an image, along with the full image, are encoded in a single forward pass for high efficiency. Superior performance on 18 diverse benchmarks demonstrates its strong semantic discrimination.",
      "source": "arXiv",
      "pubDateISO": "2026-02-02",
      "tags": [
        "cs.CV"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.01752v1",
      "title": "WorldCup Sampling for Multi-bit LLM Watermarking",
      "link": "http://arxiv.org/abs/2602.01752v1",
      "pdf_link": "https://arxiv.org/pdf/2602.01752v1",
      "authors": "Yidan Wang, Yubing Ren, Yanan Cao, Li Guo",
      "institution": "",
      "abstract": "As large language models (LLMs) generate increasingly human-like text, watermarking offers a promising solution for reliable attribution beyond mere detection. While multi-bit watermarking enables richer provenance encoding, existing methods largely extend zero-bit schemes through seed-driven steering, leading to indirect information flow, limited effective capacity, and suboptimal decoding. In this paper, we propose WorldCup, a multi-bit watermarking framework for LLMs that treats sampling as a natural communication channel and embeds message bits directly into token selection via a hierarchical competition mechanism guided by complementary signals. Moreover, WorldCup further adopts entropy-aware modulation to preserve generation quality and supports robust message recovery through confidence-aware decoding. Comprehensive experiments show that WorldCup achieves a strong balance across capacity, detectability, robustness, text quality, and decoding efficiency, consistently outperforming prior baselines and laying a solid foundation for future LLM watermarking studies.",
      "source": "arXiv",
      "pubDateISO": "2026-02-02",
      "tags": [
        "cs.CL",
        "cs.CR"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.01751v1",
      "title": "MGKAN: Predicting Asymmetric Drug-Drug Interactions via a Multimodal Graph Kolmogorov-Arnold Network",
      "link": "http://arxiv.org/abs/2602.01751v1",
      "pdf_link": "https://arxiv.org/pdf/2602.01751v1",
      "authors": "Kunyi Fan, Mengjie Chen, Longlong Li, Cunquan Qu",
      "institution": "",
      "abstract": "Predicting drug-drug interactions (DDIs) is essential for safe pharmacological treatments. Previous graph neural network (GNN) models leverage molecular structures and interaction networks but mostly rely on linear aggregation and symmetric assumptions, limiting their ability to capture nonlinear and heterogeneous patterns. We propose MGKAN, a Graph Kolmogorov-Arnold Network that introduces learnable basis functions into asymmetric DDI prediction. MGKAN replaces conventional MLP transformations with KAN-driven basis functions, enabling more expressive and nonlinear modeling of drug relationships. To capture pharmacological dependencies, MGKAN integrates three network views-an asymmetric DDI network, a co-interaction network, and a biochemical similarity network-with role-specific embeddings to preserve directional semantics. A fusion module combines linear attention and nonlinear transformation to enhance representational capacity. On two benchmark datasets, MGKAN outperforms seven state-of-the-art baselines. Ablation studies and case studies confirm its predictive accuracy and effectiveness in modeling directional drug effects.",
      "source": "arXiv",
      "pubDateISO": "2026-02-02",
      "tags": [
        "cs.LG"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.01750v1",
      "title": "Adversarial Reward Auditing for Active Detection and Mitigation of Reward Hacking",
      "link": "http://arxiv.org/abs/2602.01750v1",
      "pdf_link": "https://arxiv.org/pdf/2602.01750v1",
      "authors": "Mohammad Beigi, Ming Jin, Junshan Zhang, Qifan Wang, Lifu Huang",
      "institution": "",
      "abstract": "Reinforcement Learning from Human Feedback (RLHF) remains vulnerable to reward hacking, where models exploit spurious correlations in learned reward models to achieve high scores while violating human intent. Existing mitigations rely on static defenses that cannot adapt to novel exploitation strategies. We propose Adversarial Reward Auditing (ARA), a framework that reconceptualizes reward hacking as a dynamic, competitive game. ARA operates in two stages: first, a Hacker policy discovers reward model vulnerabilities while an Auditor learns to detect exploitation from latent representations; second, Auditor-Guided RLHF (AG-RLHF) gates reward signals to penalize detected hacking, transforming reward hacking from an unobservable failure into a measurable, controllable signal. Experiments across three hacking scenarios demonstrate that ARA achieves the best alignment-utility tradeoff among all baselines: reducing sycophancy to near-SFT levels while improving helpfulness, decreasing verbosity while achieving the highest ROUGE-L, and suppressing code gaming while improving Pass@1. Beyond single-domain evaluation, we show that reward hacking, detection, and mitigation all generalize across domains -- a Hacker trained on code gaming exhibits increased sycophancy despite no reward for this behavior, and an Auditor trained on one domain effectively suppresses exploitation in others, enabling efficient multi-domain defense with a single model.",
      "source": "arXiv",
      "pubDateISO": "2026-02-02",
      "tags": [
        "cs.AI",
        "cs.LG"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.01749v1",
      "title": "Controlling Exploration-Exploitation in GFlowNets via Markov Chain Perspectives",
      "link": "http://arxiv.org/abs/2602.01749v1",
      "pdf_link": "https://arxiv.org/pdf/2602.01749v1",
      "authors": "Lin Chen, Samuel Drapeau, Fanghao Shao, Xuekai Zhu, Bo Xue et al.",
      "institution": "",
      "abstract": "Generative Flow Network (GFlowNet) objectives implicitly fix an equal mixing of forward and backward policies, potentially constraining the exploration-exploitation trade-off during training. By further exploring the link between GFlowNets and Markov chains, we establish an equivalence between GFlowNet objectives and Markov chain reversibility, thereby revealing the origin of such constraints, and provide a framework for adapting Markov chain properties to GFlowNets. Building on these theoretical findings, we propose $α$-GFNs, which generalize the mixing via a tunable parameter $α$. This generalization enables direct control over exploration-exploitation dynamics to enhance mode discovery capabilities, while ensuring convergence to unique flows. Across various benchmarks, including Set, Bit Sequence, and Molecule Generation, $α$-GFN objectives consistently outperform previous GFlowNet objectives, achieving up to a $10 \\times$ increase in the number of discovered modes.",
      "source": "arXiv",
      "pubDateISO": "2026-02-02",
      "tags": [
        "cs.AI",
        "cs.LG"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.01747v1",
      "title": "Enhancing Automated Essay Scoring with Three Techniques: Two-Stage Fine-Tuning, Score Alignment, and Self-Training",
      "link": "http://arxiv.org/abs/2602.01747v1",
      "pdf_link": "https://arxiv.org/pdf/2602.01747v1",
      "authors": "Hongseok Choi, Serynn Kim, Wencke Liermann, Jin Seong, Jin-Xia Huang",
      "institution": "",
      "abstract": "Automated Essay Scoring (AES) plays a crucial role in education by providing scalable and efficient assessment tools. However, in real-world settings, the extreme scarcity of labeled data severely limits the development and practical adoption of robust AES systems. This study proposes a novel approach to enhance AES performance in both limited-data and full-data settings by introducing three key techniques. First, we introduce a Two-Stage fine-tuning strategy that leverages low-rank adaptations to better adapt an AES model to target prompt essays. Second, we introduce a Score Alignment technique to improve consistency between predicted and true score distributions. Third, we employ uncertainty-aware self-training using unlabeled data, effectively expanding the training set with pseudo-labeled samples while mitigating label noise propagation. We implement above three key techniques on DualBERT. We conduct extensive experiments on the ASAP++ dataset. As a result, in the 32-data setting, all three key techniques improve performance, and their integration achieves 91.2% of the full-data performance trained on approximately 1,000 labeled samples. In addition, the proposed Score Alignment technique consistently improves performance in both limited-data and full-data settings: e.g., it achieves state-of-the-art results in the full-data setting when integrated into DualBERT.",
      "source": "arXiv",
      "pubDateISO": "2026-02-02",
      "tags": [
        "cs.CL",
        "cs.LG"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.01746v1",
      "title": "Rethinking LoRA for Data Heterogeneous Federated Learning: Subspace and State Alignment",
      "link": "http://arxiv.org/abs/2602.01746v1",
      "pdf_link": "https://arxiv.org/pdf/2602.01746v1",
      "authors": "Hongyi Peng, Han Yu, Xiaoxiao Li, Qiang Yang",
      "institution": "",
      "abstract": "Low-Rank Adaptation (LoRA) is widely used for federated fine-tuning. Yet under non-IID settings, it can substantially underperform full-parameter fine-tuning. Through with-high-probability robustness analysis, we uncover that this gap can be attributed to two coupled mismatches: (i) update-space mismatch, where clients optimize in a low-rank subspace but aggregation occurs in the full space; and (ii) optimizer-state mismatch, where unsynchronized adaptive states amplify drift across rounds. We propose FedGaLore, which combines client-side GaLore-style gradient-subspace optimization with server-side drift-robust synchronization of projected second-moment states via spectral shared-signal extraction, to address this challenge. Across NLU, vision, and NLG benchmarks, FedGaLore improves robustness and accuracy over state-of-the-art federated LoRA baselines in non-IID settings.",
      "source": "arXiv",
      "pubDateISO": "2026-02-02",
      "tags": [
        "cs.LG",
        "cs.AI"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.01745v1",
      "title": "Probability-Entropy Calibration: An Elastic Indicator for Adaptive Fine-tuning",
      "link": "http://arxiv.org/abs/2602.01745v1",
      "pdf_link": "https://arxiv.org/pdf/2602.01745v1",
      "authors": "Wenhao Yu, Shaohang Wei, Jiahong Liu, Yifan Li, Minda Hu et al.",
      "institution": "",
      "abstract": "Token-level reweighting is a simple yet effective mechanism for controlling supervised fine-tuning, but common indicators are largely one-dimensional: the ground-truth probability reflects downstream alignment, while token entropy reflects intrinsic uncertainty induced by the pre-training prior. Ignoring entropy can misidentify noisy or easily replaceable tokens as learning-critical, while ignoring probability fails to reflect target-specific alignment. RankTuner introduces a probability--entropy calibration signal, the Relative Rank Indicator, which compares the rank of the ground-truth token with its expected rank under the prediction distribution. The inverse indicator is used as a token-wise Relative Scale to reweight the fine-tuning objective, focusing updates on truly under-learned tokens without over-penalizing intrinsically uncertain positions. Experiments on multiple backbones show consistent improvements on mathematical reasoning benchmarks, transfer gains on out-of-distribution reasoning, and pre code generation performance over probability-only or entropy-only reweighting baselines.",
      "source": "arXiv",
      "pubDateISO": "2026-02-02",
      "tags": [
        "cs.LG",
        "cs.AI"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.01744v1",
      "title": "Softmax Linear Attention: Reclaiming Global Competition",
      "link": "http://arxiv.org/abs/2602.01744v1",
      "pdf_link": "https://arxiv.org/pdf/2602.01744v1",
      "authors": "Mingwei Xu, Xuan Lin, Xinnan Guo, Wanqing Xu, Wanyun Cui",
      "institution": "",
      "abstract": "While linear attention reduces the quadratic complexity of standard Transformers to linear time, it often lags behind in expressivity due to the removal of softmax normalization. This omission eliminates \\emph{global competition}, a critical mechanism that enables models to sharply focus on relevant information amidst long-context noise. In this work, we propose \\textbf{Softmax Linear Attention (SLA)}, a framework designed to restore this competitive selection without sacrificing efficiency. By lifting the softmax operation from the token level to the head level, SLA leverages attention heads as coarse semantic slots, applying a competitive gating mechanism to dynamically select the most relevant subspaces. This reintroduces the ``winner-take-all'' dynamics essential for precise retrieval and robust long-context understanding. Distinct from prior methods that focus on refining local kernel functions, SLA adopts a broader perspective by exploiting the higher-level multi-head aggregation structure. Extensive experiments demonstrate that SLA consistently enhances state-of-the-art linear baselines (RetNet, GLA, GDN) across language modeling and long-context benchmarks, particularly in challenging retrieval scenarios where it significantly boosts robustness against noise, validating its capability to restore precise focus while maintaining linear complexity.",
      "source": "arXiv",
      "pubDateISO": "2026-02-02",
      "tags": [
        "cs.LG",
        "cs.AI"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.01741v1",
      "title": "Tail-Aware Post-Training Quantization for 3D Geometry Models",
      "link": "http://arxiv.org/abs/2602.01741v1",
      "pdf_link": "https://arxiv.org/pdf/2602.01741v1",
      "authors": "Sicheng Pan, Chen Tang, Shuzhao Xie, Ke Yang, Weixiang Zhang et al.",
      "institution": "",
      "abstract": "The burgeoning complexity and scale of 3D geometry models pose significant challenges for deployment on resource-constrained platforms. While Post-Training Quantization (PTQ) enables efficient inference without retraining, conventional methods, primarily optimized for 2D Vision Transformers, fail to transfer effectively to 3D models due to intricate feature distributions and prohibitive calibration overhead. To address these challenges, we propose TAPTQ, a Tail-Aware Post-Training Quantization pipeline specifically engineered for 3D geometric learning. Our contribution is threefold: (1) To overcome the data-scale bottleneck in 3D datasets, we develop a progressive coarse-to-fine calibration construction strategy that constructs a highly compact subset to achieve both statistical purity and geometric representativeness. (2) We reformulate the quantization interval search as an optimization problem and introduce a ternary-search-based solver, reducing the computational complexity from $\\mathcal{O}(N)$ to $\\mathcal{O}(\\log N)$ for accelerated deployment. (3) To mitigate quantization error accumulation, we propose TRE-Guided Module-wise Compensation, which utilizes a Tail Relative Error (TRE) metric to adaptively identify and rectify distortions in modules sensitive to long-tailed activation outliers. Extensive experiments on the VGGT and Pi3 benchmarks demonstrate that TAPTQ consistently outperforms state-of-the-art PTQ methods in accuracy while significantly reducing calibration time. The code will be released soon.",
      "source": "arXiv",
      "pubDateISO": "2026-02-02",
      "tags": [
        "cs.CV"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.01740v1",
      "title": "MACD: Model-Aware Contrastive Decoding via Counterfactual Data",
      "link": "http://arxiv.org/abs/2602.01740v1",
      "pdf_link": "https://arxiv.org/pdf/2602.01740v1",
      "authors": "Qixin Xiao, Kun Zhou",
      "institution": "",
      "abstract": "Video language models (Video-LLMs) are prone to hallucinations, often generating plausible but ungrounded content when visual evidence is weak, ambiguous, or biased. Existing decoding methods, such as contrastive decoding (CD), rely on random perturbations to construct contrastive data for mitigating hallucination patterns. However, such a way is hard to control the visual cues that drive hallucination or well align with model weaknesses. We propose Model-aware Counterfactual Data based Contrastive Decoding (MACD), a new inference strategy that combines model-guided counterfactual construction with decoding. Our approach uses the Video-LLM's own feedback to identify object regions most responsible for hallucination, generating targeted counterfactual inputs at the object level rather than arbitrary frame or temporal modifications. These model-aware counterfactual data is then integrated into CD to enforce evidence-grounded token selection during decoding. Experiments on EventHallusion, MVBench, Perception-test and Video-MME show that MACD consistently reduces hallucination while maintaining or improving task accuracy across diverse Video-LLMs, including Qwen and InternVL families. The method is especially effective in challenging scenarios involving small, occluded, or co-occurring objects. Our code and data will be publicly released.",
      "source": "arXiv",
      "pubDateISO": "2026-02-02",
      "tags": [
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.01738v1",
      "title": "Simplicity Prevails: The Emergence of Generalizable AIGI Detection in Visual Foundation Models",
      "link": "http://arxiv.org/abs/2602.01738v1",
      "pdf_link": "https://arxiv.org/pdf/2602.01738v1",
      "authors": "Yue Zhou, Xinan He, Kaiqing Lin, Bing Fan, Feng Ding et al.",
      "institution": "",
      "abstract": "While specialized detectors for AI-Generated Images (AIGI) achieve near-perfect accuracy on curated benchmarks, they suffer from a dramatic performance collapse in realistic, in-the-wild scenarios. In this work, we demonstrate that simplicity prevails over complex architectural designs. A simple linear classifier trained on the frozen features of modern Vision Foundation Models , including Perception Encoder, MetaCLIP 2, and DINOv3, establishes a new state-of-the-art. Through a comprehensive evaluation spanning traditional benchmarks, unseen generators, and challenging in-the-wild distributions, we show that this baseline not only matches specialized detectors on standard benchmarks but also decisively outperforms them on in-the-wild datasets, boosting accuracy by striking margins of over 30\\%. We posit that this superior capability is an emergent property driven by the massive scale of pre-training data containing synthetic content. We trace the source of this capability to two distinct manifestations of data exposure: Vision-Language Models internalize an explicit semantic concept of forgery, while Self-Supervised Learning models implicitly acquire discriminative forensic features from the pretraining data. However, we also reveal persistent limitations: these models suffer from performance degradation under recapture and transmission, remain blind to VAE reconstruction and localized editing. We conclude by advocating for a paradigm shift in AI forensics, moving from overfitting on static benchmarks to harnessing the evolving world knowledge of foundation models for real-world reliability.",
      "source": "arXiv",
      "pubDateISO": "2026-02-02",
      "tags": [
        "cs.CV"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.01737v1",
      "title": "Physics-Informed Chebyshev Polynomial Neural Operator for Parametric Partial Differential Equations",
      "link": "http://arxiv.org/abs/2602.01737v1",
      "pdf_link": "https://arxiv.org/pdf/2602.01737v1",
      "authors": "Biao Chen, Jing Wang, Hairun Xie, Qineng Wang, Shuai Zhang et al.",
      "institution": "",
      "abstract": "Neural operators have emerged as powerful deep learning frameworks for approximating solution operators of parameterized partial differential equations (PDE). However, current methods predominantly rely on multilayer perceptrons (MLPs) for mapping inputs to solutions, which impairs training robustness in physics-informed settings due to inherent spectral biases and fixed activation functions. To overcome the architectural limitations, we introduce the Physics-Informed Chebyshev Polynomial Neural Operator (CPNO), a novel mesh-free framework that leverages a basis transformation to replace unstable monomial expansions with the numerically stable Chebyshev spectral basis. By integrating parameter dependent modulation mechanism to main net, CPNO constructs PDE solutions in a near-optimal functional space, decoupling the model from MLP-specific constraints and enhancing multi-scale representation. Theoretical analysis demonstrates the Chebyshev basis's near-minimax uniform approximation properties and superior conditioning, with Lebesgue constants growing logarithmically with degree, thereby mitigating spectral bias and ensuring stable gradient flow during optimization. Numerical experiments on benchmark parameterized PDEs show that CPNO achieves superior accuracy, faster convergence, and enhanced robustness to hyperparameters. The experiment of transonic airfoil flow has demonstrated the capability of CPNO in characterizing complex geometric problems.",
      "source": "arXiv",
      "pubDateISO": "2026-02-02",
      "tags": [
        "cs.LG"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.01736v1",
      "title": "Position: The Inevitable End of One-Architecture-Fits-All-Domains in Time Series Forecasting",
      "link": "http://arxiv.org/abs/2602.01736v1",
      "pdf_link": "https://arxiv.org/pdf/2602.01736v1",
      "authors": "Qinwei Ma, Jingzhe Shi, Jiahao Qiu, Zaiwen Yang",
      "institution": "",
      "abstract": "Recent work has questioned the effectiveness and robustness of neural network architectures for time series forecasting tasks. We summarize these concerns and analyze groundly their inherent limitations: i.e. the irreconcilable conflict between single (or few similar) domains SOTA and generalizability over general domains for time series forecasting neural network architecture designs. Moreover, neural networks architectures for general domain time series forecasting are becoming more and more complicated and their performance has almost saturated in recent years. As a result, network architectures developed aiming at fitting general time series domains are almost not inspiring for real world practices for certain single (or few similar) domains such as Finance, Weather, Traffic, etc: each specific domain develops their own methods that rarely utilize advances in neural network architectures of time series community in recent 2-3 years. As a result, we call for the time series community to shift focus away from research on time series neural network architectures for general domains: these researches have become saturated and away from domain-specific SOTAs over time. We should either (1) focus on deep learning methods for certain specific domain(s), or (2) turn to the development of meta-learning methods for general domains.",
      "source": "arXiv",
      "pubDateISO": "2026-02-02",
      "tags": [
        "cs.LG"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.01734v1",
      "title": "MSign: An Optimizer Preventing Training Instability in Large Language Models via Stable Rank Restoration",
      "link": "http://arxiv.org/abs/2602.01734v1",
      "pdf_link": "https://arxiv.org/pdf/2602.01734v1",
      "authors": "Lianhai Ren, Yucheng Ding, Xiao Liu, Qianxiao Li, Peng Cheng et al.",
      "institution": "",
      "abstract": "Training instability remains a critical challenge in large language model (LLM) pretraining, often manifesting as sudden gradient explosions that waste significant computational resources. We study training failures in a 5M-parameter NanoGPT model scaled via $μ$P, identifying two key phenomena preceding collapse: (1) rapid decline in weight matrix stable rank (ratio of squared Frobenius norm to squared spectral norm), and (2) increasing alignment between adjacent layer Jacobians. We prove theoretically that these two conditions jointly cause exponential gradient norm growth with network depth. To break this instability mechanism, we propose MSign, a new optimizer that periodically applies matrix sign operations to restore stable rank. Experiments on models from 5M to 3B parameters demonstrate that MSign effectively prevents training failures with a computational overhead of less than 7.0%.",
      "source": "arXiv",
      "pubDateISO": "2026-02-02",
      "tags": [
        "cs.LG"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.01733v1",
      "title": "ST-BCP: Tightening Coverage Bound for Backward Conformal Prediction via Non-Conformity Score Transformation",
      "link": "http://arxiv.org/abs/2602.01733v1",
      "pdf_link": "https://arxiv.org/pdf/2602.01733v1",
      "authors": "Junxian Liu, Hao Zeng, Hongxin Wei",
      "institution": "",
      "abstract": "Conformal Prediction (CP) provides a statistical framework for uncertainty quantification that constructs prediction sets with coverage guarantees. While CP yields uncontrolled prediction set sizes, Backward Conformal Prediction (BCP) inverts this paradigm by enforcing a predefined upper bound on set size and estimating the resulting coverage guarantee. However, the looseness induced by Markov's inequality within the BCP framework causes a significant gap between the estimated coverage bound and the empirical coverage. In this work, we introduce ST-BCP, a novel method that introduces a data-dependent transformation of nonconformity scores to narrow the coverage gap. In particular, we develop a computable transformation and prove that it outperforms the baseline identity transformation. Extensive experiments demonstrate the effectiveness of our method, reducing the average coverage gap from 4.20\\% to 1.12\\% on common benchmarks.",
      "source": "arXiv",
      "pubDateISO": "2026-02-02",
      "tags": [
        "stat.ML",
        "cs.LG"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.01726v1",
      "title": "Cross-Domain Fake News Detection on Unseen Domains via LLM-Based Domain-Aware User Modeling",
      "link": "http://arxiv.org/abs/2602.01726v1",
      "pdf_link": "https://arxiv.org/pdf/2602.01726v1",
      "authors": "Xuankai Yang, Yan Wang, Jiajie Zhu, Pengfei Ding, Hongyang Liu et al.",
      "institution": "",
      "abstract": "Cross-domain fake news detection (CD-FND) transfers knowledge from a source domain to a target domain and is crucial for real-world fake news mitigation. This task becomes particularly important yet more challenging when the target domain is previously unseen (e.g., the COVID-19 outbreak or the Russia-Ukraine war). However, existing CD-FND methods overlook such scenarios and consequently suffer from the following two key limitations: (1) insufficient modeling of high-level semantics in news and user engagements; and (2) scarcity of labeled data in unseen domains. Targeting these limitations, we find that large language models (LLMs) offer strong potential for CD-FND on unseen domains, yet their effective use remains non-trivial. Nevertheless, two key challenges arise: (1) how to capture high-level semantics from both news content and user engagements using LLMs; and (2) how to make LLM-generated features more reliable and transferable for CD-FND on unseen domains. To tackle these challenges, we propose DAUD, a novel LLM-Based Domain-Aware framework for fake news detection on Unseen Domains. DAUD employs LLMs to extract high-level semantics from news content. It models users' single- and cross-domain engagements to generate domain-aware behavioral representations. In addition, DAUD captures the relations between original data-driven features and LLM-derived features of news, users, and user engagements. This allows it to extract more reliable domain-shared representations that improve knowledge transfer to unseen domains. Extensive experiments on real-world datasets demonstrate that DAUD outperforms state-of-the-art baselines in both general and unseen-domain CD-FND settings.",
      "source": "arXiv",
      "pubDateISO": "2026-02-02",
      "tags": [
        "cs.SI",
        "cs.LG"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.01725v1",
      "title": "SafePred: A Predictive Guardrail for Computer-Using Agents via World Models",
      "link": "http://arxiv.org/abs/2602.01725v1",
      "pdf_link": "https://arxiv.org/pdf/2602.01725v1",
      "authors": "Yurun Chen, Zeyi Liao, Ping Yin, Taotao Xie, Keting Yin et al.",
      "institution": "",
      "abstract": "With the widespread deployment of Computer-using Agents (CUAs) in complex real-world environments, prevalent long-term risks often lead to severe and irreversible consequences. Most existing guardrails for CUAs adopt a reactive approach, constraining agent behavior only within the current observation space. While these guardrails can prevent immediate short-term risks (e.g., clicking on a phishing link), they cannot proactively avoid long-term risks: seemingly reasonable actions can lead to high-risk consequences that emerge with a delay (e.g., cleaning logs leads to future audits being untraceable), which reactive guardrails cannot identify within the current observation space. To address these limitations, we propose a predictive guardrail approach, with the core idea of aligning predicted future risks with current decisions. Based on this approach, we present SafePred, a predictive guardrail framework for CUAs that establishes a risk-to-decision loop to ensure safe agent behavior. SafePred supports two key abilities: (1) Short- and long-term risk prediction: by using safety policies as the basis for risk prediction, SafePred leverages the prediction capability of the world model to generate semantic representations of both short-term and long-term risks, thereby identifying and pruning actions that lead to high-risk states; (2) Decision optimization: translating predicted risks into actionable safe decision guidances through step-level interventions and task-level re-planning. Extensive experiments show that SafePred significantly reduces high-risk behaviors, achieving over 97.6% safety performance and improving task utility by up to 21.4% compared with reactive baselines.",
      "source": "arXiv",
      "pubDateISO": "2026-02-02",
      "tags": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.01724v1",
      "title": "DenVisCoM: Dense Vision Correspondence Mamba for Efficient and Real-time Optical Flow and Stereo Estimation",
      "link": "http://arxiv.org/abs/2602.01724v1",
      "pdf_link": "https://arxiv.org/pdf/2602.01724v1",
      "authors": "Tushar Anand, Maheswar Bora, Antitza Dantcheva, Abhijit Das",
      "institution": "",
      "abstract": "In this work, we propose a novel Mamba block DenVisCoM, as well as a novel hybrid architecture specifically tailored for accurate and real-time estimation of optical flow and disparity estimation. Given that such multi-view geometry and motion tasks are fundamentally related, we propose a unified architecture to tackle them jointly. Specifically, the proposed hybrid architecture is based on DenVisCoM and a Transformer-based attention block that efficiently addresses real-time inference, memory footprint, and accuracy at the same time for joint estimation of motion and 3D dense perception tasks. We extensively analyze the benchmark trade-off of accuracy and real-time processing on a large number of datasets. Our experimental results and related analysis suggest that our proposed model can accurately estimate optical flow and disparity estimation in real time. All models and associated code are available at https://github.com/vimstereo/DenVisCoM.",
      "source": "arXiv",
      "pubDateISO": "2026-02-02",
      "tags": [
        "cs.CV"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.01723v1",
      "title": "FastPhysGS: Accelerating Physics-based Dynamic 3DGS Simulation via Interior Completion and Adaptive Optimization",
      "link": "http://arxiv.org/abs/2602.01723v1",
      "pdf_link": "https://arxiv.org/pdf/2602.01723v1",
      "authors": "Yikun Ma, Yiqing Li, Jingwen Ye, Zhongkai Wu, Weidong Zhang et al.",
      "institution": "",
      "abstract": "Extending 3D Gaussian Splatting (3DGS) to 4D physical simulation remains challenging. Based on the Material Point Method (MPM), existing methods either rely on manual parameter tuning or distill dynamics from video diffusion models, limiting the generalization and optimization efficiency. Recent attempts using LLMs/VLMs suffer from a text/image-to-3D perceptual gap, yielding unstable physics behavior. In addition, they often ignore the surface structure of 3DGS, leading to implausible motion. We propose FastPhysGS, a fast and robust framework for physics-based dynamic 3DGS simulation:(1) Instance-aware Particle Filling (IPF) with Monte Carlo Importance Sampling (MCIS) to efficiently populate interior particles while preserving geometric fidelity; (2) Bidirectional Graph Decoupling Optimization (BGDO), an adaptive strategy that rapidly optimizes material parameters predicted from a VLM. Experiments show FastPhysGS achieves high-fidelity physical simulation in 1 minute using only 7 GB runtime memory, outperforming prior works with broad potential applications.",
      "source": "arXiv",
      "pubDateISO": "2026-02-02",
      "tags": [
        "cs.CV"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.01719v1",
      "title": "COMI: Coarse-to-fine Context Compression via Marginal Information Gain",
      "link": "http://arxiv.org/abs/2602.01719v1",
      "pdf_link": "https://arxiv.org/pdf/2602.01719v1",
      "authors": "Jiwei Tang, Shilei Liu, Zhicheng Zhang, Yujin Yuan, Libin Zheng et al.",
      "institution": "",
      "abstract": "Large Language Models (LLMs) have demonstrated exceptional capabilities across diverse tasks. However, their deployment in long context scenarios remains hindered by computational inefficiency and information redundancy. Context compression methods address these challenges by significantly reducing input length and eliminating redundancy. We propose COMI, a coarse-to-fine adaptive context compression framework that jointly optimizes for semantic relevance and diversity under high compression rates. We introduce Marginal Information Gain (MIG), a metric defined as the relevance of a unit to the input query minus its semantic redundancy with other units, guiding the compression process to prioritize information that is both relevant and low redundant. The framework operates in two stages: (1) Coarse-Grained Group Reallocation, where the context is partitioned into groups and dynamically assigned compression rates based on inter-group MIG, ensuring compression budgets align with information value distribution; and (2) Fine-Grained Token Merging, where tokens within each group are fused via an intra-group MIG-based weighting mechanism, thereby preserving key semantics while avoiding the accumulation of redundancy. Extensive experiments across question-answering (e.g., NaturalQuestions, 2WikiMQA, HotpotQA and NarrativeQA), summarization (e.g., MultiNews) with various backbones (e.g., LLaMA-2-7B, Qwen2-7B) show that COMI outperforms existing baselines by a large margin, e.g., approximately 25-point Exact Match (EM) improvement under 32x compression constraint with Qwen2-7B on NaturalQuestions.",
      "source": "arXiv",
      "pubDateISO": "2026-02-02",
      "tags": [
        "cs.CL"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.01718v1",
      "title": "Revisiting Generalization Measures Beyond IID: An Empirical Study under Distributional Shift",
      "link": "http://arxiv.org/abs/2602.01718v1",
      "pdf_link": "https://arxiv.org/pdf/2602.01718v1",
      "authors": "Sora Nakai, Youssef Fadhloun, Kacem Mathlouthi, Kotaro Yoshida, Ganesh Talluri et al.",
      "institution": "",
      "abstract": "Generalization remains a central yet unresolved challenge in deep learning, particularly the ability to predict a model's performance beyond its training distribution using quantities available prior to test-time evaluation. Building on the large-scale study of Jiang et al. (2020). and concerns by Dziugaite et al. (2020). about instability across training configurations, we benchmark the robustness of generalization measures beyond IID regime. We train small-to-medium models over 10,000 hyperparameter configurations and evaluate more than 40 measures computable from the trained model and the available training data alone. We significantly broaden the experimental scope along multiple axes: (i) extending the evaluation beyond the standard IID setting to include benchmarking for robustness across diverse distribution shifts, (ii) evaluating multiple architectures and training recipes, and (iii) newly incorporating calibration- and information-criteria-based measures to assess their alignment with both IID and OOD generalization. We find that distribution shifts can substantially alter the predictive performance of many generalization measures, while a smaller subset remains comparatively stable across settings.",
      "source": "arXiv",
      "pubDateISO": "2026-02-02",
      "tags": [
        "cs.LG"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.01717v1",
      "title": "BBPE16: UTF-16-based byte-level byte-pair encoding for improved multilingual speech recognition",
      "link": "http://arxiv.org/abs/2602.01717v1",
      "pdf_link": "https://arxiv.org/pdf/2602.01717v1",
      "authors": "Hyunsik Kim, Haeri Kim, Munhak Lee, Kyungmin Lee",
      "institution": "",
      "abstract": "Multilingual automatic speech recognition (ASR) requires tokenization that efficiently covers many writing systems. Byte-level BPE (BBPE) using UTF-8 is widely adopted for its language-agnostic design and full Unicode coverage, but its variable-length encoding inflates token sequences for non-Latin scripts, such as Chinese, Japanese, and Korean (CJK). Longer sequences increase computational load and memory use. We propose BBPE16, a UTF-16-based BBPE tokenizer that represents most modern scripts with a uniform 2-byte code unit. BBPE16 preserves BBPE's language-agnostic properties while substantially improving cross-lingual token sharing. Across monolingual, bilingual, and trilingual ASR, and in a multilingual continual-learning setup, BBPE16 attains comparable or better accuracy; for Chinese, it reduces token counts by up to 10.4% and lowers decoding iterations by up to 10.3%. These reductions speed up fine-tuning and inference and decrease memory usage, making BBPE16 a practical tokenization choice for multilingual ASR.",
      "source": "arXiv",
      "pubDateISO": "2026-02-02",
      "tags": [
        "cs.CL",
        "cs.AI"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.01716v1",
      "title": "Mechanistic Indicators of Steering Effectiveness in Large Language Models",
      "link": "http://arxiv.org/abs/2602.01716v1",
      "pdf_link": "https://arxiv.org/pdf/2602.01716v1",
      "authors": "Mehdi Jafari, Hao Xue, Flora Salim",
      "institution": "",
      "abstract": "Activation-based steering enables Large Language Models (LLMs) to exhibit targeted behaviors by intervening on intermediate activations without retraining. Despite its widespread use, the mechanistic factors that govern when steering succeeds or fails remain poorly understood, as prior work has relied primarily on black-box outputs or LLM-based judges. In this study, we investigate whether the reliability of steering can be diagnosed using internal model signals. We focus on two information-theoretic measures: the entropy-derived Normalized Branching Factor (NBF), and the Kullback-Leibler (KL) divergence between steered activations and targeted concepts in the vocabulary space. We hypothesize that effective steering corresponds to structured entropy preservation and coherent KL alignment across decoding steps. Building on a reliability study demonstrating high inter-judge agreement between two architecturally distinct LLMs, we use LLM-generated annotations as ground truth and show that these mechanistic signals provide meaningful predictive power for identifying successful steering and estimating failure probability. We further introduce a stronger evaluation baseline for Contrastive Activation Addition (CAA) and Sparse Autoencoder-based steering, the two most widely adopted activation-steering methods.",
      "source": "arXiv",
      "pubDateISO": "2026-02-02",
      "tags": [
        "cs.CL"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.01714v1",
      "title": "MedAraBench: Large-Scale Arabic Medical Question Answering Dataset and Benchmark",
      "link": "http://arxiv.org/abs/2602.01714v1",
      "pdf_link": "https://arxiv.org/pdf/2602.01714v1",
      "authors": "Mouath Abu-Daoud, Leen Kharouf, Omar El Hajj, Dana El Samad, Mariam Al-Omari et al.",
      "institution": "",
      "abstract": "Arabic remains one of the most underrepresented languages in natural language processing research, particularly in medical applications, due to the limited availability of open-source data and benchmarks. The lack of resources hinders efforts to evaluate and advance the multilingual capabilities of Large Language Models (LLMs). In this paper, we introduce MedAraBench, a large-scale dataset consisting of Arabic multiple-choice question-answer pairs across various medical specialties. We constructed the dataset by manually digitizing a large repository of academic materials created by medical professionals in the Arabic-speaking region. We then conducted extensive preprocessing and split the dataset into training and test sets to support future research efforts in the area. To assess the quality of the data, we adopted two frameworks, namely expert human evaluation and LLM-as-a-judge. Our dataset is diverse and of high quality, spanning 19 specialties and five difficulty levels. For benchmarking purposes, we assessed the performance of eight state-of-the-art open-source and proprietary models, such as GPT-5, Gemini 2.0 Flash, and Claude 4-Sonnet. Our findings highlight the need for further domain-specific enhancements. We release the dataset and evaluation scripts to broaden the diversity of medical data benchmarks, expand the scope of evaluation suites for LLMs, and enhance the multilingual capabilities of models for deployment in clinical settings.",
      "source": "arXiv",
      "pubDateISO": "2026-02-02",
      "tags": [
        "cs.CL"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.01711v1",
      "title": "Optimizing Prompts for Large Language Models: A Causal Approach",
      "link": "http://arxiv.org/abs/2602.01711v1",
      "pdf_link": "https://arxiv.org/pdf/2602.01711v1",
      "authors": "Wei Chen, Yanbin Fang, Shuran Fu, Fasheng Xu, Xuan Wei",
      "institution": "",
      "abstract": "Large Language Models (LLMs) are increasingly embedded in enterprise workflows, yet their performance remains highly sensitive to prompt design. Automatic Prompt Optimization (APO) seeks to mitigate this instability, but existing approaches face two persistent challenges. First, commonly used prompt strategies rely on static instructions that perform well on average but fail to adapt to heterogeneous queries. Second, more dynamic approaches depend on offline reward models that are fundamentally correlational, confounding prompt effectiveness with query characteristics. We propose Causal Prompt Optimization (CPO), a framework that reframes prompt design as a problem of causal estimation. CPO operates in two stages. First, it learns an offline causal reward model by applying Double Machine Learning (DML) to semantic embeddings of prompts and queries, isolating the causal effect of prompt variations from confounding query attributes. Second, it utilizes this unbiased reward signal to guide a resource-efficient search for query-specific prompts without relying on costly online evaluation. We evaluate CPO across benchmarks in mathematical reasoning, visualization, and data analytics. CPO consistently outperforms human-engineered prompts and state-of-the-art automated optimizers. The gains are driven primarily by improved robustness on hard queries, where existing methods tend to deteriorate. Beyond performance, CPO fundamentally reshapes the economics of prompt optimization: by shifting evaluation from real-time model execution to an offline causal model, it enables high-precision, per-query customization at a fraction of the inference cost required by online methods. Together, these results establish causal inference as a scalable foundation for reliable and cost-efficient prompt optimization in enterprise LLM deployments.",
      "source": "arXiv",
      "pubDateISO": "2026-02-02",
      "tags": [
        "cs.AI",
        "cs.LG"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.01710v1",
      "title": "Physics Informed Generative AI Enabling Labour Free Segmentation For Microscopy Analysis",
      "link": "http://arxiv.org/abs/2602.01710v1",
      "pdf_link": "https://arxiv.org/pdf/2602.01710v1",
      "authors": "Salma Zahran, Zhou Ao, Zhengyang Zhang, Chen Chi, Chenchen Yuan et al.",
      "institution": "",
      "abstract": "Semantic segmentation of microscopy images is a critical task for high-throughput materials characterisation, yet its automation is severely constrained by the prohibitive cost, subjectivity, and scarcity of expert-annotated data. While physics-based simulations offer a scalable alternative to manual labelling, models trained on such data historically fail to generalise due to a significant domain gap, lacking the complex textures, noise patterns, and imaging artefacts inherent to experimental data. This paper introduces a novel framework for labour-free segmentation that successfully bridges this simulation-to-reality gap. Our pipeline leverages phase-field simulations to generate an abundant source of microstructural morphologies with perfect, intrinsically-derived ground-truth masks. We then employ a Cycle-Consistent Generative Adversarial Network (CycleGAN) for unpaired image-to-image translation, transforming the clean simulations into a large-scale dataset of high-fidelity, realistic SEM images. A U-Net model, trained exclusively on this synthetic data, demonstrated remarkable generalisation when deployed on unseen experimental images, achieving a mean Boundary F1-Score of 0.90 and an Intersection over Union (IOU) of 0.88. Comprehensive validation using t-SNE feature-space projection and Shannon entropy analysis confirms that our synthetic images are statistically and featurally indistinguishable from the real data manifold. By completely decoupling model training from manual annotation, our generative framework transforms a data-scarce problem into one of data abundance, providing a robust and fully automated solution to accelerate materials discovery and analysis.",
      "source": "arXiv",
      "pubDateISO": "2026-02-02",
      "tags": [
        "cs.CV",
        "cs.AI"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.01709v1",
      "title": "ARTIS: Agentic Risk-Aware Test-Time Scaling via Iterative Simulation",
      "link": "http://arxiv.org/abs/2602.01709v1",
      "pdf_link": "https://arxiv.org/pdf/2602.01709v1",
      "authors": "Xingshan Zeng, Lingzhi Wang, Weiwen Liu, Liangyou Li, Yasheng Wang et al.",
      "institution": "",
      "abstract": "Current test-time scaling (TTS) techniques enhance large language model (LLM) performance by allocating additional computation at inference time, yet they remain insufficient for agentic settings, where actions directly interact with external environments and their effects can be irreversible and costly. We propose \\emph{\\name}, \\emph{\\underline{A}gentic \\underline{R}isk-Aware \\underline{T}est-Time Scaling via \\underline{I}terative \\underline{S}imulation}, a framework that decouples exploration from commitment by enabling test-time exploration through simulated interactions prior to real-world execution. This design allows extending inference-time computation to improve action-level reliability and robustness without incurring environmental risk. We further show that naive LLM-based simulators struggle to capture rare but high-impact failure modes, substantially limiting their effectiveness for agentic decision making. To address this limitation, we introduce a \\emph{risk-aware tool simulator} that emphasizes fidelity on failure-inducing actions via targeted data generation and rebalanced training. Experiments on multi-turn and multi-step agentic benchmarks demonstrate that iterative simulation substantially improves agent reliability, and that risk-aware simulation is essential for consistently realizing these gains across models and tasks.",
      "source": "arXiv",
      "pubDateISO": "2026-02-02",
      "tags": [
        "cs.CL"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.01708v1",
      "title": "Game of Thought: Robust Information Seeking with Large Language Models Using Game Theory",
      "link": "http://arxiv.org/abs/2602.01708v1",
      "pdf_link": "https://arxiv.org/pdf/2602.01708v1",
      "authors": "Langyuan Cui, Chun Kai Ling, Hwee Tou Ng",
      "institution": "",
      "abstract": "Large Language Models (LLMs) are increasingly deployed in real-world scenarios where they may lack sufficient information to complete a given task. In such settings, the ability to actively seek out missing information becomes a critical capability. Existing approaches to enhancing this ability often rely on simplifying assumptions that degrade \\textit{worst-case} performance. This is an issue with serious implications in high-stakes applications. In this work, we use the game of Twenty Questions to evaluate the information-seeking ability of LLMs. We introduce and formalize its adversarial counterpart, the Strategic Language Search (SLS) problem along with its variants as a two-player zero-sum extensive form game. We propose Game of Thought (GoT), a framework that applies game-theoretic techniques to approximate a Nash equilibrium (NE) strategy for the restricted variant of the game. Empirical results demonstrate that our approach consistently improves worst-case performance compared to (1) direct prompting-based methods and (2) heuristic-guided search methods across all tested settings.",
      "source": "arXiv",
      "pubDateISO": "2026-02-02",
      "tags": [
        "cs.CL",
        "cs.AI",
        "cs.GT"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.01705v1",
      "title": "Beyond Mode Elicitation: Diversity-Preserving Reinforcement Learning via Latent Diffusion Reasoner",
      "link": "http://arxiv.org/abs/2602.01705v1",
      "pdf_link": "https://arxiv.org/pdf/2602.01705v1",
      "authors": "Haoqiang Kang, Yizhe Zhang, Nikki Lijing Kuang, Yi-An Ma, Lianhui Qin",
      "institution": "",
      "abstract": "Recent reinforcement learning (RL) methods improve LLM reasoning by optimizing discrete Chain-of-Thought (CoT) generation; however, exploration in token space often suffers from diversity collapse as policy entropy decreases due to mode elicitation behavior in discrete RL. To mitigate this issue, we propose Latent Diffusion Reasoning with Reinforcement Learning (LaDi-RL), a framework that conducts exploration directly in a continuous latent space, where latent variables encode semantic-level reasoning trajectories. By modeling exploration via guided diffusion, multi-step denoising distributes stochasticity and preserves multiple coexisting solution modes without mutual suppression. Furthermore, by decoupling latent-space exploration from text-space generation, we show that latent diffusion-based optimization is more effective than text-space policy optimization alone, while a complementary text policy provides additional gains when combined with latent exploration. Experiments on code generation and mathematical reasoning benchmarks demonstrate consistent improvements in both pass@1 and pass@k over discrete RL baselines, with absolute pass@1 gains of +9.4% on code generation and +5.7% on mathematical reasoning, highlighting diffusion-based latent RL as a principled alternative to discrete token-level RL for reasoning.",
      "source": "arXiv",
      "pubDateISO": "2026-02-02",
      "tags": [
        "cs.LG",
        "cs.AI"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.01703v1",
      "title": "$\\textbf{AGT$^{AO}$}$: Robust and Stabilized LLM Unlearning via Adversarial Gating Training with Adaptive Orthogonality",
      "link": "http://arxiv.org/abs/2602.01703v1",
      "pdf_link": "https://arxiv.org/pdf/2602.01703v1",
      "authors": "Pengyu Li, Lingling Zhang, Zhitao Gao, Yanrui Wu, Yuxuan Dong et al.",
      "institution": "",
      "abstract": "While Large Language Models (LLMs) have achieved remarkable capabilities, they unintentionally memorize sensitive data, posing critical privacy and security risks. Machine unlearning is pivotal for mitigating these risks, yet existing paradigms face a fundamental dilemma: aggressive unlearning often induces catastrophic forgetting that degrades model utility, whereas conservative strategies risk superficial forgetting, leaving models vulnerable to adversarial recovery. To address this trade-off, we propose $\\textbf{AGT$^{AO}$}$ (Adversarial Gating Training with Adaptive Orthogonality), a unified framework designed to reconcile robust erasure with utility preservation. Specifically, our approach introduces $\\textbf{Adaptive Orthogonality (AO)}$ to dynamically mitigate geometric gradient conflicts between forgetting and retention objectives, thereby minimizing unintended knowledge degradation. Concurrently, $\\textbf{Adversarial Gating Training (AGT)}$ formulates unlearning as a latent-space min-max game, employing a curriculum-based gating mechanism to simulate and counter internal recovery attempts. Extensive experiments demonstrate that $\\textbf{AGT$^{AO}$}$ achieves a superior trade-off between unlearning efficacy (KUR $\\approx$ 0.01) and model utility (MMLU 58.30). Code is available at https://github.com/TiezMind/AGT-unlearning.",
      "source": "arXiv",
      "pubDateISO": "2026-02-02",
      "tags": [
        "cs.LG",
        "cs.CL"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.01701v1",
      "title": "Meta Engine: A Unified Semantic Query Engine on Heterogeneous LLM-Based Query Systems",
      "link": "http://arxiv.org/abs/2602.01701v1",
      "pdf_link": "https://arxiv.org/pdf/2602.01701v1",
      "authors": "Ruyu Li, Tinghui Zhang, Haodi Ma, Daisy Zhe Wang, Yifan Wang",
      "institution": "",
      "abstract": "With the increasingly use of multi-modal data, semantic query has become more and more demanded in data management systems, which is an important way to access and analyze multi-modal data. As unstructured data, most information of multi-modal data (text, image, video, etc) hides in the semantics, which cannot be accessed by the traditional database queries like SQL.\n  Given the power of Large Language Model (LLM) in understanding semantics and processing natural language, in recent years several LLM-based semantic query systems have been proposed, to support semantic querying over unstructured data. However, this rapid growth has produced a fragmented ecosystem. Applications face significant integration challenges due to (1) disparate APIs of different semantic query systems and (2) a fundamental trade-off between specialization and generality. Many semantic query systems are highly specialized, offering state-of-the-art performance within a single modality but struggling with multi-modal data. Conversely, some \"all-in-one\" systems handle multiple modalities but often exhibit suboptimal performance compared to their specialized counterparts in specific modalities.\n  This paper introduces Meta Engine, a novel \"query system on query systems\", designed to resolve those aforementioned challenges. Meta Engine is a unified semantic query engine that integrates heterogeneous, specialized LLM-based query systems. Its architecture comprises five key components: (1) a Natural Language (NL) Query Parser, (2) an Operator Generator, (3) a Query Router, (4) a set of Adapters, and (5) a Result Aggregator. In the evaluation, Meta Engine consistently outperforms all baselines, yielding 3-6x higher F1 in most cases and up to 24x on specific datasets.",
      "source": "arXiv",
      "pubDateISO": "2026-02-02",
      "tags": [
        "cs.DB",
        "cs.AI"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.01699v1",
      "title": "Mitigating loss of control in advanced AI systems through instrumental goal trajectories",
      "link": "http://arxiv.org/abs/2602.01699v1",
      "pdf_link": "https://arxiv.org/pdf/2602.01699v1",
      "authors": "Willem Fourie",
      "institution": "",
      "abstract": "Researchers at artificial intelligence labs and universities are concerned that highly capable artificial intelligence (AI) systems may erode human control by pursuing instrumental goals. Existing mitigations remain largely technical and system-centric: tracking capability in advanced systems, shaping behaviour through methods such as reinforcement learning from human feedback, and designing systems to be corrigible and interruptible. Here we develop instrumental goal trajectories to expand these options beyond the model. Gaining capability typically depends on access to additional technical resources, such as compute, storage, data and adjacent services, which in turn requires access to monetary resources. In organisations, these resources can be obtained through three organisational pathways. We label these pathways the procurement, governance and finance instrumental goal trajectories (IGTs). Each IGT produces a trail of organisational artefacts that can be monitored and used as intervention points when a systems capabilities or behaviour exceed acceptable thresholds. In this way, IGTs offer concrete avenues for defining capability levels and for broadening how corrigibility and interruptibility are implemented, shifting attention from model properties alone to the organisational systems that enable them.",
      "source": "arXiv",
      "pubDateISO": "2026-02-02",
      "tags": [
        "cs.AI",
        "cs.CY"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.01698v1",
      "title": "Restoring Exploration after Post-Training: Latent Exploration Decoding for Large Reasoning Models",
      "link": "http://arxiv.org/abs/2602.01698v1",
      "pdf_link": "https://arxiv.org/pdf/2602.01698v1",
      "authors": "Wenhui Tan, Fiorenzo Parascandolo, Enver Sangineto, Jianzhong Ju, Zhenbo Luo et al.",
      "institution": "",
      "abstract": "Large Reasoning Models (LRMs) have recently achieved strong mathematical and code reasoning performance through Reinforcement Learning (RL) post-training. However, we show that modern reasoning post-training induces an unintended exploration collapse: temperature-based sampling no longer increases pass@$n$ accuracy. Empirically, the final-layer posterior of post-trained LRMs exhibit sharply reduced entropy, while the entropy of intermediate layers remains relatively high. Motivated by this entropy asymmetry, we propose Latent Exploration Decoding (LED), a depth-conditioned decoding strategy. LED aggregates intermediate posteriors via cumulative sum and selects depth configurations with maximal entropy as exploration candidates. Without additional training or parameters, LED consistently improves pass@1 and pass@16 accuracy by 0.61 and 1.03 percentage points across multiple reasoning benchmarks and models. Project page: https://GitHub.com/Xiaomi-Research/LED.",
      "source": "arXiv",
      "pubDateISO": "2026-02-02",
      "tags": [
        "cs.CL",
        "cs.LG"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.01696v1",
      "title": "Cross-Modal Alignment and Fusion for RGB-D Transmission-Line Defect Detection",
      "link": "http://arxiv.org/abs/2602.01696v1",
      "pdf_link": "https://arxiv.org/pdf/2602.01696v1",
      "authors": "Jiaming Cui, Shuai Zhou, Wenqiang Li, Ruifeng Qin, Feng Shen",
      "institution": "",
      "abstract": "Transmission line defect detection remains challenging for automated UAV inspection due to the dominance of small-scale defects, complex backgrounds, and illumination variations. Existing RGB-based detectors, despite recent progress, struggle to distinguish geometrically subtle defects from visually similar background structures under limited chromatic contrast. This paper proposes CMAFNet, a Cross-Modal Alignment and Fusion Network that integrates RGB appearance and depth geometry through a principled purify-then-fuse paradigm. CMAFNet consists of a Semantic Recomposition Module that performs dictionary-based feature purification via a learned codebook to suppress modality-specific noise while preserving defect-discriminative information, and a Contextual Semantic Integration Framework that captures global spatial dependencies using partial-channel attention to enhance structural semantic reasoning. Position-wise normalization within the purification stage enforces explicit reconstruction-driven cross-modal alignment, ensuring statistical compatibility between heterogeneous features prior to fusion. Extensive experiments on the TLRGBD benchmark, where 94.5% of instances are small objects, demonstrate that CMAFNet achieves 32.2% mAP@50 and 12.5% APs, outperforming the strongest baseline by 9.8 and 4.0 percentage points, respectively. A lightweight variant reaches 24.8% mAP50 at 228 FPS with only 4.9M parameters, surpassing all YOLO-based detectors while matching transformer-based methods at substantially lower computational cost.",
      "source": "arXiv",
      "pubDateISO": "2026-02-02",
      "tags": [
        "cs.CV",
        "cs.AI"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.01695v1",
      "title": "Beyond Dense States: Elevating Sparse Transcoders to Active Operators for Latent Reasoning",
      "link": "http://arxiv.org/abs/2602.01695v1",
      "pdf_link": "https://arxiv.org/pdf/2602.01695v1",
      "authors": "Yadong Wang, Haodong Chen, Yu Tian, Chuanxing Geng, Dong Liang et al.",
      "institution": "",
      "abstract": "Latent reasoning compresses the chain-of-thought (CoT) into continuous hidden states, yet existing methods rely on dense latent transitions that remain difficult to interpret and control. Meanwhile, sparse representation models uncover human-interpretable semantic features but remain largely confined to post-hoc analysis. We reconcile this tension by proposing LSTR (Latent Sparse Transcoder Reasoning), a latent reasoning framework that elevates functional sparse transcoders into active reasoning operators to perform multi-step computation through sparse semantic transitions. At its core, LSTR employs a Latent Transition Transcoder (LTT) with a residual skip architecture that decouples linear manifold transport from sparse semantic updates, enabling controllable semantic resolution via explicit sparsity constraints. Extensive experiments show that LSTR preserves reasoning accuracy and compression efficiency while substantially improving interpretability over dense latent baselines. Causal interventions and trajectory analyses further demonstrate that these sparse features act as both interpretable and causally effective operators in the reasoning process.",
      "source": "arXiv",
      "pubDateISO": "2026-02-02",
      "tags": [
        "cs.AI",
        "cs.LG"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.01689v1",
      "title": "What LLMs Think When You Don't Tell Them What to Think About?",
      "link": "http://arxiv.org/abs/2602.01689v1",
      "pdf_link": "https://arxiv.org/pdf/2602.01689v1",
      "authors": "Yongchan Kwon, James Zou",
      "institution": "",
      "abstract": "Characterizing the behavior of large language models (LLMs) across diverse settings is critical for reliable monitoring and AI safety. However, most existing analyses rely on topic- or task-specific prompts, which can substantially limit what can be observed. In this work, we study what LLMs generate from minimal, topic-neutral inputs and probe their near-unconstrained generative behavior. Despite the absence of explicit topics, model outputs cover a broad semantic space, and surprisingly, each model family exhibits strong and systematic topical preferences. GPT-OSS predominantly generates programming (27.1%) and mathematical content (24.6%), whereas Llama most frequently generates literary content (9.1%). DeepSeek often generates religious content, while Qwen frequently generates multiple-choice questions. Beyond topical preferences, we also observe differences in content specialization and depth: GPT-OSS often generates more technically advanced content (e.g., dynamic programming) compared with other models (e.g., basic Python). Furthermore, we find that the near-unconstrained generation often degenerates into repetitive phrases, revealing interesting behaviors unique to each model family. For instance, degenerate outputs from Llama include multiple URLs pointing to personal Facebook and Instagram accounts. We release the complete dataset of 256,000 samples from 16 LLMs, along with a reproducible codebase.",
      "source": "arXiv",
      "pubDateISO": "2026-02-02",
      "tags": [
        "cs.AI",
        "cs.LG"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.01687v1",
      "title": "Counting Hypothesis: Potential Mechanism of In-Context Learning",
      "link": "http://arxiv.org/abs/2602.01687v1",
      "pdf_link": "https://arxiv.org/pdf/2602.01687v1",
      "authors": "Jung H. Lee, Sujith Vijayan",
      "institution": "",
      "abstract": "In-Context Learning (ICL) indicates that large language models (LLMs) pretrained on a massive amount of data can learn specific tasks from input prompts' examples. ICL is notable for two reasons. First, it does not need modification of LLMs' internal structure. Second, it enables LLMs to perform a wide range of tasks/functions with a few examples demonstrating a desirable task. ICL opens up new ways to utilize LLMs in more domains, but its underlying mechanisms still remain poorly understood, making error correction and diagnosis extremely challenging. Thus, it is imperative that we better understand the limitations of ICL and how exactly LLMs support ICL. Inspired by ICL properties and LLMs' functional modules, we propose 1the counting hypothesis' of ICL, which suggests that LLMs' encoding strategy may underlie ICL, and provide supporting evidence.",
      "source": "arXiv",
      "pubDateISO": "2026-02-02",
      "tags": [
        "cs.CL",
        "cs.AI"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.01685v1",
      "title": "Semantic-aware Wasserstein Policy Regularization for Large Language Model Alignment",
      "link": "http://arxiv.org/abs/2602.01685v1",
      "pdf_link": "https://arxiv.org/pdf/2602.01685v1",
      "authors": "Byeonghu Na, Hyungho Na, Yeongmin Kim, Suhyeon Jo, HeeSun Bae et al.",
      "institution": "",
      "abstract": "Large language models (LLMs) are commonly aligned with human preferences using reinforcement learning from human feedback (RLHF). In this method, LLM policies are generally optimized through reward maximization with Kullback-Leibler (KL) divergence regularization of the reference policy. However, KL and its $f$-divergence variants only compare token probabilities at identical indices, failing to capture semantic similarity. We propose Wasserstein Policy Regularization (WPR), a semantic-aware regularization for the RLHF framework based on the entropy-regularized Wasserstein distance, which incorporates the geometry of the token space. The dual formulation of the distance expresses the regularization as penalty terms applied to the reward via optimal dual variables, which yield a tractable objective compatible with standard RL algorithms. Empirically, our method outperforms KL- and $f$-divergence-based baselines, demonstrating the benefits of semantic-aware policy distances for alignment. Our code is available at https://github.com/aailab-kaist/WPR.",
      "source": "arXiv",
      "pubDateISO": "2026-02-02",
      "tags": [
        "cs.LG",
        "cs.AI"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.01684v1",
      "title": "The Strategic Foresight of LLMs: Evidence from a Fully Prospective Venture Tournament",
      "link": "http://arxiv.org/abs/2602.01684v1",
      "pdf_link": "https://arxiv.org/pdf/2602.01684v1",
      "authors": "Felipe A. Csaszar, Aticus Peterson, Daniel Wilde",
      "institution": "",
      "abstract": "Can artificial intelligence outperform humans at strategic foresight -- the capacity to form accurate judgments about uncertain, high-stakes outcomes before they unfold? We address this question through a fully prospective prediction tournament using live Kickstarter crowdfunding projects. Thirty U.S.-based technology ventures, launched after the training cutoffs of all models studied, were evaluated while fundraising remained in progress and outcomes were unknown. A diverse suite of frontier and open-weight large language models (LLMs) completed 870 pairwise comparisons, producing complete rankings of predicted fundraising success. We benchmarked these forecasts against 346 experienced managers recruited via Prolific and three MBA-trained investors working under monitored conditions. The results are striking: human evaluators achieved rank correlations with actual outcomes between 0.04 and 0.45, while several frontier LLMs exceeded 0.60, with the best (Gemini 2.5 Pro) reaching 0.74 -- correctly ordering nearly four of every five venture pairs. These differences persist across multiple performance metrics and robustness checks. Neither wisdom-of-the-crowd ensembles nor human-AI hybrid teams outperformed the best standalone model.",
      "source": "arXiv",
      "pubDateISO": "2026-02-02",
      "tags": [
        "cs.AI"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.01683v1",
      "title": "FreshMem: Brain-Inspired Frequency-Space Hybrid Memory for Streaming Video Understanding",
      "link": "http://arxiv.org/abs/2602.01683v1",
      "pdf_link": "https://arxiv.org/pdf/2602.01683v1",
      "authors": "Kangcong Li, Peng Ye, Lin Zhang, Chao Wang, Huafeng Qin et al.",
      "institution": "",
      "abstract": "Transitioning Multimodal Large Language Models (MLLMs) from offline to online streaming video understanding is essential for continuous perception. However, existing methods lack flexible adaptivity, leading to irreversible detail loss and context fragmentation. To resolve this, we propose FreshMem, a Frequency-Space Hybrid Memory network inspired by the brain's logarithmic perception and memory consolidation. FreshMem reconciles short-term fidelity with long-term coherence through two synergistic modules: Multi-scale Frequency Memory (MFM), which projects overflowing frames into representative frequency coefficients, complemented by residual details to reconstruct a global historical \"gist\"; and Space Thumbnail Memory (STM), which discretizes the continuous stream into episodic clusters by employing an adaptive compression strategy to distill them into high-density space thumbnails. Extensive experiments show that FreshMem significantly boosts the Qwen2-VL baseline, yielding gains of 5.20%, 4.52%, and 2.34% on StreamingBench, OV-Bench, and OVO-Bench, respectively. As a training-free solution, FreshMem outperforms several fully fine-tuned methods, offering a highly efficient paradigm for long-horizon streaming video understanding.",
      "source": "arXiv",
      "pubDateISO": "2026-02-02",
      "tags": [
        "cs.CV",
        "cs.AI"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.01682v1",
      "title": "Finite and Corruption-Robust Regret Bounds in Online Inverse Linear Optimization under M-Convex Action Sets",
      "link": "http://arxiv.org/abs/2602.01682v1",
      "pdf_link": "https://arxiv.org/pdf/2602.01682v1",
      "authors": "Taihei Oki, Shinsaku Sakaue",
      "institution": "",
      "abstract": "We study online inverse linear optimization, also known as contextual recommendation, where a learner sequentially infers an agent's hidden objective vector from observed optimal actions over feasible sets that change over time. The learner aims to recommend actions that perform well under the agent's true objective, and the performance is measured by the regret, defined as the cumulative gap between the agent's optimal values and those achieved by the learner's recommended actions. Prior work has established a regret bound of $O(d\\log T)$, as well as a finite but exponentially large bound of $\\exp(O(d\\log d))$, where $d$ is the dimension of the optimization problem and $T$ is the time horizon, while a regret lower bound of $Ω(d)$ is known (Gollapudi et al. 2021; Sakaue et al. 2025). Whether a finite regret bound polynomial in $d$ is achievable or not has remained an open question. We partially resolve this by showing that when the feasible sets are M-convex -- a broad class that includes matroids -- a finite regret bound of $O(d\\log d)$ is possible. We achieve this by combining a structural characterization of optimal solutions on M-convex sets with a geometric volume argument. Moreover, we extend our approach to adversarially corrupted feedback in up to $C$ rounds. We obtain a regret bound of $O((C+1)d\\log d)$ without prior knowledge of $C$, by monitoring directed graphs induced by the observed feedback to detect corruptions adaptively.",
      "source": "arXiv",
      "pubDateISO": "2026-02-02",
      "tags": [
        "cs.LG",
        "cs.DS",
        "stat.ML"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.01681v1",
      "title": "Hyperspectral Image Fusion with Spectral-Band and Fusion-Scale Agnosticism",
      "link": "http://arxiv.org/abs/2602.01681v1",
      "pdf_link": "https://arxiv.org/pdf/2602.01681v1",
      "authors": "Yu-Jie Liang, Zihan Cao, Liang-Jian Deng, Yang Yang, Malu Zhang",
      "institution": "",
      "abstract": "Current deep learning models for Multispectral and Hyperspectral Image Fusion (MS/HS fusion) are typically designed for fixed spectral bands and spatial scales, which limits their transferability across diverse sensors. To address this, we propose SSA, a universal framework for MS/HS fusion with spectral-band and fusion-scale agnosticism. Specifically, we introduce Matryoshka Kernel (MK), a novel operator that enables a single model to adapt to arbitrary numbers of spectral channels. Meanwhile, we build SSA upon an Implicit Neural Representation (INR) backbone that models the HS signal as a continuous function, enabling reconstruction at arbitrary spatial resolutions. Together, these two forms of agnosticism enable a single MS/HS fusion model that generalizes effectively to unseen sensors and spatial scales. Extensive experiments demonstrate that our single model achieves state-of-the-art performance while generalizing well to unseen sensors and scales, paving the way toward future HS foundation models.",
      "source": "arXiv",
      "pubDateISO": "2026-02-02",
      "tags": [
        "cs.CV",
        "cs.MM"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.01679v1",
      "title": "Towards Autonomous Instrument Tray Assembly for Sterile Processing Applications",
      "link": "http://arxiv.org/abs/2602.01679v1",
      "pdf_link": "https://arxiv.org/pdf/2602.01679v1",
      "authors": "Raghavasimhan Sankaranarayanan, Paul Stuart, Nicholas Ahn, Arno Sungarian, Yash Chitalia",
      "institution": "",
      "abstract": "The Sterile Processing and Distribution (SPD) department is responsible for cleaning, disinfecting, inspecting, and assembling surgical instruments between surgeries. Manual inspection and preparation of instrument trays is a time-consuming, error-prone task, often prone to contamination and instrument breakage. In this work, we present a fully automated robotic system that sorts and structurally packs surgical instruments into sterile trays, focusing on automation of the SPD assembly stage. A custom dataset comprising 31 surgical instruments and 6,975 annotated images was collected to train a hybrid perception pipeline using YOLO12 for detection and a cascaded ResNet-based model for fine-grained classification. The system integrates a calibrated vision module, a 6-DOF Staubli TX2-60L robotic arm with a custom dual electromagnetic gripper, and a rule-based packing algorithm that reduces instrument collisions during transport. The packing framework uses 3D printed dividers and holders to physically isolate instruments, reducing collision and friction during transport. Experimental evaluations show high perception accuracy and statistically significant reduction in tool-to-tool collisions compared to human-assembled trays. This work serves as the scalable first step toward automating SPD workflows, improving safety, and consistency of surgical preparation while reducing SPD processing times.",
      "source": "arXiv",
      "pubDateISO": "2026-02-02",
      "tags": [
        "cs.RO",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    }
  ]
}