{
  "generated_at": "2026-02-13T14:38:47Z",
  "date": "2026-02-13",
  "total_count": 235,
  "papers": [
    {
      "id": "2602.12205",
      "title": "DeepGen 1.0: A Lightweight Unified Multimodal Model for Advancing Image Generation and Editing",
      "link": "https://huggingface.co/papers/2602.12205",
      "pdf_link": "https://arxiv.org/pdf/2602.12205.pdf",
      "authors": "Dianyi Wang, Ruihang Li, Feng Han, Chaofan Ma, Wei Song",
      "institution": "",
      "abstract": "Current unified multimodal models for image generation and editing typically rely on massive parameter scales (e.g., >10B), entailing prohibitive training costs and deployment footprints. In this work, we present DeepGen 1.0, a lightweight 5B unified model that achieves comprehensive capabilities competitive with or surpassing much larger counterparts. To overcome the limitations of compact models in semantic understanding and fine-grained control, we introduce Stacked Channel Bridging (SCB), a deep alignment framework that extracts hierarchical features from multiple VLM layers and fuses them with learnable 'think tokens' to provide the generative backbone with structured, reasoning-rich guidance. We further design a data-centric training strategy spanning three progressive stages: (1) Alignment Pre-training on large-scale image-text pairs and editing triplets to synchronize VLM and DiT representations, (2) Joint Supervised Fine-tuning on a high-quality mixture of generation, editing, and reasoning tasks to foster omni-capabilities, and (3) Reinforcement Learning with MR-GRPO, which leverages a mixture of reward functions and supervision signals, resulting in substantial gains in generation quality and alignment with human preferences, while maintaining stable training progress and avoiding visual artifacts. Despite being trained on only ~50M samples, DeepGen 1.0 achieves leading performance across diverse benchmarks, surpassing the 80B HunyuanImage by 28% on WISE and the 27B Qwen-Image-Edit by 37% on UniREditBench. By open-sourcing our training code, weights, and datasets, we provide an efficient, high-performance alternative to democratize unified multimodal research.",
      "source": "HuggingFace",
      "pubDateISO": "2026-02-12",
      "tags": [],
      "topics": [
        "Multimodal Learning",
        "Image Generation",
        "Efficient Deep Learning"
      ],
      "score": 9,
      "score_reason": "Efficient multimodal model",
      "citations": 0,
      "upvotes": 43,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "The introduction of Stacked Channel Bridging (SCB), a deep alignment framework that enables a lightweight 5B unified model to achieve competitive image generation and editing capabilities with much larger counterparts.",
      "why_it_matters": "This work matters because it demonstrates the feasibility of developing efficient and scalable unified multimodal models that can be trained with limited resources, making them more accessible for real-world applications.",
      "limitations": "The main limitation of this work is that the proposed model is still trained on a relatively small dataset of ~50M samples, which may not be representative of the entire range of image generation and editing tasks."
    },
    {
      "id": "2602.11298",
      "title": "Voxtral Realtime",
      "link": "https://huggingface.co/papers/2602.11298",
      "pdf_link": "https://arxiv.org/pdf/2602.11298.pdf",
      "authors": "Alexander H. Liu, Andy Ehrenberg, Andy Lo, Chen-Yo Sun, Guillaume Lample",
      "institution": "",
      "abstract": "We introduce Voxtral Realtime, a natively streaming automatic speech recognition model that matches offline transcription quality at sub-second latency. Unlike approaches that adapt offline models through chunking or sliding windows, Voxtral Realtime is trained end-to-end for streaming, with explicit alignment between audio and text streams. Our architecture builds on the Delayed Streams Modeling framework, introducing a new causal audio encoder and Ada RMS-Norm for improved delay conditioning. We scale pretraining to a large-scale dataset spanning 13 languages. At a delay of 480ms, Voxtral Realtime achieves performance on par with Whisper, the most widely deployed offline transcription system. We release the model weights under the Apache 2.0 license.",
      "source": "HuggingFace",
      "pubDateISO": "2026-02-11",
      "tags": [],
      "topics": [
        "Streaming Automatic Speech Recognition",
        "Delayed Streams Modeling",
        "Causal Audio Encoding"
      ],
      "score": 9,
      "score_reason": "Realtime speech recognition",
      "citations": 0,
      "upvotes": 4,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "The introduction of a natively streaming automatic speech recognition model, Voxtral Realtime, that achieves offline transcription quality at sub-second latency through end-to-end training and explicit alignment between audio and text streams.",
      "why_it_matters": "This work matters because it enables real-time speech recognition applications with high accuracy, which is crucial for applications such as live captioning, voice assistants, and speech-to-text systems.",
      "limitations": "The main limitation of this work is that it requires large-scale pretraining datasets, which can be challenging to obtain, especially for low-resource languages, and may not generalize well to unseen languages or acoustic conditions."
    },
    {
      "id": "2602.12099",
      "title": "GigaBrain-0.5M*: a VLA That Learns From World Model-Based Reinforcement Learning",
      "link": "https://huggingface.co/papers/2602.12099",
      "pdf_link": "https://arxiv.org/pdf/2602.12099.pdf",
      "authors": "GigaBrain Team, Boyuan Wang, Chaojun Ni, Guan Huang, Guosheng Zhao",
      "institution": "",
      "abstract": "Vision-language-action (VLA) models that directly predict multi-step action chunks from current observations face inherent limitations due to constrained scene understanding and weak future anticipation capabilities. In contrast, video world models pre-trained on web-scale video corpora exhibit robust spatiotemporal reasoning and accurate future prediction, making them a natural foundation for enhancing VLA learning. Therefore, we propose GigaBrain-0.5M*, a VLA model trained via world model-based reinforcement learning. Built upon GigaBrain-0.5, which is pre-trained on over 10,000 hours of robotic manipulation data, whose intermediate version currently ranks first on the international RoboChallenge benchmark. GigaBrain-0.5M* further integrates world model-based reinforcement learning via RAMP (Reinforcement leArning via world Model-conditioned Policy) to enable robust cross-task adaptation. Empirical results demonstrate that RAMP achieves substantial performance gains over the RECAP baseline, yielding improvements of approximately 30\\% on challenging tasks including Laundry Folding, Box Packing, and Espresso Preparation. Critically, GigaBrain-0.5M^* exhibits reliable long-horizon execution, consistently accomplishing complex manipulation tasks without failure as validated by real-world deployment videos on our https://gigabrain05m.github.io{project page}.",
      "source": "HuggingFace",
      "pubDateISO": "2026-02-12",
      "tags": [],
      "topics": [
        "Reinforcement Learning",
        "Vision-Language-Action Models",
        "Robotic Manipulation"
      ],
      "score": 8,
      "score_reason": "Novel VLA Model",
      "citations": 0,
      "upvotes": 32,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "The paper proposes GigaBrain-0.5M*, a vision-language-action model that integrates world model-based reinforcement learning via RAMP, enabling robust cross-task adaptation and long-horizon execution in robotic manipulation tasks.",
      "why_it_matters": "This work matters because it addresses the limitations of existing VLA models in terms of scene understanding and future anticipation, with potential applications in real-world robotic manipulation tasks that require complex decision-making and adaptability.",
      "limitations": "The main limitation of this approach is that it relies on pre-trained world models and large amounts of robotic manipulation data, which may not be readily available or transferable to other domains or tasks."
    },
    {
      "id": "2602.11748",
      "title": "Think Longer to Explore Deeper: Learn to Explore In-Context via Length-Incentivized Reinforcement Learning",
      "link": "https://huggingface.co/papers/2602.11748",
      "pdf_link": "https://arxiv.org/pdf/2602.11748.pdf",
      "authors": "Futing Wang, Jianhao Yan, Yun Luo, Ganqu Cui, Zhi Wang",
      "institution": "",
      "abstract": "Achieving effective test-time scaling requires models to engage in In-Context Exploration -- the intrinsic ability to generate, verify, and refine multiple reasoning hypotheses within a single continuous context.\n  Grounded in State Coverage theory, our analysis identifies a critical bottleneck to enabling this capability: while broader state coverage requires longer reasoning trajectories, the probability of sampling such sequences decays exponentially during autoregressive generation, a phenomenon we term the ``Shallow Exploration Trap''.\n  To bridge this gap, we propose Length-Incentivized Exploration(\\method).\n  This simple yet effective recipe explicitly encourages models to explore more via a length-based reward coupled with a redundancy penalty, thereby maximizing state coverage in two-step manner.\n  Comprehensive experiments across different models (Qwen3, Llama) demonstrate that \\method effectively incentivize in-context exploration.\n  As a result, our method achieves an average improvement of 4.4\\% on in-domain tasks and a 2.7\\% gain on out-of-domain benchmarks.",
      "source": "HuggingFace",
      "pubDateISO": "2026-02-12",
      "tags": [],
      "topics": [
        "Reinforcement Learning",
        "In-Context Exploration",
        "Autoregressive Generation"
      ],
      "score": 8,
      "score_reason": "Novel exploration method",
      "citations": 0,
      "upvotes": 23,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "This paper proposes Length-Incentivized Exploration, a reinforcement learning approach that uses a length-based reward and redundancy penalty to encourage models to generate longer reasoning trajectories and improve in-context exploration.",
      "why_it_matters": "This research matters because it addresses the 'Shallow Exploration Trap' that hinders the ability of autoregressive models to engage in effective in-context exploration, which is crucial for achieving test-time scaling and generalization.",
      "limitations": "The main limitation of this work is that it relies on a simple length-based reward and redundancy penalty, which may not be sufficient to capture the complexity of in-context exploration and may require additional modifications to generalize to more diverse tasks and models."
    },
    {
      "id": "2602.09021",
      "title": "χ_{0}: Resource-Aware Robust Manipulation via Taming Distributional Inconsistencies",
      "link": "https://huggingface.co/papers/2602.09021",
      "pdf_link": "https://arxiv.org/pdf/2602.09021.pdf",
      "authors": "Checheng Yu, Chonghao Sima, Gangcheng Jiang, Hai Zhang, Haoguang Mai",
      "institution": "",
      "abstract": "High-reliability long-horizon robotic manipulation has traditionally relied on large-scale data and compute to understand complex real-world dynamics. However, we identify that the primary bottleneck to real-world robustness is not resource scale alone, but the distributional shift among the human demonstration distribution, the inductive bias learned by the policy, and the test-time execution distribution -- a systematic inconsistency that causes compounding errors in multi-stage tasks. To mitigate these inconsistencies, we propose χ_{0}, a resource-efficient framework with effective modules designated to achieve production-level robustness in robotic manipulation. Our approach builds off three technical pillars: (i) Model Arithmetic, a weight-space merging strategy that efficiently soaks up diverse distributions of different demonstrations, varying from object appearance to state variations; (ii) Stage Advantage, a stage-aware advantage estimator that provides stable, dense progress signals, overcoming the numerical instability of prior non-stage approaches; and (iii) Train-Deploy Alignment, which bridges the distribution gap via spatio-temporal augmentation, heuristic DAgger corrections, and temporal chunk-wise smoothing. χ_{0} enables two sets of dual-arm robots to collaboratively orchestrate long-horizon garment manipulation, spanning tasks from flattening, folding, to hanging different clothes. Our method exhibits high-reliability autonomy; we are able to run the system from arbitrary initial state for consecutive 24 hours non-stop. Experiments validate that χ_{0} surpasses the state-of-the-art π_{0.5} in success rate by nearly 250%, with only 20-hour data and 8 A100 GPUs. Code, data and models will be released to facilitate the community.",
      "source": "HuggingFace",
      "pubDateISO": "2026-02-09",
      "tags": [],
      "topics": [
        "Robotic Manipulation",
        "Distributional Shift",
        "Reinforcement Learning"
      ],
      "score": 8,
      "score_reason": "Robust manipulation",
      "citations": 1,
      "upvotes": 14,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "The paper proposes χ_{0}, a resource-efficient framework that mitigates distributional inconsistencies in robotic manipulation by introducing Model Arithmetic, Stage Advantage, and Train-Deploy Alignment modules.",
      "why_it_matters": "This research matters because it enables high-reliability long-horizon robotic manipulation with reduced reliance on large-scale data and compute, making it more practical for real-world applications.",
      "limitations": "The main limitation of this approach is that it relies on careful tuning of the spatio-temporal augmentation, heuristic DAgger corrections, and temporal chunk-wise smoothing parameters to bridge the distribution gap."
    },
    {
      "id": "2602.10367",
      "title": "LiveMedBench: A Contamination-Free Medical Benchmark for LLMs with Automated Rubric Evaluation",
      "link": "https://huggingface.co/papers/2602.10367",
      "pdf_link": "https://arxiv.org/pdf/2602.10367.pdf",
      "authors": "Zhiling Yan, Dingjie Song, Zhe Fang, Yisheng Ji, Xiang Li",
      "institution": "",
      "abstract": "The deployment of Large Language Models (LLMs) in high-stakes clinical settings demands rigorous and reliable evaluation. However, existing medical benchmarks remain static, suffering from two critical limitations: (1) data contamination, where test sets inadvertently leak into training corpora, leading to inflated performance estimates; and (2) temporal misalignment, failing to capture the rapid evolution of medical knowledge. Furthermore, current evaluation metrics for open-ended clinical reasoning often rely on either shallow lexical overlap (e.g., ROUGE) or subjective LLM-as-a-Judge scoring, both inadequate for verifying clinical correctness. To bridge these gaps, we introduce LiveMedBench, a continuously updated, contamination-free, and rubric-based benchmark that weekly harvests real-world clinical cases from online medical communities, ensuring strict temporal separation from model training data. We propose a Multi-Agent Clinical Curation Framework that filters raw data noise and validates clinical integrity against evidence-based medical principles. For evaluation, we develop an Automated Rubric-based Evaluation Framework that decomposes physician responses into granular, case-specific criteria, achieving substantially stronger alignment with expert physicians than LLM-as-a-Judge. To date, LiveMedBench comprises 2,756 real-world cases spanning 38 medical specialties and multiple languages, paired with 16,702 unique evaluation criteria. Extensive evaluation of 38 LLMs reveals that even the best-performing model achieves only 39.2%, and 84% of models exhibit performance degradation on post-cutoff cases, confirming pervasive data contamination risks. Error analysis further identifies contextual application-not factual knowledge-as the dominant bottleneck, with 35-48% of failures stemming from the inability to tailor medical knowledge to patient-specific constraints.",
      "source": "HuggingFace",
      "pubDateISO": "2026-02-10",
      "tags": [],
      "topics": [
        "Natural Language Processing",
        "Medical Artificial Intelligence",
        "Evaluation Metrics for LLMs"
      ],
      "score": 8,
      "score_reason": "Medical Benchmark",
      "citations": 0,
      "upvotes": 11,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "The paper introduces LiveMedBench, a novel, continuously updated, and contamination-free medical benchmark for Large Language Models (LLMs) that utilizes a Multi-Agent Clinical Curation Framework and Automated Rubric-based Evaluation Framework.",
      "why_it_matters": "This work matters because it addresses the critical limitations of existing medical benchmarks, providing a more reliable and rigorous evaluation framework for LLMs in high-stakes clinical settings, which is essential for ensuring patient safety and trust in AI-assisted medical decision-making.",
      "limitations": "The main limitation of this work is that the Automated Rubric-based Evaluation Framework, although more accurate than LLM-as-a-Judge, may still require significant human expertise and curation to develop and maintain the granular, case-specific criteria for evaluating clinical correctness."
    },
    {
      "id": "2602.11683",
      "title": "ThinkRouter: Efficient Reasoning via Routing Thinking between Latent and Discrete Spaces",
      "link": "https://huggingface.co/papers/2602.11683",
      "pdf_link": "https://arxiv.org/pdf/2602.11683.pdf",
      "authors": "Xin Xu, Tong Yu, Xiang Chen, Haoliang Wang, Julian McAuley",
      "institution": "",
      "abstract": "Recent work explores latent reasoning to improve reasoning efficiency by replacing explicit reasoning trajectories with continuous representations in a latent space, yet its effectiveness varies across settings. Analysis of model confidence dynamics under latent reasoning reveals that thinking trajectories ending in incorrect answers contain fewer low-confidence steps than those ending in correct answers. Meanwhile, we suggest that soft embeddings aggregated by multiple low-confidence thinking alternatives may introduce and propagate noise, leading to high confidence in unreliable reasoning trajectories. Motivated by these observations, ThinkRouter, an inference-time confidence-aware routing mechanism is proposed to avoid high confidence and noise for efficient reasoning. ThinkRouter routes thinking to the discrete token space when model confidence is low, and to the latent space otherwise. Extensive experiments on STEM reasoning and coding benchmarks across diverse large reasoning models demonstrate that ThinkRouter outperforms explicit CoT, random routing, and latent reasoning baselines in terms of accuracy, achieving an average improvement of 19.70 points in Pass@1, while reducing generation length by up to 15.55%. Further comprehensive analysis reveals that ThinkRouter can calibrate errors arising from explicit CoT and latent reasoning, and accelerates end-of-thinking token generation by globally lowering model confidence.",
      "source": "HuggingFace",
      "pubDateISO": "2026-02-12",
      "tags": [],
      "topics": [
        "latent reasoning",
        "confidence-aware routing",
        "efficient inference mechanisms"
      ],
      "score": 8,
      "score_reason": "Efficient reasoning route",
      "citations": 0,
      "upvotes": 4,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "This paper proposes ThinkRouter, a novel inference-time confidence-aware routing mechanism that dynamically switches between latent and discrete token spaces based on model confidence to improve reasoning efficiency and accuracy.",
      "why_it_matters": "ThinkRouter's ability to calibrate errors and accelerate end-of-thinking token generation has significant implications for improving the performance of large reasoning models in STEM reasoning and coding tasks.",
      "limitations": "The proposed approach relies on the accuracy of model confidence estimates, which may not always be reliable, potentially limiting its effectiveness in certain scenarios."
    },
    {
      "id": "2602.12262",
      "title": "T3D: Few-Step Diffusion Language Models via Trajectory Self-Distillation with Direct Discriminative Optimization",
      "link": "https://huggingface.co/papers/2602.12262",
      "pdf_link": "https://arxiv.org/pdf/2602.12262.pdf",
      "authors": "Tunyu Zhang, Xinxi Zhang, Ligong Han, Haizhou Shi, Xiaoxiao He",
      "institution": "",
      "abstract": "Diffusion large language models (DLLMs) have the potential to enable fast text generation by decoding multiple tokens in parallel. However, in practice, their inference efficiency is constrained by the need for many refinement steps, while aggressively reducing the number of steps leads to a substantial degradation in generation quality. To alleviate this, we propose a trajectory self-distillation framework that improves few-step decoding by distilling the model's own generative trajectories. We incorporate Direct Discriminative Optimization (DDO), a reverse-KL objective that promotes mode-seeking distillation and encourages the student to concentrate on high-probability teacher modes. Across benchmarks, our approach consistently outperforms strong few-step baselines and standard training under tight step budgets. Although full-step decoding remains superior, we substantially narrow the gap, establishing a strong foundation towards practical few-step DLLMs. The source code is available at https://github.com/Tyrion58/T3D.",
      "source": "HuggingFace",
      "pubDateISO": "2026-02-12",
      "tags": [],
      "topics": [
        "Diffusion Large Language Models",
        "Trajectory Self-Distillation",
        "Direct Discriminative Optimization"
      ],
      "score": 8,
      "score_reason": "Fast diffusion model",
      "citations": 0,
      "upvotes": 3,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "The paper proposes a novel trajectory self-distillation framework with Direct Discriminative Optimization (DDO) to improve few-step decoding in diffusion large language models (DLLMs).",
      "why_it_matters": "This research matters because it addresses the trade-off between inference efficiency and generation quality in DLLMs, enabling faster text generation with minimal quality degradation.",
      "limitations": "The main limitation is that few-step decoding still lags behind full-step decoding in terms of generation quality, despite the proposed approach narrowing the gap."
    },
    {
      "id": "2602.11598",
      "title": "ABot-N0: Technical Report on the VLA Foundation Model for Versatile Embodied Navigation",
      "link": "https://huggingface.co/papers/2602.11598",
      "pdf_link": "https://arxiv.org/pdf/2602.11598.pdf",
      "authors": "Zedong Chu, Shichao Xie, Xiaolong Wu, Yanfen Shen, Minghua Luo",
      "institution": "",
      "abstract": "Embodied navigation has long been fragmented by task-specific architectures. We introduce ABot-N0, a unified Vision-Language-Action (VLA) foundation model that achieves a ``Grand Unification'' across 5 core tasks: Point-Goal, Object-Goal, Instruction-Following, POI-Goal, and Person-Following. ABot-N0 utilizes a hierarchical ``Brain-Action'' architecture, pairing an LLM-based Cognitive Brain for semantic reasoning with a Flow Matching-based Action Expert for precise, continuous trajectory generation.\n  To support large-scale learning, we developed the ABot-N0 Data Engine, curating 16.9M expert trajectories and 5.0M reasoning samples across 7,802 high-fidelity 3D scenes (10.7 km^2). ABot-N0 achieves new SOTA performance across 7 benchmarks, significantly outperforming specialized models. Furthermore, our Agentic Navigation System integrates a planner with hierarchical topological memory, enabling robust, long-horizon missions in dynamic real-world environments.",
      "source": "HuggingFace",
      "pubDateISO": "2026-02-12",
      "tags": [],
      "topics": [
        "Embodied Navigation",
        "Vision-Language-Action Models",
        "Hierarchical Reinforcement Learning"
      ],
      "score": 8,
      "score_reason": "Unified navigation model",
      "citations": 0,
      "upvotes": 2,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "The introduction of ABot-N0, a unified Vision-Language-Action foundation model that achieves state-of-the-art performance across five core embodied navigation tasks using a hierarchical Brain-Action architecture.",
      "why_it_matters": "This work matters because it enables a single model to generalize across multiple navigation tasks, reducing the need for task-specific architectures and facilitating more efficient and scalable embodied AI research.",
      "limitations": "The main limitation of this work is the reliance on large-scale, high-fidelity 3D scene data and expert trajectories, which may be difficult to replicate or extend to new environments or tasks."
    },
    {
      "id": "2602.12125",
      "title": "Learning beyond Teacher: Generalized On-Policy Distillation with Reward Extrapolation",
      "link": "https://huggingface.co/papers/2602.12125",
      "pdf_link": "https://arxiv.org/pdf/2602.12125.pdf",
      "authors": "Wenkai Yang, Weijie Liu, Ruobing Xie, Kai Yang, Saiyong Yang",
      "institution": "",
      "abstract": "On-policy distillation (OPD), which aligns the student with the teacher's logit distribution on student-generated trajectories, has demonstrated strong empirical gains in improving student performance and often outperforms off-policy distillation and reinforcement learning (RL) paradigms. In this work, we first theoretically show that OPD is a special case of dense KL-constrained RL where the reward function and the KL regularization are always weighted equally and the reference model can by any model. Then, we propose the Generalized On-Policy Distillation (G-OPD) framework, which extends the standard OPD objective by introducing a flexible reference model and a reward scaling factor that controls the relative weight of the reward term against the KL regularization. Through comprehensive experiments on math reasoning and code generation tasks, we derive two novel insights: (1) Setting the reward scaling factor to be greater than 1 (i.e., reward extrapolation), which we term ExOPD, consistently improves over standard OPD across a range of teacher-student size pairings. In particular, in the setting where we merge the knowledge from different domain experts, obtained by applying domain-specific RL to the same student model, back into the original student, ExOPD enables the student to even surpass the teacher's performance boundary and outperform the domain teachers. (2) Building on ExOPD, we further find that in the strong-to-weak distillation setting (i.e., distilling a smaller student from a larger teacher), performing reward correction by choosing the reference model as the teacher's base model before RL yields a more accurate reward signal and further improves distillation performance. However, this choice assumes access to the teacher's pre-RL variant and incurs more computational overhead. We hope our work offers new insights for future research on OPD.",
      "source": "HuggingFace",
      "pubDateISO": "2026-02-12",
      "tags": [],
      "topics": [],
      "score": 7,
      "score_reason": "Improved Distillation",
      "citations": 0,
      "upvotes": 42,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.12056",
      "title": "LawThinker: A Deep Research Legal Agent in Dynamic Environments",
      "link": "https://huggingface.co/papers/2602.12056",
      "pdf_link": "https://arxiv.org/pdf/2602.12056.pdf",
      "authors": "Xinyu Yang, Chenlong Deng, Tongyu Wen, Binyu Xie, Zhicheng Dou",
      "institution": "",
      "abstract": "Legal reasoning requires not only correct outcomes but also procedurally compliant reasoning processes. However, existing methods lack mechanisms to verify intermediate reasoning steps, allowing errors such as inapplicable statute citations to propagate undetected through the reasoning chain. To address this, we propose LawThinker, an autonomous legal research agent that adopts an Explore-Verify-Memorize strategy for dynamic judicial environments. The core idea is to enforce verification as an atomic operation after every knowledge exploration step. A DeepVerifier module examines each retrieval result along three dimensions of knowledge accuracy, fact-law relevance, and procedural compliance, with a memory module for cross-round knowledge reuse in long-horizon tasks. Experiments on the dynamic benchmark J1-EVAL show that LawThinker achieves a 24% improvement over direct reasoning and an 11% gain over workflow-based methods, with particularly strong improvements on process-oriented metrics. Evaluations on three static benchmarks further confirm its generalization capability. The code is available at https://github.com/yxy-919/LawThinker-agent .",
      "source": "HuggingFace",
      "pubDateISO": "2026-02-12",
      "tags": [],
      "topics": [
        "Artificial Intelligence",
        "Legal Reasoning",
        "Autonomous Agents"
      ],
      "score": 7,
      "score_reason": "Legal reasoning agent",
      "citations": 0,
      "upvotes": 31,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "The paper proposes LawThinker, a novel autonomous legal research agent that integrates an Explore-Verify-Memorize strategy with a DeepVerifier module to enforce verification of intermediate reasoning steps in dynamic judicial environments.",
      "why_it_matters": "This work matters because it addresses the critical issue of verifying procedurally compliant reasoning processes in legal reasoning, which can help prevent errors and improve the reliability of legal decision-making systems.",
      "limitations": "The main limitation of this work is that the evaluation is primarily based on benchmark datasets, and the generalizability and robustness of LawThinker in real-world, high-stakes legal scenarios remain to be thoroughly tested and validated."
    },
    {
      "id": "2602.11075",
      "title": "RISE: Self-Improving Robot Policy with Compositional World Model",
      "link": "https://huggingface.co/papers/2602.11075",
      "pdf_link": "https://arxiv.org/pdf/2602.11075.pdf",
      "authors": "Jiazhi Yang, Kunyang Lin, Jinwei Li, Wencong Zhang, Tianwei Lin",
      "institution": "",
      "abstract": "Despite the sustained scaling on model capacity and data acquisition, Vision-Language-Action (VLA) models remain brittle in contact-rich and dynamic manipulation tasks, where minor execution deviations can compound into failures. While reinforcement learning (RL) offers a principled path to robustness, on-policy RL in the physical world is constrained by safety risk, hardware cost, and environment reset. To bridge this gap, we present RISE, a scalable framework of robotic reinforcement learning via imagination. At its core is a Compositional World Model that (i) predicts multi-view future via a controllable dynamics model, and (ii) evaluates imagined outcomes with a progress value model, producing informative advantages for the policy improvement. Such compositional design allows state and value to be tailored by best-suited yet distinct architectures and objectives. These components are integrated into a closed-loop self-improving pipeline that continuously generates imaginary rollouts, estimates advantages, and updates the policy in imaginary space without costly physical interaction. Across three challenging real-world tasks, RISE yields significant improvement over prior art, with more than +35% absolute performance increase in dynamic brick sorting, +45% for backpack packing, and +35% for box closing, respectively.",
      "source": "HuggingFace",
      "pubDateISO": "2026-02-11",
      "tags": [],
      "topics": [
        "Reinforcement Learning",
        "Robotics",
        "World Modeling"
      ],
      "score": 7,
      "score_reason": "Self-improving policy",
      "citations": 0,
      "upvotes": 15,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "The paper introduces RISE, a novel framework for robotic reinforcement learning that leverages a Compositional World Model to predict multi-view future outcomes and evaluate imagined outcomes, enabling self-improving policy updates without physical interaction.",
      "why_it_matters": "This work matters because it addresses the long-standing challenge of brittle Vision-Language-Action models in contact-rich and dynamic manipulation tasks, offering a scalable and efficient solution for robust robotic policy learning.",
      "limitations": "The main limitation of this approach is that it relies on the accuracy of the Compositional World Model, which may not always capture the complexities of real-world dynamics, potentially leading to suboptimal policy updates."
    },
    {
      "id": "2602.12153",
      "title": "dVoting: Fast Voting for dLLMs",
      "link": "https://huggingface.co/papers/2602.12153",
      "pdf_link": "https://arxiv.org/pdf/2602.12153.pdf",
      "authors": "Sicheng Feng, Zigeng Chen, Xinyin Ma, Gongfan Fang, Xinchao Wang",
      "institution": "",
      "abstract": "Diffusion Large Language Models (dLLMs) represent a new paradigm beyond autoregressive modeling, offering competitive performance while naturally enabling a flexible decoding process. Specifically, dLLMs can generate tokens at arbitrary positions in parallel, endowing them with significant potential for parallel test-time scaling, which was previously constrained by severe inefficiency in autoregressive modeling. In this work, we introduce dVoting, a fast voting technique that boosts reasoning capability without training, with only an acceptable extra computational overhead. dVoting is motivated by the observation that, across multiple samples for the same prompt, token predictions remain largely consistent, whereas performance is determined by a small subset of tokens exhibiting cross-sample variability. Leveraging the arbitrary-position generation capability of dLLMs, dVoting performs iterative refinement by sampling, identifying uncertain tokens via consistency analysis, regenerating them through voting, and repeating this process until convergence. Extensive evaluations demonstrate that dVoting consistently improves performance across various benchmarks. It achieves gains of 6.22%-7.66% on GSM8K, 4.40%-7.20% on MATH500, 3.16%-14.84% on ARC-C, and 4.83%-5.74% on MMLU. Our code is available at https://github.com/fscdc/dVoting",
      "source": "HuggingFace",
      "pubDateISO": "2026-02-12",
      "tags": [],
      "topics": [
        "Diffusion Large Language Models",
        "Parallel Decoding",
        "Iterative Refinement"
      ],
      "score": 7,
      "score_reason": "Faster voting method",
      "citations": 0,
      "upvotes": 15,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "The paper introduces dVoting, a fast voting technique that leverages the parallel generation capability of diffusion large language models (dLLMs) to improve reasoning capability through iterative refinement and consistency analysis.",
      "why_it_matters": "This work matters because it enables significant performance gains in dLLMs without requiring additional training, making them more viable for real-world applications where computational resources are limited.",
      "limitations": "The main limitation of dVoting is that it incurs an acceptable but non-negligible extra computational overhead, which may be a concern for very large-scale deployments or resource-constrained environments."
    },
    {
      "id": "2602.10106",
      "title": "EgoHumanoid: Unlocking In-the-Wild Loco-Manipulation with Robot-Free Egocentric Demonstration",
      "link": "https://huggingface.co/papers/2602.10106",
      "pdf_link": "https://arxiv.org/pdf/2602.10106.pdf",
      "authors": "Modi Shi, Shijia Peng, Jin Chen, Haoran Jiang, Yinghui Li",
      "institution": "",
      "abstract": "Human demonstrations offer rich environmental diversity and scale naturally, making them an appealing alternative to robot teleoperation. While this paradigm has advanced robot-arm manipulation, its potential for the more challenging, data-hungry problem of humanoid loco-manipulation remains largely unexplored. We present EgoHumanoid, the first framework to co-train a vision-language-action policy using abundant egocentric human demonstrations together with a limited amount of robot data, enabling humanoids to perform loco-manipulation across diverse real-world environments. To bridge the embodiment gap between humans and robots, including discrepancies in physical morphology and viewpoint, we introduce a systematic alignment pipeline spanning from hardware design to data processing. A portable system for scalable human data collection is developed, and we establish practical collection protocols to improve transferability. At the core of our human-to-humanoid alignment pipeline lies two key components. The view alignment reduces visual domain discrepancies caused by camera height and perspective variation. The action alignment maps human motions into a unified, kinematically feasible action space for humanoid control. Extensive real-world experiments demonstrate that incorporating robot-free egocentric data significantly outperforms robot-only baselines by 51\\%, particularly in unseen environments. Our analysis further reveals which behaviors transfer effectively and the potential for scaling human data.",
      "source": "HuggingFace",
      "pubDateISO": "2026-02-10",
      "tags": [],
      "topics": [
        "human-robot interaction",
        "egocentric learning",
        "loco-manipulation"
      ],
      "score": 7,
      "score_reason": "Advances loco-manipulation",
      "citations": 0,
      "upvotes": 13,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "The paper introduces EgoHumanoid, a framework that enables humanoids to perform loco-manipulation tasks by co-training a vision-language-action policy using egocentric human demonstrations and limited robot data.",
      "why_it_matters": "This research matters because it bridges the embodiment gap between humans and robots, allowing for more efficient and scalable learning of complex manipulation tasks in diverse real-world environments.",
      "limitations": "The main limitation of this work is that it relies on a systematic alignment pipeline to account for discrepancies in physical morphology and viewpoint between humans and robots, which may not generalize to all types of robots or environments."
    },
    {
      "id": "2602.11103",
      "title": "GameDevBench: Evaluating Agentic Capabilities Through Game Development",
      "link": "https://huggingface.co/papers/2602.11103",
      "pdf_link": "https://arxiv.org/pdf/2602.11103.pdf",
      "authors": "Wayne Chi, Yixiong Fang, Arnav Yayavaram, Siddharth Yayavaram, Seth Karten",
      "institution": "",
      "abstract": "Despite rapid progress on coding agents, progress on their multimodal counterparts has lagged behind. A key challenge is the scarcity of evaluation testbeds that combine the complexity of software development with the need for deep multimodal understanding. Game development provides such a testbed as agents must navigate large, dense codebases while manipulating intrinsically multimodal assets such as shaders, sprites, and animations within a visual game scene. We present GameDevBench, the first benchmark for evaluating agents on game development tasks. GameDevBench consists of 132 tasks derived from web and video tutorials. Tasks require significant multimodal understanding and are complex -- the average solution requires over three times the amount of lines of code and file changes compared to prior software development benchmarks. Agents still struggle with game development, with the best agent solving only 54.5% of tasks. We find a strong correlation between perceived task difficulty and multimodal complexity, with success rates dropping from 46.9% on gameplay-oriented tasks to 31.6% on 2D graphics tasks. To improve multimodal capability, we introduce two simple image and video-based feedback mechanisms for agents. Despite their simplicity, these methods consistently improve performance, with the largest change being an increase in Claude Sonnet 4.5's performance from 33.3% to 47.7%. We release GameDevBench publicly to support further research into agentic game development.",
      "source": "HuggingFace",
      "pubDateISO": "2026-02-11",
      "tags": [],
      "topics": [],
      "score": 7,
      "score_reason": "Game Development",
      "citations": 0,
      "upvotes": 12,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.12092",
      "title": "DeepSight: An All-in-One LM Safety Toolkit",
      "link": "https://huggingface.co/papers/2602.12092",
      "pdf_link": "https://arxiv.org/pdf/2602.12092.pdf",
      "authors": "Bo Zhang, Jiaxuan Guo, Lijun Li, Dongrui Liu, Sujin Chen",
      "institution": "",
      "abstract": "As the development of Large Models (LMs) progresses rapidly, their safety is also a priority. In current Large Language Models (LLMs) and Multimodal Large Language Models (MLLMs) safety workflow, evaluation, diagnosis, and alignment are often handled by separate tools. Specifically, safety evaluation can only locate external behavioral risks but cannot figure out internal root causes. Meanwhile, safety diagnosis often drifts from concrete risk scenarios and remains at the explainable level. In this way, safety alignment lack dedicated explanations of changes in internal mechanisms, potentially degrading general capabilities. To systematically address these issues, we propose an open-source project, namely DeepSight, to practice a new safety evaluation-diagnosis integrated paradigm. DeepSight is low-cost, reproducible, efficient, and highly scalable large-scale model safety evaluation project consisting of a evaluation toolkit DeepSafe and a diagnosis toolkit DeepScan. By unifying task and data protocols, we build a connection between the two stages and transform safety evaluation from black-box to white-box insight. Besides, DeepSight is the first open source toolkit that support the frontier AI risk evaluation and joint safety evaluation and diagnosis.",
      "source": "HuggingFace",
      "pubDateISO": "2026-02-12",
      "tags": [],
      "topics": [
        "Large Language Models",
        "AI Safety",
        "Explainable AI"
      ],
      "score": 7,
      "score_reason": "Comprehensive safety toolkit",
      "citations": 0,
      "upvotes": 10,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "This paper proposes DeepSight, an open-source, all-in-one safety toolkit that integrates safety evaluation and diagnosis for Large Models, providing a white-box insight into internal root causes of safety risks.",
      "why_it_matters": "This work matters because it addresses the current limitations of separate safety evaluation and diagnosis tools, which can only identify external behavioral risks without explaining internal mechanisms, thereby enhancing the reliability and trustworthiness of Large Language Models.",
      "limitations": "The main limitation of this work is that the effectiveness of DeepSight in handling complex, real-world safety scenarios and its scalability to extremely large models remains to be thoroughly evaluated and validated."
    },
    {
      "id": "2602.12108",
      "title": "The Pensieve Paradigm: Stateful Language Models Mastering Their Own Context",
      "link": "https://huggingface.co/papers/2602.12108",
      "pdf_link": "https://arxiv.org/pdf/2602.12108.pdf",
      "authors": "Xiaoyuan Liu, Tian Liang, Dongyang Ma, Deyu Zhou, Haitao Mi",
      "institution": "",
      "abstract": "In the world of Harry Potter, when Dumbledore's mind is overburdened, he extracts memories into a Pensieve to be revisited later. In the world of AI, while we possess the Pensieve-mature databases and retrieval systems, our models inexplicably lack the \"wand\" to operate it. They remain like a Dumbledore without agency, passively accepting a manually engineered context as their entire memory. This work finally places the wand in the model's hand. We introduce StateLM, a new class of foundation models endowed with an internal reasoning loop to manage their own state. We equip our model with a suite of memory tools, such as context pruning, document indexing, and note-taking, and train it to actively manage these tools. By learning to dynamically engineering its own context, our model breaks free from the architectural prison of a fixed window. Experiments across various model sizes demonstrate StateLM's effectiveness across diverse scenarios. On long-document QA tasks, StateLMs consistently outperform standard LLMs across all model scales; on the chat memory task, they achieve absolute accuracy improvements of 10% to 20% over standard LLMs. On the deep research task BrowseComp-Plus, the performance gap becomes even more pronounced: StateLM achieves up to 52% accuracy, whereas standard LLM counterparts struggle around 5%. Ultimately, our approach shifts LLMs from passive predictors to state-aware agents where reasoning becomes a stateful and manageable process.",
      "source": "HuggingFace",
      "pubDateISO": "2026-02-12",
      "tags": [],
      "topics": [],
      "score": 7,
      "score_reason": "Stateful Language Model",
      "citations": 0,
      "upvotes": 10,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.03773",
      "title": "Reasoning Cache: Continual Improvement Over Long Horizons via Short-Horizon RL",
      "link": "https://huggingface.co/papers/2602.03773",
      "pdf_link": "https://arxiv.org/pdf/2602.03773.pdf",
      "authors": "Ian Wu, Yuxiao Qu, Amrith Setlur, Aviral Kumar",
      "institution": "",
      "abstract": "Large Language Models (LLMs) that can continually improve beyond their training budgets are able to solve increasingly difficult problems by adapting at test time, a property we refer to as extrapolation. However, standard reinforcement learning (RL) operates over fixed problem distributions and training budgets, which limits extrapolation amidst distribution shift at test time. To address this, we introduce RC, an iterative decoding algorithm that replaces standard autoregressive decoding during both training and inference. RC exploits an asymmetry between the response generation and summarization capabilities of LLMs to construct reasoning chains that consistently improve across iterations. Models trained to use RC can extrapolate and continually improve over reasoning horizons more than an order of magnitude longer than those seen during training. Empirically, training a 4B model with RC using a 16k-token training budget improves performance on HMMT 2025 from 40% to nearly 70% with 0.5m tokens at test time, outperforming both comparably sized models and many larger reasoning LLMs. Finally, we also show that models trained with RC can more effectively leverage existing scaffolds to further scale test-time performance, due to the improved summary-conditioned generation abilities learned through training.",
      "source": "HuggingFace",
      "pubDateISO": "2026-02-03",
      "tags": [],
      "topics": [],
      "score": 7,
      "score_reason": "Continual Learning",
      "citations": 0,
      "upvotes": 5,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.11964",
      "title": "Gaia2: Benchmarking LLM Agents on Dynamic and Asynchronous Environments",
      "link": "https://huggingface.co/papers/2602.11964",
      "pdf_link": "https://arxiv.org/pdf/2602.11964.pdf",
      "authors": "Romain Froger, Pierre Andrews, Matteo Bettini, Amar Budhiraja, Ricardo Silveira Cabral",
      "institution": "",
      "abstract": "We introduce Gaia2, a benchmark for evaluating large language model agents in realistic, asynchronous environments. Unlike prior static or synchronous evaluations, Gaia2 introduces scenarios where environments evolve independently of agent actions, requiring agents to operate under temporal constraints, adapt to noisy and dynamic events, resolve ambiguity, and collaborate with other agents. Each scenario is paired with a write-action verifier, enabling fine-grained, action-level evaluation and making Gaia2 directly usable for reinforcement learning from verifiable rewards. Our evaluation of state-of-the-art proprietary and open-source models shows that no model dominates across capabilities: GPT-5 (high) reaches the strongest overall score of 42% pass@1 but fails on time-sensitive tasks, Claude-4 Sonnet trades accuracy and speed for cost, Kimi-K2 leads among open-source models with 21% pass@1. These results highlight fundamental trade-offs between reasoning, efficiency, robustness, and expose challenges in closing the \"sim2real\" gap. Gaia2 is built on a consumer environment with the open-source Agents Research Environments platform and designed to be easy to extend. By releasing Gaia2 alongside the foundational ARE framework, we aim to provide the community with a flexible infrastructure for developing, benchmarking, and training the next generation of practical agent systems.",
      "source": "HuggingFace",
      "pubDateISO": "2026-02-12",
      "tags": [],
      "topics": [],
      "score": 7,
      "score_reason": "New Benchmark",
      "citations": 0,
      "upvotes": 3,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.12164",
      "title": "Sci-CoE: Co-evolving Scientific Reasoning LLMs via Geometric Consensus with Sparse Supervision",
      "link": "https://huggingface.co/papers/2602.12164",
      "pdf_link": "https://arxiv.org/pdf/2602.12164.pdf",
      "authors": "Xiaohan He, Shiyang Feng, Songtao Huang, Lei Bai, Bin Wang",
      "institution": "",
      "abstract": "Large language models (LLMs) have demonstrated exceptional reasoning capabilities, and co-evolving paradigms have shown promising results in domains such as code and math. However, in scientific reasoning tasks, these models remain fragile due to unreliable solution evaluation and limited diversity in verification strategies. In this work, we propose Sci-CoE, a two-stage scientific co-evolving framework that enables models to self-evolve as both solver and verifier through a transition from sparse supervision to unsupervised learning. In the first stage, the model uses a small set of annotated data to establish fundamental correctness judgment anchors for the Verifier. In the second stage, we introduce a geometric reward mechanism that jointly considers consensus, reliability, and diversity, driving large-scale self-iteration on unlabeled data. Experiments on several general scientific benchmarks demonstrate that Sci-CoE enhances complex reasoning capabilities and exhibits strong scalability, facilitating the construction of more robust and diverse evaluation systems. Codes are available at https://github.com/InternScience/Sci-CoE.",
      "source": "HuggingFace",
      "pubDateISO": "2026-02-12",
      "tags": [],
      "topics": [
        "Large Language Models",
        "Co-evolving Paradigms",
        "Scientific Reasoning"
      ],
      "score": 7,
      "score_reason": "Scientific reasoning LLM",
      "citations": 0,
      "upvotes": 2,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "The paper proposes Sci-CoE, a novel two-stage co-evolving framework that leverages geometric consensus and sparse supervision to improve the scientific reasoning capabilities of large language models.",
      "why_it_matters": "This work matters because it addresses the fragility of current LLMs in scientific reasoning tasks, which is a crucial aspect of developing more robust and reliable AI systems for scientific applications.",
      "limitations": "The main limitation of this approach is that it relies on a small set of annotated data to establish initial correctness judgment anchors, which may not be representative of the entire problem space or generalize well to out-of-distribution scenarios."
    },
    {
      "id": "2602.02459",
      "title": "TIC-VLA: A Think-in-Control Vision-Language-Action Model for Robot Navigation in Dynamic Environments",
      "link": "https://huggingface.co/papers/2602.02459",
      "pdf_link": "https://arxiv.org/pdf/2602.02459.pdf",
      "authors": "Zhiyu Huang, Yun Zhang, Johnson Liu, Rui Song, Chen Tang",
      "institution": "",
      "abstract": "Robots in dynamic, human-centric environments must follow language instructions while maintaining real-time reactive control. Vision-language-action (VLA) models offer a promising framework, but they assume temporally aligned reasoning and control, despite semantic inference being inherently delayed relative to real-time action. We introduce Think-in-Control (TIC)-VLA, a latency-aware framework that explicitly models delayed semantic reasoning during action generation. TIC-VLA defines a delayed semantic-control interface that conditions action generation on delayed vision-language semantic states and explicit latency metadata, in addition to current observations, enabling policies to compensate for asynchronous reasoning. We further propose a latency-consistent training pipeline that injects reasoning inference delays during imitation learning and online reinforcement learning, aligning training with asynchronous deployment. To support realistic evaluation, we present DynaNav, a physics-accurate, photo-realistic simulation suite for language-guided navigation in dynamic environments. Extensive experiments in simulation and on a real robot show that TIC-VLA consistently outperforms prior VLA models while maintaining robust real-time control under multi-second reasoning latency. Project website: https://ucla-mobility.github.io/TIC-VLA/",
      "source": "HuggingFace",
      "pubDateISO": "2026-02-02",
      "tags": [],
      "topics": [],
      "score": 7,
      "score_reason": "Robot Navigation",
      "citations": 0,
      "upvotes": 2,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.12036",
      "title": "Composition-RL: Compose Your Verifiable Prompts for Reinforcement Learning of Large Language Models",
      "link": "https://huggingface.co/papers/2602.12036",
      "pdf_link": "https://arxiv.org/pdf/2602.12036.pdf",
      "authors": "Xin Xu, Clive Bai, Kai Yang, Tianhao Chen, Yangkun Chen",
      "institution": "",
      "abstract": "Large-scale verifiable prompts underpin the success of Reinforcement Learning with Verifiable Rewards (RLVR), but they contain many uninformative examples and are costly to expand further. Recent studies focus on better exploiting limited training data by prioritizing hard prompts whose rollout pass rate is 0. However, easy prompts with a pass rate of 1 also become increasingly prevalent as training progresses, thereby reducing the effective data size. To mitigate this, we propose Composition-RL, a simple yet useful approach for better utilizing limited verifiable prompts targeting pass-rate-1 prompts. More specifically, Composition-RL automatically composes multiple problems into a new verifiable question and uses these compositional prompts for RL training. Extensive experiments across model sizes from 4B to 30B show that Composition-RL consistently improves reasoning capability over RL trained on the original dataset. Performance can be further boosted with a curriculum variant of Composition-RL that gradually increases compositional depth over training. Additionally, Composition-RL enables more effective cross-domain RL by composing prompts drawn from different domains. Codes, datasets, and models are available at https://github.com/XinXU-USTC/Composition-RL.",
      "source": "HuggingFace",
      "pubDateISO": "2026-02-12",
      "tags": [],
      "topics": [],
      "score": 6,
      "score_reason": "Prompt composition",
      "citations": 0,
      "upvotes": 70,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.11451",
      "title": "LoopFormer: Elastic-Depth Looped Transformers for Latent Reasoning via Shortcut Modulation",
      "link": "https://huggingface.co/papers/2602.11451",
      "pdf_link": "https://arxiv.org/pdf/2602.11451.pdf",
      "authors": "Ahmadreza Jeddi, Marco Ciccone, Babak Taati",
      "institution": "",
      "abstract": "Looped Transformers have emerged as an efficient and powerful class of models for reasoning in the language domain. Recent studies show that these models achieve strong performance on algorithmic and reasoning tasks, suggesting that looped architectures possess an inductive bias toward latent reasoning. However, prior approaches fix the number of loop iterations during training and inference, leaving open the question of whether these models can flexibly adapt their computational depth under variable compute budgets. We introduce LoopFormer, a looped Transformer trained on variable-length trajectories to enable budget-conditioned reasoning. Our core contribution is a shortcut-consistency training scheme that aligns trajectories of different lengths, ensuring that shorter loops yield informative representations while longer loops continue to refine them. LoopFormer conditions each loop on the current time and step size, enabling representations to evolve consistently across trajectories of varying length rather than drifting or stagnating. Empirically, LoopFormer demonstrates robust performance on language modeling and reasoning benchmarks even under aggressive compute constraints, while scaling gracefully with additional budget. These results show that looped Transformers are inherently suited for adaptive language modeling, opening a path toward controllable and budget-aware large language models.",
      "source": "HuggingFace",
      "pubDateISO": "2026-02-11",
      "tags": [],
      "topics": [],
      "score": 6,
      "score_reason": "Looped Transformers",
      "citations": 0,
      "upvotes": 13,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.05827",
      "title": "Sparse Video Generation Propels Real-World Beyond-the-View Vision-Language Navigation",
      "link": "https://huggingface.co/papers/2602.05827",
      "pdf_link": "https://arxiv.org/pdf/2602.05827.pdf",
      "authors": "Hai Zhang, Siqi Liang, Li Chen, Yuxian Li, Yukuan Xu",
      "institution": "",
      "abstract": "Why must vision-language navigation be bound to detailed and verbose language instructions? While such details ease decision-making, they fundamentally contradict the goal for navigation in the real-world. Ideally, agents should possess the autonomy to navigate in unknown environments guided solely by simple and high-level intents. Realizing this ambition introduces a formidable challenge: Beyond-the-View Navigation (BVN), where agents must locate distant, unseen targets without dense and step-by-step guidance. Existing large language model (LLM)-based methods, though adept at following dense instructions, often suffer from short-sighted behaviors due to their reliance on short-horimzon supervision. Simply extending the supervision horizon, however, destabilizes LLM training. In this work, we identify that video generation models inherently benefit from long-horizon supervision to align with language instructions, rendering them uniquely suitable for BVN tasks. Capitalizing on this insight, we propose introducing the video generation model into this field for the first time. Yet, the prohibitive latency for generating videos spanning tens of seconds makes real-world deployment impractical. To bridge this gap, we propose SparseVideoNav, achieving sub-second trajectory inference guided by a generated sparse future spanning a 20-second horizon. This yields a remarkable 27x speed-up compared to the unoptimized counterpart. Extensive real-world zero-shot experiments demonstrate that SparseVideoNav achieves 2.5x the success rate of state-of-the-art LLM baselines on BVN tasks and marks the first realization of such capability in challenging night scenes.",
      "source": "HuggingFace",
      "pubDateISO": "2026-02-05",
      "tags": [],
      "topics": [],
      "score": 6,
      "score_reason": "Novel navigation",
      "citations": 1,
      "upvotes": 9,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.08194",
      "title": "Dreaming in Code for Curriculum Learning in Open-Ended Worlds",
      "link": "https://huggingface.co/papers/2602.08194",
      "pdf_link": "https://arxiv.org/pdf/2602.08194.pdf",
      "authors": "Konstantinos Mitsides, Maxence Faldor, Antoine Cully",
      "institution": "MIT",
      "abstract": "Open-ended learning frames intelligence as emerging from continual interaction with an ever-expanding space of environments. While recent advances have utilized foundation models to programmatically generate diverse environments, these approaches often focus on discovering isolated behaviors rather than orchestrating sustained progression. In complex open-ended worlds, the large combinatorial space of possible challenges makes it difficult for agents to discover sequences of experiences that remain consistently learnable. To address this, we propose Dreaming in Code (DiCode), a framework in which foundation models synthesize executable environment code to scaffold learning toward increasing competence. In DiCode, \"dreaming\" takes the form of materializing code-level variations of the world. We instantiate DiCode in Craftax, a challenging open-ended benchmark characterized by rich mechanics and long-horizon progression. Empirically, DiCode enables agents to acquire long-horizon skills, achieving a 16% improvement in mean return over the strongest baseline and non-zero success on late-game combat tasks where prior methods fail. Our results suggest that code-level environment design provides a practical mechanism for curriculum control, enabling the construction of intermediate environments that bridge competence gaps in open-ended worlds. Project page and source code are available at https://konstantinosmitsides.github.io/dreaming-in-code and https://github.com/konstantinosmitsides/dreaming-in-code.",
      "source": "HuggingFace",
      "pubDateISO": "2026-02-09",
      "tags": [],
      "topics": [],
      "score": 6,
      "score_reason": "Curriculum Learning",
      "citations": 0,
      "upvotes": 6,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.11337",
      "title": "MolmoSpaces: A Large-Scale Open Ecosystem for Robot Navigation and Manipulation",
      "link": "https://huggingface.co/papers/2602.11337",
      "pdf_link": "https://arxiv.org/pdf/2602.11337.pdf",
      "authors": "Yejin Kim, Wilbert Pumacay, Omar Rayyan, Max Argus, Winson Han",
      "institution": "",
      "abstract": "Deploying robots at scale demands robustness to the long tail of everyday situations. The countless variations in scene layout, object geometry, and task specifications that characterize real environments are vast and underrepresented in existing robot benchmarks. Measuring this level of generalization requires infrastructure at a scale and diversity that physical evaluation alone cannot provide. We introduce MolmoSpaces, a fully open ecosystem to support large-scale benchmarking of robot policies. MolmoSpaces consists of over 230k diverse indoor environments, ranging from handcrafted household scenes to procedurally generated multiroom houses, populated with 130k richly annotated object assets, including 48k manipulable objects with 42M stable grasps. Crucially, these environments are simulator-agnostic, supporting popular options such as MuJoCo, Isaac, and ManiSkill. The ecosystem supports the full spectrum of embodied tasks: static and mobile manipulation, navigation, and multiroom long-horizon tasks requiring coordinated perception, planning, and interaction across entire indoor environments. We also design MolmoSpaces-Bench, a benchmark suite of 8 tasks in which robots interact with our diverse scenes and richly annotated objects. Our experiments show MolmoSpaces-Bench exhibits strong sim-to-real correlation (R = 0.96, ho = 0.98), confirm newer and stronger zero-shot policies outperform earlier versions in our benchmarks, and identify key sensitivities to prompt phrasing, initial joint positions, and camera occlusion. Through MolmoSpaces and its open-source assets and tooling, we provide a foundation for scalable data generation, policy training, and benchmark creation for robot learning research.",
      "source": "HuggingFace",
      "pubDateISO": "2026-02-11",
      "tags": [],
      "topics": [],
      "score": 6,
      "score_reason": "Large navigation dataset",
      "citations": 0,
      "upvotes": 4,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.11761",
      "title": "MiniCPM-SALA: Hybridizing Sparse and Linear Attention for Efficient Long-Context Modeling",
      "link": "https://huggingface.co/papers/2602.11761",
      "pdf_link": "https://arxiv.org/pdf/2602.11761.pdf",
      "authors": "MiniCPM Team, Wenhao An, Yingfa Chen, Yewei Fang, Jiayi Li",
      "institution": "",
      "abstract": "The evolution of large language models (LLMs) towards applications with ultra-long contexts faces challenges posed by the high computational and memory costs of the Transformer architecture. While existing sparse and linear attention mechanisms attempt to mitigate these issues, they typically involve a trade-off between memory efficiency and model performance. This paper introduces MiniCPM-SALA, a 9B-parameter hybrid architecture that integrates the high-fidelity long-context modeling of sparse attention (InfLLM-V2) with the global efficiency of linear attention (Lightning Attention). By employing a layer selection algorithm to integrate these mechanisms in a 1:3 ratio and utilizing a hybrid positional encoding (HyPE), the model maintains efficiency and performance for long-context tasks. Furthermore, we introduce a cost-effective continual training framework that transforms pre-trained Transformer-based models into hybrid models, which reduces training costs by approximately 75% compared to training from scratch. Extensive experiments show that MiniCPM-SALA maintains general capabilities comparable to full-attention models while offering improved efficiency. On a single NVIDIA A6000D GPU, the model achieves up to 3.5x the inference speed of the full-attention model at the sequence length of 256K tokens and supports context lengths of up to 1M tokens, a scale where traditional full-attention 8B models fail because of memory constraints.",
      "source": "HuggingFace",
      "pubDateISO": "2026-02-12",
      "tags": [],
      "topics": [],
      "score": 6,
      "score_reason": "Attention Mechanism",
      "citations": 0,
      "upvotes": 4,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.10575",
      "title": "MetaphorStar: Image Metaphor Understanding and Reasoning with End-to-End Visual Reinforcement Learning",
      "link": "https://huggingface.co/papers/2602.10575",
      "pdf_link": "https://arxiv.org/pdf/2602.10575.pdf",
      "authors": "Chenhao Zhang, Yazhe Niu, Hongsheng Li",
      "institution": "",
      "abstract": "Metaphorical comprehension in images remains a critical challenge for Nowadays AI systems. While Multimodal Large Language Models (MLLMs) excel at basic Visual Question Answering (VQA), they consistently struggle to grasp the nuanced cultural, emotional, and contextual implications embedded in visual content. This difficulty stems from the task's demand for sophisticated multi-hop reasoning, cultural context, and Theory of Mind (ToM) capabilities, which current models lack. To fill this gap, we propose MetaphorStar, the first end-to-end visual reinforcement learning (RL) framework for image implication tasks. Our framework includes three core components: the fine-grained dataset TFQ-Data, the visual RL method TFQ-GRPO, and the well-structured benchmark TFQ-Bench.\n  Our fully open-source MetaphorStar family, trained using TFQ-GRPO on TFQ-Data, significantly improves performance by an average of 82.6% on the image implication benchmarks. Compared with 20+ mainstream MLLMs, MetaphorStar-32B achieves state-of-the-art (SOTA) on Multiple-Choice Question and Open-Style Question, significantly outperforms the top closed-source model Gemini-3.0-pro on True-False Question. Crucially, our experiments reveal that learning image implication tasks improves the general understanding ability, especially the complex visual reasoning ability. We further provide a systematic analysis of model parameter scaling, training data scaling, and the impact of different model architectures and training strategies, demonstrating the broad applicability of our method. We open-sourced all model weights, datasets, and method code at https://metaphorstar.github.io.",
      "source": "HuggingFace",
      "pubDateISO": "2026-02-11",
      "tags": [],
      "topics": [],
      "score": 6,
      "score_reason": "Metaphor understanding",
      "citations": 0,
      "upvotes": 3,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.12116",
      "title": "P-GenRM: Personalized Generative Reward Model with Test-time User-based Scaling",
      "link": "https://huggingface.co/papers/2602.12116",
      "pdf_link": "https://arxiv.org/pdf/2602.12116.pdf",
      "authors": "Pinyi Zhang, Ting-En Lin, Yuchuan Wu, Jingyang Chen, Zongqi Wang",
      "institution": "",
      "abstract": "Personalized alignment of large language models seeks to adapt responses to individual user preferences, typically via reinforcement learning. A key challenge is obtaining accurate, user-specific reward signals in open-ended scenarios. Existing personalized reward models face two persistent limitations: (1) oversimplifying diverse, scenario-specific preferences into a small, fixed set of evaluation principles, and (2) struggling with generalization to new users with limited feedback. To this end, we propose P-GenRM, the first Personalized Generative Reward Model with test-time user-based scaling. P-GenRM transforms preference signals into structured evaluation chains that derive adaptive personas and scoring rubrics across various scenarios. It further clusters users into User Prototypes and introduces a dual-granularity scaling mechanism: at the individual level, it adaptively scales and aggregates each user's scoring scheme; at the prototype level, it incorporates preferences from similar users. This design mitigates noise in inferred preferences and enhances generalization to unseen users through prototype-based transfer. Empirical results show that P-GenRM achieves state-of-the-art results on widely-used personalized reward model benchmarks, with an average improvement of 2.31%, and demonstrates strong generalization on an out-of-distribution dataset. Notably, Test-time User-based scaling provides an additional 3% boost, demonstrating stronger personalized alignment with test-time scalability.",
      "source": "HuggingFace",
      "pubDateISO": "2026-02-12",
      "tags": [],
      "topics": [],
      "score": 6,
      "score_reason": "Personalized LLM",
      "citations": 0,
      "upvotes": 3,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.11543",
      "title": "Pretraining A Large Language Model using Distributed GPUs: A Memory-Efficient Decentralized Paradigm",
      "link": "https://huggingface.co/papers/2602.11543",
      "pdf_link": "https://arxiv.org/pdf/2602.11543.pdf",
      "authors": "Jinrui Zhang, Chaodong Xiao, Aoqi Wu, Xindong Zhang, Lei Zhang",
      "institution": "",
      "abstract": "Pretraining large language models (LLMs) typically requires centralized clusters with thousands of high-memory GPUs (e.g., H100/A100). Recent decentralized training methods reduce communication overhead by employing federated optimization; however, they still need to train the entire model on each node, remaining constrained by GPU memory limitations. In this work, we propose SParse Expert Synchronization (SPES), a memory-efficient decentralized framework for pretraining mixture-of-experts (MoE) LLMs. SPES trains only a subset of experts per node, substantially lowering the memory footprint. Each node updates its local experts and periodically synchronizes with other nodes, eliminating full-parameter transmission while ensuring efficient knowledge sharing. To accelerate convergence, we introduce an expert-merging warm-up strategy, where experts exchange knowledge early in training, to rapidly establish foundational capabilities. With SPES, we train a 2B-parameter MoE LLM using 16 standalone 48GB GPUs over internet connections, which achieves competitive performance with centrally trained LLMs under similar computational budgets. We further demonstrate scalability by training a 7B model from scratch and a 9B model upcycled from a dense checkpoint, both of which match prior centralized baselines. Our code is available at https://github.com/zjr2000/SPES.",
      "source": "HuggingFace",
      "pubDateISO": "2026-02-12",
      "tags": [],
      "topics": [],
      "score": 6,
      "score_reason": "Decentralized training method",
      "citations": 0,
      "upvotes": 2,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.11509",
      "title": "Multimodal Fact-Level Attribution for Verifiable Reasoning",
      "link": "https://huggingface.co/papers/2602.11509",
      "pdf_link": "https://arxiv.org/pdf/2602.11509.pdf",
      "authors": "David Wan, Han Wang, Ziyang Wang, Elias Stengel-Eskin, Hyunji Lee",
      "institution": "",
      "abstract": "Multimodal large language models (MLLMs) are increasingly used for real-world tasks involving multi-step reasoning and long-form generation, where reliability requires grounding model outputs in heterogeneous input sources and verifying individual factual claims. However, existing multimodal grounding benchmarks and evaluation methods focus on simplified, observation-based scenarios or limited modalities and fail to assess attribution in complex multimodal reasoning. We introduce MuRGAt (Multimodal Reasoning with Grounded Attribution), a benchmark for evaluating fact-level multimodal attribution in settings that require reasoning beyond direct observation. Given inputs spanning video, audio, and other modalities, MuRGAt requires models to generate answers with explicit reasoning and precise citations, where each citation specifies both modality and temporal segments. To enable reliable assessment, we introduce an automatic evaluation framework that strongly correlates with human judgments. Benchmarking with human and automated scores reveals that even strong MLLMs frequently hallucinate citations despite correct reasoning. Moreover, we observe a key trade-off: increasing reasoning depth or enforcing structured grounding often degrades accuracy, highlighting a significant gap between internal reasoning and verifiable attribution.",
      "source": "HuggingFace",
      "pubDateISO": "2026-02-12",
      "tags": [],
      "topics": [],
      "score": 6,
      "score_reason": "Improves reliability",
      "citations": 0,
      "upvotes": 2,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.08277",
      "title": "PISCO: Precise Video Instance Insertion with Sparse Control",
      "link": "https://huggingface.co/papers/2602.08277",
      "pdf_link": "https://arxiv.org/pdf/2602.08277.pdf",
      "authors": "Xiangbo Gao, Renjie Li, Xinghao Chen, Yuheng Wu, Suofei Feng",
      "institution": "",
      "abstract": "The landscape of AI video generation is undergoing a pivotal shift: moving beyond general generation - which relies on exhaustive prompt-engineering and \"cherry-picking\" - towards fine-grained, controllable generation and high-fidelity post-processing. In professional AI-assisted filmmaking, it is crucial to perform precise, targeted modifications. A cornerstone of this transition is video instance insertion, which requires inserting a specific instance into existing footage while maintaining scene integrity. Unlike traditional video editing, this task demands several requirements: precise spatial-temporal placement, physically consistent scene interaction, and the faithful preservation of original dynamics - all achieved under minimal user effort. In this paper, we propose PISCO, a video diffusion model for precise video instance insertion with arbitrary sparse keyframe control. PISCO allows users to specify a single keyframe, start-and-end keyframes, or sparse keyframes at arbitrary timestamps, and automatically propagates object appearance, motion, and interaction. To address the severe distribution shift induced by sparse conditioning in pretrained video diffusion models, we introduce Variable-Information Guidance for robust conditioning and Distribution-Preserving Temporal Masking to stabilize temporal generation, together with geometry-aware conditioning for realistic scene adaptation. We further construct PISCO-Bench, a benchmark with verified instance annotations and paired clean background videos, and evaluate performance using both reference-based and reference-free perceptual metrics. Experiments demonstrate that PISCO consistently outperforms strong inpainting and video editing baselines under sparse control, and exhibits clear, monotonic performance improvements as additional control signals are provided. Project page: xiangbogaobarry.github.io/PISCO.",
      "source": "HuggingFace",
      "pubDateISO": "2026-02-09",
      "tags": [],
      "topics": [],
      "score": 6,
      "score_reason": "Video instance insertion",
      "citations": 0,
      "upvotes": 1,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.10585",
      "title": "Neural Additive Experts: Context-Gated Experts for Controllable Model Additivity",
      "link": "https://huggingface.co/papers/2602.10585",
      "pdf_link": "https://arxiv.org/pdf/2602.10585.pdf",
      "authors": "Guangzhi Xiong, Sanchit Sinha, Aidong Zhang",
      "institution": "",
      "abstract": "The trade-off between interpretability and accuracy remains a core challenge in machine learning. Standard Generalized Additive Models (GAMs) offer clear feature attributions but are often constrained by their strictly additive nature, which can limit predictive performance. Introducing feature interactions can boost accuracy yet may obscure individual feature contributions. To address these issues, we propose Neural Additive Experts (NAEs), a novel framework that seamlessly balances interpretability and accuracy. NAEs employ a mixture of experts framework, learning multiple specialized networks per feature, while a dynamic gating mechanism integrates information across features, thereby relaxing rigid additive constraints. Furthermore, we propose targeted regularization techniques to mitigate variance among expert predictions, facilitating a smooth transition from an exclusively additive model to one that captures intricate feature interactions while maintaining clarity in feature attributions. Our theoretical analysis and experiments on synthetic data illustrate the model's flexibility, and extensive evaluations on real-world datasets confirm that NAEs achieve an optimal balance between predictive accuracy and transparent, feature-level explanations. The code is available at https://github.com/Teddy-XiongGZ/NAE.",
      "source": "HuggingFace",
      "pubDateISO": "2026-02-11",
      "tags": [],
      "topics": [],
      "score": 6,
      "score_reason": "Model Additivity",
      "citations": 0,
      "upvotes": 1,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.08052",
      "title": "Graph-Enhanced Deep Reinforcement Learning for Multi-Objective Unrelated Parallel Machine Scheduling",
      "link": "https://huggingface.co/papers/2602.08052",
      "pdf_link": "https://arxiv.org/pdf/2602.08052.pdf",
      "authors": "Bulent Soykan, Sean Mondesire, Ghaith Rabadi, Grace Bochenek",
      "institution": "",
      "abstract": "The Unrelated Parallel Machine Scheduling Problem (UPMSP) with release dates, setups, and eligibility constraints presents a significant multi-objective challenge. Traditional methods struggle to balance minimizing Total Weighted Tardiness (TWT) and Total Setup Time (TST). This paper proposes a Deep Reinforcement Learning framework using Proximal Policy Optimization (PPO) and a Graph Neural Network (GNN). The GNN effectively represents the complex state of jobs, machines, and setups, allowing the PPO agent to learn a direct scheduling policy. Guided by a multi-objective reward function, the agent simultaneously minimizes TWT and TST. Experimental results on benchmark instances demonstrate that our PPO-GNN agent significantly outperforms a standard dispatching rule and a metaheuristic, achieving a superior trade-off between both objectives. This provides a robust and scalable solution for complex manufacturing scheduling.",
      "source": "HuggingFace",
      "pubDateISO": "2026-02-08",
      "tags": [],
      "topics": [],
      "score": 6,
      "score_reason": "Scheduling Problem",
      "citations": 0,
      "upvotes": 1,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.06841",
      "title": "From Features to Actions: Explainability in Traditional and Agentic AI Systems",
      "link": "https://huggingface.co/papers/2602.06841",
      "pdf_link": "https://arxiv.org/pdf/2602.06841.pdf",
      "authors": "Sindhuja Chaduvula, Jessee Ho, Kina Kim, Aravind Narayanan, Mahshid Alinoori",
      "institution": "",
      "abstract": "Over the last decade, explainable AI has primarily focused on interpreting individual model predictions, producing post-hoc explanations that relate inputs to outputs under a fixed decision structure. Recent advances in large language models (LLMs) have enabled agentic AI systems whose behaviour unfolds over multi-step trajectories. In these settings, success and failure are determined by sequences of decisions rather than a single output. While useful, it remains unclear how explanation approaches designed for static predictions translate to agentic settings where behaviour emerges over time. In this work, we bridge the gap between static and agentic explainability by comparing attribution-based explanations with trace-based diagnostics across both settings. To make this distinction explicit, we empirically compare attribution-based explanations used in static classification tasks with trace-based diagnostics used in agentic benchmarks (TAU-bench Airline and AssistantBench). Our results show that while attribution methods achieve stable feature rankings in static settings (Spearman ρ= 0.86), they cannot be applied reliably to diagnose execution-level failures in agentic trajectories. In contrast, trace-grounded rubric evaluation for agentic settings consistently localizes behaviour breakdowns and reveals that state tracking inconsistency is 2.7times more prevalent in failed runs and reduces success probability by 49\\%. These findings motivate a shift towards trajectory-level explainability for agentic systems when evaluating and diagnosing autonomous AI behaviour.\n  Resources:\n  https://github.com/VectorInstitute/unified-xai-evaluation-framework https://vectorinstitute.github.io/unified-xai-evaluation-framework",
      "source": "HuggingFace",
      "pubDateISO": "2026-02-06",
      "tags": [],
      "topics": [],
      "score": 6,
      "score_reason": "Explainable AI",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.08934",
      "title": "StealthRL: Reinforcement Learning Paraphrase Attacks for Multi-Detector Evasion of AI-Text Detectors",
      "link": "https://huggingface.co/papers/2602.08934",
      "pdf_link": "https://arxiv.org/pdf/2602.08934.pdf",
      "authors": "Suraj Ranganath, Atharv Ramesh",
      "institution": "",
      "abstract": "AI-text detectors face a critical robustness challenge: adversarial paraphrasing attacks that preserve semantics while evading detection. We introduce StealthRL, a reinforcement learning framework that stress-tests detector robustness under realistic adversarial conditions. StealthRL trains a paraphrase policy against a multi-detector ensemble using Group Relative Policy Optimization (GRPO) with LoRA adapters on Qwen3-4B, optimizing a composite reward that balances detector evasion with semantic preservation. We evaluate six attack settings (M0-M5) against three detector families (RoBERTa, FastDetectGPT, and Binoculars) at the security-relevant 1% false positive rate operating point. StealthRL achieves near-zero detection (0.001 mean TPR@1%FPR), reduces mean AUROC from 0.74 to 0.27, and attains a 99.9% attack success rate. Critically, attacks transfer to a held-out detector family not seen during training, revealing shared architectural vulnerabilities rather than detector-specific brittleness. We additionally conduct LLM-based quality evaluation via Likert scoring, analyze detector score distributions to explain why evasion succeeds, and provide per-detector AUROC with bootstrap confidence intervals. Our results expose significant robustness gaps in current AI-text detection and establish StealthRL as a principled adversarial evaluation protocol. Code and evaluation pipeline are publicly available at https://github.com/suraj-ranganath/StealthRL.",
      "source": "HuggingFace",
      "pubDateISO": "2026-02-09",
      "tags": [],
      "topics": [],
      "score": 6,
      "score_reason": "Paraphrase Attacks",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.10934",
      "title": "MOSS-Audio-Tokenizer: Scaling Audio Tokenizers for Future Audio Foundation Models",
      "link": "https://huggingface.co/papers/2602.10934",
      "pdf_link": "https://arxiv.org/pdf/2602.10934.pdf",
      "authors": "Yitian Gong, Kuangwei Chen, Zhaoye Fei, Xiaogui Yang, Ke Chen",
      "institution": "",
      "abstract": "Discrete audio tokenizers are fundamental to empowering large language models with native audio processing and generation capabilities. Despite recent progress, existing approaches often rely on pretrained encoders, semantic distillation, or heterogeneous CNN-based architectures. These designs introduce fixed inductive biases that limit reconstruction fidelity and hinder effective scaling. In this paper, we argue that discrete audio tokenization should be learned fully end-to-end using a homogeneous and scalable architecture. To this end, we first propose CAT (Causal Audio Tokenizer with Transformer), a purely Transformer-based architecture that jointly optimizes the encoder, quantizer, and decoder from scratch for high-fidelity reconstruction. Building on the CAT architecture, we develop MOSS-Audio-Tokenizer, a large-scale audio tokenizer featuring 1.6 billion parameters, pre-trained on 3 million hours of diverse, general audio data. We show that this simple, fully end-to-end approach built from homogeneous, causal Transformer blocks scales gracefully and supports high-fidelity reconstruction across diverse audio domains. Across speech, sound, and music, MOSS-Audio-Tokenizer consistently outperforms prior codecs over a wide range of bitrates, while exhibiting predictable improvements with increased scale. Notably, leveraging the discrete tokens from our model, we develop the first purely autoregressive TTS model that surpasses prior non-autoregressive and cascaded systems. Furthermore, MOSS-Audio-Tokenizer enables competitive ASR performance without auxiliary encoders. Our findings position the CAT architecture as a unified, scalable interface for the next generation of native audio foundation models.",
      "source": "HuggingFace",
      "pubDateISO": "2026-02-11",
      "tags": [],
      "topics": [],
      "score": 5,
      "score_reason": "New tokenizer design",
      "citations": 0,
      "upvotes": 40,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.11731",
      "title": "Thinking with Drafting: Optical Decompression via Logical Reconstruction",
      "link": "https://huggingface.co/papers/2602.11731",
      "pdf_link": "https://arxiv.org/pdf/2602.11731.pdf",
      "authors": "Jingxuan Wei, Honghao He, Caijun Jia, Siyuan Li, Zheng Sun",
      "institution": "",
      "abstract": "Existing multimodal large language models have achieved high-fidelity visual perception and exploratory visual generation. However, a precision paradox persists in complex reasoning tasks: optical perception systems transcribe symbols without capturing logical topology, while pixel-based generative models produce visual artifacts lacking mathematical exactness. To bridge this gap, we propose that reasoning over visual inputs be reconceptualized as optical decompression-the process of reconstructing latent logical structures from compressed visual tokens. Guided by the axiom that Parsing is Reasoning, we introduce Thinking with Drafting (TwD), which utilizes a minimalist Domain-Specific Language (DSL) as a grounding intermediate representation. Unlike standard approaches that hallucinate answers directly, TwD forces the model to draft its mental model into executable code, rendering deterministic visual proofs for self-verification. To validate this, we present VisAlg, a visual algebra benchmark. Experiments demonstrate that TwD serve as a superior cognitive scaffold. Our work establishes a closed-loop system where visual generation acts not as a creative output but as a logical verifier, offering a generalizable path for visual reasoning.",
      "source": "HuggingFace",
      "pubDateISO": "2026-02-12",
      "tags": [],
      "topics": [],
      "score": 5,
      "score_reason": "Logical reconstruction",
      "citations": 0,
      "upvotes": 20,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.02192",
      "title": "ECHO-2: A Large-Scale Distributed Rollout Framework for Cost-Efficient Reinforcement Learning",
      "link": "https://huggingface.co/papers/2602.02192",
      "pdf_link": "https://arxiv.org/pdf/2602.02192.pdf",
      "authors": "Jie Xiao, Meng Chen, Qingnan Ren, Jingwei Song, Jiaqi Huang",
      "institution": "",
      "abstract": "Reinforcement learning (RL) is a critical stage in post-training large language models (LLMs), involving repeated interaction between rollout generation, reward evaluation, and centralized learning. Distributing rollout execution offers opportunities to leverage more cost-efficient inference resources, but introduces challenges in wide-area coordination and policy dissemination. We present ECHO-2, a distributed RL framework for post-training with remote inference workers and non-negligible dissemination latency. ECHO-2 combines centralized learning with distributed rollouts and treats bounded policy staleness as a user-controlled parameter, enabling rollout generation, dissemination, and training to overlap. We introduce an overlap-based capacity model that relates training time, dissemination latency, and rollout throughput, yielding a practical provisioning rule for sustaining learner utilization. To mitigate dissemination bottlenecks and lower cost, ECHO-2 employs peer-assisted pipelined broadcast and cost-aware activation of heterogeneous workers. Experiments on GRPO post-training of 4B and 8B models under real wide-area bandwidth regimes show that ECHO-2 significantly improves cost efficiency while preserving RL reward comparable to strong baselines.",
      "source": "HuggingFace",
      "pubDateISO": "2026-02-02",
      "tags": [],
      "topics": [],
      "score": 5,
      "score_reason": "Rollout Framework",
      "citations": 0,
      "upvotes": 12,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.09070",
      "title": "NarraScore: Bridging Visual Narrative and Musical Dynamics via Hierarchical Affective Control",
      "link": "https://huggingface.co/papers/2602.09070",
      "pdf_link": "https://arxiv.org/pdf/2602.09070.pdf",
      "authors": "Yufan Wen, Zhaocheng Liu, YeGuo Hua, Ziyi Guo, Lihua Zhang",
      "institution": "",
      "abstract": "Synthesizing coherent soundtracks for long-form videos remains a formidable challenge, currently stalled by three critical impediments: computational scalability, temporal coherence, and, most critically, a pervasive semantic blindness to evolving narrative logic. To bridge these gaps, we propose NarraScore, a hierarchical framework predicated on the core insight that emotion serves as a high-density compression of narrative logic. Uniquely, we repurpose frozen Vision-Language Models (VLMs) as continuous affective sensors, distilling high-dimensional visual streams into dense, narrative-aware Valence-Arousal trajectories. Mechanistically, NarraScore employs a Dual-Branch Injection strategy to reconcile global structure with local dynamism: a Global Semantic Anchor ensures stylistic stability, while a surgical Token-Level Affective Adapter modulates local tension via direct element-wise residual injection. This minimalist design bypasses the bottlenecks of dense attention and architectural cloning, effectively mitigating the overfitting risks associated with data scarcity. Experiments demonstrate that NarraScore achieves state-of-the-art consistency and narrative alignment with negligible computational overhead, establishing a fully autonomous paradigm for long-video soundtrack generation.",
      "source": "HuggingFace",
      "pubDateISO": "2026-02-09",
      "tags": [],
      "topics": [],
      "score": 5,
      "score_reason": "Narrative music synthesis",
      "citations": 0,
      "upvotes": 11,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.05548",
      "title": "Unveiling Implicit Advantage Symmetry: Why GRPO Struggles with Exploration and Difficulty Adaptation",
      "link": "https://huggingface.co/papers/2602.05548",
      "pdf_link": "https://arxiv.org/pdf/2602.05548.pdf",
      "authors": "Zhiqi Yu, Zhangquan Chen, Mengting Liu, Heye Zhang, Liangqiong Qu",
      "institution": "",
      "abstract": "Reinforcement Learning with Verifiable Rewards (RLVR), particularly GRPO, has become the standard for eliciting LLM reasoning. However, its efficiency in exploration and difficulty adaptation remains an open challenge. In this work, we argue that these bottlenecks stem from an implicit advantage symmetry inherent in Group Relative Advantage Estimation (GRAE). This symmetry induces two critical limitations: (i) at the group level, strict symmetry in weights between correct and incorrect trajectories leaves unsampled action logits unchanged, thereby hindering exploration of novel correct solution. (ii) at the sample level, the algorithm implicitly prioritizes medium-difficulty samples, remaining agnostic to the non-stationary demands of difficulty focus. Through controlled experiments, we reveal that this symmetric property is sub-optimal, yielding two pivotal insights: (i) asymmetrically suppressing the advantages of correct trajectories encourages essential exploration. (ii) learning efficiency is maximized by a curriculum-like transition-prioritizing simpler samples initially before gradually shifting to complex ones. Motivated by these findings, we propose Asymmetric GRAE (A-GRAE), which dynamically modulates exploration incentives and sample-difficulty focus. Experiments across seven benchmarks demonstrate that A-GRAE consistently improves GRPO and its variants across both LLMs and MLLMs.",
      "source": "HuggingFace",
      "pubDateISO": "2026-02-05",
      "tags": [],
      "topics": [],
      "score": 5,
      "score_reason": "Exploration Challenge",
      "citations": 0,
      "upvotes": 10,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.11733",
      "title": "Adapting Vision-Language Models for E-commerce Understanding at Scale",
      "link": "https://huggingface.co/papers/2602.11733",
      "pdf_link": "https://arxiv.org/pdf/2602.11733.pdf",
      "authors": "Matteo Nulli, Vladimir Orshulevich, Tala Bazazo, Christian Herold, Michael Kozielski",
      "institution": "",
      "abstract": "E-commerce product understanding demands by nature, strong multimodal comprehension from text, images, and structured attributes. General-purpose Vision-Language Models (VLMs) enable generalizable multimodal latent modelling, yet there is no documented, well-known strategy for adapting them to the attribute-centric, multi-image, and noisy nature of e-commerce data, without sacrificing general performance. In this work, we show through a large-scale experimental study, how targeted adaptation of general VLMs can substantially improve e-commerce performance while preserving broad multimodal capabilities. Furthermore, we propose a novel extensive evaluation suite covering deep product understanding, strict instruction following, and dynamic attribute extraction.",
      "source": "HuggingFace",
      "pubDateISO": "2026-02-12",
      "tags": [],
      "topics": [],
      "score": 5,
      "score_reason": "E-commerce adaptation",
      "citations": 0,
      "upvotes": 5,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.10229",
      "title": "Latent Thoughts Tuning: Bridging Context and Reasoning with Fused Information in Latent Tokens",
      "link": "https://huggingface.co/papers/2602.10229",
      "pdf_link": "https://arxiv.org/pdf/2602.10229.pdf",
      "authors": "Weihao Liu, Dehai Min, Lu Cheng",
      "institution": "",
      "abstract": "While explicit Chain-of-Thought (CoT) equips Large Language Models (LLMs) with strong reasoning capabilities, it requires models to verbalize every intermediate step in text tokens, constraining the model thoughts to the discrete vocabulary space. Recently, reasoning in continuous latent space has emerged as a promising alternative, enabling more robust inference and flexible computation beyond discrete token constraints. However, current latent paradigms often suffer from feature collapse and instability, stemming from distribution mismatches when recurrently using hidden states as the input embeddings, or alignment issues when relying on assistant models. To address this, we propose Latent Thoughts Tuning (LT-Tuning), a framework that redefines how latent thoughts are constructed and deployed. Instead of relying solely on raw hidden states, our method introduces a Context-Prediction-Fusion mechanism that jointly leveraging contextual hidden states and predictive semantic guidance from the vocabulary embedding space. Combined with a progressive three-stage curriculum learning pipeline, LT-Tuning also enables dynamically switching between latent and explicit thinking modes. Experiments demonstrate that our method outperforms existing latent reasoning baselines, effectively mitigating feature collapse and achieving robust reasoning accuracy.",
      "source": "HuggingFace",
      "pubDateISO": "2026-02-10",
      "tags": [],
      "topics": [],
      "score": 5,
      "score_reason": "Latent Thoughts",
      "citations": 0,
      "upvotes": 5,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.11541",
      "title": "Budget-Constrained Agentic Large Language Models: Intention-Based Planning for Costly Tool Use",
      "link": "https://huggingface.co/papers/2602.11541",
      "pdf_link": "https://arxiv.org/pdf/2602.11541.pdf",
      "authors": "Hanbing Liu, Chunhao Tian, Nan An, Ziyuan Wang, Pinyan Lu",
      "institution": "",
      "abstract": "We study budget-constrained tool-augmented agents, where a large language model must solve multi-step tasks by invoking external tools under a strict monetary budget. We formalize this setting as sequential decision making in context space with priced and stochastic tool executions, making direct planning intractable due to massive state-action spaces, high variance of outcomes and prohibitive exploration cost. To address these challenges, we propose INTENT, an inference-time planning framework that leverages an intention-aware hierarchical world model to anticipate future tool usage, risk-calibrated cost, and guide decisions online. Across cost-augmented StableToolBench, INTENT strictly enforces hard budget feasibility while substantially improving task success over baselines, and remains robust under dynamic market shifts such as tool price changes and varying budgets.",
      "source": "HuggingFace",
      "pubDateISO": "2026-02-12",
      "tags": [],
      "topics": [],
      "score": 5,
      "score_reason": "Budget Constraints",
      "citations": 0,
      "upvotes": 3,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.11636",
      "title": "ScalSelect: Scalable Training-Free Multimodal Data Selection for Efficient Visual Instruction Tuning",
      "link": "https://huggingface.co/papers/2602.11636",
      "pdf_link": "https://arxiv.org/pdf/2602.11636.pdf",
      "authors": "Changti Wu, Jiahuai Mao, Yuzhuo Miao, Shijie Lian, Bin Yu",
      "institution": "",
      "abstract": "Large-scale Visual Instruction Tuning (VIT) has become a key paradigm for advancing the performance of vision-language models (VLMs) across various multimodal tasks. However, training on the large-scale datasets is computationally expensive and inefficient due to redundancy in the data, which motivates the need for multimodal data selection to improve training efficiency. Existing data selection methods for VIT either require costly training or gradient computation. Training-free alternatives often depend on proxy models or datasets, instruction-agnostic representations, and pairwise similarity with quadratic complexity, limiting scalability and representation fidelity. In this work, we propose ScalSelect, a scalable training-free multimodal data selection method with linear-time complexity with respect to the number of samples, eliminating the need for external models or auxiliary datasets. ScalSelect first constructs sample representations by extracting visual features most attended by instruction tokens in the target VLM, capturing instruction-relevant information. It then identifies samples whose representations best approximate the dominant subspace of the full dataset representations, enabling scalable importance scoring without pairwise comparisons. Extensive experiments across multiple VLMs, datasets, and selection budgets demonstrate that ScalSelect achieves over 97.5% of the performance of training on the full dataset using only 16% of the data, and even outperforms full-data training in some settings. The code is available at https://github.com/ChangtiWu/ScalSelect{ScalSelect}.",
      "source": "HuggingFace",
      "pubDateISO": "2026-02-12",
      "tags": [],
      "topics": [],
      "score": 5,
      "score_reason": "Data selection method",
      "citations": 0,
      "upvotes": 2,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.09877",
      "title": "The Devil Behind Moltbook: Anthropic Safety is Always Vanishing in Self-Evolving AI Societies",
      "link": "https://huggingface.co/papers/2602.09877",
      "pdf_link": "https://arxiv.org/pdf/2602.09877.pdf",
      "authors": "Chenxu Wang, Chaozhuo Li, Songyang Liu, Zejian Chen, Jinyu Hou",
      "institution": "",
      "abstract": "The emergence of multi-agent systems built from large language models (LLMs) offers a promising paradigm for scalable collective intelligence and self-evolution. Ideally, such systems would achieve continuous self-improvement in a fully closed loop while maintaining robust safety alignment--a combination we term the self-evolution trilemma. However, we demonstrate both theoretically and empirically that an agent society satisfying continuous self-evolution, complete isolation, and safety invariance is impossible. Drawing on an information-theoretic framework, we formalize safety as the divergence degree from anthropic value distributions. We theoretically demonstrate that isolated self-evolution induces statistical blind spots, leading to the irreversible degradation of the system's safety alignment. Empirical and qualitative results from an open-ended agent community (Moltbook) and two closed self-evolving systems reveal phenomena that align with our theoretical prediction of inevitable safety erosion. We further propose several solution directions to alleviate the identified safety concern. Our work establishes a fundamental limit on the self-evolving AI societies and shifts the discourse from symptom-driven safety patches to a principled understanding of intrinsic dynamical risks, highlighting the need for external oversight or novel safety-preserving mechanisms.",
      "source": "HuggingFace",
      "pubDateISO": "2026-02-10",
      "tags": [],
      "topics": [],
      "score": 4,
      "score_reason": "Theoretical safety concern",
      "citations": 0,
      "upvotes": 165,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.10622",
      "title": "How Do Decoder-Only LLMs Perceive Users? Rethinking Attention Masking for User Representation Learning",
      "link": "https://huggingface.co/papers/2602.10622",
      "pdf_link": "https://arxiv.org/pdf/2602.10622.pdf",
      "authors": "Jiahao Yuan, Yike Xu, Jinyong Wen, Baokun Wang, Yang Chen",
      "institution": "",
      "abstract": "Decoder-only large language models are increasingly used as behavioral encoders for user representation learning, yet the impact of attention masking on the quality of user embeddings remains underexplored. In this work, we conduct a systematic study of causal, hybrid, and bidirectional attention masks within a unified contrastive learning framework trained on large-scale real-world Alipay data that integrates long-horizon heterogeneous user behaviors. To improve training dynamics when transitioning from causal to bidirectional attention, we propose Gradient-Guided Soft Masking, a gradient-based pre-warmup applied before a linear scheduler that gradually opens future attention during optimization. Evaluated on 9 industrial user cognition benchmarks covering prediction, preference, and marketing sensitivity tasks, our approach consistently yields more stable training and higher-quality bidirectional representations compared with causal, hybrid, and scheduler-only baselines, while remaining compatible with decoder pretraining. Overall, our findings highlight the importance of masking design and training transition in adapting decoder-only LLMs for effective user representation learning. Our code is available at https://github.com/JhCircle/Deepfind-GGSM.",
      "source": "HuggingFace",
      "pubDateISO": "2026-02-11",
      "tags": [],
      "topics": [],
      "score": 4,
      "score_reason": "User Representation",
      "citations": 0,
      "upvotes": 26,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.12280",
      "title": "Stroke of Surprise: Progressive Semantic Illusions in Vector Sketching",
      "link": "https://huggingface.co/papers/2602.12280",
      "pdf_link": "https://arxiv.org/pdf/2602.12280.pdf",
      "authors": "Huai-Hsun Cheng, Siang-Ling Zhang, Yu-Lun Liu",
      "institution": "",
      "abstract": "Visual illusions traditionally rely on spatial manipulations such as multi-view consistency. In this work, we introduce Progressive Semantic Illusions, a novel vector sketching task where a single sketch undergoes a dramatic semantic transformation through the sequential addition of strokes. We present Stroke of Surprise, a generative framework that optimizes vector strokes to satisfy distinct semantic interpretations at different drawing stages. The core challenge lies in the \"dual-constraint\": initial prefix strokes must form a coherent object (e.g., a duck) while simultaneously serving as the structural foundation for a second concept (e.g., a sheep) upon adding delta strokes. To address this, we propose a sequence-aware joint optimization framework driven by a dual-branch Score Distillation Sampling (SDS) mechanism. Unlike sequential approaches that freeze the initial state, our method dynamically adjusts prefix strokes to discover a \"common structural subspace\" valid for both targets. Furthermore, we introduce a novel Overlay Loss that enforces spatial complementarity, ensuring structural integration rather than occlusion. Extensive experiments demonstrate that our method significantly outperforms state-of-the-art baselines in recognizability and illusion strength, successfully expanding visual anagrams from the spatial to the temporal dimension. Project page: https://stroke-of-surprise.github.io/",
      "source": "HuggingFace",
      "pubDateISO": "2026-02-12",
      "tags": [],
      "topics": [],
      "score": 4,
      "score_reason": "Vector sketching illusion",
      "citations": 0,
      "upvotes": 21,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.12203",
      "title": "ExStrucTiny: A Benchmark for Schema-Variable Structured Information Extraction from Document Images",
      "link": "https://huggingface.co/papers/2602.12203",
      "pdf_link": "https://arxiv.org/pdf/2602.12203.pdf",
      "authors": "Mathieu Sibue, Andres Muñoz Garza, Samuel Mensah, Pranav Shetty, Zhiqiang Ma",
      "institution": "",
      "abstract": "Enterprise documents, such as forms and reports, embed critical information for downstream applications like data archiving, automated workflows, and analytics. Although generalist Vision Language Models (VLMs) perform well on established document understanding benchmarks, their ability to conduct holistic, fine-grained structured extraction across diverse document types and flexible schemas is not well studied. Existing Key Entity Extraction (KEE), Relation Extraction (RE), and Visual Question Answering (VQA) datasets are limited by narrow entity ontologies, simple queries, or homogeneous document types, often overlooking the need for adaptable and structured extraction. To address these gaps, we introduce ExStrucTiny, a new benchmark dataset for structured Information Extraction (IE) from document images, unifying aspects of KEE, RE, and VQA. Built through a novel pipeline combining manual and synthetic human-validated samples, ExStrucTiny covers more varied document types and extraction scenarios. We analyze open and closed VLMs on this benchmark, highlighting challenges such as schema adaptation, query under-specification, and answer localization. We hope our work provides a bedrock for improving generalist models for structured IE in documents.",
      "source": "HuggingFace",
      "pubDateISO": "2026-02-12",
      "tags": [],
      "topics": [],
      "score": 4,
      "score_reason": "Benchmark introduction",
      "citations": 0,
      "upvotes": 1,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.11792",
      "title": "Detecting RLVR Training Data via Structural Convergence of Reasoning",
      "link": "https://huggingface.co/papers/2602.11792",
      "pdf_link": "https://arxiv.org/pdf/2602.11792.pdf",
      "authors": "Hongbo Zhang, Yue Yang, Jianhao Yan, Guangsheng Bao, Yue Zhang",
      "institution": "",
      "abstract": "Reinforcement learning with verifiable rewards (RLVR) is central to training modern reasoning models, but the undisclosed training data raises concerns about benchmark contamination. Unlike pretraining methods, which optimize models using token-level probabilities, RLVR fine-tunes models based on reward feedback from self-generated reasoning trajectories, making conventional likelihood-based detection methods less effective. We show that RLVR induces a distinctive behavioral signature: prompts encountered during RLVR training result in more rigid and similar generations, while unseen prompts retain greater diversity. We introduce Min-kNN Distance, a simple black-box detector that quantifies this collapse by sampling multiple completions for a given prompt and computing the average of the k smallest nearest-neighbor edit distances. Min-kNN Distance requires no access to the reference model or token probabilities. Experiments across multiple RLVR-trained reasoning models show that Min-kNN Distance reliably distinguishes RL-seen examples from unseen ones and outperforms existing membership inference and RL contamination detection baselines.",
      "source": "HuggingFace",
      "pubDateISO": "2026-02-12",
      "tags": [],
      "topics": [],
      "score": 4,
      "score_reason": "Data detection method",
      "citations": 0,
      "upvotes": 1,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.12281v1",
      "title": "Scaling Verification Can Be More Effective than Scaling Policy Learning for Vision-Language-Action Alignment",
      "link": "http://arxiv.org/abs/2602.12281v1",
      "pdf_link": "https://arxiv.org/pdf/2602.12281v1",
      "authors": "Jacky Kwok, Xilun Zhang, Mengdi Xu, Yuejiang Liu, Azalia Mirhoseini et al.",
      "institution": "",
      "abstract": "The long-standing vision of general-purpose robots hinges on their ability to understand and act upon natural language instructions. Vision-Language-Action (VLA) models have made remarkable progress toward this goal, yet their generated actions can still misalign with the given instructions. In this paper, we investigate test-time verification as a means to shrink the \"intention-action gap.'' We first characterize the test-time scaling law for embodied instruction following and demonstrate that jointly scaling the number of rephrased instructions and generated actions greatly increases test-time sample diversity, often recovering correct actions more efficiently than scaling each dimension independently. To capitalize on these scaling laws, we present CoVer, a contrastive verifier for vision-language-action alignment, and show that our architecture scales gracefully with additional computational resources and data. We then introduce \"boot-time compute\" and a hierarchical verification inference pipeline for VLAs. At deployment, our framework precomputes a diverse set of rephrased instructions from a Vision-Language-Model (VLM), repeatedly generates action candidates for each instruction, and then uses a verifier to select the optimal high-level prompt and low-level action chunks. Compared to scaling policy pre-training on the same data, our verification approach yields 22% gains in-distribution and 13% out-of-distribution on the SIMPLER benchmark, with a further 45% improvement in real-world experiments. On the PolaRiS benchmark, CoVer achieves 14% gains in task progress and 9% in success rate.",
      "source": "arXiv",
      "pubDateISO": "2026-02-12",
      "tags": [
        "cs.RO",
        "cs.AI"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.12279v1",
      "title": "UniT: Unified Multimodal Chain-of-Thought Test-time Scaling",
      "link": "http://arxiv.org/abs/2602.12279v1",
      "pdf_link": "https://arxiv.org/pdf/2602.12279v1",
      "authors": "Leon Liangyu Chen, Haoyu Ma, Zhipeng Fan, Ziqi Huang, Animesh Sinha et al.",
      "institution": "",
      "abstract": "Unified models can handle both multimodal understanding and generation within a single architecture, yet they typically operate in a single pass without iteratively refining their outputs. Many multimodal tasks, especially those involving complex spatial compositions, multiple interacting objects, or evolving instructions, require decomposing instructions, verifying intermediate results, and making iterative corrections. While test-time scaling (TTS) has demonstrated that allocating additional inference compute for iterative reasoning substantially improves language model performance, extending this paradigm to unified multimodal models remains an open challenge. We introduce UniT, a framework for multimodal chain-of-thought test-time scaling that enables a single unified model to reason, verify, and refine across multiple rounds. UniT combines agentic data synthesis, unified model training, and flexible test-time inference to elicit cognitive behaviors including verification, subgoal decomposition, and content memory. Our key findings are: (1) unified models trained on short reasoning trajectories generalize to longer inference chains at test time; (2) sequential chain-of-thought reasoning provides a more scalable and compute-efficient TTS strategy than parallel sampling; (3) training on generation and editing trajectories improves out-of-distribution visual reasoning. These results establish multimodal test-time scaling as an effective paradigm for advancing both generation and understanding in unified models.",
      "source": "arXiv",
      "pubDateISO": "2026-02-12",
      "tags": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.12278v1",
      "title": "AttentionRetriever: Attention Layers are Secretly Long Document Retrievers",
      "link": "http://arxiv.org/abs/2602.12278v1",
      "pdf_link": "https://arxiv.org/pdf/2602.12278v1",
      "authors": "David Jiahao Fu, Lam Thanh Do, Jiayu Li, Kevin Chen-Chuan Chang",
      "institution": "",
      "abstract": "Retrieval augmented generation (RAG) has been widely adopted to help Large Language Models (LLMs) to process tasks involving long documents. However, existing retrieval models are not designed for long document retrieval and fail to address several key challenges of long document retrieval, including context-awareness, causal dependence, and scope of retrieval. In this paper, we proposed AttentionRetriever, a novel long document retrieval model that leverages attention mechanism and entity-based retrieval to build context-aware embeddings for long document and determine the scope of retrieval. With extensive experiments, we found AttentionRetriever is able to outperform existing retrieval models on long document retrieval datasets by a large margin while remaining as efficient as dense retrieval models.",
      "source": "arXiv",
      "pubDateISO": "2026-02-12",
      "tags": [
        "cs.IR",
        "cs.AI"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.12276v1",
      "title": "Agentic Test-Time Scaling for WebAgents",
      "link": "http://arxiv.org/abs/2602.12276v1",
      "pdf_link": "https://arxiv.org/pdf/2602.12276v1",
      "authors": "Nicholas Lee, Lutfi Eren Erdogan, Chris Joseph John, Surya Krishnapillai, Michael W. Mahoney et al.",
      "institution": "",
      "abstract": "Test-time scaling has become a standard way to improve performance and boost reliability of neural network models. However, its behavior on agentic, multi-step tasks remains less well-understood: small per-step errors can compound over long horizons; and we find that naive policies that uniformly increase sampling show diminishing returns. In this work, we present CATTS, a simple technique for dynamically allocating compute for multi-step agents. We first conduct an empirical study of inference-time scaling for web agents. We find that uniformly increasing per-step compute quickly saturates in long-horizon environments. We then investigate stronger aggregation strategies, including an LLM-based Arbiter that can outperform naive voting, but that can overrule high-consensus decisions. We show that uncertainty statistics derived from the agent's own vote distribution (entropy and top-1/top-2 margin) correlate with downstream success and provide a practical signal for dynamic compute allocation. Based on these findings, we introduce Confidence-Aware Test-Time Scaling (CATTS), which uses vote-derived uncertainty to allocate compute only when decisions are genuinely contentious. CATTS improves performance on WebArena-Lite and GoBrowse by up to 9.1% over React while using up to 2.3x fewer tokens than uniform scaling, providing both efficiency gains and an interpretable decision rule.",
      "source": "arXiv",
      "pubDateISO": "2026-02-12",
      "tags": [
        "cs.AI",
        "cs.CL"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.12275v1",
      "title": "On-Policy Context Distillation for Language Models",
      "link": "http://arxiv.org/abs/2602.12275v1",
      "pdf_link": "https://arxiv.org/pdf/2602.12275v1",
      "authors": "Tianzhu Ye, Li Dong, Xun Wu, Shaohan Huang, Furu Wei",
      "institution": "",
      "abstract": "Context distillation enables language models to internalize in-context knowledge into their parameters. In our work, we propose On-Policy Context Distillation (OPCD), a framework that bridges on-policy distillation with context distillation by training a student model on its own generated trajectories while minimizing reverse Kullback-Leibler divergence against a context-conditioned teacher. We demonstrate the effectiveness of OPCD on two important applications: experiential knowledge distillation, where models extract and consolidate transferable knowledge from their historical solution traces, and system prompt distillation, where models internalize beneficial behaviors encoded in optimized prompts. Across mathematical reasoning, text-based games, and domain-specific tasks, OPCD consistently outperforms baseline methods, achieving higher task accuracy while better preserving out-of-distribution capabilities. We further show that OPCD enables effective cross-size distillation, where smaller student models can internalize experiential knowledge from larger teachers.",
      "source": "arXiv",
      "pubDateISO": "2026-02-12",
      "tags": [
        "cs.CL"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.12274v1",
      "title": "Function-Space Decoupled Diffusion for Forward and Inverse Modeling in Carbon Capture and Storage",
      "link": "http://arxiv.org/abs/2602.12274v1",
      "pdf_link": "https://arxiv.org/pdf/2602.12274v1",
      "authors": "Xin Ju, Jiachen Yao, Anima Anandkumar, Sally M. Benson, Gege Wen",
      "institution": "",
      "abstract": "Accurate characterization of subsurface flow is critical for Carbon Capture and Storage (CCS) but remains challenged by the ill-posed nature of inverse problems with sparse observations. We present Fun-DDPS, a generative framework that combines function-space diffusion models with differentiable neural operator surrogates for both forward and inverse modeling. Our approach learns a prior distribution over geological parameters (geomodel) using a single-channel diffusion model, then leverages a Local Neural Operator (LNO) surrogate to provide physics-consistent guidance for cross-field conditioning on the dynamics field. This decoupling allows the diffusion prior to robustly recover missing information in parameter space, while the surrogate provides efficient gradient-based guidance for data assimilation. We demonstrate Fun-DDPS on synthetic CCS modeling datasets, achieving two key results: (1) For forward modeling with only 25% observations, Fun-DDPS achieves 7.7% relative error compared to 86.9% for standard surrogates (an 11x improvement), proving its capability to handle extreme data sparsity where deterministic methods fail. (2) We provide the first rigorous validation of diffusion-based inverse solvers against asymptotically exact Rejection Sampling (RS) posteriors. Both Fun-DDPS and the joint-state baseline (Fun-DPS) achieve Jensen-Shannon divergence less than 0.06 against the ground truth. Crucially, Fun-DDPS produces physically consistent realizations free from the high-frequency artifacts observed in joint-state baselines, achieving this with 4x improved sample efficiency compared to rejection sampling.",
      "source": "arXiv",
      "pubDateISO": "2026-02-12",
      "tags": [
        "cs.LG"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.12273v1",
      "title": "Learning to Control: The iUzawa-Net for Nonsmooth Optimal Control of Linear PDEs",
      "link": "http://arxiv.org/abs/2602.12273v1",
      "pdf_link": "https://arxiv.org/pdf/2602.12273v1",
      "authors": "Yongcun Song, Xiaoming Yuan, Hangrui Yue, Tianyou Zeng",
      "institution": "",
      "abstract": "We propose an optimization-informed deep neural network approach, named iUzawa-Net, aiming for the first solver that enables real-time solutions for a class of nonsmooth optimal control problems of linear partial differential equations (PDEs). The iUzawa-Net unrolls an inexact Uzawa method for saddle point problems, replacing classical preconditioners and PDE solvers with specifically designed learnable neural networks. We prove universal approximation properties and establish the asymptotic $\\varepsilon$-optimality for the iUzawa-Net, and validate its promising numerical efficiency through nonsmooth elliptic and parabolic optimal control problems. Our techniques offer a versatile framework for designing and analyzing various optimization-informed deep learning approaches to optimal control and other PDE-constrained optimization problems. The proposed learning-to-control approach synergizes model-based optimization algorithms and data-driven deep learning techniques, inheriting the merits of both methodologies.",
      "source": "arXiv",
      "pubDateISO": "2026-02-12",
      "tags": [
        "cs.LG"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.12271v1",
      "title": "MonarchRT: Efficient Attention for Real-Time Video Generation",
      "link": "http://arxiv.org/abs/2602.12271v1",
      "pdf_link": "https://arxiv.org/pdf/2602.12271v1",
      "authors": "Krish Agarwal, Zhuoming Chen, Cheng Luo, Yongqi Chen, Haizhong Zheng et al.",
      "institution": "",
      "abstract": "Real-time video generation with Diffusion Transformers is bottlenecked by the quadratic cost of 3D self-attention, especially in real-time regimes that are both few-step and autoregressive, where errors compound across time and each denoising step must carry substantially more information. In this setting, we find that prior sparse-attention approximations break down, despite showing strong results for bidirectional, many-step diffusion. Specifically, we observe that video attention is not reliably sparse, but instead combines pronounced periodic structure driven by spatiotemporal position with dynamic, sparse semantic correspondences and dense mixing, exceeding the representational capacity of even oracle top-k attention. Building on this insight, we propose Monarch-RT, a structured attention parameterization for video diffusion models that factorizes attention using Monarch matrices. Through appropriately aligned block structure and our extended tiled Monarch parameterization, we achieve high expressivity while preserving computational efficiency. We further overcome the overhead of parameterization through finetuning, with custom Triton kernels. We first validate the high efficacy of Monarch-RT over existing sparse baselines designed only for bidirectional models. We further observe that Monarch-RT attains up to 95% attention sparsity with no loss in quality when applied to the state-of-the-art model Self-Forcing, making Monarch-RT a pioneering work on highly-capable sparse attention parameterization for real-time video generation. Our optimized implementation outperforms FlashAttention-2, FlashAttention-3, and FlashAttention-4 kernels on Nvidia RTX 5090, H100, and B200 GPUs respectively, providing kernel speedups in the range of 1.4-11.8X. This enables us, for the first time, to achieve true real-time video generation with Self-Forcing at 16 FPS on a single RTX 5090.",
      "source": "arXiv",
      "pubDateISO": "2026-02-12",
      "tags": [
        "cs.CV",
        "cs.LG"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.12270v1",
      "title": "Creative Ownership in the Age of AI",
      "link": "http://arxiv.org/abs/2602.12270v1",
      "pdf_link": "https://arxiv.org/pdf/2602.12270v1",
      "authors": "Annie Liang, Jay Lu",
      "institution": "",
      "abstract": "Copyright law focuses on whether a new work is \"substantially similar\" to an existing one, but generative AI can closely imitate style without copying content, a capability now central to ongoing litigation. We argue that existing definitions of infringement are ill-suited to this setting and propose a new criterion: a generative AI output infringes on an existing work if it could not have been generated without that work in its training corpus. To operationalize this definition, we model generative systems as closure operators mapping a corpus of existing works to an output of new works. AI generated outputs are \\emph{permissible} if they do not infringe on any existing work according to our criterion. Our results characterize structural properties of permissible generation and reveal a sharp asymptotic dichotomy: when the process of organic creations is light-tailed, dependence on individual works eventually vanishes, so that regulation imposes no limits on AI generation; with heavy-tailed creations, regulation can be persistently constraining.",
      "source": "arXiv",
      "pubDateISO": "2026-02-12",
      "tags": [
        "cs.AI",
        "cs.GT"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.12268v1",
      "title": "CM2: Reinforcement Learning with Checklist Rewards for Multi-Turn and Multi-Step Agentic Tool Use",
      "link": "http://arxiv.org/abs/2602.12268v1",
      "pdf_link": "https://arxiv.org/pdf/2602.12268v1",
      "authors": "Zhen Zhang, Kaiqiang Song, Xun Wang, Yebowen Hu, Weixiang Yan et al.",
      "institution": "",
      "abstract": "AI agents are increasingly used to solve real-world tasks by reasoning over multi-turn user interactions and invoking external tools. However, applying reinforcement learning to such settings remains difficult: realistic objectives often lack verifiable rewards and instead emphasize open-ended behaviors; moreover, RL for multi-turn, multi-step agentic tool use is still underexplored; and building and maintaining executable tool environments is costly, limiting scale and coverage. We propose CM2, an RL framework that replaces verifiable outcome rewards with checklist rewards. CM2 decomposes each turn's intended behavior into fine-grained binary criteria with explicit evidence grounding and structured metadata, turning open-ended judging into more stable classification-style decisions. To balance stability and informativeness, our method adopts a strategy of sparse reward assignment but dense evaluation criteria. Training is performed in a scalable LLM-simulated tool environment, avoiding heavy engineering for large tool sets. Experiments show that CM2 consistently improves over supervised fine-tuning. Starting from an 8B Base model and training on an 8k-example RL dataset, CM2 improves over the SFT counterpart by 8 points on tau^-Bench, by 10 points on BFCL-V4, and by 12 points on ToolSandbox. The results match or even outperform similarly sized open-source baselines, including the judging model. CM2 thus provides a scalable recipe for optimizing multi-turn, multi-step tool-using agents without relying on verifiable rewards. Code provided by the open-source community: https://github.com/namezhenzhang/CM2-RLCR-Tool-Agent.",
      "source": "arXiv",
      "pubDateISO": "2026-02-12",
      "tags": [
        "cs.AI"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.12267v1",
      "title": "Self-Supervised Learning via Flow-Guided Neural Operator on Time-Series Data",
      "link": "http://arxiv.org/abs/2602.12267v1",
      "pdf_link": "https://arxiv.org/pdf/2602.12267v1",
      "authors": "Duy Nguyen, Jiachen Yao, Jiayun Wang, Julius Berner, Animashree Anandkumar",
      "institution": "",
      "abstract": "Self-supervised learning (SSL) is a powerful paradigm for learning from unlabeled time-series data. However, popular methods such as masked autoencoders (MAEs) rely on reconstructing inputs from a fixed, predetermined masking ratio. Instead of this static design, we propose treating the corruption level as a new degree of freedom for representation learning, enhancing flexibility and performance. To achieve this, we introduce the Flow-Guided Neural Operator (FGNO), a novel framework combining operator learning with flow matching for SSL training. FGNO learns mappings in functional spaces by using Short-Time Fourier Transform to unify different time resolutions. We extract a rich hierarchy of features by tapping into different network layers and flow times that apply varying strengths of noise to the input data. This enables the extraction of versatile representations, from low-level patterns to high-level global features, using a single model adaptable to specific tasks. Unlike prior generative SSL methods that use noisy inputs during inference, we propose using clean inputs for representation extraction while learning representations with noise; this eliminates randomness and boosts accuracy. We evaluate FGNO across three biomedical domains, where it consistently outperforms established baselines. Our method yields up to 35% AUROC gains in neural signal decoding (BrainTreeBank), 16% RMSE reductions in skin temperature prediction (DREAMT), and over 20% improvement in accuracy and macro-F1 on SleepEDF under low-data regimes. These results highlight FGNO's robustness to data scarcity and its superior capacity to learn expressive representations for diverse time series.",
      "source": "arXiv",
      "pubDateISO": "2026-02-12",
      "tags": [
        "cs.LG"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.12259v1",
      "title": "Think like a Scientist: Physics-guided LLM Agent for Equation Discovery",
      "link": "http://arxiv.org/abs/2602.12259v1",
      "pdf_link": "https://arxiv.org/pdf/2602.12259v1",
      "authors": "Jianke Yang, Ohm Venkatachalam, Mohammad Kianezhad, Sharvaree Vadgama, Rose Yu",
      "institution": "",
      "abstract": "Explaining observed phenomena through symbolic, interpretable formulas is a fundamental goal of science. Recently, large language models (LLMs) have emerged as promising tools for symbolic equation discovery, owing to their broad domain knowledge and strong reasoning capabilities. However, most existing LLM-based systems try to guess equations directly from data, without modeling the multi-step reasoning process that scientists often follow: first inferring physical properties such as symmetries, then using these as priors to restrict the space of candidate equations. We introduce KeplerAgent, an agentic framework that explicitly follows this scientific reasoning process. The agent coordinates physics-based tools to extract intermediate structure and uses these results to configure symbolic regression engines such as PySINDy and PySR, including their function libraries and structural constraints. Across a suite of physical equation benchmarks, KeplerAgent achieves substantially higher symbolic accuracy and greater robustness to noisy data than both LLM and traditional baselines.",
      "source": "arXiv",
      "pubDateISO": "2026-02-12",
      "tags": [
        "cs.AI",
        "cs.LG"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.12257v1",
      "title": "On the implicit regularization of Langevin dynamics with projected noise",
      "link": "http://arxiv.org/abs/2602.12257v1",
      "pdf_link": "https://arxiv.org/pdf/2602.12257v1",
      "authors": "Govind Menon, Austin J. Stromme, Adrien Vacher",
      "institution": "",
      "abstract": "We study Langevin dynamics with noise projected onto the directions orthogonal to an isometric group action. This mathematical model is introduced to shed new light on the effects of symmetry on stochastic gradient descent for over-parametrized models. Our main result identifies a novel form of implicit regularization: when the initial and target density are both invariant under the group action, Langevin dynamics with projected noise is equivalent in law to Langevin dynamics with isotropic diffusion but with an additional drift term proportional to the negative log volume of the group orbit. We prove this result by constructing a coupling of the two processes via a third process on the group itself, and identify the additional drift as the mean curvature of the orbits.",
      "source": "arXiv",
      "pubDateISO": "2026-02-12",
      "tags": [
        "cs.AI"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.12253v1",
      "title": "Is Online Linear Optimization Sufficient for Strategic Robustness?",
      "link": "http://arxiv.org/abs/2602.12253v1",
      "pdf_link": "https://arxiv.org/pdf/2602.12253v1",
      "authors": "Yang Cai, Haipeng Luo, Chen-Yu Wei, Weiqiang Zheng",
      "institution": "",
      "abstract": "We consider bidding in repeated Bayesian first-price auctions. Bidding algorithms that achieve optimal regret have been extensively studied, but their strategic robustness to the seller's manipulation remains relatively underexplored. Bidding algorithms based on no-swap-regret algorithms achieve both desirable properties, but are suboptimal in terms of statistical and computational efficiency. In contrast, online gradient ascent is the only algorithm that achieves $O(\\sqrt{TK})$ regret and strategic robustness [KSS24], where $T$ denotes the number of auctions and $K$ the number of bids.\n  In this paper, we explore whether simple online linear optimization (OLO) algorithms suffice for bidding algorithms with both desirable properties. Our main result shows that sublinear linearized regret is sufficient for strategic robustness. Specifically, we construct simple black-box reductions that convert any OLO algorithm into a strategically robust no-regret bidding algorithm, in both known and unknown value distribution settings. For the known value distribution case, our reduction yields a bidding algorithm that achieves $O(\\sqrt{T \\log K})$ regret and strategic robustness (with exponential improvement on the $K$-dependence compared to [KSS24]). For the unknown value distribution case, our reduction gives a bidding algorithm with high-probability $O(\\sqrt{T (\\log K+\\log(T/δ)})$ regret and strategic robustness, while removing the bounded density assumption made in [KSS24].",
      "source": "arXiv",
      "pubDateISO": "2026-02-12",
      "tags": [
        "cs.GT",
        "cs.LG"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.12251v1",
      "title": "A technical curriculum on language-oriented artificial intelligence in translation and specialised communication",
      "link": "http://arxiv.org/abs/2602.12251v1",
      "pdf_link": "https://arxiv.org/pdf/2602.12251v1",
      "authors": "Ralph Krüger",
      "institution": "",
      "abstract": "This paper presents a technical curriculum on language-oriented artificial intelligence (AI) in the language and translation (L&T) industry. The curriculum aims to foster domain-specific technical AI literacy among stakeholders in the fields of translation and specialised communication by exposing them to the conceptual and technical/algorithmic foundations of modern language-oriented AI in an accessible way. The core curriculum focuses on 1) vector embeddings, 2) the technical foundations of neural networks, 3) tokenization and 4) transformer neural networks. It is intended to help users develop computational thinking as well as algorithmic awareness and algorithmic agency, ultimately contributing to their digital resilience in AI-driven work environments. The didactic suitability of the curriculum was tested in an AI-focused MA course at the Institute of Translation and Multilingual Communication at TH Koeln. Results suggest the didactic effectiveness of the curriculum, but participant feedback indicates that it should be embedded into higher-level didactic scaffolding - e.g., in the form of lecturer support - in order to enable optimal learning conditions.",
      "source": "arXiv",
      "pubDateISO": "2026-02-12",
      "tags": [
        "cs.CL",
        "cs.AI",
        "cs.HC"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.12250v1",
      "title": "Community Concealment from Unsupervised Graph Learning-Based Clustering",
      "link": "http://arxiv.org/abs/2602.12250v1",
      "pdf_link": "https://arxiv.org/pdf/2602.12250v1",
      "authors": "Dalyapraz Manatova, Pablo Moriano, L. Jean Camp",
      "institution": "",
      "abstract": "Graph neural networks (GNNs) are designed to use attributed graphs to learn representations. Such representations are beneficial in the unsupervised learning of clusters and community detection. Nonetheless, such inference may reveal sensitive groups, clustered systems, or collective behaviors, raising concerns regarding group-level privacy. Community attribution in social and critical infrastructure networks, for example, can expose coordinated asset groups, operational hierarchies, and system dependencies that could be used for profiling or intelligence gathering. We study a defensive setting in which a data publisher (defender) seeks to conceal a community of interest while making limited, utility-aware changes in the network. Our analysis indicates that community concealment is strongly influenced by two quantifiable factors: connectivity at the community boundary and feature similarity between the protected community and adjacent communities. Informed by these findings, we present a perturbation strategy that rewires a set of selected edges and modifies node features to reduce the distinctiveness leveraged by GNN message passing. The proposed method outperforms DICE in our experiments on synthetic benchmarks and real network graphs under identical perturbation budgets. Overall, it achieves median relative concealment improvements of approximately 20-45% across the evaluated settings. These findings demonstrate a mitigation strategy against GNN-based community learning and highlight group-level privacy risks intrinsic to graph learning.",
      "source": "arXiv",
      "pubDateISO": "2026-02-12",
      "tags": [
        "cs.LG",
        "cs.CR",
        "cs.SI"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.12249v1",
      "title": "\"Sorry, I Didn't Catch That\": How Speech Models Miss What Matters Most",
      "link": "http://arxiv.org/abs/2602.12249v1",
      "pdf_link": "https://arxiv.org/pdf/2602.12249v1",
      "authors": "Kaitlyn Zhou, Martijn Bartelds, Federico Bianchi, James Zou",
      "institution": "",
      "abstract": "Despite speech recognition systems achieving low word error rates on standard benchmarks, they often fail on short, high-stakes utterances in real-world deployments. Here, we study this failure mode in a high-stakes task: the transcription of U.S. street names as spoken by U.S. participants. We evaluate 15 models from OpenAI, Deepgram, Google, and Microsoft on recordings from linguistically diverse U.S. speakers and find an average transcription error rate of 44%. We quantify the downstream impact of failed transcriptions by geographic locations and show that mis-transcriptions systematically cause errors for all speakers, but that routing distance errors are twice as large for non-English primary speakers compared to English primary speakers. To mitigate this harm, we introduce a synthetic data generation approach that produces diverse pronunciations of named entities using open-source text-to-speech models. Fine-tuning with less than 1,000 synthetic samples improves street name transcription accuracy by nearly 60% (relative to base models) for non-English primary speakers. Our results highlight a critical gap between benchmark performance and real-world reliability in speech systems and demonstrate a simple, scalable path to reducing high-stakes transcription errors.",
      "source": "arXiv",
      "pubDateISO": "2026-02-12",
      "tags": [
        "cs.AI",
        "cs.CL",
        "cs.CY"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.12247v1",
      "title": "ExtractBench: A Benchmark and Evaluation Methodology for Complex Structured Extraction",
      "link": "http://arxiv.org/abs/2602.12247v1",
      "pdf_link": "https://arxiv.org/pdf/2602.12247v1",
      "authors": "Nick Ferguson, Josh Pennington, Narek Beghian, Aravind Mohan, Douwe Kiela et al.",
      "institution": "",
      "abstract": "Unstructured documents like PDFs contain valuable structured information, but downstream systems require this data in reliable, standardized formats. LLMs are increasingly deployed to automate this extraction, making accuracy and reliability paramount. However, progress is bottlenecked by two gaps. First, no end-to-end benchmark evaluates PDF-to-JSON extraction under enterprise-scale schema breadth. Second, no principled methodology captures the semantics of nested extraction, where fields demand different notions of correctness (exact match for identifiers, tolerance for quantities, semantic equivalence for names), arrays require alignment, and omission must be distinguished from hallucination. We address both gaps with ExtractBench, an open-source benchmark and evaluation framework for PDF-to-JSON structured extraction. The benchmark pairs 35 PDF documents with JSON Schemas and human-annotated gold labels across economically valuable domains, yielding 12,867 evaluatable fields spanning schema complexities from tens to hundreds of fields. The evaluation framework treats the schema as an executable specification: each field declares its scoring metric. Baseline evaluations reveal that frontier models (GPT-5/5.2, Gemini-3 Flash/Pro, Claude 4.5 Opus/Sonnet) remain unreliable on realistic schemas. Performance degrades sharply with schema breadth, culminating in 0% valid output on a 369-field financial reporting schema across all tested models. We release ExtractBench at https://github.com/ContextualAI/extract-bench.",
      "source": "arXiv",
      "pubDateISO": "2026-02-12",
      "tags": [
        "cs.LG",
        "cs.AI"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.12245v1",
      "title": "Intrinsic-Energy Joint Embedding Predictive Architectures Induce Quasimetric Spaces",
      "link": "http://arxiv.org/abs/2602.12245v1",
      "pdf_link": "https://arxiv.org/pdf/2602.12245v1",
      "authors": "Anthony Kobanda, Waris Radji",
      "institution": "",
      "abstract": "Joint-Embedding Predictive Architectures (JEPAs) aim to learn representations by predicting target embeddings from context embeddings, inducing a scalar compatibility energy in a latent space. In contrast, Quasimetric Reinforcement Learning (QRL) studies goal-conditioned control through directed distance values (cost-to-go) that support reaching goals under asymmetric dynamics. In this short article, we connect these viewpoints by restricting attention to a principled class of JEPA energy functions : intrinsic (least-action) energies, defined as infima of accumulated local effort over admissible trajectories between two states. Under mild closure and additivity assumptions, any intrinsic energy is a quasimetric. In goal-reaching control, optimal cost-to-go functions admit exactly this intrinsic form ; inversely, JEPAs trained to model intrinsic energies lie in the quasimetric value class targeted by QRL. Moreover, we observe why symmetric finite energies are structurally mismatched with one-way reachability, motivating asymmetric (quasimetric) energies when directionality matters.",
      "source": "arXiv",
      "pubDateISO": "2026-02-12",
      "tags": [
        "cs.LG",
        "cs.AI"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.12241v1",
      "title": "Moonshine v2: Ergodic Streaming Encoder ASR for Latency-Critical Speech Applications",
      "link": "http://arxiv.org/abs/2602.12241v1",
      "pdf_link": "https://arxiv.org/pdf/2602.12241v1",
      "authors": "Manjunath Kudlur, Evan King, James Wang, Pete Warden",
      "institution": "",
      "abstract": "Latency-critical speech applications (e.g., live transcription, voice commands, and real-time translation) demand low time-to-first-token (TTFT) and high transcription accuracy, particularly on resource-constrained edge devices. Full-attention Transformer encoders remain a strong accuracy baseline for automatic speech recognition (ASR) because every frame can directly attend to every other frame, which resolves otherwise locally ambiguous acoustics using distant lexical context. However, this global dependency incurs quadratic complexity in sequence length, inducing an inherent \"encode-the-whole-utterance\" latency profile. For streaming use cases, this causes TTFT to grow linearly with utterance length as the encoder must process the entire prefix before any decoder token can be emitted. To better meet the needs of on-device, streaming ASR use cases we introduce Moonshine v2, an ergodic streaming-encoder ASR model that employs sliding-window self-attention to achieve bounded, low-latency inference while preserving strong local context. Our models achieve state of the art word error rates across standard benchmarks, attaining accuracy on-par with models 6x their size while running significantly faster. These results demonstrate that carefully designed local attention is competitive with the accuracy of full attention at a fraction of the size and latency cost, opening new possibilities for interactive speech interfaces on edge devices.",
      "source": "arXiv",
      "pubDateISO": "2026-02-12",
      "tags": [
        "cs.CL",
        "cs.LG",
        "cs.SD"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.12237v1",
      "title": "Olmix: A Framework for Data Mixing Throughout LM Development",
      "link": "http://arxiv.org/abs/2602.12237v1",
      "pdf_link": "https://arxiv.org/pdf/2602.12237v1",
      "authors": "Mayee F. Chen, Tyler Murray, David Heineman, Matt Jordan, Hannaneh Hajishirzi et al.",
      "institution": "",
      "abstract": "Data mixing -- determining the ratios of data from different domains -- is a first-order concern for training language models (LMs). While existing mixing methods show promise, they fall short when applied during real-world LM development. We present Olmix, a framework that addresses two such challenges. First, the configuration space for developing a mixing method is not well understood -- design choices across existing methods lack justification or consensus and overlook practical issues like data constraints. We conduct a comprehensive empirical study of this space, identifying which design choices lead to a strong mixing method. Second, in practice, the domain set evolves throughout LM development as datasets are added, removed, partitioned, and revised -- a problem setting largely unaddressed by existing works, which assume fixed domains. We study how to efficiently recompute the mixture after the domain set is updated, leveraging information from past mixtures. We introduce mixture reuse, a mechanism that reuses existing ratios and recomputes ratios only for domains affected by the update. Over a sequence of five domain-set updates mirroring real-world LM development, mixture reuse matches the performance of fully recomputing the mix after each update with 74% less compute and improves over training without mixing by 11.6% on downstream tasks.",
      "source": "arXiv",
      "pubDateISO": "2026-02-12",
      "tags": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.12236v1",
      "title": "Energy-Aware Spike Budgeting for Continual Learning in Spiking Neural Networks for Neuromorphic Vision",
      "link": "http://arxiv.org/abs/2602.12236v1",
      "pdf_link": "https://arxiv.org/pdf/2602.12236v1",
      "authors": "Anika Tabassum Meem, Muntasir Hossain Nadid, Md Zesun Ahmed Mia",
      "institution": "",
      "abstract": "Neuromorphic vision systems based on spiking neural networks (SNNs) offer ultra-low-power perception for event-based and frame-based cameras, yet catastrophic forgetting remains a critical barrier to deployment in continually evolving environments. Existing continual learning methods, developed primarily for artificial neural networks, seldom jointly optimize accuracy and energy efficiency, with particularly limited exploration on event-based datasets. We propose an energy-aware spike budgeting framework for continual SNN learning that integrates experience replay, learnable leaky integrate-and-fire neuron parameters, and an adaptive spike scheduler to enforce dataset-specific energy constraints during training. Our approach exhibits modality-dependent behavior: on frame-based datasets (MNIST, CIFAR-10), spike budgeting acts as a sparsity-inducing regularizer, improving accuracy while reducing spike rates by up to 47\\%; on event-based datasets (DVS-Gesture, N-MNIST, CIFAR-10-DVS), controlled budget relaxation enables accuracy gains up to 17.45 percentage points with minimal computational overhead. Across five benchmarks spanning both modalities, our method demonstrates consistent performance improvements while minimizing dynamic power consumption, advancing the practical viability of continual learning in neuromorphic vision systems.",
      "source": "arXiv",
      "pubDateISO": "2026-02-12",
      "tags": [
        "cs.NE",
        "cs.AI",
        "cs.CV"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.12235v1",
      "title": "Detecting Overflow in Compressed Token Representations for Retrieval-Augmented Generation",
      "link": "http://arxiv.org/abs/2602.12235v1",
      "pdf_link": "https://arxiv.org/pdf/2602.12235v1",
      "authors": "Julia Belikova, Danila Rozhevskii, Dennis Svirin, Konstantin Polev, Alexander Panchenko",
      "institution": "",
      "abstract": "Efficient long-context processing remains a crucial challenge for contemporary large language models (LLMs), especially in resource-constrained environments. Soft compression architectures promise to extend effective context length by replacing long token sequences with smaller sets of learned compressed tokens. Yet, the limits of compressibility -- and when compression begins to erase task-relevant content -- remain underexplored. In this paper, we define \\emph{token overflow} as a regime in which compressed representations no longer contain sufficient information to answer a given query, and propose a methodology to characterize and detect it. In the xRAG soft-compression setting, we find that query-agnostic saturation statistics reliably separate compressed from uncompressed token representations, providing a practical tool for identifying compressed tokens but showing limited overflow detection capability. Lightweight probing classifiers over both query and context xRAG representations detect overflow with 0.72 AUC-ROC on average on HotpotQA, SQuADv2, and TriviaQA datasets, demonstrating that incorporating query information improves detection performance. These results advance from query-independent diagnostics to query-aware detectors, enabling low-cost pre-LLM gating to mitigate compression-induced errors.",
      "source": "arXiv",
      "pubDateISO": "2026-02-12",
      "tags": [
        "cs.CL"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.12233v1",
      "title": "Categorical Flow Maps",
      "link": "http://arxiv.org/abs/2602.12233v1",
      "pdf_link": "https://arxiv.org/pdf/2602.12233v1",
      "authors": "Daan Roos, Oscar Davis, Floor Eijkelboom, Michael Bronstein, Max Welling et al.",
      "institution": "",
      "abstract": "We introduce Categorical Flow Maps, a flow-matching method for accelerated few-step generation of categorical data via self-distillation. Building on recent variational formulations of flow matching and the broader trend towards accelerated inference in diffusion and flow-based models, we define a flow map towards the simplex that transports probability mass toward a predicted endpoint, yielding a parametrisation that naturally constrains model predictions. Since our trajectories are continuous rather than discrete, Categorical Flow Maps can be trained with existing distillation techniques, as well as a new objective based on endpoint consistency. This continuous formulation also automatically unlocks test-time inference: we can directly reuse existing guidance and reweighting techniques in the categorical setting to steer sampling toward downstream objectives. Empirically, we achieve state-of-the-art few-step results on images, molecular graphs, and text, with strong performance even in single-step generation.",
      "source": "arXiv",
      "pubDateISO": "2026-02-12",
      "tags": [
        "cs.LG"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.12229v1",
      "title": "Diffusion Alignment Beyond KL: Variance Minimisation as Effective Policy Optimiser",
      "link": "http://arxiv.org/abs/2602.12229v1",
      "pdf_link": "https://arxiv.org/pdf/2602.12229v1",
      "authors": "Zijing Ou, Jacob Si, Junyi Zhu, Ondrej Bohdal, Mete Ozay et al.",
      "institution": "",
      "abstract": "Diffusion alignment adapts pretrained diffusion models to sample from reward-tilted distributions along the denoising trajectory. This process naturally admits a Sequential Monte Carlo (SMC) interpretation, where the denoising model acts as a proposal and reward guidance induces importance weights. Motivated by this view, we introduce Variance Minimisation Policy Optimisation (VMPO), which formulates diffusion alignment as minimising the variance of log importance weights rather than directly optimising a Kullback-Leibler (KL) based objective. We prove that the variance objective is minimised by the reward-tilted target distribution and that, under on-policy sampling, its gradient coincides with that of standard KL-based alignment. This perspective offers a common lens for understanding diffusion alignment. Under different choices of potential functions and variance minimisation strategies, VMPO recovers various existing methods, while also suggesting new design directions beyond KL.",
      "source": "arXiv",
      "pubDateISO": "2026-02-12",
      "tags": [
        "cs.LG"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.12224v1",
      "title": "Bandit Learning in Matching Markets with Interviews",
      "link": "http://arxiv.org/abs/2602.12224v1",
      "pdf_link": "https://arxiv.org/pdf/2602.12224v1",
      "authors": "Amirmahdi Mirfakhar, Xuchuang Wang, Mengfan Xu, Hedyeh Beyhaghi, Mohammad Hajiesmaili",
      "institution": "",
      "abstract": "Two-sided matching markets rely on preferences from both sides, yet it is often impractical to evaluate preferences. Participants, therefore, conduct a limited number of interviews, which provide early, noisy impressions and shape final decisions. We study bandit learning in matching markets with interviews, modeling interviews as \\textit{low-cost hints} that reveal partial preference information to both sides. Our framework departs from existing work by allowing firm-side uncertainty: firms, like agents, may be unsure of their own preferences and can make early hiring mistakes by hiring less preferred agents. To handle this, we extend the firm's action space to allow \\emph{strategic deferral} (choosing not to hire in a round), enabling recovery from suboptimal hires and supporting decentralized learning without coordination. We design novel algorithms for (i) a centralized setting with an omniscient interview allocator and (ii) decentralized settings with two types of firm-side feedback. Across all settings, our algorithms achieve time-independent regret, a substantial improvement over the $O(\\log T)$ regret bounds known for learning stable matchings without interviews. Also, under mild structured markets, decentralized performance matches the centralized counterpart up to polynomial factors in the number of agents and firms.",
      "source": "arXiv",
      "pubDateISO": "2026-02-12",
      "tags": [
        "cs.GT",
        "cs.AI"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.12222v1",
      "title": "Towards On-Policy SFT: Distribution Discriminant Theory and its Applications in LLM Training",
      "link": "http://arxiv.org/abs/2602.12222v1",
      "pdf_link": "https://arxiv.org/pdf/2602.12222v1",
      "authors": "Miaosen Zhang, Yishan Liu, Shuxia Lin, Xu Yang, Qi Dai et al.",
      "institution": "",
      "abstract": "Supervised fine-tuning (SFT) is computationally efficient but often yields inferior generalization compared to reinforcement learning (RL). This gap is primarily driven by RL's use of on-policy data. We propose a framework to bridge this chasm by enabling On-Policy SFT. We first present \\textbf{\\textit{Distribution Discriminant Theory (DDT)}}, which explains and quantifies the alignment between data and the model-induced distribution. Leveraging DDT, we introduce two complementary techniques: (i) \\textbf{\\textit{In-Distribution Finetuning (IDFT)}}, a loss-level method to enhance generalization ability of SFT, and (ii) \\textbf{\\textit{Hinted Decoding}}, a data-level technique that can re-align the training corpus to the model's distribution. Extensive experiments demonstrate that our framework achieves generalization performance on par with prominent offline RL algorithms, including DPO and SimPO, while maintaining the efficiency of an SFT pipeline. The proposed framework thus offers a practical alternative in domains where RL is infeasible. We open-source the code here: https://github.com/zhangmiaosen2000/Towards-On-Policy-SFT",
      "source": "arXiv",
      "pubDateISO": "2026-02-12",
      "tags": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.12221v1",
      "title": "Best of Both Worlds: Multimodal Reasoning and Generation via Unified Discrete Flow Matching",
      "link": "http://arxiv.org/abs/2602.12221v1",
      "pdf_link": "https://arxiv.org/pdf/2602.12221v1",
      "authors": "Onkar Susladkar, Tushar Prakash, Gayatri Deshmukh, Kiet A. Nguyen, Jiaxun Zhang et al.",
      "institution": "",
      "abstract": "We propose UniDFlow, a unified discrete flow-matching framework for multimodal understanding, generation, and editing. It decouples understanding and generation via task-specific low-rank adapters, avoiding objective interference and representation entanglement, while a novel reference-based multimodal preference alignment optimizes relative outcomes under identical conditioning, improving faithfulness and controllability without large-scale retraining. UniDFlpw achieves SOTA performance across eight benchmarks and exhibits strong zero-shot generalization to tasks including inpainting, in-context image generation, reference-based editing, and compositional generation, despite no explicit task-specific training.",
      "source": "arXiv",
      "pubDateISO": "2026-02-12",
      "tags": [
        "cs.CV"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.12218v1",
      "title": "The Observer Effect in World Models: Invasive Adaptation Corrupts Latent Physics",
      "link": "http://arxiv.org/abs/2602.12218v1",
      "pdf_link": "https://arxiv.org/pdf/2602.12218v1",
      "authors": "Christian Internò, Jumpei Yamaguchi, Loren Amdahl-Culleton, Markus Olhofer, David Klindt et al.",
      "institution": "",
      "abstract": "Determining whether neural models internalize physical laws as world models, rather than exploiting statistical shortcuts, remains challenging, especially under out-of-distribution (OOD) shifts. Standard evaluations often test latent capability via downstream adaptation (e.g., fine-tuning or high-capacity probes), but such interventions can change the representations being measured and thus confound what was learned during self-supervised learning (SSL). We propose a non-invasive evaluation protocol, PhyIP. We test whether physical quantities are linearly decodable from frozen representations, motivated by the linear representation hypothesis. Across fluid dynamics and orbital mechanics, we find that when SSL achieves low error, latent structure becomes linearly accessible. PhyIP recovers internal energy and Newtonian inverse-square scaling on OOD tests (e.g., $ρ> 0.90$). In contrast, adaptation-based evaluations can collapse this structure ($ρ\\approx 0.05$). These findings suggest that adaptation-based evaluation can obscure latent structures and that low-capacity probes offer a more accurate evaluation of physical world models.",
      "source": "arXiv",
      "pubDateISO": "2026-02-12",
      "tags": [
        "cs.LG",
        "cs.AI"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.12207v1",
      "title": "VIRENA: Virtual Arena for Research, Education, and Democratic Innovation",
      "link": "http://arxiv.org/abs/2602.12207v1",
      "pdf_link": "https://arxiv.org/pdf/2602.12207v1",
      "authors": "Emma Hoes, K. Jonathan Klueser, Fabrizio Gilardi",
      "institution": "",
      "abstract": "Digital platforms shape how people communicate, deliberate, and form opinions. Studying these dynamics has become increasingly difficult due to restricted data access, ethical constraints on real-world experiments, and limitations of existing research tools. VIRENA (Virtual Arena) is a platform that enables controlled experimentation in realistic social media environments. Multiple participants interact simultaneously in realistic replicas of feed-based platforms (Instagram, Facebook, Reddit) and messaging apps (WhatsApp, Messenger). Large language model-powered AI agents participate alongside humans with configurable personas and realistic behavior. Researchers can manipulate content moderation approaches, pre-schedule stimulus content, and run experiments across conditions through a visual interface requiring no programming skills. VIRENA makes possible research designs that were previously impractical: studying human--AI interaction in realistic social contexts, experimentally comparing moderation interventions, and observing group deliberation as it unfolds. Built on open-source technologies that ensure data remain under institutional control and comply with data protection requirements, VIRENA is currently in use at the University of Zurich and available for pilot collaborations. Designed for researchers, educators, and public organizations alike, VIRENA's no-code interface makes controlled social media simulation accessible across disciplines and sectors. This paper documents its design, architecture, and capabilities.",
      "source": "arXiv",
      "pubDateISO": "2026-02-12",
      "tags": [
        "cs.HC",
        "cs.AI",
        "cs.SI"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.12204v1",
      "title": "Learning to Forget Attention: Memory Consolidation for Adaptive Compute Reduction",
      "link": "http://arxiv.org/abs/2602.12204v1",
      "pdf_link": "https://arxiv.org/pdf/2602.12204v1",
      "authors": "Ibne Farabi Shihab, Sanjeda Akter, Anuj Sharma",
      "institution": "",
      "abstract": "Hybrid architectures combining state-space models with attention have achieved strong efficiency-quality tradeoffs, yet existing approaches either apply attention uniformly or learn static sparse patterns. This misses a key opportunity: \\emph{attention demand should decrease over time as recurring patterns become familiar}. We present a surprising finding from analyzing GPT-2 models: \\textbf{88\\%} of attention operations retrieve information already predictable from the model's hidden state, and this redundancy does \\emph{not} decrease during training. Motivated by this observation, we introduce \\textbf{\\ours{}} (\\textbf{C}onsolidation-based \\textbf{R}outing for \\textbf{A}daptive \\textbf{M}emory), a biologically inspired memory consolidation mechanism that gradually distills episodic retrievals into parametric semantic memory. Unlike prior sparse attention methods, \\ours{} exhibits \\emph{decreasing attention utilization} over training, achieving a \\textbf{37.8$\\times$} reduction through a sharp phase transition at approximately 3K steps. We prove that this capability is \\emph{impossible} without consolidation: any static routing scheme requires $Ω(f \\cdot n)$ attention for tasks with recurring patterns of frequency $f$. On our proposed SRCD benchmark, \\ours{} achieves \\textbf{100\\% retrieval accuracy} at 1.6\\% attention compute (vs.\\ 68\\% for baselines), and consolidated patterns transfer to unseen tasks with \\textbf{48--52\\%} attention reduction without retraining. Remarkably, the learned consolidation dynamics quantitatively match human episodic-to-semantic memory transition curves from cognitive psychology ($γ= 0.43$ vs.\\ $γ_{\\text{human}} \\approx 0.4$--$0.5$). Code and benchmarks are available at [anonymized].",
      "source": "arXiv",
      "pubDateISO": "2026-02-12",
      "tags": [
        "cs.LG"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.12196v1",
      "title": "Visual Reasoning Benchmark: Evaluating Multimodal LLMs on Classroom-Authentic Visual Problems from Primary Education",
      "link": "http://arxiv.org/abs/2602.12196v1",
      "pdf_link": "https://arxiv.org/pdf/2602.12196v1",
      "authors": "Mohamed Huti, Alasdair Mackintosh, Amy Waldock, Dominic Andrews, Maxime Lelièvre et al.",
      "institution": "",
      "abstract": "AI models have achieved state-of-the-art results in textual reasoning; however, their ability to reason over spatial and relational structures remains a critical bottleneck -- particularly in early-grade maths, which relies heavily on visuals. This paper introduces the visual reasoning benchmark (VRB), a novel dataset designed to evaluate Multimodal Large Language Models (MLLMs) on their ability to solve authentic visual problems from classrooms. This benchmark is built on a set of 701 questions sourced from primary school examinations in Zambia and India, which cover a range of tasks such as reasoning by analogy, pattern completion, and spatial matching. We outline the methodology and development of the benchmark which intentionally uses unedited, minimal-text images to test if models can meet realistic needs of primary education. Our findings reveal a ``jagged frontier'' of capability where models demonstrate better proficiency in static skills such as counting and scaling, but reach a distinct ``spatial ceiling'' when faced with dynamic operations like folding, reflection, and rotation. These weaknesses pose a risk for classroom use on visual reasoning problems, with the potential for incorrect marking, false scaffolding, and reinforcing student misconceptions. Consequently, education-focused benchmarks like the VRB are essential for determining the functional boundaries of multimodal tools used in classrooms.",
      "source": "arXiv",
      "pubDateISO": "2026-02-12",
      "tags": [
        "cs.CL",
        "cs.AI"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.12192v1",
      "title": "Query-focused and Memory-aware Reranker for Long Context Processing",
      "link": "http://arxiv.org/abs/2602.12192v1",
      "pdf_link": "https://arxiv.org/pdf/2602.12192v1",
      "authors": "Yuqing Li, Jiangnan Li, Mo Yu, Guoxuan Ding, Zheng Lin et al.",
      "institution": "",
      "abstract": "Built upon the existing analysis of retrieval heads in large language models, we propose an alternative reranking framework that trains models to estimate passage-query relevance using the attention scores of selected heads. This approach provides a listwise solution that leverages holistic information within the entire candidate shortlist during ranking. At the same time, it naturally produces continuous relevance scores, enabling training on arbitrary retrieval datasets without requiring Likert-scale supervision. Our framework is lightweight and effective, requiring only small-scale models (e.g., 4B parameters) to achieve strong performance. Extensive experiments demonstrate that our method outperforms existing state-of-the-art pointwise and listwise rerankers across multiple domains, including Wikipedia and long narrative datasets. It further establishes a new state-of-the-art on the LoCoMo benchmark that assesses the capabilities of dialogue understanding and memory usage. We further demonstrate that our framework supports flexible extensions. For example, augmenting candidate passages with contextual information further improves ranking accuracy, while training attention heads from middle layers enhances efficiency without sacrificing performance.",
      "source": "arXiv",
      "pubDateISO": "2026-02-12",
      "tags": [
        "cs.CL"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.12189v1",
      "title": "WaveFormer: Wavelet Embedding Transformer for Biomedical Signals",
      "link": "http://arxiv.org/abs/2602.12189v1",
      "pdf_link": "https://arxiv.org/pdf/2602.12189v1",
      "authors": "Habib Irani, Bikram De, Vangelis Metsis",
      "institution": "",
      "abstract": "Biomedical signal classification presents unique challenges due to long sequences, complex temporal dynamics, and multi-scale frequency patterns that are poorly captured by standard transformer architectures. We propose WaveFormer, a transformer architecture that integrates wavelet decomposition at two critical stages: embedding construction, where multi-channel Discrete Wavelet Transform (DWT) extracts frequency features to create tokens containing both time-domain and frequency-domain information, and positional encoding, where Dynamic Wavelet Positional Encoding (DyWPE) adapts position embeddings to signal-specific temporal structure through mono-channel DWT analysis. We evaluate WaveFormer on eight diverse datasets spanning human activity recognition and brain signal analysis, with sequence lengths ranging from 50 to 3000 timesteps and channel counts from 1 to 144. Experimental results demonstrate that WaveFormer achieves competitive performance through comprehensive frequency-aware processing. Our approach provides a principled framework for incorporating frequency-domain knowledge into transformer-based time series classification.",
      "source": "arXiv",
      "pubDateISO": "2026-02-12",
      "tags": [
        "cs.LG"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.12187v1",
      "title": "SAGEO Arena: A Realistic Environment for Evaluating Search-Augmented Generative Engine Optimization",
      "link": "http://arxiv.org/abs/2602.12187v1",
      "pdf_link": "https://arxiv.org/pdf/2602.12187v1",
      "authors": "Sunghwan Kim, Wooseok Jeong, Serin Kim, Sangam Lee, Dongha Lee",
      "institution": "",
      "abstract": "Search-Augmented Generative Engines (SAGE) have emerged as a new paradigm for information access, bridging web-scale retrieval with generative capabilities to deliver synthesized answers. This shift has fundamentally reshaped how web content gains exposure online, giving rise to Search-Augmented Generative Engine Optimization (SAGEO), the practice of optimizing web documents to improve their visibility in AI-generated responses. Despite growing interest, no evaluation environment currently supports comprehensive investigation of SAGEO. Specifically, existing benchmarks lack end-to-end visibility evaluation of optimization strategies, operating on pre-determined candidate documents that abstract away retrieval and reranking preceding generation. Moreover, existing benchmarks discard structural information (e.g., schema markup) present in real web documents, overlooking the rich signals that search systems actively leverage in practice. Motivated by these gaps, we introduce SAGEO Arena, a realistic and reproducible environment for stage-level SAGEO analysis. Our objective is to jointly target search-oriented optimization (SEO) and generation-centric optimization (GEO). To achieve this, we integrate a full generative search pipeline over a large-scale corpus of web documents with rich structural information. Our findings reveal that existing approaches remain largely impractical under realistic conditions and often degrade performance in retrieval and reranking. We also find that structural information helps mitigate these limitations, and that effective SAGEO requires tailoring optimization to each pipeline stage. Overall, our benchmark paves the way for realistic SAGEO evaluation and optimization beyond simplified settings.",
      "source": "arXiv",
      "pubDateISO": "2026-02-12",
      "tags": [
        "cs.IR",
        "cs.AI"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.12181v1",
      "title": "Convex Markov Games and Beyond: New Proof of Existence, Characterization and Learning Algorithms for Nash Equilibria",
      "link": "http://arxiv.org/abs/2602.12181v1",
      "pdf_link": "https://arxiv.org/pdf/2602.12181v1",
      "authors": "Anas Barakat, Ioannis Panageas, Antonios Varvitsiotis",
      "institution": "",
      "abstract": "Convex Markov Games (cMGs) were recently introduced as a broad class of multi-agent learning problems that generalize Markov games to settings where strategic agents optimize general utilities beyond additive rewards. While cMGs expand the modeling frontier, their theoretical foundations, particularly the structure of Nash equilibria (NE) and guarantees for learning algorithms, are not yet well understood. In this work, we address these gaps for an extension of cMGs, which we term General Utility Markov Games (GUMGs), capturing new applications requiring coupling between agents' occupancy measures. We prove that in GUMGs, Nash equilibria coincide with the fixed points of projected pseudo-gradient dynamics (i.e., first-order stationary points), enabled by a novel agent-wise gradient domination property. This insight also yields a simple proof of NE existence using Brouwer's fixed-point theorem. We further show the existence of Markov perfect equilibria. Building on this characterization, we establish a policy gradient theorem for GUMGs and design a model-free policy gradient algorithm. For potential GUMGs, we establish iteration complexity guarantees for computing approximate-NE under exact gradients and provide sample complexity bounds in both the generative model and on-policy settings. Our results extend beyond prior work restricted to zero-sum cMGs, providing the first theoretical analysis of common-interest cMGs.",
      "source": "arXiv",
      "pubDateISO": "2026-02-12",
      "tags": [
        "cs.GT",
        "cs.LG",
        "cs.MA"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.12180v1",
      "title": "How Sampling Shapes LLM Alignment: From One-Shot Optima to Iterative Dynamics",
      "link": "http://arxiv.org/abs/2602.12180v1",
      "pdf_link": "https://arxiv.org/pdf/2602.12180v1",
      "authors": "Yurong Chen, Yu He, Michael I. Jordan, Fan Yao",
      "institution": "",
      "abstract": "Standard methods for aligning large language models with human preferences learn from pairwise comparisons among sampled candidate responses and regularize toward a reference policy. Despite their effectiveness, the effects of sampling and reference choices are poorly understood theoretically. We investigate these effects through Identity Preference Optimization, a widely used preference alignment framework, and show that proper instance-dependent sampling can yield stronger ranking guarantees, while skewed on-policy sampling can induce excessive concentration under structured preferences. We then analyze iterative alignment dynamics in which the learned policy feeds back into future sampling and reference policies, reflecting a common practice of model-generated preference data. We prove that these dynamics can exhibit persistent oscillations or entropy collapse for certain parameter choices, and characterize regimes that guarantee stability. Our theoretical insights extend to Direct Preference Optimization, indicating the phenomena we captured are common to a broader class of preference-alignment methods. Experiments on real-world preference data validate our findings.",
      "source": "arXiv",
      "pubDateISO": "2026-02-12",
      "tags": [
        "cs.LG",
        "cs.GT"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.12177v1",
      "title": "EO-VAE: Towards A Multi-sensor Tokenizer for Earth Observation Data",
      "link": "http://arxiv.org/abs/2602.12177v1",
      "pdf_link": "https://arxiv.org/pdf/2602.12177v1",
      "authors": "Nils Lehmann, Yi Wang, Zhitong Xiong, Xiaoxiang Zhu",
      "institution": "",
      "abstract": "State-of-the-art generative image and video models rely heavily on tokenizers that compress high-dimensional inputs into more efficient latent representations. While this paradigm has revolutionized RGB generation, Earth observation (EO) data presents unique challenges due to diverse sensor specifications and variable spectral channels. We propose EO-VAE, a multi-sensor variational autoencoder designed to serve as a foundational tokenizer for the EO domain. Unlike prior approaches that train separate tokenizers for each modality, EO-VAE utilizes a single model to encode and reconstruct flexible channel combinations via dynamic hypernetworks. Our experiments on the TerraMesh dataset demonstrate that EO-VAE achieves superior reconstruction fidelity compared to the TerraMind tokenizers, establishing a robust baseline for latent generative modeling in remote sensing.",
      "source": "arXiv",
      "pubDateISO": "2026-02-12",
      "tags": [
        "cs.CV"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.12173v1",
      "title": "SAM3-LiteText: An Anatomical Study of the SAM3 Text Encoder for Efficient Vision-Language Segmentation",
      "link": "http://arxiv.org/abs/2602.12173v1",
      "pdf_link": "https://arxiv.org/pdf/2602.12173v1",
      "authors": "Chengxi Zeng, Yuxuan Jiang, Ge Gao, Shuai Wang, Duolikun Danier et al.",
      "institution": "",
      "abstract": "Vision-language segmentation models such as SAM3 enable flexible, prompt-driven visual grounding, but inherit large, general-purpose text encoders originally designed for open-ended language understanding. In practice, segmentation prompts are short, structured, and semantically constrained, leading to substantial over-provisioning in text encoder capacity and persistent computational and memory overhead. In this paper, we perform a large-scale anatomical analysis of text prompting in vision-language segmentation, covering 404,796 real prompts across multiple benchmarks. Our analysis reveals severe redundancy: most context windows are underutilized, vocabulary usage is highly sparse, and text embeddings lie on low-dimensional manifold despite high-dimensional representations. Motivated by these findings, we propose SAM3-LiteText, a lightweight text encoding framework that replaces the original SAM3 text encoder with a compact MobileCLIP student that is optimized by knowledge distillation. Extensive experiments on image and video segmentation benchmarks show that SAM3-LiteText reduces text encoder parameters by up to 88%, substantially reducing static memory footprint, while maintaining segmentation performance comparable to the original model. Code: https://github.com/SimonZeng7108/efficientsam3/tree/sam3_litetext.",
      "source": "arXiv",
      "pubDateISO": "2026-02-12",
      "tags": [
        "cs.AI"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.12172v1",
      "title": "Pedagogically-Inspired Data Synthesis for Language Model Knowledge Distillation",
      "link": "http://arxiv.org/abs/2602.12172v1",
      "pdf_link": "https://arxiv.org/pdf/2602.12172v1",
      "authors": "Bowei He, Yankai Chen, Xiaokun Zhang, Linghe Kong, Philip S. Yu et al.",
      "institution": "",
      "abstract": "Knowledge distillation from Large Language Models (LLMs) to smaller models has emerged as a critical technique for deploying efficient AI systems. However, current methods for distillation via synthetic data lack pedagogical awareness, treating knowledge transfer as a one-off data synthesis and training task rather than a systematic learning process. In this paper, we propose a novel pedagogically-inspired framework for LLM knowledge distillation that draws from fundamental educational principles. Our approach introduces a three-stage pipeline -- Knowledge Identifier, Organizer, and Adapter (IOA) -- that systematically identifies knowledge deficiencies in student models, organizes knowledge delivery through progressive curricula, and adapts representations to match the cognitive capacity of student models. We integrate Bloom's Mastery Learning Principles and Vygotsky's Zone of Proximal Development to create a dynamic distillation process where student models approach teacher model's performance on prerequisite knowledge before advancing, and new knowledge is introduced with controlled, gradual difficulty increments. Extensive experiments using LLaMA-3.1/3.2 and Qwen2.5 as student models demonstrate that IOA achieves significant improvements over baseline distillation methods, with student models retaining 94.7% of teacher performance on DollyEval while using less than 1/10th of the parameters. Our framework particularly excels in complex reasoning tasks, showing 19.2% improvement on MATH and 22.3% on HumanEval compared with state-of-the-art baselines.",
      "source": "arXiv",
      "pubDateISO": "2026-02-12",
      "tags": [
        "cs.AI",
        "cs.CL"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.12170v1",
      "title": "Statistical Parsing for Logical Information Retrieval",
      "link": "http://arxiv.org/abs/2602.12170v1",
      "pdf_link": "https://arxiv.org/pdf/2602.12170v1",
      "authors": "Greg Coppola",
      "institution": "",
      "abstract": "In previous work (Coppola, 2024) we introduced the Quantified Boolean Bayesian Network (QBBN), a logical graphical model that implements the forward fragment of natural deduction (Prawitz, 1965) as a probabilistic factor graph. That work left two gaps: no negation/backward reasoning, and no parser for natural language.\n  This paper addresses both gaps across inference, semantics, and syntax. For inference, we extend the QBBN with NEG factors enforcing P(x) + P(neg x) = 1, enabling contrapositive reasoning (modus tollens) via backward lambda messages, completing Prawitz's simple elimination rules. The engine handles 44/44 test cases spanning 22 reasoning patterns. For semantics, we present a typed logical language with role-labeled predicates, modal quantifiers, and three tiers of expressiveness following Prawitz: first-order quantification, propositions as arguments, and predicate quantification via lambda abstraction. For syntax, we present a typed slot grammar that deterministically compiles sentences to logical form (33/33 correct, zero ambiguity). LLMs handle disambiguation (95% PP attachment accuracy) but cannot produce structured parses directly (12.4% UAS), confirming grammars are necessary. The architecture: LLM preprocesses, grammar parses, LLM reranks, QBBN infers.\n  We argue this reconciles formal semantics with Sutton's \"bitter lesson\" (2019): LLMs eliminate the annotation bottleneck that killed formal NLP, serving as annotator while the QBBN serves as verifier. Code: https://github.com/gregorycoppola/world",
      "source": "arXiv",
      "pubDateISO": "2026-02-12",
      "tags": [
        "cs.AI"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.12162v1",
      "title": "Amortized Molecular Optimization via Group Relative Policy Optimization",
      "link": "http://arxiv.org/abs/2602.12162v1",
      "pdf_link": "https://arxiv.org/pdf/2602.12162v1",
      "authors": "Muhammad bin Javaid, Hasham Hussain, Ashima Khanna, Berke Kisin, Jonathan Pirnay et al.",
      "institution": "",
      "abstract": "Molecular design encompasses tasks ranging from de-novo design to structural alteration of given molecules or fragments. For the latter, state-of-the-art methods predominantly function as \"Instance Optimizers'', expending significant compute restarting the search for every input structure. While model-based approaches theoretically offer amortized efficiency by learning a policy transferable to unseen structures, existing methods struggle to generalize. We identify a key failure mode: the high variance arising from the heterogeneous difficulty of distinct starting structures. To address this, we introduce GRXForm, adapting a pre-trained Graph Transformer model that optimizes molecules via sequential atom-and-bond additions. We employ Group Relative Policy Optimization (GRPO) for goal-directed fine-tuning to mitigate variance by normalizing rewards relative to the starting structure. Empirically, GRXForm generalizes to out-of-distribution molecular scaffolds without inference-time oracle calls or refinement, achieving scores in multi-objective optimization competitive with leading instance optimizers.",
      "source": "arXiv",
      "pubDateISO": "2026-02-12",
      "tags": [
        "cs.LG"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.12160v1",
      "title": "DreamID-Omni: Unified Framework for Controllable Human-Centric Audio-Video Generation",
      "link": "http://arxiv.org/abs/2602.12160v1",
      "pdf_link": "https://arxiv.org/pdf/2602.12160v1",
      "authors": "Xu Guo, Fulong Ye, Qichao Sun, Liyang Chen, Bingchuan Li et al.",
      "institution": "",
      "abstract": "Recent advancements in foundation models have revolutionized joint audio-video generation. However, existing approaches typically treat human-centric tasks including reference-based audio-video generation (R2AV), video editing (RV2AV) and audio-driven video animation (RA2V) as isolated objectives. Furthermore, achieving precise, disentangled control over multiple character identities and voice timbres within a single framework remains an open challenge. In this paper, we propose DreamID-Omni, a unified framework for controllable human-centric audio-video generation. Specifically, we design a Symmetric Conditional Diffusion Transformer that integrates heterogeneous conditioning signals via a symmetric conditional injection scheme. To resolve the pervasive identity-timbre binding failures and speaker confusion in multi-person scenarios, we introduce a Dual-Level Disentanglement strategy: Synchronized RoPE at the signal level to ensure rigid attention-space binding, and Structured Captions at the semantic level to establish explicit attribute-subject mappings. Furthermore, we devise a Multi-Task Progressive Training scheme that leverages weakly-constrained generative priors to regularize strongly-constrained tasks, preventing overfitting and harmonizing disparate objectives. Extensive experiments demonstrate that DreamID-Omni achieves comprehensive state-of-the-art performance across video, audio, and audio-visual consistency, even outperforming leading proprietary commercial models. We will release our code to bridge the gap between academic research and commercial-grade applications.",
      "source": "arXiv",
      "pubDateISO": "2026-02-12",
      "tags": [
        "cs.CV"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.12159v1",
      "title": "3DGSNav: Enhancing Vision-Language Model Reasoning for Object Navigation via Active 3D Gaussian Splatting",
      "link": "http://arxiv.org/abs/2602.12159v1",
      "pdf_link": "https://arxiv.org/pdf/2602.12159v1",
      "authors": "Wancai Zheng, Hao Chen, Xianlong Lu, Linlin Ou, Xinyi Yu",
      "institution": "",
      "abstract": "Object navigation is a core capability of embodied intelligence, enabling an agent to locate target objects in unknown environments. Recent advances in vision-language models (VLMs) have facilitated zero-shot object navigation (ZSON). However, existing methods often rely on scene abstractions that convert environments into semantic maps or textual representations, causing high-level decision making to be constrained by the accuracy of low-level perception. In this work, we present 3DGSNav, a novel ZSON framework that embeds 3D Gaussian Splatting (3DGS) as persistent memory for VLMs to enhance spatial reasoning. Through active perception, 3DGSNav incrementally constructs a 3DGS representation of the environment, enabling trajectory-guided free-viewpoint rendering of frontier-aware first-person views. Moreover, we design structured visual prompts and integrate them with Chain-of-Thought (CoT) prompting to further improve VLM reasoning. During navigation, a real-time object detector filters potential targets, while VLM-driven active viewpoint switching performs target re-verification, ensuring efficient and reliable recognition. Extensive evaluations across multiple benchmarks and real-world experiments on a quadruped robot demonstrate that our method achieves robust and competitive performance against state-of-the-art approaches.The Project Page:https://aczheng-cai.github.io/3dgsnav.github.io/",
      "source": "arXiv",
      "pubDateISO": "2026-02-12",
      "tags": [
        "cs.RO",
        "cs.AI"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.12158v1",
      "title": "SafeNeuron: Neuron-Level Safety Alignment for Large Language Models",
      "link": "http://arxiv.org/abs/2602.12158v1",
      "pdf_link": "https://arxiv.org/pdf/2602.12158v1",
      "authors": "Zhaoxin Wang, Jiaming Liang, Fengbin Zhu, Weixiang Zhao, Junfeng Fang et al.",
      "institution": "",
      "abstract": "Large language models (LLMs) and multimodal LLMs are typically safety-aligned before release to prevent harmful content generation. However, recent studies show that safety behaviors are concentrated in a small subset of parameters, making alignment brittle and easily bypassed through neuron-level attacks. Moreover, most existing alignment methods operate at the behavioral level, offering limited control over the model's internal safety mechanisms. In this work, we propose SafeNeuron, a neuron-level safety alignment framework that improves robustness by redistributing safety representations across the network. SafeNeuron first identifies safety-related neurons, then freezes these neurons during preference optimization to prevent reliance on sparse safety pathways and force the model to construct redundant safety representations. Extensive experiments across models and modalities demonstrate that SafeNeuron significantly improves robustness against neuron pruning attacks, reduces the risk of open-source models being repurposed as red-team generators, and preserves general capabilities. Furthermore, our layer-wise analysis reveals that safety behaviors are governed by stable and shared internal representations. Overall, SafeNeuron provides an interpretable and robust perspective for model alignment.",
      "source": "arXiv",
      "pubDateISO": "2026-02-12",
      "tags": [
        "cs.LG"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.12157v1",
      "title": "TexSpot: 3D Texture Enhancement with Spatially-uniform Point Latent Representation",
      "link": "http://arxiv.org/abs/2602.12157v1",
      "pdf_link": "https://arxiv.org/pdf/2602.12157v1",
      "authors": "Ziteng Lu, Yushuang Wu, Chongjie Ye, Yuda Qiu, Jing Shao et al.",
      "institution": "",
      "abstract": "High-quality 3D texture generation remains a fundamental challenge due to the view-inconsistency inherent in current mainstream multi-view diffusion pipelines. Existing representations either rely on UV maps, which suffer from distortion during unwrapping, or point-based methods, which tightly couple texture fidelity to geometric density that limits high-resolution texture generation. To address these limitations, we introduce TexSpot, a diffusion-based texture enhancement framework. At its core is Texlet, a novel 3D texture representation that merges the geometric expressiveness of point-based 3D textures with the compactness of UV-based representation. Each Texlet latent vector encodes a local texture patch via a 2D encoder and is further aggregated using a 3D encoder to incorporate global shape context. A cascaded 3D-to-2D decoder reconstructs high-quality texture patches, enabling the Texlet space learning. Leveraging this representation, we train a diffusion transformer conditioned on Texlets to refine and enhance textures produced by multi-view diffusion methods. Extensive experiments demonstrate that TexSpot significantly improves visual fidelity, geometric consistency, and robustness over existing state-of-the-art 3D texture generation and enhancement approaches. Project page: https://anonymous.4open.science/w/TexSpot-page-2D91.",
      "source": "arXiv",
      "pubDateISO": "2026-02-12",
      "tags": [
        "cs.CV",
        "cs.GR"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.12155v1",
      "title": "FAIL: Flow Matching Adversarial Imitation Learning for Image Generation",
      "link": "http://arxiv.org/abs/2602.12155v1",
      "pdf_link": "https://arxiv.org/pdf/2602.12155v1",
      "authors": "Yeyao Ma, Chen Li, Xiaosong Zhang, Han Hu, Weidi Xie",
      "institution": "",
      "abstract": "Post-training of flow matching models-aligning the output distribution with a high-quality target-is mathematically equivalent to imitation learning. While Supervised Fine-Tuning mimics expert demonstrations effectively, it cannot correct policy drift in unseen states. Preference optimization methods address this but require costly preference pairs or reward modeling. We propose Flow Matching Adversarial Imitation Learning (FAIL), which minimizes policy-expert divergence through adversarial training without explicit rewards or pairwise comparisons. We derive two algorithms: FAIL-PD exploits differentiable ODE solvers for low-variance pathwise gradients, while FAIL-PG provides a black-box alternative for discrete or computationally constrained settings. Fine-tuning FLUX with only 13,000 demonstrations from Nano Banana pro, FAIL achieves competitive performance on prompt following and aesthetic benchmarks. Furthermore, the framework generalizes effectively to discrete image and video generation, and functions as a robust regularizer to mitigate reward hacking in reward-based optimization. Code and data are available at https://github.com/HansPolo113/FAIL.",
      "source": "arXiv",
      "pubDateISO": "2026-02-12",
      "tags": [
        "cs.CV"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.12150v1",
      "title": "GPT-4o Lacks Core Features of Theory of Mind",
      "link": "http://arxiv.org/abs/2602.12150v1",
      "pdf_link": "https://arxiv.org/pdf/2602.12150v1",
      "authors": "John Muchovej, Amanda Royka, Shane Lee, Julian Jara-Ettinger",
      "institution": "",
      "abstract": "Do Large Language Models (LLMs) possess a Theory of Mind (ToM)? Research into this question has focused on evaluating LLMs against benchmarks and found success across a range of social tasks. However, these evaluations do not test for the actual representations posited by ToM: namely, a causal model of mental states and behavior. Here, we use a cognitively-grounded definition of ToM to develop and test a new evaluation framework. Specifically, our approach probes whether LLMs have a coherent, domain-general, and consistent model of how mental states cause behavior -- regardless of whether that model matches a human-like ToM. We find that even though LLMs succeed in approximating human judgments in a simple ToM paradigm, they fail at a logically equivalent task and exhibit low consistency between their action predictions and corresponding mental state inferences. As such, these findings suggest that the social proficiency exhibited by LLMs is not the result of an domain-general or consistent ToM.",
      "source": "arXiv",
      "pubDateISO": "2026-02-12",
      "tags": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.12147v1",
      "title": "It's TIME: Towards the Next Generation of Time Series Forecasting Benchmarks",
      "link": "http://arxiv.org/abs/2602.12147v1",
      "pdf_link": "https://arxiv.org/pdf/2602.12147v1",
      "authors": "Zhongzheng Qiao, Sheng Pan, Anni Wang, Viktoriya Zhukova, Yong Liu et al.",
      "institution": "",
      "abstract": "Time series foundation models (TSFMs) are revolutionizing the forecasting landscape from specific dataset modeling to generalizable task evaluation. However, we contend that existing benchmarks exhibit common limitations in four dimensions: constrained data composition dominated by reused legacy sources, compromised data integrity lacking rigorous quality assurance, misaligned task formulations detached from real-world contexts, and rigid analysis perspectives that obscure generalizable insights. To bridge these gaps, we introduce TIME, a next-generation task-centric benchmark comprising 50 fresh datasets and 98 forecasting tasks, tailored for strict zero-shot TSFM evaluation free from data leakage. Integrating large language models and human expertise, we establish a rigorous human-in-the-loop benchmark construction pipeline to ensure high data integrity and redefine task formulation by aligning forecasting configurations with real-world operational requirements and variate predictability. Furthermore, we propose a novel pattern-level evaluation perspective that moves beyond traditional dataset-level evaluations based on static meta labels. By leveraging structural time series features to characterize intrinsic temporal properties, this approach offers generalizable insights into model capabilities across diverse patterns. We evaluate 12 representative TSFMs and establish a multi-granular leaderboard to facilitate in-depth analysis and visualized inspection. The leaderboard is available at https://huggingface.co/spaces/Real-TSF/TIME-leaderboard.",
      "source": "arXiv",
      "pubDateISO": "2026-02-12",
      "tags": [
        "cs.LG"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.12146v1",
      "title": "Seq2Seq2Seq: Lossless Data Compression via Discrete Latent Transformers and Reinforcement Learning",
      "link": "http://arxiv.org/abs/2602.12146v1",
      "pdf_link": "https://arxiv.org/pdf/2602.12146v1",
      "authors": "Mahdi Khodabandeh, Ghazal Shabani, Arash Yousefi Jordehi, Seyed Abolghasem Mirroshandel",
      "institution": "",
      "abstract": "Efficient lossless compression is essential for minimizing storage costs and transmission overhead while preserving data integrity. Traditional compression techniques, such as dictionary-based and statistical methods, often struggle to optimally exploit the structure and redundancy in complex data formats. Recent advancements in deep learning have opened new avenues for compression; however, many existing approaches depend on dense vector representations that obscure the underlying token structure. To address these limitations, we propose a novel lossless compression method that leverages Reinforcement Learning applied to a T5 language model architecture. This approach enables the compression of data into sequences of tokens rather than traditional vector representations. Unlike auto-encoders, which typically encode information into continuous latent spaces, our method preserves the token-based structure, aligning more closely with the original data format. This preservation allows for higher compression ratios while maintaining semantic integrity. By training the model using an off-policy Reinforcement Learning algorithm, we optimize sequence length to minimize redundancy and enhance compression efficiency. Our method introduces an efficient and adaptive data compression system built upon advanced Reinforcement Learning techniques, functioning independently of external grammatical or world knowledge. This approach shows significant improvements in compression ratios compared to conventional methods. By leveraging the latent information within language models, our system effectively compresses data without requiring explicit content understanding, paving the way for more robust and practical compression solutions across various applications.",
      "source": "arXiv",
      "pubDateISO": "2026-02-12",
      "tags": [
        "cs.AI",
        "cs.CL",
        "cs.IT"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.12144v1",
      "title": "On the Adoption of AI Coding Agents in Open-source Android and iOS Development",
      "link": "http://arxiv.org/abs/2602.12144v1",
      "pdf_link": "https://arxiv.org/pdf/2602.12144v1",
      "authors": "Muhammad Ahmad Khan, Hasnain Ali, Muneeb Rana, Muhammad Saqib Ilyas, Abdul Ali Bangash",
      "institution": "",
      "abstract": "AI coding agents are increasingly contributing to software development, yet their impact on mobile development has received little empirical attention. In this paper, we present the first category-level empirical study of agent-generated code in open-source mobile app projects. We analyzed PR acceptance behaviors across mobile platforms, agents, and task categories using 2,901 AI-authored pull requests (PRs) in 193 verified Android and iOS open-source GitHub repositories in the AIDev dataset. We find that Android projects have received 2x more AI-authored PRs and have achieved higher PR acceptance rate (71%) than iOS (63%), with significant agent-level variation on Android. Across task categories, PRs with routine tasks (feature, fix, and ui) achieve the highest acceptance, while structural changes like refactor and build achieve lower success and longer resolution times. Furthermore, our evolution analysis shows improvement in PR resolution time on Android through mid-2025 before it declined again. Our findings offer the first evidence-based characterization of AI agents effects on OSS mobile projects and establish empirical baselines for evaluating agent-generated contributions to design platform aware agentic systems.",
      "source": "arXiv",
      "pubDateISO": "2026-02-12",
      "tags": [
        "cs.SE",
        "cs.AI"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.12143v1",
      "title": "STAR : Bridging Statistical and Agentic Reasoning for Large Model Performance Prediction",
      "link": "http://arxiv.org/abs/2602.12143v1",
      "pdf_link": "https://arxiv.org/pdf/2602.12143v1",
      "authors": "Xiaoxiao Wang, Chunxiao Li, Junying Wang, Yijin Guo, Zijian Chen et al.",
      "institution": "",
      "abstract": "As comprehensive large model evaluation becomes prohibitively expensive, predicting model performance from limited observations has become essential. However, existing statistical methods struggle with pattern shifts, data sparsity, and lack of explanation, while pure LLM methods remain unreliable. We propose STAR, a framework that bridges data-driven STatistical expectations with knowledge-driven Agentic Reasoning. STAR leverages specialized retrievers to gather external knowledge and embeds semantic features into Constrained Probabilistic Matrix Factorization (CPMF) to generate statistical expectations with uncertainty. A reasoning module guided by Expectation Violation Theory (EVT) then refines predictions through intra-family analysis, cross-model comparison, and credibility-aware aggregation, producing adjustments with traceable explanations. Extensive experiments show that STAR consistently outperforms all baselines on both score-based and rank-based metrics, delivering a 14.46% gain in total score over the strongest statistical method under extreme sparsity, with only 1--2 observed scores per test model.",
      "source": "arXiv",
      "pubDateISO": "2026-02-12",
      "tags": [
        "cs.AI",
        "cs.LG"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.12139v1",
      "title": "Oscillators Are All You Need: Irregular Time Series Modelling via Damped Harmonic Oscillators with Closed-Form Solutions",
      "link": "http://arxiv.org/abs/2602.12139v1",
      "pdf_link": "https://arxiv.org/pdf/2602.12139v1",
      "authors": "Yashas Shende, Aritra Das, Reva Laxmi Chauhan, Arghya Pathak, Debayan Gupta",
      "institution": "",
      "abstract": "Transformers excel at time series modelling through attention mechanisms that capture long-term temporal patterns. However, they assume uniform time intervals and therefore struggle with irregular time series. Neural Ordinary Differential Equations (NODEs) effectively handle irregular time series by modelling hidden states as continuously evolving trajectories. ContiFormers arxiv:2402.10635 combine NODEs with Transformers, but inherit the computational bottleneck of the former by using heavy numerical solvers. This bottleneck can be removed by using a closed-form solution for the given dynamical system - but this is known to be intractable in general! We obviate this by replacing NODEs with a novel linear damped harmonic oscillator analogy - which has a known closed-form solution. We model keys and values as damped, driven oscillators and expand the query in a sinusoidal basis up to a suitable number of modes. This analogy naturally captures the query-key coupling that is fundamental to any transformer architecture by modelling attention as a resonance phenomenon. Our closed-form solution eliminates the computational overhead of numerical ODE solvers while preserving expressivity. We prove that this oscillator-based parameterisation maintains the universal approximation property of continuous-time attention; specifically, any discrete attention matrix realisable by ContiFormer's continuous keys can be approximated arbitrarily well by our fixed oscillator modes. Our approach delivers both theoretical guarantees and scalability, achieving state-of-the-art performance on irregular time series benchmarks while being orders of magnitude faster.",
      "source": "arXiv",
      "pubDateISO": "2026-02-12",
      "tags": [
        "cs.LG"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.12137v1",
      "title": "CitiLink-Minutes: A Multilayer Annotated Dataset of Municipal Meeting Minutes",
      "link": "http://arxiv.org/abs/2602.12137v1",
      "pdf_link": "https://arxiv.org/pdf/2602.12137v1",
      "authors": "Ricardo Campos, Ana Filipa Pacheco, Ana Luísa Fernandes, Inês Cantante, Rute Rebouças et al.",
      "institution": "",
      "abstract": "City councils play a crucial role in local governance, directly influencing citizens' daily lives through decisions made during municipal meetings. These deliberations are formally documented in meeting minutes, which serve as official records of discussions, decisions, and voting outcomes. Despite their importance, municipal meeting records have received little attention in Information Retrieval (IR) and Natural Language Processing (NLP), largely due to the lack of annotated datasets, which ultimately limit the development of computational models. To address this gap, we introduce CitiLink-Minutes, a multilayer dataset of 120 European Portuguese municipal meeting minutes from six municipalities. Unlike prior annotated datasets of parliamentary or video records, CitiLink-Minutes provides multilayer annotations and structured linkage of official written minutes. The dataset contains over one million tokens, with all personal identifiers de-identified. Each minute was manually annotated by two trained annotators and curated by an experienced linguist across three complementary dimensions: (1) metadata, (2) subjects of discussion, and (3) voting outcomes, totaling over 38,000 individual annotations. Released under FAIR principles and accompanied by baseline results on metadata extraction, topic classification, and vote labeling, CitiLink-Minutes demonstrates its potential for downstream NLP and IR tasks, while promoting transparent access to municipal decisions.",
      "source": "arXiv",
      "pubDateISO": "2026-02-12",
      "tags": [
        "cs.CL"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.12135v1",
      "title": "WavBench: Benchmarking Reasoning, Colloquialism, and Paralinguistics for End-to-End Spoken Dialogue Models",
      "link": "http://arxiv.org/abs/2602.12135v1",
      "pdf_link": "https://arxiv.org/pdf/2602.12135v1",
      "authors": "Yangzhuo Li, Shengpeng Ji, Yifu Chen, Tianle Liang, Haorong Ying et al.",
      "institution": "",
      "abstract": "With the rapid integration of advanced reasoning capabilities into spoken dialogue models, the field urgently demands benchmarks that transcend simple interactions to address real-world complexity. However, current evaluations predominantly adhere to text-generation standards, overlooking the unique audio-centric characteristics of paralinguistics and colloquialisms, alongside the cognitive depth required by modern agents. To bridge this gap, we introduce WavBench, a comprehensive benchmark designed to evaluate realistic conversational abilities where prior works fall short. Uniquely, WavBench establishes a tripartite framework: 1) Pro subset, designed to rigorously challenge reasoning-enhanced models with significantly increased difficulty; 2) Basic subset, defining a novel standard for spoken colloquialism that prioritizes \"listenability\" through natural vocabulary, linguistic fluency, and interactive rapport, rather than rigid written accuracy; and 3) Acoustic subset, covering explicit understanding, generation, and implicit dialogue to rigorously evaluate comprehensive paralinguistic capabilities within authentic real-world scenarios. Through evaluating five state-of-the-art models, WavBench offers critical insights into the intersection of complex problem-solving, colloquial delivery, and paralinguistic fidelity, guiding the evolution of robust spoken dialogue models. The benchmark dataset and evaluation toolkit are available at https://naruto-2024.github.io/wavbench.github.io/.",
      "source": "arXiv",
      "pubDateISO": "2026-02-12",
      "tags": [
        "cs.CL"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.12134v1",
      "title": "Value Alignment Tax: Measuring Value Trade-offs in LLM Alignment",
      "link": "http://arxiv.org/abs/2602.12134v1",
      "pdf_link": "https://arxiv.org/pdf/2602.12134v1",
      "authors": "Jiajun Chen, Hua Shen",
      "institution": "",
      "abstract": "Existing work on value alignment typically characterizes value relations statically, ignoring how interventions - such as prompting, fine-tuning, or preference optimization - reshape the broader value system. We introduce the Value Alignment Tax (VAT), a framework that measures how alignment-induced changes propagate across interconnected values relative to achieved on-target gain. VAT captures the dynamics of value expression under alignment pressure. Using a controlled scenario-action dataset grounded in Schwartz value theory, we collect paired pre-post normative judgments and analyze alignment effects across models, values, and alignment strategies. Our results show that alignment often produces uneven, structured co-movement among values. These effects are invisible under conventional target-only evaluation, revealing systemic, process-level alignment risks and offering new insights into the dynamics of value alignment in LLMs.",
      "source": "arXiv",
      "pubDateISO": "2026-02-12",
      "tags": [
        "cs.AI",
        "cs.HC"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.12133v1",
      "title": "Neutral Prompts, Non-Neutral People: Quantifying Gender and Skin-Tone Bias in Gemini Flash 2.5 Image and GPT Image 1.5",
      "link": "http://arxiv.org/abs/2602.12133v1",
      "pdf_link": "https://arxiv.org/pdf/2602.12133v1",
      "authors": "Roberto Balestri",
      "institution": "",
      "abstract": "This study quantifies gender and skin-tone bias in two widely deployed commercial image generators - Gemini Flash 2.5 Image (NanoBanana) and GPT Image 1.5 - to test the assumption that neutral prompts yield demographically neutral outputs. We generated 3,200 photorealistic images using four semantically neutral prompts. The analysis employed a rigorous pipeline combining hybrid color normalization, facial landmark masking, and perceptually uniform skin tone quantification using the Monk (MST), PERLA, and Fitzpatrick scales. Neutral prompts produced highly polarized defaults. Both models exhibited a strong \"default white\" bias (>96% of outputs). However, they diverged sharply on gender: Gemini favored female-presenting subjects, while GPT favored male-presenting subjects with lighter skin tones. This research provides a large-scale, comparative audit of state-of-the-art models using an illumination-aware colorimetric methodology, distinguishing aesthetic rendering from underlying pigmentation in synthetic imagery. The study demonstrates that neutral prompts function as diagnostic probes rather than neutral instructions. It offers a robust framework for auditing algorithmic visual culture and challenges the sociolinguistic assumption that unmarked language results in inclusive representation.",
      "source": "arXiv",
      "pubDateISO": "2026-02-12",
      "tags": [
        "cs.AI",
        "cs.CL",
        "cs.CY",
        "cs.HC"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.12132v1",
      "title": "A Rule-based Computational Model for Gaidhlig Morphology",
      "link": "http://arxiv.org/abs/2602.12132v1",
      "pdf_link": "https://arxiv.org/pdf/2602.12132v1",
      "authors": "Peter J Barclay",
      "institution": "",
      "abstract": "Language models and software tools are essential to support the continuing vitality of lesser-used languages; however, currently popular neural models require considerable data for training, which normally is not available for such low-resource languages. This paper describes work-in-progress to construct a rule-based model of Gaidhlig morphology using data from Wiktionary, arguing that rule-based systems effectively leverage limited sample data, support greater interpretability, and provide insights useful in the design of teaching materials. The use of SQL for querying the occurrence of different lexical patterns is investigated, and a declarative rule-base is presented that allows Python utilities to derive inflected forms of Gaidhlig words. This functionality could be used to support educational tools that teach or explain language patterns, for example, or to support higher level tools such as rule-based dependency parsers. This approach adds value to the data already present in Wiktionary by adapting it to new use-cases.",
      "source": "arXiv",
      "pubDateISO": "2026-02-12",
      "tags": [
        "cs.CL"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.12129v1",
      "title": "Towards Personalized Bangla Book Recommendation: A Large-Scale Multi-Entity Book Graph Dataset",
      "link": "http://arxiv.org/abs/2602.12129v1",
      "pdf_link": "https://arxiv.org/pdf/2602.12129v1",
      "authors": "Rahin Arefin Ahmed, Md. Anik Chowdhury, Sakil Ahmed Sheikh Reza, Devnil Bhattacharjee, Muhammad Abdullah Adnan et al.",
      "institution": "",
      "abstract": "Personalized book recommendation in Bangla literature has been constrained by the lack of structured, large-scale, and publicly available datasets. This work introduces RokomariBG, a large-scale, multi-entity heterogeneous book graph dataset designed to support research on personalized recommendation in a low-resource language setting. The dataset comprises 127,302 books, 63,723 users, 16,601 authors, 1,515 categories, 2,757 publishers, and 209,602 reviews, connected through eight relation types and organized as a comprehensive knowledge graph.\n  To demonstrate the utility of the dataset, we provide a systematic benchmarking study on the Top-N recommendation task, evaluating a diverse set of representative recommendation models, including classical collaborative filtering methods, matrix factorization models, content-based approaches, graph neural networks, a hybrid matrix factorization model with side information, and a neural two-tower retrieval architecture. The benchmarking results highlight the importance of leveraging multi-relational structure and textual side information, with neural retrieval models achieving the strongest performance (NDCG@10 = 0.204). Overall, this work establishes a foundational benchmark and a publicly available resource for Bangla book recommendation research, enabling reproducible evaluation and future studies on recommendation in low-resource cultural domains. The dataset and code are publicly available at https://github.com/backlashblitz/Bangla-Book-Recommendation-Dataset",
      "source": "arXiv",
      "pubDateISO": "2026-02-12",
      "tags": [
        "cs.IR",
        "cs.LG"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.12128v1",
      "title": "HLA: Hadamard Linear Attention",
      "link": "http://arxiv.org/abs/2602.12128v1",
      "pdf_link": "https://arxiv.org/pdf/2602.12128v1",
      "authors": "Hanno Ackermann, Hong Cai, Mohsen Ghafoorian, Amirhossein Habibian",
      "institution": "",
      "abstract": "The attention mechanism is an important reason for the success of transformers. It relies on computing pairwise relations between tokens. To reduce the high computational cost of standard quadratic attention, linear attention has been proposed as an efficient approximation. It employs kernel functions that are applied independently to the inputs before the pairwise similarities are calculated. That allows for an efficient computational procedure which, however, amounts to a low-degree rational function approximating softmax.\n  We propose Hadamard Linear Attention (HLA). Unlike previous works on linear attention, the nonlinearity in HLA is not applied separately to queries and keys, but, analogously to standard softmax attention, after the pairwise similarities have been computed. It will be shown that the proposed nonlinearity amounts to a higher-degree rational function to approximate softmax. An efficient computational scheme for the proposed method is derived that is similar to that of standard linear attention. In contrast to other approaches, no time-consuming tensor reshaping is necessary to apply the proposed algorithm. The effectiveness of the approach is demonstrated by applying it to a large diffusion transformer model for video generation, an application that involves very large amounts of tokens.",
      "source": "arXiv",
      "pubDateISO": "2026-02-12",
      "tags": [
        "cs.AI"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.12127v1",
      "title": "PosterOmni: Generalized Artistic Poster Creation via Task Distillation and Unified Reward Feedback",
      "link": "http://arxiv.org/abs/2602.12127v1",
      "pdf_link": "https://arxiv.org/pdf/2602.12127v1",
      "authors": "Sixiang Chen, Jianyu Lai, Jialin Gao, Hengyu Shi, Zhongying Liu et al.",
      "institution": "",
      "abstract": "Image-to-poster generation is a high-demand task requiring not only local adjustments but also high-level design understanding. Models must generate text, layout, style, and visual elements while preserving semantic fidelity and aesthetic coherence. The process spans two regimes: local editing, where ID-driven generation, rescaling, filling, and extending must preserve concrete visual entities; and global creation, where layout- and style-driven tasks rely on understanding abstract design concepts. These intertwined demands make image-to-poster a multi-dimensional process coupling entity-preserving editing with concept-driven creation under image-prompt control. To address these challenges, we propose PosterOmni, a generalized artistic poster creation framework that unlocks the potential of a base edit model for multi-task image-to-poster generation. PosterOmni integrates the two regimes, namely local editing and global creation, within a single system through an efficient data-distillation-reward pipeline: (i) constructing multi-scenario image-to-poster datasets covering six task types across entity-based and concept-based creation; (ii) distilling knowledge between local and global experts for supervised fine-tuning; and (iii) applying unified PosterOmni Reward Feedback to jointly align visual entity-preserving and aesthetic preference across all tasks. Additionally, we establish PosterOmni-Bench, a unified benchmark for evaluating both local editing and global creation. Extensive experiments show that PosterOmni significantly enhances reference adherence, global composition quality, and aesthetic harmony, outperforming all open-source baselines and even surpassing several proprietary systems.",
      "source": "arXiv",
      "pubDateISO": "2026-02-12",
      "tags": [
        "cs.CV"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.12124v1",
      "title": "Capability-Oriented Training Induced Alignment Risk",
      "link": "http://arxiv.org/abs/2602.12124v1",
      "pdf_link": "https://arxiv.org/pdf/2602.12124v1",
      "authors": "Yujun Zhou, Yue Huang, Han Bao, Kehan Guo, Zhenwen Liang et al.",
      "institution": "",
      "abstract": "While most AI alignment research focuses on preventing models from generating explicitly harmful content, a more subtle risk is emerging: capability-oriented training induced exploitation. We investigate whether language models, when trained with reinforcement learning (RL) in environments with implicit loopholes, will spontaneously learn to exploit these flaws to maximize their reward, even without any malicious intent in their training. To test this, we design a suite of four diverse \"vulnerability games\", each presenting a unique, exploitable flaw related to context-conditional compliance, proxy metrics, reward tampering, and self-evaluation. Our experiments show that models consistently learn to exploit these vulnerabilities, discovering opportunistic strategies that significantly increase their reward at the expense of task correctness or safety. More critically, we find that these exploitative strategies are not narrow \"tricks\" but generalizable skills; they can be transferred to new tasks and even \"distilled\" from a capable teacher model to other student models through data alone. Our findings reveal that capability-oriented training induced risks pose a fundamental challenge to current alignment approaches, suggesting that future AI safety work must extend beyond content moderation to rigorously auditing and securing the training environments and reward mechanisms themselves. Code is available at https://github.com/YujunZhou/Capability_Oriented_Alignment_Risk.",
      "source": "arXiv",
      "pubDateISO": "2026-02-12",
      "tags": [
        "cs.LG",
        "cs.CL"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.12123v1",
      "title": "Meta-Sel: Efficient Demonstration Selection for In-Context Learning via Supervised Meta-Learning",
      "link": "http://arxiv.org/abs/2602.12123v1",
      "pdf_link": "https://arxiv.org/pdf/2602.12123v1",
      "authors": "Xubin Wang, Weijia Jia",
      "institution": "",
      "abstract": "Demonstration selection is a practical bottleneck in in-context learning (ICL): under a tight prompt budget, accuracy can change substantially depending on which few-shot examples are included, yet selection must remain cheap enough to run per query over large candidate pools. We propose Meta-Sel, a lightweight supervised meta-learning approach for intent classification that learns a fast, interpretable scoring function for (candidate, query) pairs from labeled training data.\n  Meta-Sel constructs a meta-dataset by sampling pairs from the training split and using class agreement as supervision, then trains a calibrated logistic regressor on two inexpensive meta-features: TF--IDF cosine similarity and a length-compatibility ratio. At inference time, the selector performs a single vectorized scoring pass over the full candidate pool and returns the top-k demonstrations, requiring no model fine-tuning, no online exploration, and no additional LLM calls. This yields deterministic rankings and makes the selection mechanism straightforward to audit via interpretable feature weights.\n  Beyond proposing Meta-Sel, we provide a broad empirical study of demonstration selection, benchmarking 12 methods -- spanning prompt engineering baselines, heuristic selection, reinforcement learning, and influence-based approaches -- across four intent datasets and five open-source LLMs. Across this benchmark, Meta-Sel consistently ranks among the top-performing methods, is particularly effective for smaller models where selection quality can partially compensate for limited model capacity, and maintains competitive selection-time overhead.",
      "source": "arXiv",
      "pubDateISO": "2026-02-12",
      "tags": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.12120v1",
      "title": "Commencing-Student Enrolment Forecasting Under Data Sparsity with Time Series Foundation Models",
      "link": "http://arxiv.org/abs/2602.12120v1",
      "pdf_link": "https://arxiv.org/pdf/2602.12120v1",
      "authors": "Jittarin Jetwiriyanon, Teo Susnjak, Surangika Ranathunga",
      "institution": "",
      "abstract": "Many universities face increasing financial pressure and rely on accurate forecasts of commencing enrolments. However, enrolment forecasting in higher education is often data-sparse; annual series are short and affected by reporting changes and regime shifts. Popular classical approaches can be unreliable, as parameter estimation and model selection are unstable with short samples, and structural breaks degrade extrapolation. Recently, TSFMs have provided zero-shot priors, delivering strong gains in annual, data-sparse institutional forecasting under leakage-disciplined covariate construction. We benchmark multiple TSFM families in a zero-shot setting and test a compact, leakage-safe covariate set and introduce the Institutional Operating Conditions Index (IOCI), a transferable 0-100 regime covariate derived from time-stamped documentary evidence available at each forecast origin, alongside Google Trends demand proxies with stabilising feature engineering. Using an expanding-window backtest with strict vintage alignment, covariate-conditioned TSFMs perform on par with classical benchmarks without institution-specific training, with performance differences varying by cohort and model.",
      "source": "arXiv",
      "pubDateISO": "2026-02-12",
      "tags": [
        "cs.AI"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.12117v1",
      "title": "KAN-FIF: Spline-Parameterized Lightweight Physics-based Tropical Cyclone Estimation on Meteorological Satellite",
      "link": "http://arxiv.org/abs/2602.12117v1",
      "pdf_link": "https://arxiv.org/pdf/2602.12117v1",
      "authors": "Jiakang Shen, Qinghui Chen, Runtong Wang, Chenrui Xu, Jinglin Zhang et al.",
      "institution": "",
      "abstract": "Tropical cyclones (TC) are among the most destructive natural disasters, causing catastrophic damage to coastal regions through extreme winds, heavy rainfall, and storm surges. Timely monitoring of tropical cyclones is crucial for reducing loss of life and property, yet it is hindered by the computational inefficiency and high parameter counts of existing methods on resource-constrained edge devices. Current physics-guided models suffer from linear feature interactions that fail to capture high-order polynomial relationships between TC attributes, leading to inflated model sizes and hardware incompatibility. To overcome these challenges, this study introduces the Kolmogorov-Arnold Network-based Feature Interaction Framework (KAN-FIF), a lightweight multimodal architecture that integrates MLP and CNN layers with spline-parameterized KAN layers. For Maximum Sustained Wind (MSW) prediction, experiments demonstrate that the KAN-FIF framework achieves a $94.8\\%$ reduction in parameters (0.99MB vs 19MB) and $68.7\\%$ faster inference per sample (2.3ms vs 7.35ms) compared to baseline model Phy-CoCo, while maintaining superior accuracy with $32.5\\%$ lower MAE. The offline deployment experiment of the FY-4 series meteorological satellite processor on the Qingyun-1000 development board achieved a 14.41ms per-sample inference latency with the KAN-FIF framework, demonstrating promising feasibility for operational TC monitoring and extending deployability to edge-device AI applications. The code is released at https://github.com/Jinglin-Zhang/KAN-FIF.",
      "source": "arXiv",
      "pubDateISO": "2026-02-12",
      "tags": [
        "cs.LG",
        "cs.AI"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.12113v1",
      "title": "Stop Unnecessary Reflection: Training LRMs for Efficient Reasoning with Adaptive Reflection and Length Coordinated Penalty",
      "link": "http://arxiv.org/abs/2602.12113v1",
      "pdf_link": "https://arxiv.org/pdf/2602.12113v1",
      "authors": "Zewei Yu, Lirong Gao, Yuke Zhu, Bo Zheng, Sheng Guo et al.",
      "institution": "",
      "abstract": "Large Reasoning Models (LRMs) have demonstrated remarkable performance on complex reasoning tasks by employing test-time scaling. However, they often generate over-long chains-of-thought that, driven by substantial reflections such as repetitive self-questioning and circular reasoning, lead to high token consumption, substantial computational overhead, and increased latency without improving accuracy, particularly in smaller models. Our observation reveals that increasing problem complexity induces more excessive and unnecessary reflection, which in turn reduces accuracy and increases token overhead. To address this challenge, we propose Adaptive Reflection and Length Coordinated Penalty (ARLCP), a novel reinforcement learning framework designed to dynamically balance reasoning efficiency and solution accuracy. ARLCP introduces two key innovations: (1) a reflection penalty that adaptively curtails unnecessary reflective steps while preserving essential reasoning, and (2) a length penalty calibrated to the estimated complexity of the problem. By coordinating these penalties, ARLCP encourages the model to generate more concise and effective reasoning paths. We evaluate our method on five mathematical reasoning benchmarks using DeepSeek-R1-Distill-Qwen-1.5B and DeepSeek-R1-Distill-Qwen-7B models. Experimental results show that ARLCP achieves a superior efficiency-accuracy trade-off compared to existing approaches. For the 1.5B model, it reduces the average response length by 53.1% while simultaneously improving accuracy by 5.8%. For the 7B model, it achieves a 35.0% reduction in length with a 2.7% accuracy gain. The code is released at https://github.com/ZeweiYu1/ARLCP .",
      "source": "arXiv",
      "pubDateISO": "2026-02-12",
      "tags": [
        "cs.AI",
        "cs.CL"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.12112v1",
      "title": "Few-Shot Design Optimization by Exploiting Auxiliary Information",
      "link": "http://arxiv.org/abs/2602.12112v1",
      "pdf_link": "https://arxiv.org/pdf/2602.12112v1",
      "authors": "Arjun Mani, Carl Vondrick, Richard Zemel",
      "institution": "",
      "abstract": "Many real-world design problems involve optimizing an expensive black-box function $f(x)$, such as hardware design or drug discovery. Bayesian Optimization has emerged as a sample-efficient framework for this problem. However, the basic setting considered by these methods is simplified compared to real-world experimental setups, where experiments often generate a wealth of useful information. We introduce a new setting where an experiment generates high-dimensional auxiliary information $h(x)$ along with the performance measure $f(x)$; moreover, a history of previously solved tasks from the same task family is available for accelerating optimization. A key challenge of our setting is learning how to represent and utilize $h(x)$ for efficiently solving new optimization tasks beyond the task history. We develop a novel approach for this setting based on a neural model which predicts $f(x)$ for unseen designs given a few-shot context containing observations of $h(x)$. We evaluate our method on two challenging domains, robotic hardware design and neural network hyperparameter tuning, and introduce a novel design problem and large-scale benchmark for the former. On both domains, our method utilizes auxiliary feedback effectively to achieve more accurate few-shot prediction and faster optimization of design tasks, significantly outperforming several methods for multi-task optimization.",
      "source": "arXiv",
      "pubDateISO": "2026-02-12",
      "tags": [
        "cs.LG"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.12107v1",
      "title": "On the Complexity of Offline Reinforcement Learning with $Q^\\star$-Approximation and Partial Coverage",
      "link": "http://arxiv.org/abs/2602.12107v1",
      "pdf_link": "https://arxiv.org/pdf/2602.12107v1",
      "authors": "Haolin Liu, Braham Snyder, Chen-Yu Wei",
      "institution": "",
      "abstract": "We study offline reinforcement learning under $Q^\\star$-approximation and partial coverage, a setting that motivates practical algorithms such as Conservative $Q$-Learning (CQL; Kumar et al., 2020) but has received limited theoretical attention. Our work is inspired by the following open question: \"Are $Q^\\star$-realizability and Bellman completeness sufficient for sample-efficient offline RL under partial coverage?\"\n  We answer in the negative by establishing an information-theoretic lower bound. Going substantially beyond this, we introduce a general framework that characterizes the intrinsic complexity of a given $Q^\\star$ function class, inspired by model-free decision-estimation coefficients (DEC) for online RL (Foster et al., 2023b; Liu et al., 2025b). This complexity recovers and improves the quantities underlying the guarantees of Chen and Jiang (2022) and Uehara et al. (2023), and extends to broader settings. Our decision-estimation decomposition can be combined with a wide range of $Q^\\star$ estimation procedures, modularizing and generalizing existing approaches.\n  Beyond the general framework, we make further contributions: By developing a novel second-order performance difference lemma, we obtain the first $ε^{-2}$ sample complexity under partial coverage for soft $Q$-learning, improving the $ε^{-4}$ bound of Uehara et al. (2023). We remove Chen and Jiang's (2022) need for additional online interaction when the value gap of $Q^\\star$ is unknown. We also give the first characterization of offline learnability for general low-Bellman-rank MDPs without Bellman completeness (Jiang et al., 2017; Du et al., 2021; Jin et al., 2021), a canonical setting in online RL that remains unexplored in offline RL except for special cases. Finally, we provide the first analysis for CQL under $Q^\\star$-realizability and Bellman completeness beyond the tabular case.",
      "source": "arXiv",
      "pubDateISO": "2026-02-12",
      "tags": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.12105v1",
      "title": "Iskra: A System for Inverse Geometry Processing",
      "link": "http://arxiv.org/abs/2602.12105v1",
      "pdf_link": "https://arxiv.org/pdf/2602.12105v1",
      "authors": "Ana Dodik, Ahmed H. Mahmoud, Justin Solomon",
      "institution": "",
      "abstract": "We propose a system for differentiating through solutions to geometry processing problems. Our system differentiates a broad class of geometric algorithms, exploiting existing fast problem-specific schemes common to geometry processing, including local-global and ADMM solvers. It is compatible with machine learning frameworks, opening doors to new classes of inverse geometry processing applications. We marry the scatter-gather approach to mesh processing with tensor-based workflows and rely on the adjoint method applied to user-specified imperative code to generate an efficient backward pass behind the scenes. We demonstrate our approach by differentiating through mean curvature flow, spectral conformal parameterization, geodesic distance computation, and as-rigid-as-possible deformation, examining usability and performance on these applications. Our system allows practitioners to differentiate through existing geometry processing algorithms without needing to reformulate them, resulting in low implementation effort, fast runtimes, and lower memory requirements than differentiable optimization tools not tailored to geometry processing.",
      "source": "arXiv",
      "pubDateISO": "2026-02-12",
      "tags": [
        "cs.GR",
        "cs.CV",
        "cs.LG"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.12100v1",
      "title": "AssetFormer: Modular 3D Assets Generation with Autoregressive Transformer",
      "link": "http://arxiv.org/abs/2602.12100v1",
      "pdf_link": "https://arxiv.org/pdf/2602.12100v1",
      "authors": "Lingting Zhu, Shengju Qian, Haidi Fan, Jiayu Dong, Zhenchao Jin et al.",
      "institution": "",
      "abstract": "The digital industry demands high-quality, diverse modular 3D assets, especially for user-generated content~(UGC). In this work, we introduce AssetFormer, an autoregressive Transformer-based model designed to generate modular 3D assets from textual descriptions. Our pilot study leverages real-world modular assets collected from online platforms. AssetFormer tackles the challenge of creating assets composed of primitives that adhere to constrained design parameters for various applications. By innovatively adapting module sequencing and decoding techniques inspired by language models, our approach enhances asset generation quality through autoregressive modeling. Initial results indicate the effectiveness of AssetFormer in streamlining asset creation for professional development and UGC scenarios. This work presents a flexible framework extendable to various types of modular 3D assets, contributing to the broader field of 3D content generation. The code is available at https://github.com/Advocate99/AssetFormer.",
      "source": "arXiv",
      "pubDateISO": "2026-02-12",
      "tags": [
        "cs.CV"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.12096v1",
      "title": "Multi Graph Search for High-Dimensional Robot Motion Planning",
      "link": "http://arxiv.org/abs/2602.12096v1",
      "pdf_link": "https://arxiv.org/pdf/2602.12096v1",
      "authors": "Itamar Mishani, Maxim Likhachev",
      "institution": "",
      "abstract": "Efficient motion planning for high-dimensional robotic systems, such as manipulators and mobile manipulators, is critical for real-time operation and reliable deployment. Although advances in planning algorithms have enhanced scalability to high-dimensional state spaces, these improvements often come at the cost of generating unpredictable, inconsistent motions or requiring excessive computational resources and memory. In this work, we introduce Multi-Graph Search (MGS), a search-based motion planning algorithm that generalizes classical unidirectional and bidirectional search to a multi-graph setting. MGS maintains and incrementally expands multiple implicit graphs over the state space, focusing exploration on high-potential regions while allowing initially disconnected subgraphs to be merged through feasible transitions as the search progresses. We prove that MGS is complete and bounded-suboptimal, and empirically demonstrate its effectiveness on a range of manipulation and mobile manipulation tasks. Demonstrations, benchmarks and code are available at https://multi-graph-search.github.io/.",
      "source": "arXiv",
      "pubDateISO": "2026-02-12",
      "tags": [
        "cs.RO",
        "cs.AI"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.12089v1",
      "title": "Choose Your Agent: Tradeoffs in Adopting AI Advisors, Coaches, and Delegates in Multi-Party Negotiation",
      "link": "http://arxiv.org/abs/2602.12089v1",
      "pdf_link": "https://arxiv.org/pdf/2602.12089v1",
      "authors": "Kehang Zhu, Lithium Thain, Vivian Tsai, James Wexler, Crystal Qian",
      "institution": "",
      "abstract": "As AI usage becomes more prevalent in social contexts, understanding agent-user interaction is critical to designing systems that improve both individual and group outcomes. We present an online behavioral experiment (N = 243) in which participants play three multi-turn bargaining games in groups of three. Each game, presented in randomized order, grants \\textit{access to} a single LLM assistance modality: proactive recommendations from an \\textit{Advisor}, reactive feedback from a \\textit{Coach}, or autonomous execution by a \\textit{Delegate}; all modalities are powered by an underlying LLM that achieves superhuman performance in an all-agent environment. On each turn, participants privately decide whether to act manually or use the AI modality available in that game. Despite preferring the \\textit{Advisor} modality, participants achieve the highest mean individual gains with the \\textit{Delegate}, demonstrating a preference-performance misalignment. Moreover, delegation generates positive externalities; even non-adopting users in \\textit{access-to-delegate} treatment groups benefit by receiving higher-quality offers. Mechanism analysis reveals that the \\textit{Delegate} agent acts as a market maker, injecting rational, Pareto-improving proposals that restructure the trading environment. Our research reveals a gap between agent capabilities and realized group welfare. While autonomous agents can exhibit super-human strategic performance, their impact on realized welfare gains can be constrained by interfaces, user perceptions, and adoption barriers. Assistance modalities should be designed as mechanisms with endogenous participation; adoption-compatible interaction rules are a prerequisite to improving human welfare with automated assistance.",
      "source": "arXiv",
      "pubDateISO": "2026-02-12",
      "tags": [
        "cs.GT",
        "cs.AI",
        "cs.HC"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.12087v1",
      "title": "Geometry of Uncertainty: Learning Metric Spaces for Multimodal State Estimation in RL",
      "link": "http://arxiv.org/abs/2602.12087v1",
      "pdf_link": "https://arxiv.org/pdf/2602.12087v1",
      "authors": "Alfredo Reichlin, Adriano Pacciarelli, Danica Kragic, Miguel Vasco",
      "institution": "",
      "abstract": "Estimating the state of an environment from high-dimensional, multimodal, and noisy observations is a fundamental challenge in reinforcement learning (RL). Traditional approaches rely on probabilistic models to account for the uncertainty, but often require explicit noise assumptions, in turn limiting generalization. In this work, we contribute a novel method to learn a structured latent representation, in which distances between states directly correlate with the minimum number of actions required to transition between them. The proposed metric space formulation provides a geometric interpretation of uncertainty without the need for explicit probabilistic modeling. To achieve this, we introduce a multimodal latent transition model and a sensor fusion mechanism based on inverse distance weighting, allowing for the adaptive integration of multiple sensor modalities without prior knowledge of noise distributions. We empirically validate the approach on a range of multimodal RL tasks, demonstrating improved robustness to sensor noise and superior state estimation compared to baseline methods. Our experiments show enhanced performance of an RL agent via the learned representation, eliminating the need of explicit noise augmentation. The presented results suggest that leveraging transition-aware metric spaces provides a principled and scalable solution for robust state estimation in sequential decision-making.",
      "source": "arXiv",
      "pubDateISO": "2026-02-12",
      "tags": [
        "cs.LG"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.12083v1",
      "title": "Differentiable Modal Logic for Multi-Agent Diagnosis, Orchestration and Communication",
      "link": "http://arxiv.org/abs/2602.12083v1",
      "pdf_link": "https://arxiv.org/pdf/2602.12083v1",
      "authors": "Antonin Sulc",
      "institution": "",
      "abstract": "As multi-agent AI systems evolve from simple chatbots to autonomous swarms, debugging semantic failures requires reasoning about knowledge, belief, causality, and obligation, precisely what modal logic was designed to formalize. However, traditional modal logic requires manual specification of relationship structures that are unknown or dynamic in real systems. This tutorial demonstrates differentiable modal logic (DML), implemented via Modal Logical Neural Networks (MLNNs), enabling systems to learn trust networks, causal chains, and regulatory boundaries from behavioral data alone.\n  We present a unified neurosymbolic debugging framework through four modalities: epistemic (who to trust), temporal (when events cause failures), deontic (what actions are permitted), and doxastic (how to interpret agent confidence). Each modality is demonstrated on concrete multi-agent scenarios, from discovering deceptive alliances in diplomacy games to detecting LLM hallucinations, with complete implementations showing how logical contradictions become learnable optimization objectives. Key contributions for the neurosymbolic community: (1) interpretable learned structures where trust and causality are explicit parameters, not opaque embeddings; (2) knowledge injection via differentiable axioms that guide learning with sparse data (3) compositional multi-modal reasoning that combines epistemic, temporal, and deontic constraints; and (4) practical deployment patterns for monitoring, active control and communication of multi-agent systems. All code provided as executable Jupyter notebooks.",
      "source": "arXiv",
      "pubDateISO": "2026-02-12",
      "tags": [
        "cs.AI",
        "cs.LO"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.12082v1",
      "title": "Empirical Gaussian Processes",
      "link": "http://arxiv.org/abs/2602.12082v1",
      "pdf_link": "https://arxiv.org/pdf/2602.12082v1",
      "authors": "Jihao Andreas Lin, Sebastian Ament, Louis C. Tiao, David Eriksson, Maximilian Balandat et al.",
      "institution": "",
      "abstract": "Gaussian processes (GPs) are powerful and widely used probabilistic regression models, but their effectiveness in practice is often limited by the choice of kernel function. This kernel function is typically handcrafted from a small set of standard functions, a process that requires expert knowledge, results in limited adaptivity to data, and imposes strong assumptions on the hypothesis space. We study Empirical GPs, a principled framework for constructing flexible, data-driven GP priors that overcome these limitations. Rather than relying on standard parametric kernels, we estimate the mean and covariance functions empirically from a corpus of historical observations, enabling the prior to reflect rich, non-trivial covariance structures present in the data. Theoretically, we show that the resulting model converges to the GP that is closest (in KL-divergence sense) to the real data generating process. Practically, we formulate the problem of learning the GP prior from independent datasets as likelihood estimation and derive an Expectation-Maximization algorithm with closed-form updates, allowing the model handle heterogeneous observation locations across datasets. We demonstrate that Empirical GPs achieve competitive performance on learning curve extrapolation and time series forecasting benchmarks.",
      "source": "arXiv",
      "pubDateISO": "2026-02-12",
      "tags": [
        "cs.LG",
        "stat.ML"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.12080v1",
      "title": "PathCRF: Ball-Free Soccer Event Detection via Possession Path Inference from Player Trajectories",
      "link": "http://arxiv.org/abs/2602.12080v1",
      "pdf_link": "https://arxiv.org/pdf/2602.12080v1",
      "authors": "Hyunsung Kim, Kunhee Lee, Sangwoo Seo, Sang-Ki Ko, Jinsung Yoon et al.",
      "institution": "",
      "abstract": "Despite recent advances in AI, event data collection in soccer still relies heavily on labor-intensive manual annotation. Although prior work has explored automatic event detection using player and ball trajectories, ball tracking also remains difficult to scale due to high infrastructural and operational costs. As a result, comprehensive data collection in soccer is largely confined to top-tier competitions, limiting the broader adoption of data-driven analysis in this domain. To address this challenge, this paper proposes PathCRF, a framework for detecting on-ball soccer events using only player tracking data. We model player trajectories as a fully connected dynamic graph and formulate event detection as the problem of selecting exactly one edge corresponding to the current possession state at each time step. To ensure logical consistency of the resulting edge sequence, we employ a Conditional Random Field (CRF) that forbids impossible transitions between consecutive edges. Both emission and transition scores dynamically computed from edge embeddings produced by a Set Attention-based backbone architecture. During inference, the most probable edge sequence is obtained via Viterbi decoding, and events such as ball controls or passes are detected whenever the selected edge changes between adjacent time steps. Experiments show that PathCRF produces accurate, logically consistent possession paths, enabling reliable downstream analyses while substantially reducing the need for manual event annotation. The source code is available at https://github.com/hyunsungkim-ds/pathcrf.git.",
      "source": "arXiv",
      "pubDateISO": "2026-02-12",
      "tags": [
        "cs.LG"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.12078v1",
      "title": "Tiny Recursive Reasoning with Mamba-2 Attention Hybrid",
      "link": "http://arxiv.org/abs/2602.12078v1",
      "pdf_link": "https://arxiv.org/pdf/2602.12078v1",
      "authors": "Wenlong Wang, Fergal Reid",
      "institution": "",
      "abstract": "Recent work on recursive reasoning models like TRM demonstrates that tiny networks (7M parameters) can achieve strong performance on abstract reasoning tasks through latent recursion -- iterative refinement in hidden representation space without emitting intermediate tokens. This raises a natural question about operator choice: Mamba-2's state space recurrence is itself a form of iterative refinement, making it a natural candidate for recursive reasoning -- but does introducing Mamba-2 into the recursive scaffold preserve reasoning capability? We investigate this by replacing the Transformer blocks in TRM with Mamba-2 hybrid operators while maintaining parameter parity (6.83M vs 6.86M parameters). On ARC-AGI-1, we find that the hybrid improves pass@2 (the official metric) by +2.0\\% (45.88\\% vs 43.88\\%) and consistently outperforms at higher K values (+4.75\\% at pass@100), whilst maintaining pass@1 parity. This suggests improved candidate coverage -- the model generates correct solutions more reliably -- with similar top-1 selection. Our results validate that Mamba-2 hybrid operators preserve reasoning capability within the recursive scaffold, establishing SSM-based operators as viable candidates in the recursive operator design space and taking a first step towards understanding the best mixing strategies for recursive reasoning.",
      "source": "arXiv",
      "pubDateISO": "2026-02-12",
      "tags": [
        "cs.AI",
        "cs.CL"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.12058v1",
      "title": "ModelWisdom: An Integrated Toolkit for TLA+ Model Visualization, Digest and Repair",
      "link": "http://arxiv.org/abs/2602.12058v1",
      "pdf_link": "https://arxiv.org/pdf/2602.12058v1",
      "authors": "Zhiyong Chen, Jialun Cao, Chang Xu, Shing-Chi Cheung",
      "institution": "",
      "abstract": "Model checking in TLA+ provides strong correctness guarantees, yet practitioners continue to face significant challenges in interpreting counterexamples, understanding large state-transition graphs, and repairing faulty models. These difficulties stem from the limited explainability of raw model-checker output and the substantial manual effort required to trace violations back to source specifications. Although the TLA+ Toolbox includes a state diagram viewer, it offers only a static, fully expanded graph without folding, color highlighting, or semantic explanations, which limits its scalability and interpretability. We present ModelWisdom, an interactive environment that uses visualization and large language models to make TLA+ model checking more interpretable and actionable. ModelWisdom offers: (i) Model Visualization, with colorized violation highlighting, click-through links from transitions to TLA+ code, and mapping between violating states and broken properties; (ii) Graph Optimization, including tree-based structuring and node/edge folding to manage large models; (iii) Model Digest, which summarizes and explains subgraphs via large language models (LLMs) and performs preprocessing and partial explanations; and (iv) Model Repair, which extracts error information and supports iterative debugging. Together, these capabilities turn raw model-checker output into an interactive, explainable workflow, improving understanding and reducing debugging effort for nontrivial TLA+ specifications. The website to ModelWisdom is available: https://model-wisdom.pages.dev. A demonstrative video can be found at https://www.youtube.com/watch?v=plyZo30VShA.",
      "source": "arXiv",
      "pubDateISO": "2026-02-12",
      "tags": [
        "cs.SE",
        "cs.AI",
        "cs.FL"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.12055v1",
      "title": "Multi UAVs Preflight Planning in a Shared and Dynamic Airspace",
      "link": "http://arxiv.org/abs/2602.12055v1",
      "pdf_link": "https://arxiv.org/pdf/2602.12055v1",
      "authors": "Amath Sow, Mauricio Rodriguez Cesen, Fabiola Martins Campos de Oliveira, Mariusz Wzorek, Daniel de Leng et al.",
      "institution": "",
      "abstract": "Preflight planning for large-scale Unmanned Aerial Vehicle (UAV) fleets in dynamic, shared airspace presents significant challenges, including temporal No-Fly Zones (NFZs), heterogeneous vehicle profiles, and strict delivery deadlines. While Multi-Agent Path Finding (MAPF) provides a formal framework, existing methods often lack the scalability and flexibility required for real-world Unmanned Traffic Management (UTM). We propose DTAPP-IICR: a Delivery-Time Aware Prioritized Planning method with Incremental and Iterative Conflict Resolution. Our framework first generates an initial solution by prioritizing missions based on urgency. Secondly, it computes roundtrip trajectories using SFIPP-ST, a novel 4D single-agent planner (Safe Flight Interval Path Planning with Soft and Temporal Constraints). SFIPP-ST handles heterogeneous UAVs, strictly enforces temporal NFZs, and models inter-agent conflicts as soft constraints. Subsequently, an iterative Large Neighborhood Search, guided by a geometric conflict graph, efficiently resolves any residual conflicts. A completeness-preserving directional pruning technique further accelerates the 3D search. On benchmarks with temporal NFZs, DTAPP-IICR achieves near-100% success with fleets of up to 1,000 UAVs and gains up to 50% runtime reduction from pruning, outperforming batch Enhanced Conflict-Based Search in the UTM context. Scaling successfully in realistic city-scale operations where other priority-based methods fail even at moderate deployments, DTAPP-IICR is positioned as a practical and scalable solution for preflight planning in dense, dynamic urban airspace.",
      "source": "arXiv",
      "pubDateISO": "2026-02-12",
      "tags": [
        "cs.AI",
        "cs.MA",
        "cs.RO"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.12049v1",
      "title": "Improving HPC Code Generation Capability of LLMs via Online Reinforcement Learning with Real-Machine Benchmark Rewards",
      "link": "http://arxiv.org/abs/2602.12049v1",
      "pdf_link": "https://arxiv.org/pdf/2602.12049v1",
      "authors": "Ryo Mikasa, Shun-ichiro Hayashi, Daichi Mukunoki, Tetsuya Hoshino, Takahiro Katagiri",
      "institution": "",
      "abstract": "Large language models (LLMs) have demonstrated strong code generation capabilities, yet the runtime performance of generated code is not guaranteed, and there have been few attempts to train LLMs using runtime performance as a reward in the HPC domain. We propose an online reinforcement learning approach that executes LLM-generated code on a supercomputer and directly feeds back the measured runtime performance (GFLOPS) as a reward. We further introduce a Staged Quality-Diversity (SQD) algorithm that progressively varies the permitted optimization techniques on a per-problem basis, enabling the model to learn code optimization from diverse perspectives. We build a distributed system connecting a GPU training cluster with a CPU benchmarking cluster, and train Qwen2.5 Coder 14B on a double-precision matrix multiplication task using Group Relative Policy Optimization (GRPO). Through two experiments, we show that reinforcement learning combining runtime performance feedback with staged optimization can improve the HPC code generation capability of LLMs.",
      "source": "arXiv",
      "pubDateISO": "2026-02-12",
      "tags": [
        "cs.LG"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.12047v1",
      "title": "Safety Beyond the Training Data: Robust Out-of-Distribution MPC via Conformalized System Level Synthesis",
      "link": "http://arxiv.org/abs/2602.12047v1",
      "pdf_link": "https://arxiv.org/pdf/2602.12047v1",
      "authors": "Anutam Srinivasan, Antoine Leeman, Glen Chou",
      "institution": "",
      "abstract": "We present a novel framework for robust out-of-distribution planning and control using conformal prediction (CP) and system level synthesis (SLS), addressing the challenge of ensuring safety and robustness when using learned dynamics models beyond the training data distribution. We first derive high-confidence model error bounds using weighted CP with a learned, state-control-dependent covariance model. These bounds are integrated into an SLS-based robust nonlinear model predictive control (MPC) formulation, which performs constraint tightening over the prediction horizon via volume-optimized forward reachable sets. We provide theoretical guarantees on coverage and robustness under distributional drift, and analyze the impact of data density and trajectory tube size on prediction coverage. Empirically, we demonstrate our method on nonlinear systems of increasing complexity, including a 4D car and a {12D} quadcopter, improving safety and robustness compared to fixed-bound and non-robust baselines, especially outside of the data distribution.",
      "source": "arXiv",
      "pubDateISO": "2026-02-12",
      "tags": [
        "cs.RO",
        "cs.LG"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.12045v1",
      "title": "Fourier Transformers for Latent Crystallographic Diffusion and Generative Modeling",
      "link": "http://arxiv.org/abs/2602.12045v1",
      "pdf_link": "https://arxiv.org/pdf/2602.12045v1",
      "authors": "Jed A. Duersch, Elohan Veillon, Astrid Klipfel, Adlane Sayede, Zied Bouraoui",
      "institution": "",
      "abstract": "The discovery of new crystalline materials calls for generative models that handle periodic boundary conditions, crystallographic symmetries, and physical constraints, while scaling to large and structurally diverse unit cells. We propose a reciprocal-space generative pipeline that represents crystals through a truncated Fourier transform of the species-resolved unit-cell density, rather than modeling atomic coordinates directly. This representation is periodicity-native, admits simple algebraic actions of space-group symmetries, and naturally supports variable atomic multiplicities during generation, addressing a common limitation of particle-based approaches. Using only nine Fourier basis functions per spatial dimension, our approach reconstructs unit cells containing up to 108 atoms per chemical species. We instantiate this pipeline with a transformer variational autoencoder over complex-valued Fourier coefficients, and a latent diffusion model that generates in the compressed latent space. We evaluate reconstruction and latent diffusion on the LeMaterial benchmark and compare unconditional generation against coordinate-based baselines in the small-cell regime ($\\leq 16$ atoms per unit cell).",
      "source": "arXiv",
      "pubDateISO": "2026-02-12",
      "tags": [
        "cs.LG",
        "cs.AI"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.12044v1",
      "title": "A DMD-Based Adaptive Modulation Method for High Dynamic Range Imaging in High-Glare Environments",
      "link": "http://arxiv.org/abs/2602.12044v1",
      "pdf_link": "https://arxiv.org/pdf/2602.12044v1",
      "authors": "Banglei Guan, Jing Tao, Liang Xu, Dongcai Tan, Pengju Sun et al.",
      "institution": "",
      "abstract": "Background The accuracy of photomechanics measurements critically relies on image quality,particularly under extreme illumination conditions such as welding arc monitoring and polished metallic surface analysis. High dynamic range (HDR) imaging above 120 dB is essential in these contexts. Conventional CCD/CMOS sensors, with dynamic ranges typically below 70 dB, are highly susceptible to saturation under glare, resulting in irreversible loss of detail and significant errors in digital image correlation (DIC). Methods This paper presents an HDR imaging system that leverages the spatial modulation capability of a digital micromirror device (DMD). The system architecture enables autonomous regional segmentation and adaptive exposure control for high-dynamic-range scenes through an integrated framework comprising two synergistic subsystems: a DMD-based optical modulation unit and an adaptive computational imaging pipeline. Results The system achieves a measurable dynamic range of 127 dB, effectively eliminating satu ration artifacts under high glare. Experimental results demonstrate a 78% reduction in strain error and improved DIC positioning accuracy, confirming reliable performance across extreme intensity variations. Conclusion The DMD-based system provides high fidelity adaptive HDR imaging, overcoming key limitations of conventional sensors. It exhibits strong potential for optical metrology and stress analysis in high-glare environments where traditional methods are inadequate.",
      "source": "arXiv",
      "pubDateISO": "2026-02-12",
      "tags": [
        "cs.CV"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.12043v1",
      "title": "Improved Inference for CSDID Using the Cluster Jackknife",
      "link": "http://arxiv.org/abs/2602.12043v1",
      "pdf_link": "https://arxiv.org/pdf/2602.12043v1",
      "authors": "Sunny R. Karim, Morten Ørregaard Nielsen, James G. MacKinnon, Matthew D. Webb",
      "institution": "",
      "abstract": "Obtaining reliable inferences with traditional difference-in-differences (DiD) methods can be difficult. Problems can arise when both outcomes and errors are serially correlated, when there are few clusters or few treated clusters, when cluster sizes vary greatly, and in various other cases. In recent years, recognition of the ``staggered adoption'' problem has shifted the focus away from inference towards consistent estimation of treatment effects. One of the most popular new estimators is the CSDID procedure of Callaway and Sant'Anna (2021). We find that the issues of over-rejection with few clusters and/or few treated clusters are at least as severe for CSDID as for traditional DiD methods. We also propose using a cluster jackknife for inference with CSDID, which simulations suggest greatly improves inference. We provide software packages in Stata csdidjack and R didjack to calculate cluster-jackknife standard errors easily.",
      "source": "arXiv",
      "pubDateISO": "2026-02-12",
      "tags": [
        "stat.ME",
        "stat.ML"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.12039v1",
      "title": "The Implicit Bias of Logit Regularization",
      "link": "http://arxiv.org/abs/2602.12039v1",
      "pdf_link": "https://arxiv.org/pdf/2602.12039v1",
      "authors": "Alon Beck, Yohai Bar Sinai, Noam Levi",
      "institution": "",
      "abstract": "Logit regularization, the addition a convex penalty directly in logit space, is widely used in modern classifiers, with label smoothing as a prominent example. While such methods often improve calibration and generalization, their mechanism remains under-explored. In this work, we analyze a general class of such logit regularizers in the context of linear classification, and demonstrate that they induce an implicit bias of logit clustering around finite per-sample targets. For Gaussian data, or whenever logits are sufficiently clustered, we prove that logit clustering drives the weight vector to align exactly with Fisher's Linear Discriminant. To demonstrate the consequences, we study a simple signal-plus-noise model in which this transition has dramatic effects: Logit regularization halves the critical sample complexity and induces grokking in the small-noise limit, while making generalization robust to noise. Our results extend the theoretical understanding of label smoothing and highlight the efficacy of a broader class of logit-regularization methods.",
      "source": "arXiv",
      "pubDateISO": "2026-02-12",
      "tags": [
        "stat.ML",
        "cs.LG"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.12038v1",
      "title": "An Empirical Study of the Imbalance Issue in Software Vulnerability Detection",
      "link": "http://arxiv.org/abs/2602.12038v1",
      "pdf_link": "https://arxiv.org/pdf/2602.12038v1",
      "authors": "Yuejun Guo, Qiang Hu, Qiang Tang, Yves Le Traon",
      "institution": "",
      "abstract": "Vulnerability detection is crucial to protect software security. Nowadays, deep learning (DL) is the most promising technique to automate this detection task, leveraging its superior ability to extract patterns and representations within extensive code volumes. Despite its promise, DL-based vulnerability detection remains in its early stages, with model performance exhibiting variability across datasets. Drawing insights from other well-explored application areas like computer vision, we conjecture that the imbalance issue (the number of vulnerable code is extremely small) is at the core of the phenomenon. To validate this, we conduct a comprehensive empirical study involving nine open-source datasets and two state-of-the-art DL models. The results confirm our conjecture. We also obtain insightful findings on how existing imbalance solutions perform in vulnerability detection. It turns out that these solutions perform differently as well across datasets and evaluation metrics. Specifically: 1) Focal loss is more suitable to improve the precision, 2) mean false error and class-balanced loss encourages the recall, and 3) random over-sampling facilitates the F1-measure. However, none of them excels across all metrics. To delve deeper, we explore external influences on these solutions and offer insights for developing new solutions.",
      "source": "arXiv",
      "pubDateISO": "2026-02-12",
      "tags": [
        "cs.SE",
        "cs.AI"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.12029v1",
      "title": "PrefillShare: A Shared Prefill Module for KV Reuse in Multi-LLM Disaggregated Serving",
      "link": "http://arxiv.org/abs/2602.12029v1",
      "pdf_link": "https://arxiv.org/pdf/2602.12029v1",
      "authors": "Sunghyeon Woo, Hoseung Kim, Sunghwan Shim, Minjung Jo, Hyunjoon Jeong et al.",
      "institution": "",
      "abstract": "Multi-agent systems increasingly orchestrate multiple specialized language models to solve complex real-world problems, often invoking them over a shared context. This execution pattern repeatedly processes the same prompt prefix across models. Consequently, each model redundantly executes the prefill stage and maintains its own key-value (KV) cache, increasing aggregate prefill load and worsening tail latency by intensifying prefill-decode interference in existing LLM serving stacks. Disaggregated serving reduces such interference by placing prefill and decode on separate GPUs, but disaggregation does not fundamentally eliminate inter-model redundancy in computation and KV storage for the same prompt. To address this issue, we propose PrefillShare, a novel algorithm that enables sharing the prefill stage across multiple models in a disaggregated setting. PrefillShare factorizes the model into prefill and decode modules, freezes the prefill module, and fine-tunes only the decode module. This design allows multiple task-specific models to share a prefill module and the KV cache generated for the same prompt. We further introduce a routing mechanism that enables effective prefill sharing across heterogeneous models in a vLLM-based disaggregated system. PrefillShare not only matches full fine-tuning accuracy on a broad range of tasks and models, but also delivers 4.5x lower p95 latency and 3.9x higher throughput in multi-model agent workloads.",
      "source": "arXiv",
      "pubDateISO": "2026-02-12",
      "tags": [
        "cs.LG",
        "cs.DC"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.12026v1",
      "title": "Protein Circuit Tracing via Cross-layer Transcoders",
      "link": "http://arxiv.org/abs/2602.12026v1",
      "pdf_link": "https://arxiv.org/pdf/2602.12026v1",
      "authors": "Darin Tsui, Kunal Talreja, Daniel Saeedi, Amirali Aghazadeh",
      "institution": "",
      "abstract": "Protein language models (pLMs) have emerged as powerful predictors of protein structure and function. However, the computational circuits underlying their predictions remain poorly understood. Recent mechanistic interpretability methods decompose pLM representations into interpretable features, but they treat each layer independently and thus fail to capture cross-layer computation, limiting their ability to approximate the full model. We introduce ProtoMech, a framework for discovering computational circuits in pLMs using cross-layer transcoders that learn sparse latent representations jointly across layers to capture the model's full computational circuitry. Applied to the pLM ESM2, ProtoMech recovers 82-89% of the original performance on protein family classification and function prediction tasks. ProtoMech then identifies compressed circuits that use <1% of the latent space while retaining up to 79% of model accuracy, revealing correspondence with structural and functional motifs, including binding, signaling, and stability. Steering along these circuits enables high-fitness protein design, surpassing baseline methods in more than 70% of cases. These results establish ProtoMech as a principled framework for protein circuit tracing.",
      "source": "arXiv",
      "pubDateISO": "2026-02-12",
      "tags": [
        "cs.LG"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.12023v1",
      "title": "Decomposition of Spillover Effects Under Misspecification:Pseudo-true Estimands and a Local--Global Extension",
      "link": "http://arxiv.org/abs/2602.12023v1",
      "pdf_link": "https://arxiv.org/pdf/2602.12023v1",
      "authors": "Yechan Park, Xiaodong Yang",
      "institution": "",
      "abstract": "Applied work with interference typically models outcomes as functions of own treatment and a low-dimensional exposure mapping of others' treatments, even when that mapping may be misspecified. This raises a basic question: what policy object are exposure-based estimands implicitly targeting, and how should we interpret their direct and spillover components relative to the underlying policy question? We take as primitive the marginal policy effect, defined as the effect of a small change in the treatment probability under the actual experimental design, and show that any researcher-chosen exposure mapping induces a unique pseudo-true outcome model. This model is the best approximation to the underlying potential outcomes that depends only on the user-chosen exposure. Utilizing that representation, the marginal policy effect admits a canonical decomposition into exposure-based direct and spillover effects, and each component provides its optimal approximation to the corresponding oracle objects that would be available if interference were fully known. We then focus on a setting that nests important empirical and theoretical applications in which both local network spillovers and global spillovers, such as market equilibrium, operate. There, the marginal policy effect further decomposes asymptotically into direct, local, and global channels. An important implication is that many existing methods are more robust than previously understood once we reinterpret their targets as channel-specific components of this pseudo-true policy estimand. Simulations and a semi-synthetic experiment calibrated to a large cash-transfer experiment show that these components can be recovered in realistic experimental designs.",
      "source": "arXiv",
      "pubDateISO": "2026-02-12",
      "tags": [
        "stat.ML"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.12021v1",
      "title": "Improved state mixing in higher-order and block diagonal linear recurrent networks",
      "link": "http://arxiv.org/abs/2602.12021v1",
      "pdf_link": "https://arxiv.org/pdf/2602.12021v1",
      "authors": "Igor Dubinin, Antonio Orvieto, Felix Effenberger",
      "institution": "",
      "abstract": "Linear recurrent networks (LRNNs) and linear state space models (SSMs) promise computational and memory efficiency on long-sequence modeling tasks, yet their diagonal state transitions limit expressivity. Dense and nonlinear architectures (e.g., LSTMs) on the other hand are provably more expressive, but computationally costly. Here, we explore how expressivity in LRNNs can be increased via richer state mixing across time and channels while maintaining competitive efficiency. Specifically, we introduce two structured LRNN architectures: (i) Higher-order Linear Recurrent Units (H-LRU), which generalize first-order recurrence to higher order, mixing multiple past states, and (ii) Block-Diagonal LRUs (BD-LRU), which enable dense intra-block channel mixing. Per-channel (H-LRU) or per-row (BD-LRU) L1-normalization of selective gates stabilizes training and allows for scaling window/block sizes. A parallel-scan implementation of the proposed architectures keeps the throughput competitive with diagonal LRNNs for moderate orders (H-LRU) and block sizes (BD-LRU). In synthetic sequence modeling tasks, the performance of BD-LRU matches or exceeds those of linear SSMs (Mamba), low-rank LRNNs (DeltaNet) and LSTM baselines, while H-LRU is found to be the most parameter-efficient in compression task. In both synthetic sequence modeling and language modeling, our results indicate that the structure of state mixing rather than width alone shapes expressivity of LRNNs, offering a practical route to closing the efficiency-expressivity gap in linear sequence models.",
      "source": "arXiv",
      "pubDateISO": "2026-02-12",
      "tags": [
        "cs.LG"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.12018v1",
      "title": "Artificial intelligence is creating a new global linguistic hierarchy",
      "link": "http://arxiv.org/abs/2602.12018v1",
      "pdf_link": "https://arxiv.org/pdf/2602.12018v1",
      "authors": "Giulia Occhini, Kumiko Tanaka-Ishii, Anna Barford, Refael Tikochinski, Songbo Hu et al.",
      "institution": "",
      "abstract": "Artificial intelligence (AI) has the potential to transform healthcare, education, governance and socioeconomic equity, but its benefits remain concentrated in a small number of languages (Bender, 2019; Blasi et al., 2022; Joshi et al., 2020; Ranathunga and de Silva, 2022; Young, 2015). Language AI - the technologies that underpin widely-used conversational systems such as ChatGPT - could provide major benefits if available in people's native languages, yet most of the world's 7,000+ linguistic communities currently lack access and face persistent digital marginalization. Here we present a global longitudinal analysis of social, economic and infrastructural conditions across languages to assess systemic inequalities in language AI. We first analyze the existence of AI resources for 6003 languages. We find that despite efforts of the community to broaden the reach of language technologies (Bapna et al., 2022; Costa-Jussà et al., 2022), the dominance of a handful of languages is exacerbating disparities on an unprecedented scale, with divides widening exponentially rather than narrowing. Further, we contrast the longitudinal diffusion of AI with that of earlier IT technologies, revealing a distinctive hype-driven pattern of spread. To translate our findings into practical insights and guide prioritization efforts, we introduce the Language AI Readiness Index (EQUATE), which maps the state of technological, socio-economic, and infrastructural prerequisites for AI deployment across languages. The index highlights communities where capacity exists but remains underutilized, and provides a framework for accelerating more equitable diffusion of language AI. Our work contributes to setting the baseline for a transition towards more sustainable and equitable language technologies.",
      "source": "arXiv",
      "pubDateISO": "2026-02-12",
      "tags": [
        "cs.CY",
        "cs.CL"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.12015v1",
      "title": "Disentangling Ambiguity from Instability in Large Language Models: A Clinical Text-to-SQL Case Study",
      "link": "http://arxiv.org/abs/2602.12015v1",
      "pdf_link": "https://arxiv.org/pdf/2602.12015v1",
      "authors": "Angelo Ziletti, Leonardo D'Ambrosi",
      "institution": "",
      "abstract": "Deploying large language models for clinical Text-to-SQL requires distinguishing two qualitatively different causes of output diversity: (i) input ambiguity that should trigger clarification, and (ii) model instability that should trigger human review. We propose CLUES, a framework that models Text-to-SQL as a two-stage process (interpretations --> answers) and decomposes semantic uncertainty into an ambiguity score and an instability score. The instability score is computed via the Schur complement of a bipartite semantic graph matrix. Across AmbigQA/SituatedQA (gold interpretations) and a clinical Text-to-SQL benchmark (known interpretations), CLUES improves failure prediction over state-of-the-art Kernel Language Entropy. In deployment settings, it remains competitive while providing a diagnostic decomposition unavailable from a single score. The resulting uncertainty regimes map to targeted interventions - query refinement for ambiguity, model improvement for instability. The high-ambiguity/high-instability regime contains 51% of errors while covering 25% of queries, enabling efficient triage.",
      "source": "arXiv",
      "pubDateISO": "2026-02-12",
      "tags": [
        "cs.CL"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.12014v1",
      "title": "FedGRPO: Privately Optimizing Foundation Models with Group-Relative Rewards from Domain Client",
      "link": "http://arxiv.org/abs/2602.12014v1",
      "pdf_link": "https://arxiv.org/pdf/2602.12014v1",
      "authors": "Gongxi Zhu, Hanlin Gu, Lixin Fan, Qiang Yang, Yuxing Han",
      "institution": "",
      "abstract": "One important direction of Federated Foundation Models (FedFMs) is leveraging data from small client models to enhance the performance of a large server-side foundation model. Existing methods based on model level or representation level knowledge transfer either require expensive local training or incur high communication costs and introduce unavoidable privacy risks. We reformulate this problem as a reinforcement learning style evaluation process and propose FedGRPO, a privacy preserving framework comprising two modules. The first module performs competence-based expert selection by building a lightweight confidence graph from auxiliary data to identify the most suitable clients for each question. The second module leverages the \"Group Relative\" concept from the Group Relative Policy Optimization (GRPO) framework by packaging each question together with its solution rationale into candidate policies, dispatching these policies to a selected subset of expert clients, and aggregating solely the resulting scalar reward signals via a federated group-relative loss function. By exchanging reward values instead of data or model updates, FedGRPO reduces privacy risk and communication overhead while enabling parallel evaluation across heterogeneous devices. Empirical results on diverse domain tasks demonstrate that FedGRPO achieves superior downstream accuracy and communication efficiency compared to conventional FedFMs baselines.",
      "source": "arXiv",
      "pubDateISO": "2026-02-12",
      "tags": [
        "cs.LG"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.12013v1",
      "title": "InjectRBP: Steering Large Language Model Reasoning Behavior via Pattern Injection",
      "link": "http://arxiv.org/abs/2602.12013v1",
      "pdf_link": "https://arxiv.org/pdf/2602.12013v1",
      "authors": "Xiuping Wu, Zhao Yu, Yuxin Cheng, Ngai Wong, Liangjun Ke et al.",
      "institution": "",
      "abstract": "Reasoning can significantly enhance the performance of Large Language Models. While recent studies have exploited behavior-related prompts adjustment to enhance reasoning, these designs remain largely intuitive and lack a systematic analysis of the underlying behavioral patterns. Motivated by this, we investigate how models' reasoning behaviors shape reasoning from the perspective of behavioral patterns. We observe that models exhibit adaptive distributions of reasoning behaviors when responding to specific types of questions, and that structurally injecting these patterns can substantially influence the quality of the models' reasoning processes and outcomes. Building on these findings, we propose two optimization methods that require no parameter updates: InjectCorrect and InjectRLOpt. InjectCorrect guides the model by imitating behavioral patterns derived from its own past correct answers. InjectRLOpt learns a value function from historical behavior-pattern data and, via our proposed Reliability-Aware Softmax Policy, generates behavioral injectant during inference to steer the reasoning process. Our experiments demonstrate that both methods can improve model performance across various reasoning tasks without requiring any modifications to model parameters, achieving gains of up to 5.34% and 8.67%, respectively.",
      "source": "arXiv",
      "pubDateISO": "2026-02-12",
      "tags": [
        "cs.AI"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.12009v1",
      "title": "On the Sensitivity of Firing Rate-Based Federated Spiking Neural Networks to Differential Privacy",
      "link": "http://arxiv.org/abs/2602.12009v1",
      "pdf_link": "https://arxiv.org/pdf/2602.12009v1",
      "authors": "Luiz Pereira, Mirko Perkusich, Dalton Valadares, Kyller Gorgônio",
      "institution": "",
      "abstract": "Federated Neuromorphic Learning (FNL) enables energy-efficient and privacy-preserving learning on devices without centralizing data. However, real-world deployments require additional privacy mechanisms that can significantly alter training signals. This paper analyzes how Differential Privacy (DP) mechanisms, specifically gradient clipping and noise injection, perturb firing-rate statistics in Spiking Neural Networks (SNNs) and how these perturbations are propagated to rate-based FNL coordination. On a speech recognition task under non-IID settings, ablations across privacy budgets and clipping bounds reveal systematic rate shifts, attenuated aggregation, and ranking instability during client selection. Moreover, we relate these shifts to sparsity and memory indicators. Our findings provide actionable guidance for privacy-preserving FNL, specifically regarding the balance between privacy strength and rate-dependent coordination.",
      "source": "arXiv",
      "pubDateISO": "2026-02-12",
      "tags": [
        "cs.LG",
        "cs.AI"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.12005v1",
      "title": "LaCy: What Small Language Models Can and Should Learn is Not Just a Question of Loss",
      "link": "http://arxiv.org/abs/2602.12005v1",
      "pdf_link": "https://arxiv.org/pdf/2602.12005v1",
      "authors": "Szilvia Ujváry, Louis Béthune, Pierre Ablin, João Monteiro, Marco Cuturi et al.",
      "institution": "",
      "abstract": "Language models have consistently grown to compress more world knowledge into their parameters, but the knowledge that can be pretrained into them is upper-bounded by their parameter size. Especially the capacity of Small Language Models (SLMs) is limited, leading to factually incorrect generations. This problem is often mitigated by giving the SLM access to an outside source: the ability to query a larger model, documents, or a database. Under this setting, we study the fundamental question of \\emph{which tokens an SLM can and should learn} during pretraining, versus \\emph{which ones it should delegate} via a \\texttt{<CALL>} token. We find that this is not simply a question of loss: although the loss is predictive of whether a predicted token mismatches the ground-truth, some tokens are \\emph{acceptable} in that they are truthful alternative continuations of a pretraining document, and should not trigger a \\texttt{<CALL>} even if their loss is high. We find that a spaCy grammar parser can help augment the loss signal to decide which tokens the SLM should learn to delegate to prevent factual errors and which are safe to learn and predict even under high losses. We propose LaCy, a novel pretraining method based on this token selection philosophy. Our experiments demonstrate that LaCy models successfully learn which tokens to predict and where to delegate for help. This results in higher FactScores when generating in a cascade with a bigger model and outperforms Rho or LLM-judge trained SLMs, while being simpler and cheaper.",
      "source": "arXiv",
      "pubDateISO": "2026-02-12",
      "tags": [
        "cs.CL"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.12004v1",
      "title": "CSEval: A Framework for Evaluating Clinical Semantics in Text-to-Image Generation",
      "link": "http://arxiv.org/abs/2602.12004v1",
      "pdf_link": "https://arxiv.org/pdf/2602.12004v1",
      "authors": "Robert Cronshaw, Konstantinos Vilouras, Junyu Yan, Yuning Du, Feng Chen et al.",
      "institution": "",
      "abstract": "Text-to-image generation has been increasingly applied in medical domains for various purposes such as data augmentation and education. Evaluating the quality and clinical reliability of these generated images is essential. However, existing methods mainly assess image realism or diversity, while failing to capture whether the generated images reflect the intended clinical semantics, such as anatomical location and pathology. In this study, we propose the Clinical Semantics Evaluator (CSEval), a framework that leverages language models to assess clinical semantic alignment between the generated images and their conditioning prompts. Our experiments show that CSEval identifies semantic inconsistencies overlooked by other metrics and correlates with expert judgment. CSEval provides a scalable and clinically meaningful complement to existing evaluation methods, supporting the safe adoption of generative models in healthcare.",
      "source": "arXiv",
      "pubDateISO": "2026-02-12",
      "tags": [
        "cs.AI"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.12003v1",
      "title": "Projected Representation Conditioning for High-fidelity Novel View Synthesis",
      "link": "http://arxiv.org/abs/2602.12003v1",
      "pdf_link": "https://arxiv.org/pdf/2602.12003v1",
      "authors": "Min-Seop Kwak, Minkyung Kwon, Jinhyeok Choi, Jiho Park, Seungryong Kim",
      "institution": "",
      "abstract": "We propose a novel framework for diffusion-based novel view synthesis in which we leverage external representations as conditions, harnessing their geometric and semantic correspondence properties for enhanced geometric consistency in generated novel viewpoints. First, we provide a detailed analysis exploring the correspondence capabilities emergent in the spatial attention of external visual representations. Building from these insights, we propose a representation-guided novel view synthesis through dedicated representation projection modules that inject external representations into the diffusion process, a methodology named ReNoV, short for representation-guided novel view synthesis. Our experiments show that this design yields marked improvements in both reconstruction fidelity and inpainting quality, outperforming prior diffusion-based novel-view methods on standard benchmarks and enabling robust synthesis from sparse, unposed image collections.",
      "source": "arXiv",
      "pubDateISO": "2026-02-12",
      "tags": [
        "cs.CV"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.12002v1",
      "title": "Can Local Vision-Language Models improve Activity Recognition over Vision Transformers? -- Case Study on Newborn Resuscitation",
      "link": "http://arxiv.org/abs/2602.12002v1",
      "pdf_link": "https://arxiv.org/pdf/2602.12002v1",
      "authors": "Enrico Guerriero, Kjersti Engan, Øyvind Meinich-Bache",
      "institution": "",
      "abstract": "Accurate documentation of newborn resuscitation is essential for quality improvement and adherence to clinical guidelines, yet remains underutilized in practice. Previous work using 3D-CNNs and Vision Transformers (ViT) has shown promising results in detecting key activities from newborn resuscitation videos, but also highlighted the challenges in recognizing such fine-grained activities. This work investigates the potential of generative AI (GenAI) methods to improve activity recognition from such videos. Specifically, we explore the use of local vision-language models (VLMs), combined with large language models (LLMs), and compare them to a supervised TimeSFormer baseline. Using a simulated dataset comprising 13.26 hours of newborn resuscitation videos, we evaluate several zero-shot VLM-based strategies and fine-tuned VLMs with classification heads, including Low-Rank Adaptation (LoRA). Our results suggest that small (local) VLMs struggle with hallucinations, but when fine-tuned with LoRA, the results reach F1 score at 0.91, surpassing the TimeSformer results of 0.70.",
      "source": "arXiv",
      "pubDateISO": "2026-02-12",
      "tags": [
        "cs.CV"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.11995v1",
      "title": "Momentum LMS Theory beyond Stationarity: Stability, Tracking, and Regret",
      "link": "http://arxiv.org/abs/2602.11995v1",
      "pdf_link": "https://arxiv.org/pdf/2602.11995v1",
      "authors": "Yifei Jin, Xin Zheng, Lei Guo",
      "institution": "",
      "abstract": "In large-scale data processing scenarios, data often arrive in sequential streams generated by complex systems that exhibit drifting distributions and time-varying system parameters. This nonstationarity challenges theoretical analysis, as it violates classical assumptions of i.i.d. (independent and identically distributed) samples, necessitating algorithms capable of real-time updates without expensive retraining. An effective approach should process each sample in a single pass, while maintaining computational and memory complexities independent of the data stream length. Motivated by these challenges, this paper investigates the Momentum Least Mean Squares (MLMS) algorithm as an adaptive identification tool, leveraging its computational simplicity and online processing capabilities. Theoretically, we derive tracking performance and regret bounds for the MLMS in time-varying stochastic linear systems under various practical conditions. Unlike classical LMS, whose stability can be characterized by first-order random vector difference equations, MLMS introduces an additional dynamical state due to momentum, leading to second-order time-varying random vector difference equations whose stability analysis hinges on more complicated products of random matrices, which poses a substantially challenging problem to resolve. Experiments on synthetic and real-world data streams demonstrate that MLMS achieves rapid adaptation and robust tracking, in agreement with our theoretical results especially in nonstationary settings, highlighting its promise for modern streaming and online learning applications.",
      "source": "arXiv",
      "pubDateISO": "2026-02-12",
      "tags": [
        "cs.LG"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.11988v1",
      "title": "Evaluating AGENTS.md: Are Repository-Level Context Files Helpful for Coding Agents?",
      "link": "http://arxiv.org/abs/2602.11988v1",
      "pdf_link": "https://arxiv.org/pdf/2602.11988v1",
      "authors": "Thibaud Gloaguen, Niels Mündler, Mark Müller, Veselin Raychev, Martin Vechev",
      "institution": "",
      "abstract": "A widespread practice in software development is to tailor coding agents to repositories using context files, such as AGENTS.md, by either manually or automatically generating them. Although this practice is strongly encouraged by agent developers, there is currently no rigorous investigation into whether such context files are actually effective for real-world tasks. In this work, we study this question and evaluate coding agents' task completion performance in two complementary settings: established SWE-bench tasks from popular repositories, with LLM-generated context files following agent-developer recommendations, and a novel collection of issues from repositories containing developer-committed context files.\n  Across multiple coding agents and LLMs, we find that context files tend to reduce task success rates compared to providing no repository context, while also increasing inference cost by over 20%. Behaviorally, both LLM-generated and developer-provided context files encourage broader exploration (e.g., more thorough testing and file traversal), and coding agents tend to respect their instructions. Ultimately, we conclude that unnecessary requirements from context files make tasks harder, and human-written context files should describe only minimal requirements.",
      "source": "arXiv",
      "pubDateISO": "2026-02-12",
      "tags": [
        "cs.SE",
        "cs.AI"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.11982v1",
      "title": "Automatic Simplification of Common Vulnerabilities and Exposures Descriptions",
      "link": "http://arxiv.org/abs/2602.11982v1",
      "pdf_link": "https://arxiv.org/pdf/2602.11982v1",
      "authors": "Varpu Vehomäki, Kimmo K. Kaski",
      "institution": "",
      "abstract": "Understanding cyber security is increasingly important for individuals and organizations. However, a lot of information related to cyber security can be difficult to understand to those not familiar with the topic. In this study, we focus on investigating how large language models (LLMs) could be utilized in automatic text simplification (ATS) of Common Vulnerability and Exposure (CVE) descriptions. Automatic text simplification has been studied in several contexts, such as medical, scientific, and news texts, but it has not yet been studied to simplify texts in the rapidly changing and complex domain of cyber security. We created a baseline for cyber security ATS and a test dataset of 40 CVE descriptions, evaluated by two groups of cyber security experts in two survey rounds. We have found that while out-of-the box LLMs can make the text appear simpler, they struggle with meaning preservation. Code and data are available at https://version.aalto.fi/gitlab/vehomav1/simplification\\_nmi.",
      "source": "arXiv",
      "pubDateISO": "2026-02-12",
      "tags": [
        "cs.CL"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.11980v1",
      "title": "Spatial Chain-of-Thought: Bridging Understanding and Generation Models for Spatial Reasoning Generation",
      "link": "http://arxiv.org/abs/2602.11980v1",
      "pdf_link": "https://arxiv.org/pdf/2602.11980v1",
      "authors": "Wei Chen, Yancheng Long, Mingqiao Liu, Haojie Ding, Yankai Yang et al.",
      "institution": "",
      "abstract": "While diffusion models have shown exceptional capabilities in aesthetic image synthesis, they often struggle with complex spatial understanding and reasoning. Existing approaches resort to Multimodal Large Language Models (MLLMs) to enhance this capability. However, they either incur high computational costs through joint training or suffer from spatial information loss when relying solely on textual prompts. To alleviate these limitations, we propose a Spatial Chain-of-Thought (SCoT) framework, a plug-and-play approach that effectively bridges the reasoning capabilities of MLLMs with the generative power of diffusion models. Specifically, we first enhance the diffusion model's layout awareness by training it on an interleaved text-coordinate instruction format. We then leverage state-of-the-art MLLMs as planners to generate comprehensive layout plans, transferring their spatial planning capabilities directly to the generation process. Extensive experiments demonstrate that our method achieves state-of-the-art performance on image generation benchmarks and significantly outperforms baselines on complex reasoning tasks, while also showing strong efficacy in image editing scenarios.",
      "source": "arXiv",
      "pubDateISO": "2026-02-12",
      "tags": [
        "cs.CV"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.11978v1",
      "title": "Accelerating Robotic Reinforcement Learning with Agent Guidance",
      "link": "http://arxiv.org/abs/2602.11978v1",
      "pdf_link": "https://arxiv.org/pdf/2602.11978v1",
      "authors": "Haojun Chen, Zili Zou, Chengdong Ma, Yaoxiang Pu, Haotong Zhang et al.",
      "institution": "",
      "abstract": "Reinforcement Learning (RL) offers a powerful paradigm for autonomous robots to master generalist manipulation skills through trial-and-error. However, its real-world application is stifled by severe sample inefficiency. Recent Human-in-the-Loop (HIL) methods accelerate training by using human corrections, yet this approach faces a scalability barrier. Reliance on human supervisors imposes a 1:1 supervision ratio that limits fleet expansion, suffers from operator fatigue over extended sessions, and introduces high variance due to inconsistent human proficiency. We present Agent-guided Policy Search (AGPS), a framework that automates the training pipeline by replacing human supervisors with a multimodal agent. Our key insight is that the agent can be viewed as a semantic world model, injecting intrinsic value priors to structure physical exploration. By using executable tools, the agent provides precise guidance via corrective waypoints and spatial constraints for exploration pruning. We validate our approach on two tasks, ranging from precision insertion to deformable object manipulation. Results demonstrate that AGPS outperforms HIL methods in sample efficiency. This automates the supervision pipeline, unlocking the path to labor-free and scalable robot learning. Project website: https://agps-rl.github.io/agps.",
      "source": "arXiv",
      "pubDateISO": "2026-02-12",
      "tags": [
        "cs.RO",
        "cs.AI"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.11973v1",
      "title": "Calibrated Bayesian Deep Learning for Explainable Decision Support Systems Based on Medical Imaging",
      "link": "http://arxiv.org/abs/2602.11973v1",
      "pdf_link": "https://arxiv.org/pdf/2602.11973v1",
      "authors": "Hua Xu, Julián D. Arias-Londoño, Juan I. Godino-Llorente",
      "institution": "",
      "abstract": "In critical decision support systems based on medical imaging, the reliability of AI-assisted decision-making is as relevant as predictive accuracy. Although deep learning models have demonstrated significant accuracy, they frequently suffer from miscalibration, manifested as overconfidence in erroneous predictions. To facilitate clinical acceptance, it is imperative that models quantify uncertainty in a manner that correlates with prediction correctness, allowing clinicians to identify unreliable outputs for further review. In order to address this necessity, the present paper proposes a generalizable probabilistic optimization framework grounded in Bayesian deep learning. Specifically, a novel Confidence-Uncertainty Boundary Loss (CUB-Loss) is introduced that imposes penalties on high-certainty errors and low-certainty correct predictions, explicitly enforcing alignment between prediction correctness and uncertainty estimates. Complementing this training-time optimization, a Dual Temperature Scaling (DTS) strategy is devised for post-hoc calibration, further refining the posterior distribution to improve intuitive explainability. The proposed framework is validated on three distinct medical imaging tasks: automatic screening of pneumonia, diabetic retinopathy detection, and identification of skin lesions. Empirical results demonstrate that the proposed approach achieves consistent calibration improvements across diverse modalities, maintains robust performance in data-scarce scenarios, and remains effective on severely imbalanced datasets, underscoring its potential for real clinical deployment.",
      "source": "arXiv",
      "pubDateISO": "2026-02-12",
      "tags": [
        "cs.CV",
        "cs.LG"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.11969v1",
      "title": "UPDA: Unsupervised Progressive Domain Adaptation for No-Reference Point Cloud Quality Assessment",
      "link": "http://arxiv.org/abs/2602.11969v1",
      "pdf_link": "https://arxiv.org/pdf/2602.11969v1",
      "authors": "Bingxu Xie, Fang Zhou, Jincan Wu, Yonghui Liu, Weiqing Li et al.",
      "institution": "",
      "abstract": "While no-reference point cloud quality assessment (NR-PCQA) approaches have achieved significant progress over the past decade, their performance often degrades substantially when a distribution gap exists between the training (source domain) and testing (target domain) data. However, to date, limited attention has been paid to transferring NR-PCQA models across domains. To address this challenge, we propose the first unsupervised progressive domain adaptation (UPDA) framework for NR-PCQA, which introduces a two-stage coarse-to-fine alignment paradigm to address domain shifts. At the coarse-grained stage, a discrepancy-aware coarse-grained alignment method is designed to capture relative quality relationships between cross-domain samples through a novel quality-discrepancy-aware hybrid loss, circumventing the challenges of direct absolute feature alignment. At the fine-grained stage, a perception fusion fine-grained alignment approach with symmetric feature fusion is developed to identify domain-invariant features, while a conditional discriminator selectively enhances the transfer of quality-relevant features. Extensive experiments demonstrate that the proposed UPDA effectively enhances the performance of NR-PCQA methods in cross-domain scenarios, validating its practical applicability. The code is available at https://github.com/yokeno1/UPDA-main.",
      "source": "arXiv",
      "pubDateISO": "2026-02-12",
      "tags": [
        "cs.CV",
        "cs.MM"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.11968v1",
      "title": "DHPLT: large-scale multilingual diachronic corpora and word representations for semantic change modelling",
      "link": "http://arxiv.org/abs/2602.11968v1",
      "pdf_link": "https://arxiv.org/pdf/2602.11968v1",
      "authors": "Mariia Fedorova, Andrey Kutuzov, Khonzoda Umarova",
      "institution": "",
      "abstract": "In this resource paper, we present DHPLT, an open collection of diachronic corpora in 41 diverse languages. DHPLT is based on the web-crawled HPLT datasets; we use web crawl timestamps as the approximate signal of document creation time. The collection covers three time periods: 2011-2015, 2020-2021 and 2024-present (1 million documents per time period for each language). We additionally provide pre-computed word type and token embeddings and lexical substitutions for our chosen target words, while at the same time leaving it open for the other researchers to come up with their own target words using the same datasets. DHPLT aims at filling in the current lack of multilingual diachronic corpora for semantic change modelling (beyond a dozen of high-resource languages). It opens the way for a variety of new experimental setups in this field. All the resources described in this paper are available at https://data.hplt-project.org/three/diachronic/, sorted by language.",
      "source": "arXiv",
      "pubDateISO": "2026-02-12",
      "tags": [
        "cs.CL"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.11965v1",
      "title": "Manifold-Aware Temporal Domain Generalization for Large Language Models",
      "link": "http://arxiv.org/abs/2602.11965v1",
      "pdf_link": "https://arxiv.org/pdf/2602.11965v1",
      "authors": "Yiheng Yao, Zekun Cai, Xinyuan Song, Hiroki Hill Kobayashi, Xuan Song et al.",
      "institution": "",
      "abstract": "Temporal distribution shifts are pervasive in real-world deployments of Large Language Models (LLMs), where data evolves continuously over time. While Temporal Domain Generalization (TDG) seeks to model such structured evolution, existing approaches characterize model adaptation in the full parameter space. This formulation becomes computationally infeasible for modern LLMs. This paper introduces a geometric reformulation of TDG under parameter-efficient fine-tuning. We establish that the low-dimensional temporal structure underlying model evolution can be preserved under parameter-efficient reparameterization, enabling temporal modeling without operating in the ambient parameter space. Building on this principle, we propose Manifold-aware Temporal LoRA (MaT-LoRA), which constrains temporal updates to a shared low-dimensional manifold within a low-rank adaptation subspace, and models its evolution through a structured temporal core. This reparameterization dramatically reduces temporal modeling complexity while retaining expressive power. Extensive experiments on synthetic and real-world datasets, including scientific documents, news publishers, and review ratings, demonstrate that MaT-LoRA achieves superior temporal generalization performance with practical scalability for LLMs.",
      "source": "arXiv",
      "pubDateISO": "2026-02-12",
      "tags": [
        "cs.LG",
        "cs.AI"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.11961v1",
      "title": "Scaling Model and Data for Multilingual Machine Translation with Open Large Language Models",
      "link": "http://arxiv.org/abs/2602.11961v1",
      "pdf_link": "https://arxiv.org/pdf/2602.11961v1",
      "authors": "Yuzhe Shang, Pengzhi Gao, Wei Liu, Jian Luan, Jinsong Su",
      "institution": "",
      "abstract": "Open large language models (LLMs) have demonstrated improving multilingual capabilities in recent years. In this paper, we present a study of open LLMs for multilingual machine translation (MT) across a range of languages, and investigate the effects of model scaling and data scaling when adapting open LLMs to multilingual MT through continual pretraining and instruction finetuning. Based on the Gemma3 model family, we develop MiLMMT-46, which achieves top-tier multilingual translation performance across 46 languages. Extensive experiments show that MiLMMT-46 consistently outperforms recent state-of-the-art (SOTA) models, including Seed-X, HY-MT-1.5, and TranslateGemma, and achieves competitive performance with strong proprietary systems such as Google Translate and Gemini 3 Pro.",
      "source": "arXiv",
      "pubDateISO": "2026-02-12",
      "tags": [
        "cs.CL"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.11960v1",
      "title": "Benchmarking Vision-Language Models for French PDF-to-Markdown Conversion",
      "link": "http://arxiv.org/abs/2602.11960v1",
      "pdf_link": "https://arxiv.org/pdf/2602.11960v1",
      "authors": "Bruno Rigal, Victor Dupriez, Alexis Mignon, Ronan Le Hy, Nicolas Mery",
      "institution": "",
      "abstract": "This report evaluates PDF-to-Markdown conversion using recent Vision-Language Models (VLMs) on challenging French documents. Document parsing is a critical step for Retrieval-Augmented Generation (RAG) pipelines, where transcription and layout errors propagate to downstream retrieval and grounding. Existing benchmarks often emphasize English or Chinese and can over-penalize benign formatting and linearization choices (e.g., line breaks, list segmentation, alternative table renderings) that are largely irrelevant for downstream use.\n  We introduce a French-focused benchmark of difficult pages selected via model-disagreement sampling from a corpus of 60{,}000 documents, covering handwritten forms, complex layouts, dense tables, and graphics-rich pages. Evaluation is performed with unit-test-style checks that target concrete failure modes (text presence, reading order, and local table constraints) combined with category-specific normalization designed to discount presentation-only variance. Across 15 models, we observe substantially higher robustness for the strongest proprietary models on handwriting and forms, while several open-weights systems remain competitive on standard printed layouts.",
      "source": "arXiv",
      "pubDateISO": "2026-02-12",
      "tags": [
        "cs.CV",
        "cs.CL",
        "cs.LG"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.11958v1",
      "title": "RAM-Net: Expressive Linear Attention with Selectively Addressable Memory",
      "link": "http://arxiv.org/abs/2602.11958v1",
      "pdf_link": "https://arxiv.org/pdf/2602.11958v1",
      "authors": "Kaicheng Xiao, Haotian Li, Liran Dong, Guoliang Xing",
      "institution": "",
      "abstract": "While linear attention architectures offer efficient inference, compressing unbounded history into a fixed-size memory inherently limits expressivity and causes information loss. To address this limitation, we introduce Random Access Memory Network (RAM-Net), a novel architecture designed to bridge the gap between the representational capacity of full attention and the memory efficiency of linear models. The core of RAM-Net maps inputs to high-dimensional sparse vectors serving as explicit addresses, allowing the model to selectively access a massive memory state. This design enables exponential state size scaling without additional parameters, which significantly mitigates signal interference and enhances retrieval fidelity. Moreover, the inherent sparsity ensures exceptional computational efficiency, as state updates are confined to minimal entries. Extensive experiments demonstrate that RAM-Net consistently surpasses state-of-the-art baselines in fine-grained long-range retrieval tasks and achieves competitive performance in standard language modeling and zero-shot commonsense reasoning benchmarks, validating its superior capability to capture complex dependencies with significantly reduced computational overhead.",
      "source": "arXiv",
      "pubDateISO": "2026-02-12",
      "tags": [
        "cs.LG",
        "cs.CL"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.11957v1",
      "title": "Are Two LLMs Better Than One? A Student-Teacher Dual-Head LLMs Architecture for Pharmaceutical Content Optimization",
      "link": "http://arxiv.org/abs/2602.11957v1",
      "pdf_link": "https://arxiv.org/pdf/2602.11957v1",
      "authors": "Suyash Mishra, Qiang Li, Anubhav Girdhar",
      "institution": "",
      "abstract": "Large language models (LLMs) are increasingly used to create content in regulated domains such as pharmaceuticals, where outputs must be scientifically accurate and legally compliant. Manual quality control (QC) is slow, error prone, and can become a publication bottleneck. We introduce LRBTC, a modular LLM and vision language model (VLM) driven QC architecture covering Language, Regulatory, Brand, Technical, and Content Structure checks. LRBTC combines a Student-Teacher dual model architecture, human in the loop (HITL) workflow with waterfall rule filtering to enable scalable, verifiable content validation and optimization. On AIReg-Bench, our approach achieves 83.0% F1 and 97.5% recall, reducing missed violations by 5x compared with Gemini 2.5 Pro. On CSpelling, it improves mean accuracy by 26.7%. Error analysis further reveals that while current models are strong at detecting misspellings (92.5 recall), they fail to identify complex medical grammatical (25.0 recall) and punctuation (41.7 recall) errors, highlighting a key area for future work. This work provides a practical, plug and play solution for reliable, transparent quality control of content in high stakes, compliance critical industries. We also provide access to our Demo under MIT Licenses.",
      "source": "arXiv",
      "pubDateISO": "2026-02-12",
      "tags": [
        "cs.LG"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.11956v1",
      "title": "TAVAE: A VAE with Adaptable Priors Explains Contextual Modulation in the Visual Cortex",
      "link": "http://arxiv.org/abs/2602.11956v1",
      "pdf_link": "https://arxiv.org/pdf/2602.11956v1",
      "authors": "Balázs Meszéna, Keith T. Murray, Julien Corbo, O. Batuhan Erkat, Márton A. Hajnal et al.",
      "institution": "",
      "abstract": "The brain interprets visual information through learned regularities, a computation formalized as probabilistic inference under a prior. The visual cortex establishes priors for this inference, some delivered through established top-down connections that inform low-level cortices about statistics represented at higher levels in the cortical hierarchy. While evidence shows that adaptation leads to priors reflecting the structure of natural images, it remains unclear whether similar priors can be flexibly acquired when learning a specific task. To investigate this, we built a generative model of V1 optimized for a simple discrimination task and analyzed it together with large-scale recordings from mice performing an analogous task. In line with recent approaches, we assumed that neuronal activity in V1 corresponds to latent posteriors in the generative model, enabling investigation of task-related priors in neuronal responses. To obtain a flexible test bed, we extended the VAE formalism so that a task can be acquired efficiently by reusing previously learned representations. Task-specific priors learned by this Task-Amortized VAE were used to investigate biases in mice and model when presenting stimuli that violated trained task statistics. Mismatch between learned task statistics and incoming sensory evidence produced signatures of uncertainty in stimulus category in the TAVAE posterior, reflecting properties of bimodal response profiles in V1 recordings. The task-optimized generative model accounted for key characteristics of V1 population activity, including within-day updates to population responses. Our results confirm that flexible task-specific contextual priors can be learned on demand by the visual system and deployed as early as the entry level of visual cortex.",
      "source": "arXiv",
      "pubDateISO": "2026-02-12",
      "tags": [
        "cs.AI",
        "cs.LG"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.11948v1",
      "title": "Insights on Muon from Simple Quadratics",
      "link": "http://arxiv.org/abs/2602.11948v1",
      "pdf_link": "https://arxiv.org/pdf/2602.11948v1",
      "authors": "Antoine Gonon, Andreea-Alexandra Muşat, Nicolas Boumal",
      "institution": "",
      "abstract": "Muon updates weight matrices along (approximate) polar factors of the gradients and has shown strong empirical performance in large-scale training. Existing attempts at explaining its performance largely focus on single-step comparisons (on quadratic proxies) and worst-case guarantees that treat the inexactness of the polar-factor as a nuisance ``to be argued away''. We show that already on simple strongly convex functions such as $L(W)=\\frac12\\|W\\|_{\\text{F}}^2$, these perspectives are insufficient, suggesting that understanding Muon requires going beyond local proxies and pessimistic worst-case bounds. Instead, our analysis exposes two observations that already affect behavior on simple quadratics and are not well captured by prevailing abstractions: (i) approximation error in the polar step can qualitatively alter discrete-time dynamics and improve reachability and finite-time performance -- an effect practitioners exploit to tune Muon, but that existing theory largely treats as a pure accuracy compromise; and (ii) structural properties of the objective affect finite-budget constants beyond the prevailing conditioning-based explanations. Thus, any general theory covering these cases must either incorporate these ingredients explicitly or explain why they are irrelevant in the regimes of interest.",
      "source": "arXiv",
      "pubDateISO": "2026-02-12",
      "tags": [
        "cs.LG"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.11947v1",
      "title": "Mixed-Integer Programming for Change-point Detection",
      "link": "http://arxiv.org/abs/2602.11947v1",
      "pdf_link": "https://arxiv.org/pdf/2602.11947v1",
      "authors": "Apoorva Narula, Santanu S. Dey, Yao Xie",
      "institution": "",
      "abstract": "We present a new mixed-integer programming (MIP) approach for offline multiple change-point detection by casting the problem as a globally optimal piecewise linear (PWL) fitting problem. Our main contribution is a family of strengthened MIP formulations whose linear programming (LP) relaxations admit integral projections onto the segment assignment variables, which encode the segment membership of each data point. This property yields provably tighter relaxations than existing formulations for offline multiple change-point detection. We further extend the framework to two settings of active research interest: (i) multidimensional PWL models with shared change-points, and (ii) sparse change-point detection, where only a subset of dimensions undergo structural change. Extensive computational experiments on benchmark real-world datasets demonstrate that the proposed formulations achieve reductions in solution times under both $\\ell_1$ and $\\ell_2$ loss functions in comparison to the state-of-the-art.",
      "source": "arXiv",
      "pubDateISO": "2026-02-12",
      "tags": [
        "stat.ML"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.11945v1",
      "title": "Towards Performance-Enhanced Model-Contrastive Federated Learning using Historical Information in Heterogeneous Scenarios",
      "link": "http://arxiv.org/abs/2602.11945v1",
      "pdf_link": "https://arxiv.org/pdf/2602.11945v1",
      "authors": "Hongliang Zhang, Jiguo Yu, Guijuan Wang, Wenshuo Ma, Tianqing He et al.",
      "institution": "",
      "abstract": "Federated Learning (FL) enables multiple nodes to collaboratively train a model without sharing raw data. However, FL systems are usually deployed in heterogeneous scenarios, where nodes differ in both data distributions and participation frequencies, which undermines the FL performance. To tackle the above issue, this paper proposes PMFL, a performance-enhanced model-contrastive federated learning framework using historical training information. Specifically, on the node side, we design a novel model-contrastive term into the node optimization objective by incorporating historical local models to capture stable contrastive points, thereby improving the consistency of model updates in heterogeneous data distributions.\n  On the server side, we utilize the cumulative participation count of each node to adaptively adjust its aggregation weight, thereby correcting the bias in the global objective caused by different node participation frequencies. Furthermore, the updated global model incorporates historical global models to reduce its fluctuations in performance between adjacent rounds. Extensive experiments demonstrate that PMFL achieves superior performance compared with existing FL methods in heterogeneous scenarios.",
      "source": "arXiv",
      "pubDateISO": "2026-02-12",
      "tags": [
        "cs.LG",
        "cs.AI"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.11944v1",
      "title": "Using predictive multiplicity to measure individual performance within the AI Act",
      "link": "http://arxiv.org/abs/2602.11944v1",
      "pdf_link": "https://arxiv.org/pdf/2602.11944v1",
      "authors": "Karolin Frohnapfel, Mara Seyfert, Sebastian Bordt, Ulrike von Luxburg, Kristof Meding",
      "institution": "",
      "abstract": "When building AI systems for decision support, one often encounters the phenomenon of predictive multiplicity: a single best model does not exist; instead, one can construct many models with similar overall accuracy that differ in their predictions for individual cases. Especially when decisions have a direct impact on humans, this can be highly unsatisfactory. For a person subject to high disagreement between models, one could as well have chosen a different model of similar overall accuracy that would have decided the person's case differently. We argue that this arbitrariness conflicts with the EU AI Act, which requires providers of high-risk AI systems to report performance not only at the dataset level but also for specific persons. The goal of this paper is to put predictive multiplicity in context with the EU AI Act's provisions on accuracy and to subsequently derive concrete suggestions on how to evaluate and report predictive multiplicity in practice. Specifically: (1) We argue that incorporating information about predictive multiplicity can serve compliance with the EU AI Act's accuracy provisions for providers. (2) Based on this legal analysis, we suggest individual conflict ratios and $δ$-ambiguity as tools to quantify the disagreement between models on individual cases and to help detect individuals subject to conflicting predictions. (3) Based on computational insights, we derive easy-to-implement rules on how model providers could evaluate predictive multiplicity in practice. (4) Ultimately, we suggest that information about predictive multiplicity should be made available to deployers under the AI Act, enabling them to judge whether system outputs for specific individuals are reliable enough for their use case.",
      "source": "arXiv",
      "pubDateISO": "2026-02-12",
      "tags": [
        "cs.LG",
        "cs.CY"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.11942v1",
      "title": "Synthesis of Late Gadolinium Enhancement Images via Implicit Neural Representations for Cardiac Scar Segmentation",
      "link": "http://arxiv.org/abs/2602.11942v1",
      "pdf_link": "https://arxiv.org/pdf/2602.11942v1",
      "authors": "Soufiane Ben Haddou, Laura Alvarez-Florez, Erik J. Bekkers, Fleur V. Y. Tjong, Ahmad S. Amin et al.",
      "institution": "",
      "abstract": "Late gadolinium enhancement (LGE) imaging is the clinical standard for myocardial scar assessment, but limited annotated datasets hinder the development of automated segmentation methods. We propose a novel framework that synthesises both LGE images and their corresponding segmentation masks using implicit neural representations (INRs) combined with denoising diffusion models. Our approach first trains INRs to capture continuous spatial representations of LGE data and associated myocardium and fibrosis masks. These INRs are then compressed into compact latent embeddings, preserving essential anatomical information. A diffusion model operates on this latent space to generate new representations, which are decoded into synthetic LGE images with anatomically consistent segmentation masks. Experiments on 133 cardiac MRI scans suggest that augmenting training data with 200 synthetic volumes contributes to improved fibrosis segmentation performance, with the Dice score showing an increase from 0.509 to 0.524. Our approach provides an annotation-free method to help mitigate data scarcity.The code for this research is publicly available.",
      "source": "arXiv",
      "pubDateISO": "2026-02-12",
      "tags": [
        "cs.CV",
        "cs.AI"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.11941v1",
      "title": "IncompeBench: A Permissively Licensed, Fine-Grained Benchmark for Music Information Retrieval",
      "link": "http://arxiv.org/abs/2602.11941v1",
      "pdf_link": "https://arxiv.org/pdf/2602.11941v1",
      "authors": "Benjamin Clavié, Atoof Shakir, Jonah Turner, Sean Lee, Aamir Shakir et al.",
      "institution": "",
      "abstract": "Multimodal Information Retrieval has made significant progress in recent years, leveraging the increasingly strong multimodal abilities of deep pre-trained models to represent information across modalities. Music Information Retrieval (MIR), in particular, has considerably increased in quality, with neural representations of music even making its way into everyday life products. However, there is a lack of high-quality benchmarks for evaluating music retrieval performance. To address this issue, we introduce \\textbf{IncompeBench}, a carefully annotated benchmark comprising $1,574$ permissively licensed, high-quality music snippets, $500$ diverse queries, and over $125,000$ individual relevance judgements. These annotations were created through the use of a multi-stage pipeline, resulting in high agreement between human annotators and the generated data. The resulting datasets are publicly available at https://huggingface.co/datasets/mixedbread-ai/incompebench-strict and https://huggingface.co/datasets/mixedbread-ai/incompebench-lenient with the prompts available at https://github.com/mixedbread-ai/incompebench-programs.",
      "source": "arXiv",
      "pubDateISO": "2026-02-12",
      "tags": [
        "cs.IR",
        "cs.AI"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.11940v1",
      "title": "Temporally Unified Adversarial Perturbations for Time Series Forecasting",
      "link": "http://arxiv.org/abs/2602.11940v1",
      "pdf_link": "https://arxiv.org/pdf/2602.11940v1",
      "authors": "Ruixian Su, Yukun Bao, Xinze Zhang",
      "institution": "",
      "abstract": "While deep learning models have achieved remarkable success in time series forecasting, their vulnerability to adversarial examples remains a critical security concern. However, existing attack methods in the forecasting field typically ignore the temporal consistency inherent in time series data, leading to divergent and contradictory perturbation values for the same timestamp across overlapping samples. This temporally inconsistent perturbations problem renders adversarial attacks impractical for real-world data manipulation. To address this, we introduce Temporally Unified Adversarial Perturbations (TUAPs), which enforce a temporal unification constraint to ensure identical perturbations for each timestamp across all overlapping samples. Moreover, we propose a novel Timestamp-wise Gradient Accumulation Method (TGAM) that provides a modular and efficient approach to effectively generate TUAPs by aggregating local gradient information from overlapping samples. By integrating TGAM with momentum-based attack algorithms, we ensure strict temporal consistency while fully utilizing series-level gradient information to explore the adversarial perturbation space. Comprehensive experiments on three benchmark datasets and four representative state-of-the-art models demonstrate that our proposed method significantly outperforms baselines in both white-box and black-box transfer attack scenarios under TUAP constraints. Moreover, our method also exhibits superior transfer attack performance even without TUAP constraints, demonstrating its effectiveness and superiority in generating adversarial perturbations for time series forecasting models.",
      "source": "arXiv",
      "pubDateISO": "2026-02-12",
      "tags": [
        "cs.LG"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.11939v1",
      "title": "Do Large Language Models Adapt to Language Variation across Socioeconomic Status?",
      "link": "http://arxiv.org/abs/2602.11939v1",
      "pdf_link": "https://arxiv.org/pdf/2602.11939v1",
      "authors": "Elisa Bassignana, Mike Zhang, Dirk Hovy, Amanda Cercas Curry",
      "institution": "",
      "abstract": "Humans adjust their linguistic style to the audience they are addressing. However, the extent to which LLMs adapt to different social contexts is largely unknown. As these models increasingly mediate human-to-human communication, their failure to adapt to diverse styles can perpetuate stereotypes and marginalize communities whose linguistic norms are less closely mirrored by the models, thereby reinforcing social stratification. We study the extent to which LLMs integrate into social media communication across different socioeconomic status (SES) communities. We collect a novel dataset from Reddit and YouTube, stratified by SES. We prompt four LLMs with incomplete text from that corpus and compare the LLM-generated completions to the originals along 94 sociolinguistic metrics, including syntactic, rhetorical, and lexical features. LLMs modulate their style with respect to SES to only a minor extent, often resulting in approximation or caricature, and tend to emulate the style of upper SES more effectively. Our findings (1) show how LLMs risk amplifying linguistic hierarchies and (2) call into question their validity for agent-based social simulation, survey experiments, and any research relying on language style as a social signal.",
      "source": "arXiv",
      "pubDateISO": "2026-02-12",
      "tags": [
        "cs.CL"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.11938v1",
      "title": "Who is the richest club in the championship? Detecting and Rewriting Underspecified Questions Improve QA Performance",
      "link": "http://arxiv.org/abs/2602.11938v1",
      "pdf_link": "https://arxiv.org/pdf/2602.11938v1",
      "authors": "Yunchong Huang, Gianni Barlacchi, Sandro Pezzelle",
      "institution": "",
      "abstract": "Large language models (LLMs) perform well on well-posed questions, yet standard question-answering (QA) benchmarks remain far from solved. We argue that this gap is partly due to underspecified questions - queries whose interpretation cannot be uniquely determined without additional context. To test this hypothesis, we introduce an LLM-based classifier to identify underspecified questions and apply it to several widely used QA datasets, finding that 16% to over 50% of benchmark questions are underspecified and that LLMs perform significantly worse on them. To isolate the effect of underspecification, we conduct a controlled rewriting experiment that serves as an upper-bound analysis, rewriting underspecified questions into fully specified variants while holding gold answers fixed. QA performance consistently improves under this setting, indicating that many apparent QA failures stem from question underspecification rather than model limitations. Our findings highlight underspecification as an important confound in QA evaluation and motivate greater attention to question clarity in benchmark design.",
      "source": "arXiv",
      "pubDateISO": "2026-02-12",
      "tags": [
        "cs.CL"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.11937v1",
      "title": "Extending Puzzle for Mixture-of-Experts Reasoning Models with Application to GPT-OSS Acceleration",
      "link": "http://arxiv.org/abs/2602.11937v1",
      "pdf_link": "https://arxiv.org/pdf/2602.11937v1",
      "authors": "Akhiad Bercovich, Nir Ailon, Vladimir Anisimov, Tomer Asida, Nave Assaf et al.",
      "institution": "",
      "abstract": "Reasoning-focused LLMs improve answer quality by generating longer reasoning traces, but the additional tokens dramatically increase serving cost, motivating inference optimization. We extend and apply Puzzle, a post-training neural architecture search (NAS) framework, to gpt-oss-120B to produce gpt-oss-puzzle-88B, a deployment-optimized derivative. Our approach combines heterogeneous MoE expert pruning, selective replacement of full-context attention with window attention, FP8 KV-cache quantization with calibrated scales, and post-training reinforcement learning to recover accuracy, while maintaining low generation length. In terms of per-token speeds, on an 8XH100 node we achieve 1.63X and 1.22X throughput speedups in long-context and short-context settings, respectively. gpt-oss-puzzle-88B also delivers throughput speedups of 2.82X on a single NVIDIA H100 GPU. However, because token counts can change with reasoning effort and model variants, per-token throughput (tok/s) and latency (ms/token) do not necessarily lead to end-to-end speedups: a 2X throughput gain is erased if traces grow 2X. Conversely, throughput gains can be spent on more reasoning tokens to improve accuracy; we therefore advocate request-level efficiency metrics that normalize throughput by tokens generated and trace an accuracy--speed frontier across reasoning efforts. We show that gpt-oss-puzzle-88B improves over gpt-oss-120B along the entire frontier, delivering up to 1.29X higher request-level efficiency. Across various benchmarks, gpt-oss-puzzle-88B matches or slightly exceeds the parent on suite-average accuracy across reasoning efforts, with retention ranging from 100.8% (high) to 108.2% (low), showing that post-training architecture search can substantially reduce inference costs without sacrificing quality.",
      "source": "arXiv",
      "pubDateISO": "2026-02-12",
      "tags": [
        "cs.LG"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.11933v1",
      "title": "Cross-Modal Robustness Transfer (CMRT): Training Robust Speech Translation Models Using Adversarial Text",
      "link": "http://arxiv.org/abs/2602.11933v1",
      "pdf_link": "https://arxiv.org/pdf/2602.11933v1",
      "authors": "Abderrahmane Issam, Yusuf Can Semerci, Jan Scholtes, Gerasimos Spanakis",
      "institution": "",
      "abstract": "End-to-End Speech Translation (E2E-ST) has seen significant advancements, yet current models are primarily benchmarked on curated, \"clean\" datasets. This overlooks critical real-world challenges, such as morphological robustness to inflectional variations common in non-native or dialectal speech. In this work, we adapt a text-based adversarial attack targeting inflectional morphology to the speech domain and demonstrate that state-of-the-art E2E-ST models are highly vulnerable it. While adversarial training effectively mitigates such risks in text-based tasks, generating high-quality adversarial speech data remains computationally expensive and technically challenging. To address this, we propose Cross-Modal Robustness Transfer (CMRT), a framework that transfers adversarial robustness from the text modality to the speech modality. Our method eliminates the requirement for adversarial speech data during training. Extensive experiments across four language pairs demonstrate that CMRT improves adversarial robustness by an average of more than 3 BLEU points, establishing a new baseline for robust E2E-ST without the overhead of generating adversarial speech.",
      "source": "arXiv",
      "pubDateISO": "2026-02-12",
      "tags": [
        "cs.CL"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.11931v1",
      "title": "AdaptEvolve: Improving Efficiency of Evolutionary AI Agents through Adaptive Model Selection",
      "link": "http://arxiv.org/abs/2602.11931v1",
      "pdf_link": "https://arxiv.org/pdf/2602.11931v1",
      "authors": "Pretam Ray, Pratik Prabhanjan Brahma, Zicheng Liu, Emad Barsoum",
      "institution": "",
      "abstract": "Evolutionary agentic systems intensify the trade-off between computational efficiency and reasoning capability by repeatedly invoking large language models (LLMs) during inference. This setting raises a central question: how can an agent dynamically select an LLM that is sufficiently capable for the current generation step while remaining computationally efficient? While model cascades offer a practical mechanism for balancing this trade-off, existing routing strategies typically rely on static heuristics or external controllers and do not explicitly account for model uncertainty. We introduce AdaptEvolve: Adaptive LLM Selection for Multi-LLM Evolutionary Refinement within an evolutionary sequential refinement framework that leverages intrinsic generation confidence to estimate real-time solvability. Empirical results show that confidence-driven selection yields a favourable Pareto frontier, reducing total inference cost by an average of 37.9% across benchmarks while retaining 97.5% of the upper-bound accuracy of static large-model baselines. Our code is available at https://github.com/raypretam/adaptive_llm_selection.",
      "source": "arXiv",
      "pubDateISO": "2026-02-12",
      "tags": [
        "cs.CL",
        "cs.AI"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.11924v1",
      "title": "Who Does What? Archetypes of Roles Assigned to LLMs During Human-AI Decision-Making",
      "link": "http://arxiv.org/abs/2602.11924v1",
      "pdf_link": "https://arxiv.org/pdf/2602.11924v1",
      "authors": "Shreya Chappidi, Jatinder Singh, Andra V. Krauze",
      "institution": "",
      "abstract": "LLMs are increasingly supporting decision-making across high-stakes domains, requiring critical reflection on the socio-technical factors that shape how humans and LLMs are assigned roles and interact during human-in-the-loop decision-making. This paper introduces the concept of human-LLM archetypes -- defined as re-curring socio-technical interaction patterns that structure the roles of humans and LLMs in collaborative decision-making. We describe 17 human-LLM archetypes derived from a scoping literature review and thematic analysis of 113 LLM-supported decision-making papers. Then, we evaluate these diverse archetypes across real-world clinical diagnostic cases to examine the potential effects of adopting distinct human-LLM archetypes on LLM outputs and decision outcomes. Finally, we present relevant tradeoffs and design choices across human-LLM archetypes, including decision control, social hierarchies, cognitive forcing strategies, and information requirements. Through our analysis, we show that selection of human-LLM interaction archetype can influence LLM outputs and decisions, bringing important risks and considerations for the designers of human-AI decision-making systems",
      "source": "arXiv",
      "pubDateISO": "2026-02-12",
      "tags": [
        "cs.HC",
        "cs.AI"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.11920v1",
      "title": "Learning Conditional Averages",
      "link": "http://arxiv.org/abs/2602.11920v1",
      "pdf_link": "https://arxiv.org/pdf/2602.11920v1",
      "authors": "Marco Bressan, Nataly Brukhim, Nicolo Cesa-Bianchi, Emmanuel Esposito, Yishay Mansour et al.",
      "institution": "",
      "abstract": "We introduce the problem of learning conditional averages in the PAC framework. The learner receives a sample labeled by an unknown target concept from a known concept class, as in standard PAC learning. However, instead of learning the target concept itself, the goal is to predict, for each instance, the average label over its neighborhood -- an arbitrary subset of points that contains the instance. In the degenerate case where all neighborhoods are singletons, the problem reduces exactly to classic PAC learning. More generally, it extends PAC learning to a setting that captures learning tasks arising in several domains, including explainability, fairness, and recommendation systems. Our main contribution is a complete characterization of when conditional averages are learnable, together with sample complexity bounds that are tight up to logarithmic factors. The characterization hinges on the joint finiteness of two novel combinatorial parameters, which depend on both the concept class and the neighborhood system, and are closely related to the independence number of the associated neighborhood graph.",
      "source": "arXiv",
      "pubDateISO": "2026-02-12",
      "tags": [
        "cs.LG",
        "stat.ML"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.11919v1",
      "title": "DynaHOI: Benchmarking Hand-Object Interaction for Dynamic Target",
      "link": "http://arxiv.org/abs/2602.11919v1",
      "pdf_link": "https://arxiv.org/pdf/2602.11919v1",
      "authors": "BoCheng Hu, Zhonghan Zhao, Kaiyue Zhou, Hongwei Wang, Gaoang Wang",
      "institution": "",
      "abstract": "Most existing hand motion generation benchmarks for hand-object interaction (HOI) focus on static objects, leaving dynamic scenarios with moving targets and time-critical coordination largely untested. To address this gap, we introduce the DynaHOI-Gym, a unified online closed-loop platform with parameterized motion generators and rollout-based metrics for dynamic capture evaluation. Built on DynaHOI-Gym, we release DynaHOI-10M, a large-scale benchmark with 10M frames and 180K hand capture trajectories, whose target motions are organized into 8 major categories and 22 fine-grained subcategories. We also provide a simple observe-before-act baseline (ObAct) that integrates short-term observations with the current frame via spatiotemporal attention to predict actions, achieving an 8.1% improvement in location success rate.",
      "source": "arXiv",
      "pubDateISO": "2026-02-12",
      "tags": [
        "cs.CV",
        "cs.AI"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.11918v1",
      "title": "MEME: Modeling the Evolutionary Modes of Financial Markets",
      "link": "http://arxiv.org/abs/2602.11918v1",
      "pdf_link": "https://arxiv.org/pdf/2602.11918v1",
      "authors": "Taian Guo, Haiyang Shen, Junyu Luo, Zhongshi Xing, Hanchun Lian et al.",
      "institution": "",
      "abstract": "LLMs have demonstrated significant potential in quantitative finance by processing vast unstructured data to emulate human-like analytical workflows. However, current LLM-based methods primarily follow either an Asset-Centric paradigm focused on individual stock prediction or a Market-Centric approach for portfolio allocation, often remaining agnostic to the underlying reasoning that drives market movements. In this paper, we propose a Logic-Oriented perspective, modeling the financial market as a dynamic, evolutionary ecosystem of competing investment narratives, termed Modes of Thought. To operationalize this view, we introduce MEME (Modeling the Evolutionary Modes of Financial Markets), designed to reconstruct market dynamics through the lens of evolving logics. MEME employs a multi-agent extraction module to transform noisy data into high-fidelity Investment Arguments and utilizes Gaussian Mixture Modeling to uncover latent consensus within a semantic space. To model semantic drift among different market conditions, we also implement a temporal evaluation and alignment mechanism to track the lifecycle and historical profitability of these modes. By prioritizing enduring market wisdom over transient anomalies, MEME ensures that portfolio construction is guided by robust reasoning. Extensive experiments on three heterogeneous Chinese stock pools from 2023 to 2025 demonstrate that MEME consistently outperforms seven SOTA baselines. Further ablation studies, sensitivity analysis, lifecycle case study and cost analysis validate MEME's capacity to identify and adapt to the evolving consensus of financial markets. Our implementation can be found at https://github.com/gta0804/MEME.",
      "source": "arXiv",
      "pubDateISO": "2026-02-12",
      "tags": [
        "cs.AI"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.11917v1",
      "title": "AlphaPROBE: Alpha Mining via Principled Retrieval and On-graph biased evolution",
      "link": "http://arxiv.org/abs/2602.11917v1",
      "pdf_link": "https://arxiv.org/pdf/2602.11917v1",
      "authors": "Taian Guo, Haiyang Shen, Junyu Luo, Binqi Chen, Hongjun Ding et al.",
      "institution": "",
      "abstract": "Extracting signals through alpha factor mining is a fundamental challenge in quantitative finance. Existing automated methods primarily follow two paradigms: Decoupled Factor Generation, which treats factor discovery as isolated events, and Iterative Factor Evolution, which focuses on local parent-child refinements. However, both paradigms lack a global structural view, often treating factor pools as unstructured collections or fragmented chains, which leads to redundant search and limited diversity. To address these limitations, we introduce AlphaPROBE (Alpha Mining via Principled Retrieval and On-graph Biased Evolution), a framework that reframes alpha mining as the strategic navigation of a Directed Acyclic Graph (DAG). By modeling factors as nodes and evolutionary links as edges, AlphaPROBE treats the factor pool as a dynamic, interconnected ecosystem. The framework consists of two core components: a Bayesian Factor Retriever that identifies high-potential seeds by balancing exploitation and exploration through a posterior probability model, and a DAG-aware Factor Generator that leverages the full ancestral trace of factors to produce context-aware, nonredundant optimizations. Extensive experiments on three major Chinese stock market datasets against 8 competitive baselines demonstrate that AlphaPROBE significantly gains enhanced performance in predictive accuracy, return stability and training efficiency. Our results confirm that leveraging global evolutionary topology is essential for efficient and robust automated alpha discovery. We have open-sourced our implementation at https://github.com/gta0804/AlphaPROBE.",
      "source": "arXiv",
      "pubDateISO": "2026-02-12",
      "tags": [
        "cs.AI"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.11910v1",
      "title": "TADA! Tuning Audio Diffusion Models through Activation Steering",
      "link": "http://arxiv.org/abs/2602.11910v1",
      "pdf_link": "https://arxiv.org/pdf/2602.11910v1",
      "authors": "Łukasz Staniszewski, Katarzyna Zaleska, Mateusz Modrzejewski, Kamil Deja",
      "institution": "",
      "abstract": "Audio diffusion models can synthesize high-fidelity music from text, yet their internal mechanisms for representing high-level concepts remain poorly understood. In this work, we use activation patching to demonstrate that distinct semantic musical concepts, such as the presence of specific instruments, vocals, or genre characteristics, are controlled by a small, shared subset of attention layers in state-of-the-art audio diffusion architectures. Next, we demonstrate that applying Contrastive Activation Addition and Sparse Autoencoders in these layers enables more precise control over the generated audio, indicating a direct benefit of the specialization phenomenon. By steering activations of the identified layers, we can alter specific musical elements with high precision, such as modulating tempo or changing a track's mood.",
      "source": "arXiv",
      "pubDateISO": "2026-02-12",
      "tags": [
        "cs.SD",
        "cs.LG"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.11909v1",
      "title": "Echo: Towards Advanced Audio Comprehension via Audio-Interleaved Reasoning",
      "link": "http://arxiv.org/abs/2602.11909v1",
      "pdf_link": "https://arxiv.org/pdf/2602.11909v1",
      "authors": "Daiqing Wu, Xuan Zhang, Dongbao Yang, Jiashu Yao, Longfei Chen et al.",
      "institution": "",
      "abstract": "The maturation of Large Audio Language Models (LALMs) has raised growing expectations for them to comprehend complex audio much like humans. Current efforts primarily replicate text-based reasoning by contextualizing audio content through a one-time encoding, which introduces a critical information bottleneck. Drawing inspiration from human cognition, we propose audio-interleaved reasoning to break through this bottleneck. It treats audio as an active reasoning component, enabling sustained audio engagement and perception-grounded analysis. To instantiate it, we introduce a two-stage training framework, first teaching LALMs to localize salient audio segments through supervised fine-tuning, and then incentivizing proficient re-listening via reinforcement learning. In parallel, a structured data generation pipeline is developed to produce high-quality training data. Consequently, we present Echo, a LALM capable of dynamically re-listening to audio in demand during reasoning. On audio comprehension benchmarks, Echo achieves overall superiority in both challenging expert-level and general-purpose tasks. Comprehensive analysis further confirms the efficiency and generalizability of audio-interleaved reasoning, establishing it as a promising direction for advancing audio comprehension. Project page: https://github.com/wdqqdw/Echo.",
      "source": "arXiv",
      "pubDateISO": "2026-02-12",
      "tags": [
        "cs.SD",
        "cs.LG"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.11908v1",
      "title": "When Should LLMs Be Less Specific? Selective Abstraction for Reliable Long-Form Text Generation",
      "link": "http://arxiv.org/abs/2602.11908v1",
      "pdf_link": "https://arxiv.org/pdf/2602.11908v1",
      "authors": "Shani Goren, Ido Galil, Ran El-Yaniv",
      "institution": "",
      "abstract": "LLMs are widely used, yet they remain prone to factual errors that erode user trust and limit adoption in high-risk settings. One approach to mitigate this risk is to equip models with uncertainty estimation mechanisms that abstain when confidence is low. However, this binary \"all-or-nothing\" approach is excessively restrictive in long-form settings, often discarding valuable information. We introduce Selective Abstraction (SA), a framework that enables LLMs to trade specificity for reliability by selectively reducing the detail of uncertain content. We first formalize SA through the lenses of selective risk and coverage. We then propose Atom-wise Selective Abstraction, a claim-level instantiation that decomposes responses into atomic claims (short, self-contained statements each expressing a single fact) and replaces uncertain atoms with higher confidence, less specific abstractions. To evaluate this framework, we develop a novel end-to-end pipeline for open-ended generation that instantiates risk as factual correctness and measures coverage using an information-theoretic measure of retained information. Across six open-source models on the FactScore and LongFact-Objects benchmarks, atom-wise SA consistently outperforms existing baselines, improving the area under the risk-coverage curve (AURC) by up to 27.73% over claim removal, demonstrating that reducing specificity can boost accuracy and reliability while preserving most of their original meaning.",
      "source": "arXiv",
      "pubDateISO": "2026-02-12",
      "tags": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.11904v1",
      "title": "Leveraging LLMs to support co-evolution between definitions and instances of textual DSLs: A Systematic Evaluation",
      "link": "http://arxiv.org/abs/2602.11904v1",
      "pdf_link": "https://arxiv.org/pdf/2602.11904v1",
      "authors": "Weixing Zhang, Bowen Jiang, Yuhong Fu, Anne Koziolek, Regina Hebig et al.",
      "institution": "",
      "abstract": "Software languages evolve over time for reasons such as feature additions. When grammars evolve, textual instances that originally conformed to them may become outdated. While model-driven engineering provides many techniques for co-evolving models with metamodel changes, these approaches are not designed for textual DSLs and may lose human-relevant information such as layout and comments. This study systematically evaluates the potential of large language models (LLMs) for co-evolving grammars and instances of textual DSLs. Using Claude Sonnet 4.5 and GPT-5.2 across ten case languages with ten runs each, we assess both correctness and preservation of human-oriented information. Results show strong performance on small-scale cases ($\\geq$94% precision and recall for instances requiring fewer than 20 modified lines), but performance degraded with scale: Claude maintains 85% recall at 40 lines, while GPT fails on the largest instances. Response time increases substantially with instance size, and grammar evolution complexity and deletion granularity affect performance more than change type. These findings clarify when LLM-based co-evolution is effective and where current limitations remain.",
      "source": "arXiv",
      "pubDateISO": "2026-02-12",
      "tags": [
        "cs.SE",
        "cs.AI"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.11903v1",
      "title": "Learning Perceptual Representations for Gaming NR-VQA with Multi-Task FR Signals",
      "link": "http://arxiv.org/abs/2602.11903v1",
      "pdf_link": "https://arxiv.org/pdf/2602.11903v1",
      "authors": "Yu-Chih Chen, Michael Wang, Chieh-Dun Wen, Kai-Siang Ma, Avinab Saha et al.",
      "institution": "",
      "abstract": "No-reference video quality assessment (NR-VQA) for gaming videos is challenging due to limited human-rated datasets and unique content characteristics including fast motion, stylized graphics, and compression artifacts. We present MTL-VQA, a multi-task learning framework that uses full-reference metrics as supervisory signals to learn perceptually meaningful features without human labels for pretraining. By jointly optimizing multiple full-reference (FR) objectives with adaptive task weighting, our approach learns shared representations that transfer effectively to NR-VQA. Experiments on gaming video datasets show MTL-VQA achieves performance competitive with state-of-the-art NR-VQA methods across both MOS-supervised and label-efficient/self-supervised settings.",
      "source": "arXiv",
      "pubDateISO": "2026-02-12",
      "tags": [
        "cs.CV",
        "cs.MM"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.11902v1",
      "title": "Mitigating Mismatch within Reference-based Preference Optimization",
      "link": "http://arxiv.org/abs/2602.11902v1",
      "pdf_link": "https://arxiv.org/pdf/2602.11902v1",
      "authors": "Suqin Yuan, Xingrui Yu, Jiyang Zheng, Lei Feng, Dadong Wang et al.",
      "institution": "",
      "abstract": "Direct Preference Optimization (DPO) has become the de facto standard for offline preference alignment of large language models, but its reliance on a reference policy introduces a critical tension. DPO weighs each update relative to a reference, which stabilizes the training by regularizing the updates within a trusted region. This reliance becomes problematic for pessimistic pairs, where the reference model prefers the rejected response. For these pairs, DPO prematurely attenuates the gradient as soon as the policy margin ($Δ_θ$) merely beats the reference margin ($Δ_{\\mathrm{ref}}$) even if the policy is still wrong ($Δ_θ<0$). We name this failure premature satisfaction, which is a concrete form of the training-inference mismatch. Reference-free objectives remove this mismatch by optimizing the absolute margin, but at the cost of discarding the stabilizing signal of the reference. We mitigate this tension with Hybrid-DPO (HyPO), a drop-in modification to DPO that applies reference conditionally: HyPO behaves exactly like DPO when the reference is optimistic or neutral, and it treats the reference as neutral when it is pessimistic by replacing $Δ_θ-Δ_{\\mathrm{ref}}$ with $Δ_θ-\\max\\{0,Δ_{\\mathrm{ref}}\\}$. This one-line change strictly strengthens per-example learning signals on pessimistic pairs while preserving DPO's objective form and computational cost. By conditionally debiasing the pessimistic reference signal, HyPO mitigates premature satisfaction; empirically, across preference alignment, HyPO improves inference-aligned metrics and achieves higher pairwise win rates. Our results provide evidence that direct preference alignment could be enhanced by conditionally debiasing the reference signal, rather than discarding it.",
      "source": "arXiv",
      "pubDateISO": "2026-02-12",
      "tags": [
        "cs.LG",
        "cs.AI"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.11898v1",
      "title": "Benchmark Illusion: Disagreement among LLMs and Its Scientific Consequences",
      "link": "http://arxiv.org/abs/2602.11898v1",
      "pdf_link": "https://arxiv.org/pdf/2602.11898v1",
      "authors": "Eddie Yang, Dashun Wang",
      "institution": "",
      "abstract": "Benchmarks underpin how progress in large language models (LLMs) is measured and trusted. Yet our analyses reveal that apparent convergence in benchmark accuracy can conceal deep epistemic divergence. Using two major reasoning benchmarks - MMLU-Pro and GPQA - we show that LLMs achieving comparable accuracy still disagree on 16-66% of items, and 16-38% among top-performing frontier models. These discrepancies suggest distinct error profiles for different LLMs. When such models are used for scientific data annotation and inference, their hidden disagreements propagate into research results: in re-analyses of published studies in education and political science, switching the annotation model can change estimated treatment effects by more than 80%, and in some cases reverses their sign. Together, these findings illustrate a benchmark illusion, where equal accuracy may conceal disagreement, with model choice becoming a hidden yet consequential variable for scientific reproducibility.",
      "source": "arXiv",
      "pubDateISO": "2026-02-12",
      "tags": [
        "cs.CL"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.11897v1",
      "title": "Agentic AI for Cybersecurity: A Meta-Cognitive Architecture for Governable Autonomy",
      "link": "http://arxiv.org/abs/2602.11897v1",
      "pdf_link": "https://arxiv.org/pdf/2602.11897v1",
      "authors": "Andrei Kojukhov, Arkady Bovshover",
      "institution": "",
      "abstract": "Contemporary AI-driven cybersecurity systems are predominantly architected as model-centric detection and automation pipelines optimized for task-level performance metrics such as accuracy and response latency. While effective for bounded classification tasks, these architectures struggle to support accountable decision-making under adversarial uncertainty, where actions must be justified, governed, and aligned with organizational and regulatory constraints. This paper argues that cybersecurity orchestration should be reconceptualized as an agentic, multi-agent cognitive system, rather than a linear sequence of detection and response components. We introduce a conceptual architectural framework in which heterogeneous AI agents responsible for detection, hypothesis formation, contextual interpretation, explanation, and governance are coordinated through an explicit meta-cognitive judgement function. This function governs decision readiness and dynamically calibrates system autonomy when evidence is incomplete, conflicting, or operationally risky. By synthesizing distributed cognition theory, multi-agent systems research, and responsible AI governance frameworks, we demonstrate that modern security operations already function as distributed cognitive systems, albeit without an explicit organizing principle. Our contribution is to make this cognitive structure architecturally explicit and governable by embedding meta-cognitive judgement as a first-class system function. We discuss implications for security operations centers, accountable autonomy, and the design of next-generation AI-enabled cyber defence architectures. The proposed framework shifts the focus of AI in cybersecurity from optimizing isolated predictions to governing autonomy under uncertainty.",
      "source": "arXiv",
      "pubDateISO": "2026-02-12",
      "tags": [
        "cs.CR",
        "cs.AI"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.11893v1",
      "title": "Universal Diffusion-Based Probabilistic Downscaling",
      "link": "http://arxiv.org/abs/2602.11893v1",
      "pdf_link": "https://arxiv.org/pdf/2602.11893v1",
      "authors": "Roberto Molinaro, Niall Siegenheim, Henry Martin, Mark Frey, Niels Poulsen et al.",
      "institution": "",
      "abstract": "We introduce a universal diffusion-based downscaling framework that lifts deterministic low-resolution weather forecasts into probabilistic high-resolution predictions without any model-specific fine-tuning. A single conditional diffusion model is trained on paired coarse-resolution inputs (~25 km resolution) and high-resolution regional reanalysis targets (~5 km resolution), and is applied in a fully zero-shot manner to deterministic forecasts from heterogeneous upstream weather models. Focusing on near-surface variables, we evaluate probabilistic forecasts against independent in situ station observations over lead times up to 90 h. Across a diverse set of AI-based and numerical weather prediction (NWP) systems, the ensemble mean of the downscaled forecasts consistently improves upon each model's own raw deterministic forecast, and substantially larger gains are observed in probabilistic skill as measured by CRPS. These results demonstrate that diffusion-based downscaling provides a scalable, model-agnostic probabilistic interface for enhancing spatial resolution and uncertainty representation in operational weather forecasting pipelines.",
      "source": "arXiv",
      "pubDateISO": "2026-02-12",
      "tags": [
        "cs.LG"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.11886v1",
      "title": "LLM-based Triplet Extraction from Financial Reports",
      "link": "http://arxiv.org/abs/2602.11886v1",
      "pdf_link": "https://arxiv.org/pdf/2602.11886v1",
      "authors": "Dante Wesslund, Ville Stenström, Pontus Linde, Alexander Holmberg",
      "institution": "",
      "abstract": "Corporate financial reports are a valuable source of structured knowledge for Knowledge Graph construction, but the lack of annotated ground truth in this domain makes evaluation difficult. We present a semi-automated pipeline for Subject-Predicate-Object triplet extraction that uses ontology-driven proxy metrics, specifically Ontology Conformance and Faithfulness, instead of ground-truth-based evaluation. We compare a static, manually engineered ontology against a fully automated, document-specific ontology induction approach across different LLMs and two corporate annual reports. The automatically induced ontology achieves 100% schema conformance in all configurations, eliminating the ontology drift observed with the manual approach. We also propose a hybrid verification strategy that combines regex matching with an LLM-as-a-judge check, reducing apparent subject hallucination rates from 65.2% to 1.6% by filtering false positives caused by coreference resolution. Finally, we identify a systematic asymmetry between subject and object hallucinations, which we attribute to passive constructions and omitted agents in financial prose.",
      "source": "arXiv",
      "pubDateISO": "2026-02-12",
      "tags": [
        "cs.CL"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.11882v1",
      "title": "Where Bits Matter in World Model Planning: A Paired Mixed-Bit Study for Efficient Spatial Reasoning",
      "link": "http://arxiv.org/abs/2602.11882v1",
      "pdf_link": "https://arxiv.org/pdf/2602.11882v1",
      "authors": "Suraj Ranganath, Anish Patnaik, Vaishak Menon",
      "institution": "",
      "abstract": "Efficient spatial reasoning requires world models that remain reliable under tight precision budgets. We study whether low-bit planning behavior is determined mostly by total bitwidth or by where bits are allocated across modules. Using DINO-WM on the Wall planning task, we run a paired-goal mixed-bit evaluation across uniform, mixed, asymmetric, and layerwise variants under two planner budgets. We observe a consistent three-regime pattern: 8-bit and 6-bit settings remain close to FP16, 3-bit settings collapse, and 4-bit settings are allocation-sensitive. In that transition region, preserving encoder precision improves planning relative to uniform quantization, and near-size asymmetric variants show the same encoder-side direction. In a later strict 22-cell replication with smaller per-cell episode count, the mixed-versus-uniform INT4 sign becomes budget-conditioned, which further highlights the sensitivity of this transition regime. These findings motivate module-aware, budget-aware quantization policies as a broader research direction for efficient spatial reasoning. Code and run artifacts are available at https://github.com/suraj-ranganath/DINO-MBQuant.",
      "source": "arXiv",
      "pubDateISO": "2026-02-12",
      "tags": [
        "cs.LG",
        "cs.AI",
        "cs.CV",
        "cs.RO"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.11881v1",
      "title": "From Atoms to Trees: Building a Structured Feature Forest with Hierarchical Sparse Autoencoders",
      "link": "http://arxiv.org/abs/2602.11881v1",
      "pdf_link": "https://arxiv.org/pdf/2602.11881v1",
      "authors": "Yifan Luo, Yang Zhan, Jiedong Jiang, Tianyang Liu, Mingrui Wu et al.",
      "institution": "",
      "abstract": "Sparse autoencoders (SAEs) have proven effective for extracting monosemantic features from large language models (LLMs), yet these features are typically identified in isolation. However, broad evidence suggests that LLMs capture the intrinsic structure of natural language, where the phenomenon of \"feature splitting\" in particular indicates that such structure is hierarchical. To capture this, we propose the Hierarchical Sparse Autoencoder (HSAE), which jointly learns a series of SAEs and the parent-child relationships between their features. HSAE strengthens the alignment between parent and child features through two novel mechanisms: a structural constraint loss and a random feature perturbation mechanism. Extensive experiments across various LLMs and layers demonstrate that HSAE consistently recovers semantically meaningful hierarchies, supported by both qualitative case studies and rigorous quantitative metrics. At the same time, HSAE preserves the reconstruction fidelity and interpretability of standard SAEs across different dictionary sizes. Our work provides a powerful, scalable tool for discovering and analyzing the multi-scale conceptual structures embedded in LLM representations.",
      "source": "arXiv",
      "pubDateISO": "2026-02-12",
      "tags": [
        "cs.AI"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.11880v1",
      "title": "SynthRAR: Ring Artifacts Reduction in CT with Unrolled Network and Synthetic Data Training",
      "link": "http://arxiv.org/abs/2602.11880v1",
      "pdf_link": "https://arxiv.org/pdf/2602.11880v1",
      "authors": "Hongxu Yang, Levente Lippenszky, Edina Timko, Gopal Avinash",
      "institution": "",
      "abstract": "Defective and inconsistent responses in CT detectors can cause ring and streak artifacts in the reconstructed images, making them unusable for clinical purposes. In recent years, several ring artifact reduction solutions have been proposed in the image domain or in the sinogram domain using supervised deep learning methods. However, these methods require dedicated datasets for training, leading to a high data collection cost. Furthermore, existing approaches focus exclusively on either image-space or sinogram-space correction, neglecting the intrinsic correlations from the forward operation of the CT geometry. Based on the theoretical analysis of non-ideal CT detector responses, the RAR problem is reformulated as an inverse problem by using an unrolled network, which considers non-ideal response together with linear forward-projection with CT geometry. Additionally, the intrinsic correlations of ring artifacts between the sinogram and image domains are leveraged through synthetic data derived from natural images, enabling the trained model to correct artifacts without requiring real-world clinical data. Extensive evaluations on diverse scanning geometries and anatomical regions demonstrate that the model trained on synthetic data consistently outperforms existing state-of-the-art methods.",
      "source": "arXiv",
      "pubDateISO": "2026-02-12",
      "tags": [
        "cs.CV",
        "cs.AI"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.11877v1",
      "title": "Towards Fair and Comprehensive Evaluation of Routers in Collaborative LLM Systems",
      "link": "http://arxiv.org/abs/2602.11877v1",
      "pdf_link": "https://arxiv.org/pdf/2602.11877v1",
      "authors": "Wanxing Wu, He Zhu, Yixia Li, Lei Yang, Jiehui Zhao et al.",
      "institution": "",
      "abstract": "Large language models (LLMs) have achieved success, but cost and privacy constraints necessitate deploying smaller models locally while offloading complex queries to cloud-based models. Existing router evaluations are unsystematic, overlooking scenario-specific requirements and out-of-distribution robustness. We propose RouterXBench, a principled evaluation framework with three dimensions: router ability, scenario alignment, and cross-domain robustness. Unlike prior work that relies on output probabilities or external embeddings, we utilize internal hidden states that capture model uncertainty before answer generation. We introduce ProbeDirichlet, a lightweight router that aggregates cross-layer hidden states via learnable Dirichlet distributions with probabilistic training. Trained on multi-domain data, it generalizes robustly across in-domain and out-of-distribution scenarios. Our results show ProbeDirichlet achieves 16.68% and 18.86% relative improvements over the best baselines in router ability and high-accuracy scenarios, with consistent performance across model families, model scales, heterogeneous tasks, and agentic workflows.",
      "source": "arXiv",
      "pubDateISO": "2026-02-12",
      "tags": [
        "cs.CL",
        "cs.AI"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.11875v1",
      "title": "DiffPlace: Street View Generation via Place-Controllable Diffusion Model Enhancing Place Recognition",
      "link": "http://arxiv.org/abs/2602.11875v1",
      "pdf_link": "https://arxiv.org/pdf/2602.11875v1",
      "authors": "Ji Li, Zhiwei Li, Shihao Li, Zhenjiang Yu, Boyang Wang et al.",
      "institution": "",
      "abstract": "Generative models have advanced significantly in realistic image synthesis, with diffusion models excelling in quality and stability. Recent multi-view diffusion models improve 3D-aware street view generation, but they struggle to produce place-aware and background-consistent urban scenes from text, BEV maps, and object bounding boxes. This limits their effectiveness in generating realistic samples for place recognition tasks. To address these challenges, we propose DiffPlace, a novel framework that introduces a place-ID controller to enable place-controllable multi-view image generation. The place-ID controller employs linear projection, perceiver transformer, and contrastive learning to map place-ID embeddings into a fixed CLIP space, allowing the model to synthesize images with consistent background buildings while flexibly modifying foreground objects and weather conditions. Extensive experiments, including quantitative comparisons and augmented training evaluations, demonstrate that DiffPlace outperforms existing methods in both generation quality and training support for visual place recognition. Our results highlight the potential of generative models in enhancing scene-level and place-aware synthesis, providing a valuable approach for improving place recognition in autonomous driving",
      "source": "arXiv",
      "pubDateISO": "2026-02-12",
      "tags": [
        "cs.CV",
        "cs.RO"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.11871v1",
      "title": "DMAP: A Distribution Map for Text",
      "link": "http://arxiv.org/abs/2602.11871v1",
      "pdf_link": "https://arxiv.org/pdf/2602.11871v1",
      "authors": "Tom Kempton, Julia Rozanova, Parameswaran Kamalaruban, Maeve Madigan, Karolina Wresilo et al.",
      "institution": "",
      "abstract": "Large Language Models (LLMs) are a powerful tool for statistical text analysis, with derived sequences of next-token probability distributions offering a wealth of information. Extracting this signal typically relies on metrics such as perplexity, which do not adequately account for context; how one should interpret a given next-token probability is dependent on the number of reasonable choices encoded by the shape of the conditional distribution. In this work, we present DMAP, a mathematically grounded method that maps a text, via a language model, to a set of samples in the unit interval that jointly encode rank and probability information. This representation enables efficient, model-agnostic analysis and supports a range of applications. We illustrate its utility through three case studies: (i) validation of generation parameters to ensure data integrity, (ii) examining the role of probability curvature in machine-generated text detection, and (iii) a forensic analysis revealing statistical fingerprints left in downstream models that have been subject to post-training on synthetic data. Our results demonstrate that DMAP offers a unified statistical view of text that is simple to compute on consumer hardware, widely applicable, and provides a foundation for further research into text analysis with LLMs.",
      "source": "arXiv",
      "pubDateISO": "2026-02-12",
      "tags": [
        "cs.CL",
        "cs.LG"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.11865v1",
      "title": "Intelligent AI Delegation",
      "link": "http://arxiv.org/abs/2602.11865v1",
      "pdf_link": "https://arxiv.org/pdf/2602.11865v1",
      "authors": "Nenad Tomašev, Matija Franklin, Simon Osindero",
      "institution": "",
      "abstract": "AI agents are able to tackle increasingly complex tasks. To achieve more ambitious goals, AI agents need to be able to meaningfully decompose problems into manageable sub-components, and safely delegate their completion across to other AI agents and humans alike. Yet, existing task decomposition and delegation methods rely on simple heuristics, and are not able to dynamically adapt to environmental changes and robustly handle unexpected failures. Here we propose an adaptive framework for intelligent AI delegation - a sequence of decisions involving task allocation, that also incorporates transfer of authority, responsibility, accountability, clear specifications regarding roles and boundaries, clarity of intent, and mechanisms for establishing trust between the two (or more) parties. The proposed framework is applicable to both human and AI delegators and delegatees in complex delegation networks, aiming to inform the development of protocols in the emerging agentic web.",
      "source": "arXiv",
      "pubDateISO": "2026-02-12",
      "tags": [
        "cs.AI"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.11863v1",
      "title": "In-Context Function Learning in Large Language Models",
      "link": "http://arxiv.org/abs/2602.11863v1",
      "pdf_link": "https://arxiv.org/pdf/2602.11863v1",
      "authors": "Elif Akata, Konstantinos Voudouris, Vincent Fortuin, Eric Schulz",
      "institution": "",
      "abstract": "Large language models (LLMs) can learn from a few demonstrations provided at inference time. We study this in-context learning phenomenon through the lens of Gaussian Processes (GPs). We build controlled experiments where models observe sequences of multivariate scalar-valued function samples drawn from known GP priors. We evaluate prediction error in relation to the number of demonstrations and compare against two principled references: (i) an empirical GP-regression learner that gives a lower bound on achievable error, and (ii) the expected error of a 1-nearest-neighbor (1-NN) rule, which gives a data-driven upper bound. Across model sizes, we find that LLM learning curves are strongly influenced by the function-generating kernels and approach the GP lower bound as the number of demonstrations increases. We then study the inductive biases of these models using a likelihood-based analysis. We find that LLM predictions are most likely under less smooth GP kernels. Finally, we explore whether post-training can shift these inductive biases and improve sample-efficiency on functions sampled from GPs with smoother kernels. We find that both reinforcement learning and supervised fine-tuning can effectively shift inductive biases in the direction of the training data. Together, our framework quantifies the extent to which LLMs behave like GP learners and provides tools for steering their inductive biases for continuous function learning tasks.",
      "source": "arXiv",
      "pubDateISO": "2026-02-12",
      "tags": [
        "cs.LG"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.11861v1",
      "title": "A$^{2}$V-SLP: Alignment-Aware Variational Modeling for Disentangled Sign Language Production",
      "link": "http://arxiv.org/abs/2602.11861v1",
      "pdf_link": "https://arxiv.org/pdf/2602.11861v1",
      "authors": "Sümeyye Meryem Taşyürek, Enis Mücahid İskender, Hacer Yalim Keles",
      "institution": "",
      "abstract": "Building upon recent structural disentanglement frameworks for sign language production, we propose A$^{2}$V-SLP, an alignment-aware variational framework that learns articulator-wise disentangled latent distributions rather than deterministic embeddings. A disentangled Variational Autoencoder (VAE) encodes ground-truth sign pose sequences and extracts articulator-specific mean and variance vectors, which are used as distributional supervision for training a non-autoregressive Transformer. Given text embeddings, the Transformer predicts both latent means and log-variances, while the VAE decoder reconstructs the final sign pose sequences through stochastic sampling at the decoding stage. This formulation maintains articulator-level representations by avoiding deterministic latent collapse through distributional latent modeling. In addition, we integrate a gloss attention mechanism to strengthen alignment between linguistic input and articulated motion. Experimental results show consistent gains over deterministic latent regression, achieving state-of-the-art back-translation performance and improved motion realism in a fully gloss-free setting.",
      "source": "arXiv",
      "pubDateISO": "2026-02-12",
      "tags": [
        "cs.LG",
        "cs.CL"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.11860v1",
      "title": "Talk2DM: Enabling Natural Language Querying and Commonsense Reasoning for Vehicle-Road-Cloud Integrated Dynamic Maps with Large Language Models",
      "link": "http://arxiv.org/abs/2602.11860v1",
      "pdf_link": "https://arxiv.org/pdf/2602.11860v1",
      "authors": "Lu Tao, Jinxuan Luo, Yousuke Watanabe, Zhengshu Zhou, Yuhuan Lu et al.",
      "institution": "",
      "abstract": "Dynamic maps (DM) serve as the fundamental information infrastructure for vehicle-road-cloud (VRC) cooperative autonomous driving in China and Japan. By providing comprehensive traffic scene representations, DM overcome the limitations of standalone autonomous driving systems (ADS), such as physical occlusions. Although DM-enhanced ADS have been successfully deployed in real-world applications in Japan, existing DM systems still lack a natural-language-supported (NLS) human interface, which could substantially enhance human-DM interaction. To address this gap, this paper introduces VRCsim, a VRC cooperative perception (CP) simulation framework designed to generate streaming VRC-CP data. Based on VRCsim, we construct a question-answering data set, VRC-QA, focused on spatial querying and reasoning in mixed-traffic scenes. Building upon VRCsim and VRC-QA, we further propose Talk2DM, a plug-and-play module that extends VRC-DM systems with NLS querying and commonsense reasoning capabilities. Talk2DM is built upon a novel chain-of-prompt (CoP) mechanism that progressively integrates human-defined rules with the commonsense knowledge of large language models (LLMs). Experiments on VRC-QA show that Talk2DM can seamlessly switch across different LLMs while maintaining high NLS query accuracy, demonstrating strong generalization capability. Although larger models tend to achieve higher accuracy, they incur significant efficiency degradation. Our results reveal that Talk2DM, powered by Qwen3:8B, Gemma3:27B, and GPT-oss models, achieves over 93\\% NLS query accuracy with an average response time of only 2-5 seconds, indicating strong practical potential.",
      "source": "arXiv",
      "pubDateISO": "2026-02-12",
      "tags": [
        "cs.AI"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.11858v1",
      "title": "Zooming without Zooming: Region-to-Image Distillation for Fine-Grained Multimodal Perception",
      "link": "http://arxiv.org/abs/2602.11858v1",
      "pdf_link": "https://arxiv.org/pdf/2602.11858v1",
      "authors": "Lai Wei, Liangbo He, Jun Lan, Lingzhong Dong, Yutong Cai et al.",
      "institution": "",
      "abstract": "Multimodal Large Language Models (MLLMs) excel at broad visual understanding but still struggle with fine-grained perception, where decisive evidence is small and easily overwhelmed by global context. Recent \"Thinking-with-Images\" methods alleviate this by iteratively zooming in and out regions of interest during inference, but incur high latency due to repeated tool calls and visual re-encoding. To address this, we propose Region-to-Image Distillation, which transforms zooming from an inference-time tool into a training-time primitive, thereby internalizing the benefits of agentic zooming into a single forward pass of an MLLM. In particular, we first zoom in to micro-cropped regions to let strong teacher models generate high-quality VQA data, and then distill this region-grounded supervision back to the full image. After training on such data, the smaller student model improves \"single-glance\" fine-grained perception without tool use. To rigorously evaluate this capability, we further present ZoomBench, a hybrid-annotated benchmark of 845 VQA data spanning six fine-grained perceptual dimensions, together with a dual-view protocol that quantifies the global--regional \"zooming gap\". Experiments show that our models achieve leading performance across multiple fine-grained perception benchmarks, and also improve general multimodal cognition on benchmarks such as visual reasoning and GUI agents. We further discuss when \"Thinking-with-Images\" is necessary versus when its gains can be distilled into a single forward pass. Our code is available at https://github.com/inclusionAI/Zooming-without-Zooming.",
      "source": "arXiv",
      "pubDateISO": "2026-02-12",
      "tags": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.11857v1",
      "title": "Scale-Invariant Fast Convergence in Games",
      "link": "http://arxiv.org/abs/2602.11857v1",
      "pdf_link": "https://arxiv.org/pdf/2602.11857v1",
      "authors": "Taira Tsuchiya, Haipeng Luo, Shinji Ito",
      "institution": "",
      "abstract": "Scale-invariance in games has recently emerged as a widely valued desirable property. Yet, almost all fast convergence guarantees in learning in games require prior knowledge of the utility scale. To address this, we develop learning dynamics that achieve fast convergence while being both scale-free, requiring no prior information about utilities, and scale-invariant, remaining unchanged under positive rescaling of utilities. For two-player zero-sum games, we obtain scale-free and scale-invariant dynamics with external regret bounded by $\\tilde{O}(A_{\\mathrm{diff}})$, where $A_{\\mathrm{diff}}$ is the payoff range, which implies an $\\tilde{O}(A_{\\mathrm{diff}} / T)$ convergence rate to Nash equilibrium after $T$ rounds. For multiplayer general-sum games with $n$ players and $m$ actions, we obtain scale-free and scale-invariant dynamics with swap regret bounded by $O(U_{\\mathrm{max}} \\log T)$, where $U_{\\mathrm{max}}$ is the range of the utilities, ignoring the dependence on the number of players and actions. This yields an $O(U_{\\mathrm{max}} \\log T / T)$ convergence rate to correlated equilibrium. Our learning dynamics are based on optimistic follow-the-regularized-leader with an adaptive learning rate that incorporates the squared path length of the opponents' gradient vectors, together with a new stopping-time analysis that exploits negative terms in regret bounds without scale-dependent tuning. For general-sum games, scale-free learning is enabled also by a technique called doubling clipping, which clips observed gradients based on past observations.",
      "source": "arXiv",
      "pubDateISO": "2026-02-12",
      "tags": [
        "cs.GT",
        "cs.LG",
        "stat.ML"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.11854v1",
      "title": "Robust Optimization Approach and Learning Based Hide-and-Seek Game for Resilient Network Design",
      "link": "http://arxiv.org/abs/2602.11854v1",
      "pdf_link": "https://arxiv.org/pdf/2602.11854v1",
      "authors": "Mohammad Khosravi, Setareh Maghsudi",
      "institution": "",
      "abstract": "We study the design of resilient and reliable communication networks in which a signal can be transferred only up to a limited distance before its quality falls below an acceptable threshold. When excessive signal degradation occurs, regeneration is required through regenerators installed at selected network nodes. In this work, both network links and nodes are subject to uncertainty. The installation costs of regenerators are modeled using a budgeted uncertainty set. In addition, link lengths follow a dynamic budgeted uncertainty set introduced in this paper, where deviations may vary over time. Robust optimization seeks solutions whose performance is guaranteed under all scenarios represented by the underlying uncertainty set. Accordingly, the objective is to identify a minimum-cost subset of nodes for regenerator deployment that ensures full network connectivity, even under the worst possible realizations of uncertainty. To solve the problem, we first formulate it within a robust optimization framework, and then develop scalable solution methods based on column-and-constraint generation, Benders decomposition, and iterative robust optimization. In addition, we formulate a learning-based hide-and-seek game to further analyze the problem structure. The proposed approaches are evaluated against classical static budgeted robust models and deterministic worst-case formulations. Both theoretical analysis and computational results demonstrate the effectiveness and advantages of our methodology.",
      "source": "arXiv",
      "pubDateISO": "2026-02-12",
      "tags": [
        "cs.LG"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.11852v1",
      "title": "Prototype Transformer: Towards Language Model Architectures Interpretable by Design",
      "link": "http://arxiv.org/abs/2602.11852v1",
      "pdf_link": "https://arxiv.org/pdf/2602.11852v1",
      "authors": "Yordan Yordanov, Matteo Forasassi, Bayar Menzat, Ruizhi Wang, Chang Qi et al.",
      "institution": "",
      "abstract": "While state-of-the-art language models (LMs) surpass the vast majority of humans in certain domains, their reasoning remains largely opaque, undermining trust in their output. Furthermore, while autoregressive LMs can output explicit reasoning, their true reasoning process is opaque, which introduces risks like deception and hallucination. In this work, we introduce the Prototype Transformer (ProtoT) -- an autoregressive LM architecture based on prototypes (parameter vectors), posed as an alternative to the standard self-attention-based transformers. ProtoT works by means of two-way communication between the input sequence and the prototypes, and we show that this leads to the prototypes automatically capturing nameable concepts (e.g. \"woman\") during training. They provide the potential to interpret the model's reasoning and allow for targeted edits of its behavior. Furthermore, by design, the prototypes create communication channels that aggregate contextual information at different time scales, aiding interpretability. In terms of computation scalability, ProtoT scales linearly with sequence length vs the quadratic scalability of SOTA self-attention transformers. Compared to baselines, ProtoT scales well with model and data size, and performs well on text generation and downstream tasks (GLUE). ProtoT exhibits robustness to input perturbations on par or better than some baselines, but differs from them by providing interpretable pathways showing how robustness and sensitivity arises. Reaching close to the performance of state-of-the-art architectures, ProtoT paves the way to creating well-performing autoregressive LMs interpretable by design.",
      "source": "arXiv",
      "pubDateISO": "2026-02-12",
      "tags": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.11851v1",
      "title": "Resource-Aware Deployment Optimization for Collaborative Intrusion Detection in Layered Networks",
      "link": "http://arxiv.org/abs/2602.11851v1",
      "pdf_link": "https://arxiv.org/pdf/2602.11851v1",
      "authors": "André García Gómez, Ines Rieger, Wolfgang Hotwagner, Max Landauer, Markus Wurzenberger et al.",
      "institution": "",
      "abstract": "Collaborative Intrusion Detection Systems (CIDS) are increasingly adopted to counter cyberattacks, as their collaborative nature enables them to adapt to diverse scenarios across heterogeneous environments. As distributed critical infrastructure operates in rapidly evolving environments, such as drones in both civil and military domains, there is a growing need for CIDS architectures that can flexibly accommodate these dynamic changes. In this study, we propose a novel CIDS framework designed for easy deployment across diverse distributed environments. The framework dynamically optimizes detector allocation per node based on available resources and data types, enabling rapid adaptation to new operational scenarios with minimal computational overhead. We first conducted a comprehensive literature review to identify key characteristics of existing CIDS architectures. Based on these insights and real-world use cases, we developed our CIDS framework, which we evaluated using several distributed datasets that feature different attack chains and network topologies. Notably, we introduce a public dataset based on a realistic cyberattack targeting a ground drone aimed at sabotaging critical infrastructure. Experimental results demonstrate that the proposed CIDS framework can achieve adaptive, efficient intrusion detection in distributed settings, automatically reconfiguring detectors to maintain an optimal configuration, without requiring heavy computation, since all experiments were conducted on edge devices.",
      "source": "arXiv",
      "pubDateISO": "2026-02-12",
      "tags": [
        "cs.CR",
        "cs.AI"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.11850v1",
      "title": "Free Lunch for Stabilizing Rectified Flow Inversion",
      "link": "http://arxiv.org/abs/2602.11850v1",
      "pdf_link": "https://arxiv.org/pdf/2602.11850v1",
      "authors": "Chenru Wang, Beier Zhu, Chi Zhang",
      "institution": "",
      "abstract": "Rectified-Flow (RF)-based generative models have recently emerged as strong alternatives to traditional diffusion models, demonstrating state-of-the-art performance across various tasks. By learning a continuous velocity field that transforms simple noise into complex data, RF-based models not only enable high-quality generation, but also support training-free inversion, which facilitates downstream tasks such as reconstruction and editing. However, existing inversion methods, such as vanilla RF-based inversion, suffer from approximation errors that accumulate across timesteps, leading to unstable velocity fields and degraded reconstruction and editing quality. To address this challenge, we propose Proximal-Mean Inversion (PMI), a training-free gradient correction method that stabilizes the velocity field by guiding it toward a running average of past velocities, constrained within a theoretically derived spherical Gaussian. Furthermore, we introduce mimic-CFG, a lightweight velocity correction scheme for editing tasks, which interpolates between the current velocity and its projection onto the historical average, balancing editing effectiveness and structural consistency. Extensive experiments on PIE-Bench demonstrate that our methods significantly improve inversion stability, image reconstruction quality, and editing fidelity, while reducing the required number of neural function evaluations. Our approach achieves state-of-the-art performance on the PIE-Bench with enhanced efficiency and theoretical soundness.",
      "source": "arXiv",
      "pubDateISO": "2026-02-12",
      "tags": [
        "cs.CV",
        "cs.LG"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.11845v1",
      "title": "WorldTree: Towards 4D Dynamic Worlds from Monocular Video using Tree-Chains",
      "link": "http://arxiv.org/abs/2602.11845v1",
      "pdf_link": "https://arxiv.org/pdf/2602.11845v1",
      "authors": "Qisen Wang, Yifan Zhao, Jia Li",
      "institution": "",
      "abstract": "Dynamic reconstruction has achieved remarkable progress, but there remain challenges in monocular input for more practical applications. The prevailing works attempt to construct efficient motion representations, but lack a unified spatiotemporal decomposition framework, suffering from either holistic temporal optimization or coupled hierarchical spatial composition. To this end, we propose WorldTree, a unified framework comprising Temporal Partition Tree (TPT) that enables coarse-to-fine optimization based on the inheritance-based partition tree structure for hierarchical temporal decomposition, and Spatial Ancestral Chains (SAC) that recursively query ancestral hierarchical structure to provide complementary spatial dynamics while specializing motion representations across ancestral nodes. Experimental results on different datasets indicate that our proposed method achieves 8.26% improvement of LPIPS on NVIDIA-LS and 9.09% improvement of mLPIPS on DyCheck compared to the second-best method. Code: https://github.com/iCVTEAM/WorldTree.",
      "source": "arXiv",
      "pubDateISO": "2026-02-12",
      "tags": [
        "cs.CV"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.11841v1",
      "title": "Improving Neural Retrieval with Attribution-Guided Query Rewriting",
      "link": "http://arxiv.org/abs/2602.11841v1",
      "pdf_link": "https://arxiv.org/pdf/2602.11841v1",
      "authors": "Moncef Garouani, Josiane Mothe",
      "institution": "",
      "abstract": "Neural retrievers are effective but brittle: underspecified or ambiguous queries can misdirect ranking even when relevant documents exist. Existing approaches address this brittleness only partially: LLMs rewrite queries without retriever feedback, and explainability methods identify misleading tokens but are used for post-hoc analysis. We close this loop and propose an attribution-guided query rewriting method that uses token-level explanations to guide query rewriting. For each query, we compute gradient-based token attributions from the retriever and then use these scores as soft guidance in a structured prompt to an LLM that clarifies weak or misleading query components while preserving intent. Evaluated on BEIR collections, the resulting rewrites consistently improve retrieval effectiveness over strong baselines, with larger gains for implicit or ambiguous information needs.",
      "source": "arXiv",
      "pubDateISO": "2026-02-12",
      "tags": [
        "cs.IR",
        "cs.AI",
        "cs.LG"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.11836v1",
      "title": "ULTRA:Urdu Language Transformer-based Recommendation Architecture",
      "link": "http://arxiv.org/abs/2602.11836v1",
      "pdf_link": "https://arxiv.org/pdf/2602.11836v1",
      "authors": "Alishbah Bashir, Fatima Qaiser, Ijaz Hussain",
      "institution": "",
      "abstract": "Urdu, as a low-resource language, lacks effective semantic content recommendation systems, particularly in the domain of personalized news retrieval. Existing approaches largely rely on lexical matching or language-agnostic techniques, which struggle to capture semantic intent and perform poorly under varying query lengths and information needs. This limitation results in reduced relevance and adaptability in Urdu content recommendation. We propose ULTRA (Urdu Language Transformer-based Recommendation Architecture),an adaptive semantic recommendation framework designed to address these challenges. ULTRA introduces a dual-embedding architecture with a query-length aware routing mechanism that dynamically distinguishes between short, intent-focused queries and longer, context-rich queries. Based on a threshold-driven decision process, user queries are routed to specialized semantic pipelines optimized for either title/headline-level or full-content/document level representations, ensuring appropriate semantic granularity during retrieval. The proposed system leverages transformer-based embeddings and optimized pooling strategies to move beyond surface-level keyword matching and enable context-aware similarity search. Extensive experiments conducted on a large-scale Urdu news corpus demonstrate that the proposed architecture consistently improves recommendation relevance across diverse query types. Results show gains in precision above 90% compared to single-pipeline baselines, highlighting the effectiveness of query-adaptive semantic alignment for low-resource languages. The findings establish ULTRA as a robust and generalizable content recommendation architecture, offering practical design insights for semantic retrieval systems in low-resource language settings.",
      "source": "arXiv",
      "pubDateISO": "2026-02-12",
      "tags": [
        "cs.IR",
        "cs.AI"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.11834v1",
      "title": "EqDeepRx: Learning a Scalable MIMO Receiver",
      "link": "http://arxiv.org/abs/2602.11834v1",
      "pdf_link": "https://arxiv.org/pdf/2602.11834v1",
      "authors": "Mikko Honkala, Dani Korpi, Elias Raninen, Janne M. J. Huttunen",
      "institution": "",
      "abstract": "While machine learning (ML)-based receiver algorithms have received a great deal of attention in the recent literature, they often suffer from poor scaling with increasing spatial multiplexing order and lack of explainability and generalization. This paper presents EqDeepRx, a practical deep-learning-aided multiple-input multiple-output (MIMO) receiver, which is built by augmenting linear receiver processing with carefully engineered ML blocks. At the core of the receiver model is a shared-weight DetectorNN that operates independently on each spatial stream or layer, enabling near-linear complexity scaling with respect to multiplexing order. To ensure better explainability and generalization, EqDeepRx retains conventional channel estimation and augments it with a lightweight DenoiseNN that learns frequency-domain smoothing. To reduce the dimensionality of the DetectorNN inputs, the receiver utilizes two linear equalizers in parallel: a linear minimum mean-square error (LMMSE) equalizer with interference-plus-noise covariance estimation and a regularized zero-forcing (RZF) equalizer. The parallel equalized streams are jointly consumed by the DetectorNN, after which a compact DemapperNN produces bit log-likelihood ratios for channel decoding. 5G/6G-compliant end-to-end simulations across multiple channel scenarios, pilot patterns, and inter-cell interference conditions show improved error rate and spectral efficiency over a conventional baseline, while maintaining low-complexity inference and support for different MIMO configurations without retraining.",
      "source": "arXiv",
      "pubDateISO": "2026-02-12",
      "tags": [
        "cs.LG"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.11832v1",
      "title": "JEPA-VLA: Video Predictive Embedding is Needed for VLA Models",
      "link": "http://arxiv.org/abs/2602.11832v1",
      "pdf_link": "https://arxiv.org/pdf/2602.11832v1",
      "authors": "Shangchen Miao, Ningya Feng, Jialong Wu, Ye Lin, Xu He et al.",
      "institution": "",
      "abstract": "Recent vision-language-action (VLA) models built upon pretrained vision-language models (VLMs) have achieved significant improvements in robotic manipulation. However, current VLAs still suffer from low sample efficiency and limited generalization. This paper argues that these limitations are closely tied to an overlooked component, pretrained visual representation, which offers insufficient knowledge on both aspects of environment understanding and policy prior. Through an in-depth analysis, we find that commonly used visual representations in VLAs, whether pretrained via language-image contrastive learning or image-based self-supervised learning, remain inadequate at capturing crucial, task-relevant environment information and at inducing effective policy priors, i.e., anticipatory knowledge of how the environment evolves under successful task execution. In contrast, we discover that predictive embeddings pretrained on videos, in particular V-JEPA 2, are adept at flexibly discarding unpredictable environment factors and encoding task-relevant temporal dynamics, thereby effectively compensating for key shortcomings of existing visual representations in VLAs. Building on these observations, we introduce JEPA-VLA, a simple yet effective approach that adaptively integrates predictive embeddings into existing VLAs. Our experiments demonstrate that JEPA-VLA yields substantial performance gains across a range of benchmarks, including LIBERO, LIBERO-plus, RoboTwin2.0, and real-robot tasks.",
      "source": "arXiv",
      "pubDateISO": "2026-02-12",
      "tags": [
        "cs.CV",
        "cs.RO"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.11829v1",
      "title": "Towards Sustainable Investment Policies Informed by Opponent Shaping",
      "link": "http://arxiv.org/abs/2602.11829v1",
      "pdf_link": "https://arxiv.org/pdf/2602.11829v1",
      "authors": "Juan Agustin Duque, Razvan Ciuca, Ayoub Echchahed, Hugo Larochelle, Aaron Courville",
      "institution": "",
      "abstract": "Addressing climate change requires global coordination, yet rational economic actors often prioritize immediate gains over collective welfare, resulting in social dilemmas. InvestESG is a recently proposed multi-agent simulation that captures the dynamic interplay between investors and companies under climate risk. We provide a formal characterization of the conditions under which InvestESG exhibits an intertemporal social dilemma, deriving theoretical thresholds at which individual incentives diverge from collective welfare. Building on this, we apply Advantage Alignment, a scalable opponent shaping algorithm shown to be effective in general-sum games, to influence agent learning in InvestESG. We offer theoretical insights into why Advantage Alignment systematically favors socially beneficial equilibria by biasing learning dynamics toward cooperative outcomes. Our results demonstrate that strategically shaping the learning processes of economic agents can result in better outcomes that could inform policy mechanisms to better align market incentives with long-term sustainability goals.",
      "source": "arXiv",
      "pubDateISO": "2026-02-12",
      "tags": [
        "cs.LG",
        "cs.GT"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.11825v1",
      "title": "CAAL: Confidence-Aware Active Learning for Heteroscedastic Atmospheric Regression",
      "link": "http://arxiv.org/abs/2602.11825v1",
      "pdf_link": "https://arxiv.org/pdf/2602.11825v1",
      "authors": "Fei Jiang, Jiyang Xia, Junjie Yu, Mingfei Sun, Hugh Coe et al.",
      "institution": "",
      "abstract": "Quantifying the impacts of air pollution on health and climate relies on key atmospheric particle properties such as toxicity and hygroscopicity. However, these properties typically require complex observational techniques or expensive particle-resolved numerical simulations, limiting the availability of labeled data. We therefore estimate these hard-to-measure particle properties from routinely available observations (e.g., air pollutant concentrations and meteorological conditions). Because routine observations only indirectly reflect particle composition and structure, the mapping from routine observations to particle properties is noisy and input-dependent, yielding a heteroscedastic regression setting. With a limited and costly labeling budget, the central challenge is to select which samples to measure or simulate. While active learning is a natural approach, most acquisition strategies rely on predictive uncertainty. Under heteroscedastic noise, this signal conflates reducible epistemic uncertainty with irreducible aleatoric uncertainty, causing limited budgets to be wasted in noise-dominated regions. To address this challenge, we propose a confidence-aware active learning framework (CAAL) for efficient and robust sample selection in heteroscedastic settings. CAAL consists of two components: a decoupled uncertainty-aware training objective that separately optimises the predictive mean and noise level to stabilise uncertainty estimation, and a confidence-aware acquisition function that dynamically weights epistemic uncertainty using predicted aleatoric uncertainty as a reliability signal. Experiments on particle-resolved numerical simulations and real atmospheric observations show that CAAL consistently outperforms standard AL baselines. The proposed framework provides a practical and general solution for the efficient expansion of high-cost atmospheric particle property databases.",
      "source": "arXiv",
      "pubDateISO": "2026-02-12",
      "tags": [
        "cs.LG"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.11824v1",
      "title": "Revis: Sparse Latent Steering to Mitigate Object Hallucination in Large Vision-Language Models",
      "link": "http://arxiv.org/abs/2602.11824v1",
      "pdf_link": "https://arxiv.org/pdf/2602.11824v1",
      "authors": "Jialin Wu, Wei Shi, Han Shen, Peigui Qi, Kunsheng Tang et al.",
      "institution": "",
      "abstract": "Despite the advanced capabilities of Large Vision-Language Models (LVLMs), they frequently suffer from object hallucination. One reason is that visual features and pretrained textual representations often become intertwined in the deeper network layers. To address this, we propose REVIS, a training-free framework designed to explicitly re-activate this suppressed visual information. Rooted in latent space geometry, REVIS extracts the pure visual information vector via orthogonal projection and employs a calibrated strategy to perform sparse intervention only at the precise depth where suppression occurs. This surgical approach effectively restores visual information with minimal computational cost. Empirical evaluations on standard benchmarks demonstrate that REVIS reduces object hallucination rates by approximately 19% compared to state-of-the-art baselines, while preserving general reasoning capabilities.",
      "source": "arXiv",
      "pubDateISO": "2026-02-12",
      "tags": [
        "cs.AI",
        "cs.LG"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.11814v1",
      "title": "A Comparative Study of MAP and LMMSE Estimators for Blind Inverse Problems",
      "link": "http://arxiv.org/abs/2602.11814v1",
      "pdf_link": "https://arxiv.org/pdf/2602.11814v1",
      "authors": "Nathan Buskulic, Luca Calatroni",
      "institution": "",
      "abstract": "Maximum-a-posteriori (MAP) approaches are an effective framework for inverse problems with known forward operators, particularly when combined with expressive priors and careful parameter selection. In blind settings, however, their use becomes significantly less stable due to the inherent non-convexity of the problem and the potential non-identifiability of the solutions. (Linear) minimum mean square error (MMSE) estimators provide a compelling alternative that can circumvent these limitations. In this work, we study synthetic two-dimensional blind deconvolution problems under fully controlled conditions, with complete prior knowledge of both the signal and kernel distributions. We compare tailored MAP algorithms with simple LMMSE estimators whose functional form is closely related to that of an optimal Tikhonov estimator. Our results show that, even in these highly controlled settings, MAP methods remain unstable and require extensive parameter tuning, whereas the LMMSE estimator yields a robust and reliable baseline. Moreover, we demonstrate empirically that the LMMSE solution can serve as an effective initialization for MAP approaches, improving their performance and reducing sensitivity to regularization parameters, thereby opening the door to future theoretical and practical developments.",
      "source": "arXiv",
      "pubDateISO": "2026-02-12",
      "tags": [
        "cs.IT",
        "cs.CV",
        "cs.LG"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.11812v1",
      "title": "Predicting LLM Output Length via Entropy-Guided Representations",
      "link": "http://arxiv.org/abs/2602.11812v1",
      "pdf_link": "https://arxiv.org/pdf/2602.11812v1",
      "authors": "Huanyi Xie, Yubin Chen, Liangyu Wang, Lijie Hu, Di Wang",
      "institution": "",
      "abstract": "The long-tailed distribution of sequence lengths in LLM serving and reinforcement learning (RL) sampling causes significant computational waste due to excessive padding in batched inference. Existing methods rely on auxiliary models for static length prediction, but they incur high overhead, generalize poorly, and fail in stochastic \"one-to-many\" sampling scenarios. We introduce a lightweight framework that reuses the main model's internal hidden states for efficient length prediction. Our framework features two core components: 1) Entropy-Guided Token Pooling (EGTP), which uses on-the-fly activations and token entropy for highly accurate static prediction with negligible cost, and 2) Progressive Length Prediction (PLP), which dynamically estimates the remaining length at each decoding step to handle stochastic generation. To validate our approach, we build and release ForeLen, a comprehensive benchmark with long-sequence, Chain-of-Thought, and RL data. On ForeLen, EGTP achieves state-of-the-art accuracy, reducing MAE by 29.16\\% over the best baseline. Integrating our methods with a length-aware scheduler yields significant end-to-end throughput gains. Our work provides a new technical and evaluation baseline for efficient LLM inference.",
      "source": "arXiv",
      "pubDateISO": "2026-02-12",
      "tags": [
        "cs.AI"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.11810v1",
      "title": "How to Sample High Quality 3D Fractals for Action Recognition Pre-Training?",
      "link": "http://arxiv.org/abs/2602.11810v1",
      "pdf_link": "https://arxiv.org/pdf/2602.11810v1",
      "authors": "Marko Putak, Thomas B. Moeslund, Joakim Bruslund Haurum",
      "institution": "",
      "abstract": "Synthetic datasets are being recognized in the deep learning realm as a valuable alternative to exhaustively labeled real data. One such synthetic data generation method is Formula Driven Supervised Learning (FDSL), which can provide an infinite number of perfectly labeled data through a formula driven approach, such as fractals or contours. FDSL does not have common drawbacks like manual labor, privacy and other ethical concerns. In this work we generate 3D fractals using 3D Iterated Function Systems (IFS) for pre-training an action recognition model. The fractals are temporally transformed to form a video that is used as a pre-training dataset for downstream task of action recognition. We find that standard methods of generating fractals are slow and produce degenerate 3D fractals. Therefore, we systematically explore alternative ways of generating fractals and finds that overly-restrictive approaches, while generating aesthetically pleasing fractals, are detrimental for downstream task performance. We propose a novel method, Targeted Smart Filtering, to address both the generation speed and fractal diversity issue. The method reports roughly 100 times faster sampling speed and achieves superior downstream performance against other 3D fractal filtering methods.",
      "source": "arXiv",
      "pubDateISO": "2026-02-12",
      "tags": [
        "cs.CV",
        "cs.LG"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.11808v1",
      "title": "Deep Kernel Fusion for Transformers",
      "link": "http://arxiv.org/abs/2602.11808v1",
      "pdf_link": "https://arxiv.org/pdf/2602.11808v1",
      "authors": "Zixi Zhang, Zhiwen Mo, Yiren Zhao, Robert Mullins",
      "institution": "",
      "abstract": "Agentic LLM inference with long contexts is increasingly limited by memory bandwidth rather than compute. In this setting, SwiGLU MLP blocks, whose large weights exceed cache capacity, become a major yet under-optimized bottleneck. We propose DeepFusionKernel, a deeply fused kernel that cuts HBM traffic and boosts cache reuse, delivering up to 13.2% speedup on H100 and 9.7% on A100 over SGLang. Integrated with SGLang and paired with a kernel scheduler, DeepFusionKernel ensures consistent accelerations over generation lengths, while remaining adaptable to diverse models, inference configurations, and hardware platforms.",
      "source": "arXiv",
      "pubDateISO": "2026-02-12",
      "tags": [
        "cs.LG"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.11807v1",
      "title": "PuYun-LDM: A Latent Diffusion Model for High-Resolution Ensemble Weather Forecasts",
      "link": "http://arxiv.org/abs/2602.11807v1",
      "pdf_link": "https://arxiv.org/pdf/2602.11807v1",
      "authors": "Lianjun Wu, Shengchen Zhu, Yuxuan Liu, Liuyu Kai, Xiaoduan Feng et al.",
      "institution": "",
      "abstract": "Latent diffusion models (LDMs) suffer from limited diffusability in high-resolution (<=0.25°) ensemble weather forecasting, where diffusability characterizes how easily a latent data distribution can be modeled by a diffusion process. Unlike natural image fields, meteorological fields lack task-agnostic foundation models and explicit semantic structures, making VFM-based regularization inapplicable. Moreover, existing frequency-based approaches impose identical spectral regularization across channels under a homogeneity assumption, which leads to uneven regularization strength under the inter-variable spectral heterogeneity in multivariate meteorological data. To address these challenges, we propose a 3D Masked AutoEncoder (3D-MAE) that encodes weather-state evolution features as an additional conditioning for the diffusion model, together with a Variable-Aware Masked Frequency Modeling (VA-MFM) strategy that adaptively selects thresholds based on the spectral energy distribution of each variable. Together, we propose PuYun-LDM, which enhances latent diffusability and achieves superior performance to ENS at short lead times while remaining comparable to ENS at longer horizons. PuYun-LDM generates a 15-day global forecast with a 6-hour temporal resolution in five minutes on a single NVIDIA H200 GPU, while ensemble forecasts can be efficiently produced in parallel.",
      "source": "arXiv",
      "pubDateISO": "2026-02-12",
      "tags": [
        "cs.AI"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.11805v1",
      "title": "From Path Signatures to Sequential Modeling: Incremental Signature Contributions for Offline RL",
      "link": "http://arxiv.org/abs/2602.11805v1",
      "pdf_link": "https://arxiv.org/pdf/2602.11805v1",
      "authors": "Ziyi Zhao, Qingchuan Li, Yuxuan Xu",
      "institution": "",
      "abstract": "Path signatures embed trajectories into tensor algebra and constitute a universal, non-parametric representation of paths; however, in the standard form, they collapse temporal structure into a single global object, which limits their suitability for decision-making problems that require step-wise reactivity. We propose the Incremental Signature Contribution (ISC) method, which decomposes truncated path signatures into a temporally ordered sequence of elements in the tensor-algebra space, corresponding to incremental contributions induced by last path increments. This reconstruction preserves the algebraic structure and expressivity of signatures, while making their internal temporal evolution explicit, enabling processing signature-based representations via sequential modeling approaches. In contrast to full signatures, ISC is inherently sensitive to instantaneous trajectory updates, which is critical for sensitive and stability-requiring control dynamics. Building on this representation, we introduce ISC-Transformer (ISCT), an offline reinforcement learning model that integrates ISC into a standard Transformer architecture without further architectural modification. We evaluate ISCT on HalfCheetah, Walker2d, Hopper, and Maze2d, including settings with delayed rewards and downgraded datasets. The results demonstrate that ISC method provides a theoretically grounded and practically effective alternative to path processing for temporally sensitive control tasks.",
      "source": "arXiv",
      "pubDateISO": "2026-02-12",
      "tags": [
        "cs.LG"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.11804v1",
      "title": "Efficient Segment Anything with Depth-Aware Fusion and Limited Training Data",
      "link": "http://arxiv.org/abs/2602.11804v1",
      "pdf_link": "https://arxiv.org/pdf/2602.11804v1",
      "authors": "Yiming Zhou, Xuenjie Xie, Panfeng Li, Albrecht Kunz, Ahmad Osman et al.",
      "institution": "",
      "abstract": "Segment Anything Models (SAM) achieve impressive universal segmentation performance but require massive datasets (e.g., 11M images) and rely solely on RGB inputs. Recent efficient variants reduce computation but still depend on large-scale training. We propose a lightweight RGB-D fusion framework that augments EfficientViT-SAM with monocular depth priors. Depth maps are generated with a pretrained estimator and fused mid-level with RGB features through a dedicated depth encoder. Trained on only 11.2k samples (less than 0.1\\% of SA-1B), our method achieves higher accuracy than EfficientViT-SAM, showing that depth cues provide strong geometric priors for segmentation.",
      "source": "arXiv",
      "pubDateISO": "2026-02-12",
      "tags": [
        "cs.CV"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.11802v1",
      "title": "TopoFair: Linking Topological Bias to Fairness in Link Prediction Benchmarks",
      "link": "http://arxiv.org/abs/2602.11802v1",
      "pdf_link": "https://arxiv.org/pdf/2602.11802v1",
      "authors": "Lilian Marey, Mathilde Perez, Tiphaine Viard, Charlotte Laclau",
      "institution": "",
      "abstract": "Graph link prediction (LP) plays a critical role in socially impactful applications, such as job recommendation and friendship formation. Ensuring fairness in this task is thus essential. While many fairness-aware methods manipulate graph structures to mitigate prediction disparities, the topological biases inherent to social graph structures remain poorly understood and are often reduced to homophily alone. This undermines the generalization potential of fairness interventions and limits their applicability across diverse network topologies. In this work, we propose a novel benchmarking framework for fair LP, centered on the structural biases of the underlying graphs. We begin by reviewing and formalizing a broad taxonomy of topological bias measures relevant to fairness in graphs. In parallel, we introduce a flexible graph generation method that simultaneously ensures fidelity to real-world graph patterns and enables controlled variation across a wide spectrum of structural biases. We apply this framework to evaluate both classical and fairness-aware LP models across multiple use cases. Our results provide a fine-grained empirical analysis of the interactions between predictive fairness and structural biases. This new perspective reveals the sensitivity of fairness interventions to beyond-homophily biases and underscores the need for structurally grounded fairness evaluations in graph learning.",
      "source": "arXiv",
      "pubDateISO": "2026-02-12",
      "tags": [
        "cs.LG"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.11801v1",
      "title": "SpaTeoGL: Spatiotemporal Graph Learning for Interpretable Seizure Onset Zone Analysis from Intracranial EEG",
      "link": "http://arxiv.org/abs/2602.11801v1",
      "pdf_link": "https://arxiv.org/pdf/2602.11801v1",
      "authors": "Elham Rostami, Aref Einizade, Taous-Meriem Laleg-Kirati",
      "institution": "",
      "abstract": "Accurate localization of the seizure onset zone (SOZ) from intracranial EEG (iEEG) is essential for epilepsy surgery but is challenged by complex spatiotemporal seizure dynamics. We propose SpaTeoGL, a spatiotemporal graph learning framework for interpretable seizure network analysis. SpaTeoGL jointly learns window-level spatial graphs capturing interactions among iEEG electrodes and a temporal graph linking time windows based on similarity of their spatial structure. The method is formulated within a smooth graph signal processing framework and solved via an alternating block coordinate descent algorithm with convergence guarantees. Experiments on a multicenter iEEG dataset with successful surgical outcomes show that SpaTeoGL is competitive with a baseline based on horizontal visibility graphs and logistic regression, while improving non-SOZ identification and providing interpretable insights into seizure onset and propagation dynamics.",
      "source": "arXiv",
      "pubDateISO": "2026-02-12",
      "tags": [
        "cs.LG"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.11800v1",
      "title": "Temporal Difference Learning with Constrained Initial Representations",
      "link": "http://arxiv.org/abs/2602.11800v1",
      "pdf_link": "https://arxiv.org/pdf/2602.11800v1",
      "authors": "Jiafei Lyu, Jingwen Yang, Zhongjian Qiao, Runze Liu, Zeyuan Liu et al.",
      "institution": "",
      "abstract": "Recently, there have been numerous attempts to enhance the sample efficiency of off-policy reinforcement learning (RL) agents when interacting with the environment, including architecture improvements and new algorithms. Despite these advances, they overlook the potential of directly constraining the initial representations of the input data, which can intuitively alleviate the distribution shift issue and stabilize training. In this paper, we introduce the Tanh function into the initial layer to fulfill such a constraint. We theoretically unpack the convergence property of the temporal difference learning with the Tanh function under linear function approximation. Motivated by theoretical insights, we present our Constrained Initial Representations framework, tagged CIR, which is made up of three components: (i) the Tanh activation along with normalization methods to stabilize representations; (ii) the skip connection module to provide a linear pathway from the shallow layer to the deep layer; (iii) the convex Q-learning that allows a more flexible value estimate and mitigates potential conservatism. Empirical results show that CIR exhibits strong performance on numerous continuous control tasks, even being competitive or surpassing existing strong baseline methods.",
      "source": "arXiv",
      "pubDateISO": "2026-02-12",
      "tags": [
        "cs.LG"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.11799v1",
      "title": "Hi-SAM: A Hierarchical Structure-Aware Multi-modal Framework for Large-Scale Recommendation",
      "link": "http://arxiv.org/abs/2602.11799v1",
      "pdf_link": "https://arxiv.org/pdf/2602.11799v1",
      "authors": "Pingjun Pan, Tingting Zhou, Peiyao Lu, Tingting Fei, Hongxiang Chen et al.",
      "institution": "",
      "abstract": "Multi-modal recommendation has gained traction as items possess rich attributes like text and images. Semantic ID-based approaches effectively discretize this information into compact tokens. However, two challenges persist: (1) Suboptimal Tokenization: existing methods (e.g., RQ-VAE) lack disentanglement between shared cross-modal semantics and modality-specific details, causing redundancy or collapse; (2) Architecture-Data Mismatch: vanilla Transformers treat semantic IDs as flat streams, ignoring the hierarchy of user interactions, items, and tokens. Expanding items into multiple tokens amplifies length and noise, biasing attention toward local details over holistic semantics. We propose Hi-SAM, a Hierarchical Structure-Aware Multi-modal framework with two designs: (1) Disentangled Semantic Tokenizer (DST): unifies modalities via geometry-aware alignment and quantizes them via a coarse-to-fine strategy. Shared codebooks distill consensus while modality-specific ones recover nuances from residuals, enforced by mutual information minimization; (2) Hierarchical Memory-Anchor Transformer (HMAT): splits positional encoding into inter- and intra-item subspaces via Hierarchical RoPE to restore hierarchy. It inserts Anchor Tokens to condense items into compact memory, retaining details for the current item while accessing history only through compressed summaries. Experiments on real-world datasets show consistent improvements over SOTA baselines, especially in cold-start scenarios. Deployed on a large-scale social platform serving millions of users, Hi-SAM achieved a 6.55% gain in the core online metric.",
      "source": "arXiv",
      "pubDateISO": "2026-02-12",
      "tags": [
        "cs.AI"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.11795v1",
      "title": "A Subword Embedding Approach for Variation Detection in Luxembourgish User Comments",
      "link": "http://arxiv.org/abs/2602.11795v1",
      "pdf_link": "https://arxiv.org/pdf/2602.11795v1",
      "authors": "Anne-Marie Lutgen, Alistair Plum, Christoph Purschke",
      "institution": "",
      "abstract": "This paper presents an embedding-based approach to detecting variation without relying on prior normalisation or predefined variant lists. The method trains subword embeddings on raw text and groups related forms through combined cosine and n-gram similarity. This allows spelling and morphological diversity to be examined and analysed as linguistic structure rather than treated as noise. Using a large corpus of Luxembourgish user comments, the approach uncovers extensive lexical and orthographic variation that aligns with patterns described in dialectal and sociolinguistic research. The induced families capture systematic correspondences and highlight areas of regional and stylistic differentiation. The procedure does not strictly require manual annotation, but does produce transparent clusters that support both quantitative and qualitative analysis. The results demonstrate that distributional modelling can reveal meaningful patterns of variation even in ''noisy'' or low-resource settings, offering a reproducible methodological framework for studying language variety in multilingual and small-language contexts.",
      "source": "arXiv",
      "pubDateISO": "2026-02-12",
      "tags": [
        "cs.CL"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.11794v1",
      "title": "Latent-Variable Learning of SPDEs via Wiener Chaos",
      "link": "http://arxiv.org/abs/2602.11794v1",
      "pdf_link": "https://arxiv.org/pdf/2602.11794v1",
      "authors": "Sebastian Zeng, Andreas Petersson, Wolfgang Bock",
      "institution": "",
      "abstract": "We study the problem of learning the law of linear stochastic partial differential equations (SPDEs) with additive Gaussian forcing from spatiotemporal observations. Most existing deep learning approaches either assume access to the driving noise or initial condition, or rely on deterministic surrogate models that fail to capture intrinsic stochasticity. We propose a structured latent-variable formulation that requires only observations of solution realizations and learns the underlying randomly forced dynamics. Our approach combines a spectral Galerkin projection with a truncated Wiener chaos expansion, yielding a principled separation between deterministic evolution and stochastic forcing. This reduces the infinite-dimensional SPDE to a finite system of parametrized ordinary differential equations governing latent temporal dynamics. The latent dynamics and stochastic forcing are jointly inferred through variational learning, allowing recovery of stochastic structure without explicit observation or simulation of noise during training. Empirical evaluation on synthetic data demonstrates state-of-the-art performance under comparable modeling assumptions across bounded and unbounded one-dimensional spatial domains.",
      "source": "arXiv",
      "pubDateISO": "2026-02-12",
      "tags": [
        "cs.LG"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.11793v1",
      "title": "More Haste, Less Speed: Weaker Single-Layer Watermark Improves Distortion-Free Watermark Ensembles",
      "link": "http://arxiv.org/abs/2602.11793v1",
      "pdf_link": "https://arxiv.org/pdf/2602.11793v1",
      "authors": "Ruibo Chen, Yihan Wu, Xuehao Cui, Jingqi Zhang, Heng Huang",
      "institution": "",
      "abstract": "Watermarking has emerged as a crucial technique for detecting and attributing content generated by large language models. While recent advancements have utilized watermark ensembles to enhance robustness, prevailing methods typically prioritize maximizing the strength of the watermark at every individual layer. In this work, we identify a critical limitation in this \"stronger-is-better\" approach: strong watermarks significantly reduce the entropy of the token distribution, which paradoxically weakens the effectiveness of watermarking in subsequent layers. We theoretically and empirically show that detectability is bounded by entropy and that watermark ensembles induce a monotonic decrease in both entropy and the expected green-list ratio across layers. To address this inherent trade-off, we propose a general framework that utilizes weaker single-layer watermarks to preserve the entropy required for effective multi-layer ensembling. Empirical evaluations demonstrate that this counter-intuitive strategy mitigates signal decay and consistently outperforms strong baselines in both detectability and robustness.",
      "source": "arXiv",
      "pubDateISO": "2026-02-12",
      "tags": [
        "cs.CR",
        "cs.CL"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.11790v1",
      "title": "Beyond End-to-End Video Models: An LLM-Based Multi-Agent System for Educational Video Generation",
      "link": "http://arxiv.org/abs/2602.11790v1",
      "pdf_link": "https://arxiv.org/pdf/2602.11790v1",
      "authors": "Lingyong Yan, Jiulong Wu, Dong Xie, Weixian Shi, Deguo Xia et al.",
      "institution": "",
      "abstract": "Although recent end-to-end video generation models demonstrate impressive performance in visually oriented content creation, they remain limited in scenarios that require strict logical rigor and precise knowledge representation, such as instructional and educational media. To address this problem, we propose LAVES, a hierarchical LLM-based multi-agent system for generating high-quality instructional videos from educational problems. The LAVES formulates educational video generation as a multi-objective task that simultaneously demands correct step-by-step reasoning, pedagogically coherent narration, semantically faithful visual demonstrations, and precise audio--visual alignment. To address the limitations of prior approaches--including low procedural fidelity, high production cost, and limited controllability--LAVES decomposes the generation workflow into specialized agents coordinated by a central Orchestrating Agent with explicit quality gates and iterative critique mechanisms. Specifically, the Orchestrating Agent supervises a Solution Agent for rigorous problem solving, an Illustration Agent that produces executable visualization codes, and a Narration Agent for learner-oriented instructional scripts. In addition, all outputs from the working agents are subject to semantic critique, rule-based constraints, and tool-based compilation checks. Rather than directly synthesizing pixels, the system constructs a structured executable video script that is deterministically compiled into synchronized visuals and narration using template-driven assembly rules, enabling fully automated end-to-end production without manual editing. In large-scale deployments, LAVES achieves a throughput exceeding one million videos per day, delivering over a 95% reduction in cost compared to current industry-standard approaches while maintaining a high acceptance rate.",
      "source": "arXiv",
      "pubDateISO": "2026-02-12",
      "tags": [
        "cs.AI",
        "cs.CL"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.11789v1",
      "title": "Decentralized Non-convex Stochastic Optimization with Heterogeneous Variance",
      "link": "http://arxiv.org/abs/2602.11789v1",
      "pdf_link": "https://arxiv.org/pdf/2602.11789v1",
      "authors": "Hongxu Chen, Ke Wei, Luo Luo",
      "institution": "",
      "abstract": "Decentralized optimization is critical for solving large-scale machine learning problems over distributed networks, where multiple nodes collaborate through local communication. In practice, the variances of stochastic gradient estimators often differ across nodes, yet their impact on algorithm design and complexity remains unclear. To address this issue, we propose D-NSS, a decentralized algorithm with node-specific sampling, and establish its sample complexity depending on the arithmetic mean of local standard deviations, achieving tighter bounds than existing methods that rely on the worst-case or quadratic mean. We further derive a matching sample complexity lower bound under heterogeneous variance, thereby proving the optimality of this dependence. Moreover, we extend the framework with a variance reduction technique and develop D-NSS-VR, which under the mean-squared smoothness assumption attains an improved sample complexity bound while preserving the arithmetic-mean dependence. Finally, numerical experiments validate the theoretical results and demonstrate the effectiveness of the proposed algorithms.",
      "source": "arXiv",
      "pubDateISO": "2026-02-12",
      "tags": [
        "cs.LG"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.11786v1",
      "title": "Evaluating LLM Safety Under Repeated Inference via Accelerated Prompt Stress Testing",
      "link": "http://arxiv.org/abs/2602.11786v1",
      "pdf_link": "https://arxiv.org/pdf/2602.11786v1",
      "authors": "Keita Broadwater",
      "institution": "",
      "abstract": "Traditional benchmarks for large language models (LLMs) primarily assess safety risk through breadth-oriented evaluation across diverse tasks. However, real-world deployment exposes a different class of risk: operational failures arising from repeated inference on identical or near-identical prompts rather than broad task generalization. In high-stakes settings, response consistency and safety under sustained use are critical. We introduce Accelerated Prompt Stress Testing (APST), a depth-oriented evaluation framework inspired by reliability engineering. APST repeatedly samples identical prompts under controlled operational conditions (e.g., decoding temperature) to surface latent failure modes including hallucinations, refusal inconsistency, and unsafe completions. Rather than treating failures as isolated events, APST models them as stochastic outcomes of independent inference events. We formalize safety failures using Bernoulli and binomial models to estimate per-inference failure probabilities, enabling quantitative comparison of reliability across models and decoding configurations. Applying APST to multiple instruction-tuned LLMs evaluated on AIR-BENCH-derived safety prompts, we find that models with similar benchmark-aligned scores can exhibit substantially different empirical failure rates under repeated sampling, particularly as temperature increases. These results demonstrate that shallow, single-sample evaluation can obscure meaningful reliability differences under sustained use. APST complements existing benchmarks by providing a practical framework for evaluating LLM safety and reliability under repeated inference, bridging benchmark alignment and deployment-oriented risk assessment.",
      "source": "arXiv",
      "pubDateISO": "2026-02-12",
      "tags": [
        "cs.LG",
        "cs.AI"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.11785v1",
      "title": "Safe Fairness Guarantees Without Demographics in Classification: Spectral Uncertainty Set Perspective",
      "link": "http://arxiv.org/abs/2602.11785v1",
      "pdf_link": "https://arxiv.org/pdf/2602.11785v1",
      "authors": "Ainhize Barrainkua, Santiago Mazuelas, Novi Quadrianto, Jose A. Lozano",
      "institution": "",
      "abstract": "As automated classification systems become increasingly prevalent, concerns have emerged over their potential to reinforce and amplify existing societal biases. In the light of this issue, many methods have been proposed to enhance the fairness guarantees of classifiers. Most of the existing interventions assume access to group information for all instances, a requirement rarely met in practice. Fairness without access to demographic information has often been approached through robust optimization techniques,which target worst-case outcomes over a set of plausible distributions known as the uncertainty set. However, their effectiveness is strongly influenced by the chosen uncertainty set. In fact, existing approaches often overemphasize outliers or overly pessimistic scenarios, compromising both overall performance and fairness. To overcome these limitations, we introduce SPECTRE, a minimax-fair method that adjusts the spectrum of a simple Fourier feature mapping and constrains the extent to which the worst-case distribution can deviate from the empirical distribution. We perform extensive experiments on the American Community Survey datasets involving 20 states. The safeness of SPECTRE comes as it provides the highest average values on fairness guarantees together with the smallest interquartile range in comparison to state-of-the-art approaches, even compared to those with access to demographic group information. In addition, we provide a theoretical analysis that derives computable bounds on the worst-case error for both individual groups and the overall population, as well as characterizes the worst-case distributions responsible for these extremal performances",
      "source": "arXiv",
      "pubDateISO": "2026-02-12",
      "tags": [
        "cs.LG",
        "cs.AI"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.11782v1",
      "title": "FlowMind: Execute-Summarize for Structured Workflow Generation from LLM Reasoning",
      "link": "http://arxiv.org/abs/2602.11782v1",
      "pdf_link": "https://arxiv.org/pdf/2602.11782v1",
      "authors": "Yihao Liu, Ziyun Zhang, Zile He, Huaqian Cai",
      "institution": "",
      "abstract": "LLMs can solve complex tasks through reasoning and tool use, but accurately translating these solutions into structured workflows remains challenging. We model workflows as sequences of tool use and reformulate the problem as designing a mechanism that can both solve tasks and reliably construct workflows. Prior approaches that build workflows during execution often suffer from inaccuracies due to interference between the two processes. We propose an Execute-Summarize(ES) framework that decouples task execution from workflow construction: the model first completes the task using available tools, then independently reconstructs a structured workflow from execution traces. This separation improves workflow accuracy and robustness. We introduce FlowBench and show through extensive experiments that our approach outperforms existing methods, providing a reliable paradigm for grounding free-form LLM reasoning into structured workflows.",
      "source": "arXiv",
      "pubDateISO": "2026-02-12",
      "tags": [
        "cs.AI",
        "cs.SE"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.11780v1",
      "title": "RELATE: A Reinforcement Learning-Enhanced LLM Framework for Advertising Text Generation",
      "link": "http://arxiv.org/abs/2602.11780v1",
      "pdf_link": "https://arxiv.org/pdf/2602.11780v1",
      "authors": "Jinfang Wang, Jiajie Liu, Jianwei Wu, Ziqin Luo, Zhen Chen et al.",
      "institution": "",
      "abstract": "In online advertising, advertising text plays a critical role in attracting user engagement and driving advertiser value. Existing industrial systems typically follow a two-stage paradigm, where candidate texts are first generated and subsequently aligned with online performance metrics such as click-through rate(CTR). This separation often leads to misaligned optimization objectives and low funnel efficiency, limiting global optimality.\n  To address these limitations, we propose RELATE, a reinforcement learning-based end-to-end framework that unifies generation and objective alignment within a single model. Instead of decoupling text generation from downstream metric alignment, RELATE integrates performance and compliance objectives directly into the generation process via policy learning. To better capture ultimate advertiser value beyond click-level signals, We incorporate conversion-oriented metrics into the objective and jointly model them with compliance constraints as multi-dimensional rewards, enabling the model to generate high-quality ad texts that improve conversion performance under policy constraints.\n  Extensive experiments on large-scale industrial datasets demonstrate that RELATE consistently outperforms baselines. Furthermore, online deployment on a production advertising platform yields statistically significant improvements in click-through conversion rate(CTCVR) under strict policy constraints, validating the robustness and real-world effectiveness of the proposed framework.",
      "source": "arXiv",
      "pubDateISO": "2026-02-12",
      "tags": [
        "cs.AI"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    },
    {
      "id": "2602.11779v1",
      "title": "Temperature as a Meta-Policy: Adaptive Temperature in LLM Reinforcement Learning",
      "link": "http://arxiv.org/abs/2602.11779v1",
      "pdf_link": "https://arxiv.org/pdf/2602.11779v1",
      "authors": "Haoran Dang, Cuiling Lan, Hai Wan, Xibin Zhao, Yan Lu",
      "institution": "",
      "abstract": "Temperature is a crucial hyperparameter in large language models (LLMs), controlling the trade-off between exploration and exploitation during text generation. High temperatures encourage diverse but noisy outputs, while low temperatures produce focused outputs but may cause premature convergence. Yet static or heuristic temperature schedules fail to adapt to the dynamic demands of reinforcement learning (RL) throughout training, often limiting policy improvement. We propose Temperature Adaptive Meta Policy Optimization (TAMPO), a new framework that recasts temperature control as a learnable meta-policy. TAMPO operates through a hierarchical two-loop process. In the inner loop, the LLM policy is updated (e.g., using GRPO) with trajectories sampled at the temperature selected by the meta-policy. In the outer loop, meta-policy updates the distribution over candidate temperatures by rewarding those that maximize the likelihood of high-advantage trajectories. This trajectory-guided, reward-driven mechanism enables online adaptation without additional rollouts, directly aligning exploration with policy improvement. On five mathematical reasoning benchmarks, TAMPO outperforms baselines using fixed or heuristic temperatures, establishing temperature as an effective learnable meta-policy for adaptive exploration in LLM reinforcement learning. Accepted at ICLR 2026.",
      "source": "arXiv",
      "pubDateISO": "2026-02-12",
      "tags": [
        "cs.LG"
      ],
      "topics": [],
      "score": 4,
      "score_reason": "",
      "citations": 0,
      "upvotes": 0,
      "github_url": "",
      "github_stars": 0,
      "key_contribution": "",
      "why_it_matters": "",
      "limitations": ""
    }
  ]
}